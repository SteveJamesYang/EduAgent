严贝贝民编

# 数据结构

# (C语言版)

清华大学计算机系列教材

# 数据结构（C语言版）

严蔚敏 吴伟民 编著

# 内容简介

《数据结构》(C语言版)是为“数据结构”课程编写的教材，也可作为学习数据结构及其算法的C程序设计的参考教材。

本书的前半部分从抽象数据类型的角度讨论各种基本类型的数据结构及其应用；后半部分主要讨论查找和排序的各种实现方法及其综合分析比较。全书采用类C语言作为数据结构和算法的描述语言。

本书概念表述严谨，逻辑推理严密，语言精炼，用词达意，并有配套出版的《数据结构题集》（C语言版），既便于教学，又便于自学。

本书配套光盘中含有可在 DOS 环境下运行的以类 C 语言描述的“数据结构算法动态模拟辅助教学软件”，以及在 Windows 环境下运行的以类 PASCAL 或类 C 两种语言描述的“数据结构算法动态模拟辅助教学软件”。

本书可作为计算机类专业或信息类相关专业的本科或专科教材，也可供从事计算机工程与应用工作的科技工作者参考。

本书封面贴有清华大学出版社防伪标签，无标签者不得销售。

版权所有，侵权必究。侵权举报电话：010-62782989 13701121933

# 图书在版编目（CIP）数据

数据结构：C语言版/严蔚敏，吴伟民编著．一北京：清华大学出版社，2007

（清华大学计算机系列教材）

ISBN 978-7-302-14751-0

I．数…Ⅱ.  $①$  严…  $②$  吴…Ⅲ.  $①$  数据结构一高等学校一教材  $②$  C语言一程序设计一高等学校一教材 IV.TP311.12.TP312

中国版本图书馆CIP数据核字（2007）第024916号

责任编辑：范素珍

责任印制：王秀菊

出版发行：清华大学出版社 地址：北京清华大学学研大厦A座

http://www.tup.com.cn 邮编：100084

杜总机：010-62770175 邮购：010-62786544

投稿与读者服务：010-62776969，c-service@tup.tsinghua.edu.cn

质量反馈：010-62772015，zhiliang@tup.tsinghua.edu.cn

印刷者：北京密云胶印厂

装订者：北京市密云县京文制本装订厂

经销：全国新华书店

开 本：  $185\times 260$  印张：21.75 字数：493千字

附光盘1张

印次：2011年5月第34次印刷

印数：598001～668000

定价：30.00元

# 前言

“数据结构”是计算机程序设计的重要理论技术基础，它不仅是计算机学科的核心课程，而且已成为其他理工专业的热门选修课。本书是为“数据结构”课程编写的教材，其内容选取符合教学大纲要求，并兼顾学科的广度和深度，适用面广。

本书的第1章综述数据、数据结构和抽象数据类型等基本概念；第2章至第7章从抽象数据类型的角度，分别讨论线性表、栈、队列、串、数组、广义表、树和二叉树以及图等基本类型的数据结构及其应用；第8章综合介绍操作系统和编译程序中涉及的动态存储管理的基本技术；第9章至第11章讨论查找和排序，除了介绍各种实现方法之外，并着重从时间上进行定性或定量的分析和比较；第12章介绍常用的文件结构。用过《数据结构》（第二版）的读者容易看出，本书内容和章节编排与1992年4月出版的《数据结构》（第二版）基本一致，但在本书中更突出了抽象数据类型的概念。对每一种数据结构，都分别给出相应的抽象数据类型规范说明和实现方法。

全书中采用类C语言作为数据结构和算法的描述语言，在对数据的存储结构和算法进行描述时，尽量考虑C语言的特色，如利用数组的动态分配实现顺序存储结构等。虽然C语言不是抽象数据类型的理想描述工具，但鉴于目前和近一两年内，“面向对象程序设计”并非数据结构的先修课程，故本书未直接采用类和对象等设施，而是从C语言中精选了一个核心子集，并增添  $\mathbf{C} + +$  语言的引用调用参数传递方式等，构成了一个类C描述语言。它使本书对各种抽象数据类型的定义和实现简明清晰，既不拘泥于C语言的细节，又容易转换成能上机执行的C或  $\mathbf{C} + +$  程序。

从课程性质上讲，“数据结构”是一门专业技术基础课。它的教学要求是：学会分析研究计算机加工的数据结构的特性，以便为应用涉及的数据选择适当的逻辑结构、存储结构及其相应的算法，并初步掌握算法的时间分析和空间分析的技术。另一方面，本课程的学习过程也是复杂程序设计的训练过程，要求学生编写的程序结构清楚和正确易读，符合软件工程的规范。如果说高级语言程序设计课程对学生进行了结构化程序设计（程序抽象）的初步训练的话，那么数据结构课程就要培养他们的数据抽象能力。本书将用规范的数学语言描述数据结构的定义，以突出其数学特性，同时，通过若干数据结构应用实例，引导学生学习数据类型的使用，为今后学习面向对象的程序设计作一些

铺垫。

本书可作为计算机类专业的本科或专科教材，也可以作为信息类相关专业的选修教材，讲授学时可为50至80。教师可根据学时、专业和学生的实际情况，选讲或不讲目录页中带\*\*的章节，甚至删去第5、8、11和12章。本书文字通俗，简明易懂，便于自学，也可供从事计算机应用等工作的科技人员参考。只需掌握程序设计基本技术便可学习本书。若具有离散数学和概率论的知识，则对书中某些内容更易理解。如果将本书《数据结构》(C语言版)和《数据结构》(第二版)作为关于数据结构及其算法的C和Pascal程序设计的对照教材，则有助于快速且深刻地掌握这两种语言。

与本书配套的还有《数据结构题集》(C语言版), 由清华大学出版社出版。书中提供配套的习题和实习题, 并可作为学习指导手册。

严蔚敏 清华大学计算机科学与技术系吴伟民 广东工业大学计算机学院

# 目录

# 第1章 绪论

1.1 什么是数据结构  
1.2 基本概念和术语 4  
1.3 抽象数据类型的表示与实现 9  
1.4 算法和算法分析 13

1.4.1 算法 13  
1.4.2 算法设计的要求 13  
1.4.3 算法效率的度量 14  
1.4.4 算法的存储空间需求 17

# 第2章 线性表 18

2.1 线性表的类型定义 18  
2.2 线性表的顺序表示和实现 21  
2.3 线性表的链式表示和实现 27

2.3.1 线性链表 27  
2.3.2 循环链表 35  
2.3.3 双向链表 35

2.4 一元多项式的表示及相加 … 39

# 第3章 栈和队列 44

3.1 栈

3.1.1 抽象数据类型栈的定义 44  
3.1.2 栈的表示和实现 45

3.2 栈的应用举例 48

3.2.1 数制转换 48  
3.2.2 括号匹配的检验 49  
3.2.3 行编辑程序 49  
3.2.4 迷宫求解 50  
3.2.5 表达式求值 52

\*3.3 栈与递归的实现 54  
3.4 队列· 58

3.4.1 抽象数据类型队列的定义 58  
3.4.2 链队列——队列的链式表示和实现 60  
3.4.3 循环队列——队列的顺序表示和实现 63

$\star \star 3.5$  离散事件模拟 65

# 第4章 串

4.1 串类型的定义· 70  
4.2 串的表示和实现… 72

4.2.1 定长顺序存储表示 73  
4.2.2 堆分配存储表示 75  
4.2.3 串的块链存储表示 78

# \*\*4.3 串的模式匹配算法 79

4.3.1 求子串位置的定位函数Index(S,T，pos) 79  
4.3.2 模式匹配的一种改进算法 80

# 4.4 串操作应用举例· 84

4.4.1 文本编辑 84  
\*4.4.2 建立词索引表 86

# 第5章 数组和广义表 90

5.1 数组的定义 90  
5.2 数组的顺序表示和实现 91  
5.3 矩阵的压缩存储 95

5.3.1 特殊矩阵 95  
5.3.2 稀疏矩阵 96

5.4 广义表的定义 106  
5.5 广义表的存储结构 109

$^{**}5.6$ $m$  元多项式的表示 110  
\*5.7 广义表的递归算法 112

5.7.1 求广义表的深度 113  
5.7.2 复制广义表 115  
5.7.3 建立广义表的存储结构 115

# 第6章 树和二叉树 118

6.1 树的定义和基本术语 118  
6.2 二叉树 121

6.2.1 二叉树的定义 … 121  
6.2.2 二叉树的性质 … 123  
6.2.3 二叉树的存储结构 … 126

6.3 遍历二叉树和线索二叉树 128

6.3.1 遍历二叉树 128  
6.3.2 线索二叉树· 132

6.4 树和森林 135

6.4.1 树的存储结构 135  
6.4.2 森林与二叉树的转换 137  
6.4.3 树和森林的遍历 … 138

\*6.5 树与等价问题 139  
6.6赫夫曼树及其应用 144

6.6.1 最优二叉树(赫夫曼树) … 144  
6.6.2赫夫曼编码 146

\*\*6.7 回溯法与树的遍历 149  
\*6.8 树的计数 152

# 第7章 图· 156

7.1 图的定义和术语 156  
7.2 图的存储结构 160

7.2.1 数组表示法 … 161  
7.2.2 邻接表 … 163  
7.2.3 十字链表 164  
7.2.4 邻接多重表 … 166

7.3 图的遍历 167

7.3.1 深度优先搜索 … 167  
7.3.2 广度优先搜索 … 169

7.4 图的连通性问题 179

7.4.1 无向图的连通分量和生成树 ………………………………………… 170  
7.4.2 有向图的强连通分量 … 172  
7.4.3 最小生成树 … 173  
7.4.4 关节点和重连通分量 … 176

7.5 有向无环图及其应用 … 179

7.5.1 拓扑排序 … 180  
7.5.2 关键路径 183

7.6 最短路径 186

7.6.1 从某个源点到其余各顶点的最短路径 … 187  
7.6.2 每一对顶点之间的最短路径 … 190

# 第8章 动态存储管理 193

8.1 概述 193  
8.2 可利用空间表及分配方法 195

8.3 边界标识法 198

8.3.1 可利用空间表的结构 … 198  
8.3.2 分配算法 … 199  
8.3.3 回收算法 201

8.4 伙伴系统 203

8.4.1 可利用空间表的结构 … 203  
8.4.2 分配算法 204  
8.4.3 回收算法 205

\*\*8.5 无用单元收集 206  
\*\*8.6 存储紧缩 212

# 第9章 查找 214

# 9.1 静态查找表 216

9.1.1 顺序表的查找 … 216  
9.1.2 有序表的查找… 218

\*9.1.3 静态树表的查找 222  
9.1.4 索引顺序表的查找 225

# 9.2 动态查找表 226

9.2.1 二叉排序树和平衡二叉树 … 227  
9.2.2 B_树和  $\mathbf{B}^{+}$  树 238

\*9.2.3 键树· 247

# 9.3 哈希表 251

9.3.1 什么是哈希表… 251  
9.3.2 哈希函数的构造方法 253  
9.3.3 处理冲突的方法 … 256  
9.3.4 哈希表的查找及其分析 259

# 第10章 内部排序 263

10.1 概述 263  
10.2 插入排序 265

10.2.1 直接插入排序 … 265  
10.2.2 其他插入排序 266  
10.2.3 希尔排序 271

10.3 快速排序 272  
10.4 选择排序 … 277

10.4.1 简单选择排序 277  
10.4.2 树形选择排序 278  
10.4.3 堆排序 279

10.5 归并排序 283  
10.6 基数排序 284

10.6.1 多关键字的排序 284  
10.6.2 链式基数排序 286

10.7 各种内部排序方法的比较讨论 … 288

# 第11章 外部排序 293

11.1 外存信息的存取 … 293  
11.2 外部排序的方法 … 295

11.3 多路平衡归并的实现 … 297  
11.4 置换-选择排序 299

VI

\*\*11.5 最佳归并树 304

第12章 文件 306

12.1 有关文件的基本概念 … 306  
12.2 顺序文件· 308  
12.3 索引文件 311  
12.4 ISAM文件和VSAM文件 313

12.4.1 ISAM文件 313  
12.4.2 VSAM文件 316

12.5 直接存取文件(散列文件) 317  
12.6 多关键字文件 319

12.6.1 多重表文件 319  
12.6.2 倒排文件 319

附录A 名词索引 322  
附录B 函数索引 329

参考书目 334

![](images/d9e9e5086e75bada458c56300f1ea83409f62b377378c4e3ea771bca1c1d951a.jpg)

# 第1章绪论

自1946年第一台计算机问世以来，计算机产业的飞速发展已远远超出人们对它的预料，在某些生产线上，甚至几秒钟就能生产出一台微型计算机，产量猛增，价格低廉，这就使得它的应用范围迅速扩展。如今，计算机已深入到人类社会的各个领域。计算机的应用已不再局限于科学计算，而更多地用于控制、管理及数据处理等非数值计算的处理工作。与此相应，计算机加工处理的对象由纯粹的数值发展到字符、表格和图像等各种具有一定结构的数据，这就给程序设计带来一些新的问题。为了编写出一个“好”的程序，必须分析待处理的对象的特性以及各处理对象之间存在的关系。这就是“数据结构”这门学科形成和发展的背景。

# 1.1 什么是数据结构

一般来说，用计算机解决一个具体问题时，大致需要经过下列几个步骤：首先要从具体问题抽象出一个适当的数学模型，然后设计一个解此数学模型的算法，最后编出程序，进行测试、调整直至得到最终解答。寻求数学模型的实质是分析问题，从中提取操作的对象，并找出这些操作对象之间含有的关系，然后用数学的语言加以描述。例如，求解梁架结构中应力的数学模型为线性方程组；预报人口增长情况的数学模型为微分方程。然而，更多的非数值计算问题无法用数学方程加以描述。下面请看3个例子。

例1-1 图书馆的书目检索系统自动化问题。当你想借阅一本参考书但不知道书库中是否有的时候；或者，当你想找某一方面的参考书而不知图书馆内有哪些这方面的书时，你都需要到图书馆去查阅图书目录卡片。在图书馆内有各种名目的卡片：有按书名编排的，有按作者编排的，还有按分类编排的，等等。若利用计算机实现自动检索，则计算机处理的对象便是这些目录卡片上的书目信息。列在一张卡片上的一本书的书目信息可由登录号、书名、作者名、分类号、出版单位和出版时间等若干项组成，每一本书都有惟一的一个登录号，但不同的书目之间可能有相同的书名，或者有相同的作者名，或者有相同的分类号。由此，在书目自动检索系统中可以建立一张按登录号顺序排列的书目文件和3张分别按书名、作者名和分类号顺序排列的索引表，如图1.1所示。由这4张表构成的文件便是书目自动检索的数学模型，计算机的主要操作便是按照某个特定要求（如给定书名）对书目文件进行查询。诸如此类的还有查号系统自动化、仓库账目管理等。在这类文档管理的数学模型中，计算机处理的对象之间通常存在着的是一种最简单的线性关系，这类数学模型可称为线性的数据结构。

例1-2 计算机和人对弈问题。计算机之所以能和人对弈是因为有人将对弈的策略事先已存入计算机。由于对弈的过程是在一定规则下随机进行的，所以，为使计算机能灵活对弈就必须对对弈过程中所有可能发生的情况以及相应的对策都考虑周全，并且，一个

<table><tr><td>001</td><td>高等数学</td><td>樊映川</td><td>S01</td><td>...</td></tr><tr><td>002</td><td>理论力学</td><td>罗远祥</td><td>L01</td><td>...</td></tr><tr><td>003</td><td>高等数学</td><td>华罗庚</td><td>S01</td><td>...</td></tr><tr><td>004</td><td>线性代数</td><td>栾汝书</td><td>S02</td><td>...</td></tr><tr><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td></tr></table>

<table><tr><td>高等数学</td><td>001,003,…</td></tr><tr><td>理论力学</td><td>002,…</td></tr><tr><td>线性代数</td><td>004,…</td></tr><tr><td>:</td><td></td></tr></table>

<table><tr><td>樊映川</td><td>001,···</td></tr><tr><td>华罗庚</td><td>003,···</td></tr><tr><td>栾汝书</td><td>004,···</td></tr><tr><td>:</td><td></td></tr></table>

<table><tr><td>L</td><td>002,···</td></tr><tr><td>S</td><td>001,003,···</td></tr><tr><td>:</td><td></td></tr></table>

“好”的棋手在对弈时不仅要看棋盘当时的状态，还应能预测棋局发展的趋势，甚至最后结局。因此，在对弈问题中，计算机操作的对象是对弈过程中可能出现的棋盘状态——称为格局。例如图1.2(a)所示为井字棋①的一个格局，而格局之间的关系是由比赛规则决定的。通常，这个关系不是线性的，因为从一个棋盘格局可以派生出几个格局，例如从图1.2(a)所示的格局可以派生出5个格局，如图1.2(b)所示，而从每一个新的格局又可派生出4个可能出现的格局。因此，若将从对弈开始到结束的过程中所有可能出现的格局都画在一张图上，则可得到一棵倒长的“树”。“树根”是对弈开始之前的棋盘格局，而所有的“叶子”就是可能出现的结局，对弈的过程就是从树根沿树权到某个叶子的过程。“树”可以是某些非数值计算问题的数学模型，它也是一种数据结构。

图1.1 图书目录文件示例  
图1.2 井字棋对弈“树”  
![](images/ab57ecedb1564f0b11f5e04600571a7241836b18db321d3045d17b9cd282ec63.jpg)  
（a）棋盘格局示例；（b）对弈树的局部。

例1-3 多叉路口交通灯的管理问题。通常，在十字交叉路口只需设红、绿两色的交通灯便可保持正常的交通秩序，而在多叉路口需设几种颜色的交通灯才能既使车辆相互之间不碰撞，又能达到车辆的最大流通。假设有一个如图1.3(a)所示的五叉路口，其中C和E为单行道。在路口有13条可行的通路，其中有的可以同时通行，如  $\mathrm{A}\rightarrow \mathrm{B}$  和  $\mathrm{E}\rightarrow \mathrm{C}$

而有的不能同时通行, 如  $\mathrm{E} \rightarrow \mathrm{B}$  和  $\mathrm{A} \rightarrow \mathrm{D}$  。那么, 在路口应如何设置交通灯进行车辆的管理呢?

(a)  
![](images/0ef4052c9717cb15a03d0ddbd0814703cbc7361b4b414cb6a81ac4bcc3d90dcb.jpg)  
(a) 五叉路口；(b) 表示通路的图

![](images/e47605cca814aca53c988aedbf2a48105f6e0a9887febb347c55948d3d97c4e2.jpg)  
(b)  
图1.3 五叉路口交通管理示意图

通常，这类交通、道路问题的数学模型是一种称为“图”的数据结构。例如在此例的问题中，可以图中一个顶点表示一条通路，而通路之间互相矛盾的关系以两个顶点之间的连线表示。如在图1.3(b)中，每个圆圈表示图1.3(a)所示五叉路口上的一条通路，两个圆圈之间的连线表示这两个圆圈表示的两条通路不能同时通行。设置交通灯的问题等价为对图的顶点的染色问题，要求对图上的每个顶点染一种颜色，并且要求有线相连的两个顶点不能具有相同颜色，而总的颜色种类应尽可能地少。图1.3(b)所示为一种染色结果，圆圈中的数字表示交通灯的不同颜色，例如3号色灯亮时只有  $\mathrm{D} \rightarrow \mathrm{A}$  和  $\mathrm{D} \rightarrow \mathrm{B}$  两条路可通行。

综上3个例子可见，描述这类非数值计算问题的数学模型不再是数学方程，而是诸如表、树和图之类的数据结构。因此，简单说来，数据结构是一门研究非数值计算的程序设计问题中计算机的操作对象以及它们之间的关系和操作等的学科。

“数据结构”作为一门独立的课程在国外是从1968年才开始设立的。在这之前，它的某些内容曾在其他课程，如表处理语言中有所阐述。1968年在美国一些大学的计算机系的教学计划中，虽然把“数据结构”规定为一门课程，但对课程的范围仍没有作明确规定。当时，数据结构几乎和图论，特别是和表、树的理论为同义语。随后，数据结构这个概念被扩充到包括网络、集合代数论、格、关系等方面，从而变成了现在称之为《离散结构》的内容。然而，由于数据必须在计算机中进行处理，因此，不仅考虑数据本身的数学性质，而且还必须考虑数据的存储结构，这就进一步扩大了数据结构的内容。近年来，随着数据库系统的不断发展，在“数据结构”课程中又增加了文件管理(特别是大型文件的组织等)的内容。

1968年美国唐·欧·克努特教授开创了“数据结构”的最初体系，他所著的《计算机程序设计技巧》第一卷《基本算法》是第一本较系统地阐述数据的逻辑结构和存储结构及其操作的著作。从20世纪60年代末到70年代初，出现了大型程序，软件也相对独立，结构程序设计成为程序设计方法学的主要内容，人们就越来越重视“数据结构”，认为程序设

计的实质是对确定的问题选择一种好的结构，加上设计一种好的算法。从20世纪70年代中期到80年代初，各种版本的数据结构著作就相继出现。

目前在我国，“数据结构”也已经不仅仅是计算机专业的教学计划中的核心课程之一，而且是其他非计算机专业的主要选修课程之一。

“数据结构”在计算机科学中是一门综合性的专业基础课。“数据结构”的研究不仅涉及到计算机硬件(特别是编码理论、存储装置和存取方法等)的研究范围，而且和计算机软件的研究有着更密切的关系，无论是编译程序还是操作系统，都涉及到数据元素在存储器中的分配问题。在研究信息检索时也必须考虑如何组织数据，以便查找和存取数据元素更为方便。因此，可以认为“数据结构”是介于数学、计算机硬件和计算机软件三者之间的一门核心课程(如图1.4所示)。在计算机科学中，“数据结构”不仅是一般程序设计(特别是非数值计算的程序设计)的基础，而且是设计和实

![](images/3e86447565313a8dc6c331a9b6e31aba12874db290d3e1c4bc48600e8d115005.jpg)  
图1.4 “数据结构”所处的地位

现编译程序、操作系统、数据库系统及其他系统程序和大型应用程序的重要基础。

值得注意的是，“数据结构”的发展并未终结，一方面，面向各专门领域中特殊问题的数据结构得到研究和发展，如多维图形数据结构等；另一方面，从抽象数据类型的观点来讨论数据结构，已成为一种新的趋势，越来越被人们所重视。

# 1.2 基本概念和术语

在本节中，我们将对一些概念和术语赋以确定的含义，以便与读者取得“共同的语言”。这些概念和术语将在以后的章节中多次出现。

数据(data)是对客观事物的符号表示，在计算机科学中是指所有能输入到计算机中并被计算机程序处理的符号的总称。它是计算机程序加工的“原料”。例如，一个利用数值分析方法解代数方程的程序，其处理对象是整数和实数；一个编译程序或文字处理程序的处理对象是字符串。因此，对计算机科学而言，数据的含义极为广泛，如图像、声音等都可以通过编码而归之于数据的范畴。

数据元素(data element)是数据的基本单位，在计算机程序中通常作为一个整体进行考虑和处理。例如，例1-2中的“树”中的一个棋盘格局，例1-3中的“图”中的一个圆圈都被称为一个数据元素。有时，一个数据元素可由若干个数据项(data item)组成，例如，例1-1中一本书的书目信息为一个数据元素，而书目信息中的每一项(如书名、作者名等)为一个数据项。数据项是数据的不可分割的最小单位。

数据对象(data object)是性质相同的数据元素的集合，是数据的一个子集。例如，整数数据对象是集合  $N = \{0, \pm 1, \pm 2, \dots\}$ ，字母字符数据对象是集合  $C = \{A'$

$$
^ {\prime} B ^ {\prime}, \dots , ^ {\prime} Z ^ {\prime} \}.
$$

数据结构(data structure)是相互之间存在一种或多种特定关系的数据元素的集合。

这是本书对数据结构的一种简单解释①。从1.1节中3个例子可以看到，在任何问题中，数据元素都不是孤立存在的，而是在它们之间存在着某种关系，这种数据元素相互之间的关系称为结构（structure）。根据数据元素之间关系的不同特性，通常有下列4类基本结构：（1）集合结构中的数据元素之间除了“同属于一个集合”的关系外，别无其他关系②；（2）线性结构结构中的数据元素之间存在一个对一个的关系；（3）树形结构结构中的数据元素之间存在一个对多个的关系；（4）图状结构或网状结构结构中的数据元素之间存在多个对多个的关系。图1.5为上述4类基本结构的关系图。由于“集合”是数据元素之间关系极为松散的一种结构，因此也可用其他结构来表示它。

![](images/f0cb8d3046a887a76d2036ecea546d8f216cf323a32070cbb15c6b581e593edd.jpg)  
线性 0-0-0-0-0

![](images/068f06ecf408ba0b2200a2df694c0d0f6c2f564a3ae4cd7f5867be1d02924b3b.jpg)

![](images/1c0f084b532fa0a3a4be904f6696bcea152032a907b5d41652b7f53c85c534af.jpg)  
图1.5 4类基本结构关系图

数据结构的形式定义为：数据结构是一个二元组

$$
\text {D a t a} = (D, S) \tag {1-1}
$$

其中：  $D$  是数据元素的有限集，  $S$  是  $D$  上关系的有限集。下面举两个简单例子说明之。

例1-4 在计算机科学中，复数可取如下定义：复数是一种数据结构

$$
\operatorname {C o m p l e x} = (C, R) \tag {1-2}
$$

其中：  $C$  是含两个实数的集合  $\{c1,c2\} ;R = \{P\}$  ，而  $P$  是定义在集合  $C$  上的一种关系 $\{\langle c1,c2\rangle \}$  ，其中有序偶  $\langle c1,c2\rangle$  表示  $c1$  是复数的实部，  $c2$  是复数的虚部。

例1-5 假设我们需要编制一个事务管理的程序，管理学校科学研究课题小组的各项事务，则首先要为程序的操作对象——课题小组设计一个数据结构。假设每个小组由1位教师、 $1\sim 3$  名研究生及  $1\sim 6$  名本科生组成，小组成员之间的关系是：教师指导研究生，而由每位研究生指导一至两名本科生。则可以如下定义数据结构：

$$
\operatorname {G r o u p} = (P, R) \tag {1-3}
$$

其中：  $P = \{T,G_1,\dots ,G_n,S_{11}\dots S_{nm}3,1\leqslant n\leqslant 3,1\leqslant m\leqslant 2\}$

$$
R = \left\{R _ {1}, R _ {2} \right\}
$$

$$
R _ {1} = \{\langle T, G _ {i} \rangle | 1 \leqslant i \leqslant n, 1 \leqslant n \leqslant 3 \}
$$

$$
R _ {2} = \{\langle G _ {i}, S _ {i j} \rangle | 1 \leqslant i \leqslant n, 1 \leqslant j \leqslant m, 1 \leqslant n \leqslant 3, 1 \leqslant m \leqslant 2 \}
$$

上述数据结构的定义仅是对操作对象的一种数学描述，换句话说，是从操作对象抽象出来的数学模型。结构定义中的“关系”描述的是数据元素之间的逻辑关系，因此又称为

数据的逻辑结构。然而，讨论数据结构的目的是为了在计算机中实现对它的操作，因此还需研究如何在计算机中表示它。

数据结构在计算机中的表示(又称映像)称为数据的物理结构, 又称存储结构。它包括数据元素的表示和关系的表示。在计算机中表示信息的最小单位是二进制数的一位, 叫做位(bit)。在计算机中, 我们可以用一个由若干位组合起来形成的一个位串表示一个数据元素(如用一个字长的位串表示一个整数, 用8位二进制数表示一个字符等), 通常称这个位串为元素① element或结点(node)。当数据元素由若干数据项组成时, 位串中对应于各个数据项的子位串称为数据域(data field)。因此, 元素或结点可看成是数据元素在计算机中的映像。

数据元素之间的关系在计算机中有两种不同的表示方法：顺序映像和非顺序映像，并由此得到两种不同的存储结构：顺序存储结构和链式存储结构。顺序映像的特点是借助元素在存储器中的相对位置来表示数据元素之间的逻辑关系。例如，假设用两个字长的位串表示一个实数，则可以用地址相邻的4个字长的位串表示一个复数，如图1.6(a)为表示复数  $z1 = 3.0 - 2.3\mathrm{i}$  和  $z2 = -0.7 + 4.8\mathrm{i}$  的顺序存储结构；非顺序映像的特点是借助指示元素存储地址的指针(pointer)表示数据元素之间的逻辑关系，如图1.6(b)为表示复数  $z1$  的链式存储结构，其中实部和虚部之间的关系用值为“0415”的指针来表示（0415是虚部的存储地址）②。数据的逻辑结构和物理结构是密切相关的两个方面，以后读者会看到，任何一个算法的设计取决于选定的数据(逻辑)结构，而算法的实现依赖于采用的存储结构。

(a)  
![](images/1cb8e23cf49d0dade82fb559c9b7189cce1e7c300050097c047dc6b2956b14da.jpg)  
(a) 顺序存储结构；(b) 链式存储结构

![](images/872661cef85652e8a0e03088b22bac91061faf6965d44abd52b4aeb6c157e79d.jpg)  
(b)  
图1.6 复数存储结构示意图

如何描述存储结构呢。虽然存储结构涉及数据元素及其关系在存储器中的物理位置，但由于本书是在高级程序语言的层次上讨论数据结构的操作，因此不能如上那样直接以内存地址来描述存储结构，但我们可以借用高级程序语言中提供的“数据类型”来描述

它, 例如可以用所有高级程序语言中都有的“一维数组”类型来描述顺序存储结构, 以 C 语言提供的“指针”来描述链式存储结构。假如我们把 C 语言看成是一个执行 C 指令和 C 数据类型的虚拟处理器, 那么本书中讨论的存储结构是数据结构在 C 虚拟处理器中的表示, 不妨称它为虚拟存储结构。

数据类型(data type)是和数据结构密切相关的一个概念，它最早出现在高级程序语言中，用以刻画(程序)操作对象的特性。在用高级程序语言编写的程序中，每个变量、常量或表达式都有一个它所属的确定的数据类型。类型明显或隐含地规定了在程序执行期间变量或表达式所有可能取值的范围，以及在这些值上允许进行的操作。因此数据类型是一个值的集合和定义在这个值集上的一组操作的总称。例如，C语言中的整型变量，其值集为某个区间上的整数（区间大小依赖于不同的机器），定义在其上的操作为加、减、乘、除和取模等算术运算。

按“值”的不同特性，高级程序语言中的数据类型可分为两类：一类是非结构的原子类型。原子类型的值是不可分解的，例如C语言中的基本类型（整型、实型、字符型和枚举类型）、指针类型和空类型。另一类是结构类型。结构类型的值是由若干成分按某种结构组成的，因此是可以分解的，并且它的成分可以是非结构的，也可以是结构的。例如数组的值由若干分量组成，每个分量可以是整数，也可以是数组等。在某种意义上，数据结构可以看成是“一组具有相同结构的值”，则结构类型可以看成由一种数据结构和定义在其上的一组操作组成。

实际上，在计算机中，数据类型的概念并非局限于高级语言中，每个处理器①（包括计算机硬件系统、操作系统、高级语言、数据库等）都提供了一组原子类型或结构类型。例如，一个计算机硬件系统通常含有“位”、“字节”、“字”等原子类型，它们的操作通过计算机设计的一套指令系统直接由电路系统完成，而高级程序语言提供的数据类型，其操作需通过编译器或解释器转化成低层，即汇编语言或机器语言的数据类型来实现。引入“数据类型”的目的，从硬件的角度看，是作为解释计算机内存中信息含义的一种手段，而对使用数据类型的用户来说，实现了信息的隐蔽，即将一切用户不必了解的细节都封装在类型中。例如，用户在使用“整数”类型时，既不需要了解“整数”在计算机内部是如何表示的，也不需要知道其操作是如何实现的。如“两整数求和”，程序设计者注重的仅仅是其“数学上求和”的抽象特性，而不是其硬件的“位”操作如何进行。

抽象数据类型(Abstract Data Type,简称ADT)是指一个数学模型以及定义在该模型上的一组操作。抽象数据类型的定义仅取决于它的一组逻辑特性，而与其在计算机内部如何表示和实现无关，即不论其内部结构如何变化，只要它的数学特性不变，都不影响其外部的使用。

抽象数据类型和数据类型实质上是一个概念。例如，各个计算机都拥有的“整数”类型是一个抽象数据类型，尽管它们在不同处理器上实现的方法可以不同，但由于其定义的数学特性相同，在用户看来都是相同的。因此，“抽象”的意义在于数据类型的数学抽象特性。

另一方面，抽象数据类型的范畴更广，它不再局限于前述各处理器中已定义并实现的数据类型（也可称这类数据类型为固有数据类型），还包括用户在设计软件系统时自己定义的数据类型。为了提高软件的复用率，在近代程序设计方法学中指出，一个软件系统的框架应建立在数据之上，而不是建立在操作之上（后者是传统的软件设计方法所为）。即在构成软件系统的每个相对独立的模块上，定义一组数据和施于这些数据上的一组操作，并在模块内部给出这些数据的表示及其操作的细节，而在模块外部使用的只是抽象的数据和抽象的操作。显然，所定义的数据类型的抽象层次越高，含有该抽象数据类型的软件模块的复用程度也就越高。

一个含抽象数据类型的软件模块通常应包含定义、表示和实现3个部分。

如前所述，抽象数据类型的定义由一个值域和定义在该值域上的一组操作组成。若按其值的不同特性，可细分为下列3种类型：

原子类型(atomic data type)属原子类型的变量的值是不可分解的。这类抽象数据类型较少，因为一般情况下，已有的固有数据类型足以满足需求。但有时也有必要定义新的原子数据类型，例如数位为100的整数。

固定聚合类型(fixed-aggregate data type)属该类型的变量，其值由确定数目的成分按某种结构组成。例如，复数是由两个实数依确定的次序关系构成。

可变聚合类型(variable-aggregate data type)和固定聚合类型相比较，构成可变聚合类型“值”的成分的数目不确定。例如，可定义一个“有序整数序列”的抽象数据类型，其中序列的长度是可变的。

显然，后两种类型可统称为结构类型。

和数据结构的形式定义相对应，抽象数据类型可用以下三元组表示

$$
(D, S, P) \tag {1-4}
$$

其中， $D$  是数据对象， $S$  是  $D$  上的关系集， $P$  是对  $D$  的基本操作集。本书采用以下格式定义抽象数据类型：

ADT抽象数据类型名{

数据对象：（数据对象的定义）

数据关系：（数据关系的定义）

基本操作：〈基本操作的定义〉

ADT抽象数据类型名

其中，数据对象和数据关系的定义用伪码描述，基本操作的定义格式为

基本操作名（参数表）

初始条件：〈初始条件描述〉

操作结果：（操作结果描述）

基本操作有两种参数：赋值参数只为操作提供输入值；引用参数以 & 打头，除可提供输入值外，还将返回操作结果。“初始条件”描述了操作执行之前数据结构和参数应满足的条件，若不满足，则操作失败，并返回相应出错信息。“操作结果”说明了操作正常完成之后，数据结构的变化状况和应返回的结果。若初始条件为空，则省略之。

# 例1-6 抽象数据类型三元组的定义：

```txt
ADT Triplet{数据对象：  $\mathbf{D} = \{\mathbf{e1},\mathbf{e2},\mathbf{e3}\mid \mathbf{e1},\mathbf{e2},\mathbf{e3}\in \mathbf{ElemSet}$  （定义了关系运算的某个集合）}  
数据关系：  $\mathrm{Rl} = \{\langle e1,e2\rangle , <   e2,e3\rangle \}$    
基本操作：InitTriplet(  $\& \mathrm{T},\mathrm{v1},\mathrm{v2},\mathrm{v3})$  操作结果：构造了三元组T，元素e1,e2和e3分别被赋以参数v1,v2和v3的值。DestroyTriplet（&T）操作结果：三元组T被销毁。Get(T,i,&e）初始条件：三元组T已存在，  $1\leqslant i\leqslant 3$  。操作结果：用e返回T的第i元的值。Put(  $\& \mathrm{T},\mathrm{i},\mathrm{e})$  初始条件：三元组T已存在，  $1\leqslant i\leqslant 3$  。操作结果：改变T的第i元的值为e。IsAscending(T）初始条件：三元组T已存在。操作结果：如果T的3个元素按升序排列，则返回1，否则返回0。IsDescending(T）初始条件：三元组T已存在。操作结果：如果T的3个元素按降序排列，则返回1，否则返回0。Max(T,&e）初始条件：三元组T已存在。操作结果：用e返回T的3个元素中的最大值。Min(T,&e）初始条件：三元组T已存在。操作结果：用e返回T的3个元素中的最小值。}ADT Triplet
```

多形数据类型(polymorphic data type)是指其值的成分不确定的数据类型。例如, 例 1-6 中定义的抽象数据类型 Triplet, 其元素 e1、e2 和 e3 可以是整数或字符或字符串, 甚至更复杂地由多种成分构成 (只要能进行关系运算即可)。然而, 不论其元素具有何种特性, 元素之间的关系相同, 基本操作也相同。从抽象数据类型的角度看, 具有相同的数学抽象特性, 故称之为多形数据类型。显然, 需借助面向对象的程序设计语言如  $\mathrm{C}++$  等实现之。本书中讨论的各种数据类型大多是多形数据类型, 限于本书采用类 C 语言作为描述工具, 故只讨论含有确定成分的数据元素的情况。如例 1-6 中的 ElemSet 是某个确定的、将由用户自行定义的、含某个关系运算的数据对象。

# 1.3 抽象数据类型的表示与实现

抽象数据类型可通过固有数据类型来表示和实现，即利用处理器中已存在的数据类型来说明新的结构，用已经实现的操作来组合新的操作。由于本书在高级程序设计语言

的虚拟层次上讨论抽象数据类型的表示和实现，并且讨论的数据结构及其算法主要是面向读者，故采用介于伪码和C语言之间的类C语言作为描述工具，有时也用伪码描述一些只含抽象操作的抽象算法。这使得数据结构与算法的描述和讨论简明清晰，不拘泥于C语言的细节，又能容易转换成C或者  $\mathbf{C} + +$  程序。

本书采用的类C语言精选了C语言的一个核心子集，同时做了若干扩充修改，增强了语言的描述功能。以下对其作简要说明。

（1）预定义常量和类型：

//函数结果状态代码

```c
define TRUE 1  
#define FALSE 0  
#define OK 1  
#define ERROR 0  
#define INFEASIBLE -  
#define OVERFLOW -
```

```txt
// Status是函数的类型，其值是函数结果状态代码 typedef int Status;
```

(2) 数据结构的表示（存储结构）用类型定义 typedef) 描述。数据元素类型约定为 ElemType, 由用户在使用该数据类型时自行定义。

（3）基本操作的算法都用以下形式的函数描述：

函数类型 函数名（函数参数表）{

//算法说明

语句序列

\} // 函数名

除了函数的参数需要说明类型外, 算法中使用的辅助变量可以不作变量说明, 必要时对其作用给予注释。一般而言, a、b、c、d、e等用作数据元素名, i、j、k、l、m、n等用作整型变量名, p、q、r等用作指针变量名。当函数返回值为函数结果状态代码时, 函数定义为 Status 类型。为了便于算法描述, 除了值调用方式外, 增添了  $\mathbf{C}++$  语言的引用调用的参数传递方式。在形参表中, 以&打头的参数即为引用参数。

（4）赋值语句有

简单赋值 变量名  $=$  表达式；

串联赋值 变量名  $1=$  变量名  $2=\cdots=$  变量名  $\mathbf{k}=$  表达式；

成组赋值 (变量名  $1, \cdots$ , 变量名  $k$  ) = (表达式  $1, \cdots$ , 表达式  $k$ );

结构名 = 结构名;

结构名  $=$  （值1，…，值k）；

变量名[]  $=$  表达式；

变量名[起始下标..终止下标] = 变量名[起始下标..终止下标];

交换赋值 变量名  $\longleftrightarrow$  变量名；

条件赋值 变量名 = 条件表达式？表达式 T：表达式 F；

（5）选择语句有

条件语句1 if（表达式）语句；

条件语句2 if（表达式）语句；

```txt
else语句；  
开关语句1 switch（表达式）{case值1：语句序列1；break;…case值n：语句序列n；break;default：语句序列  $\mathrm{n + 1}$  ·  
}  
开关语句2 switch{case条件1：语句序列1；break;…case条件n：语句序列n；break;default：语句序列  $\mathrm{n + 1}$  ：  
}
```

(6) 循环语句有

```txt
for语句 for（赋初值表达式序列；条件；修改表达式序列）语句；  
while语句 while（条件）语句；  
do-while语句 do{语句序列；}while（条件）；
```

（7）结束语句有

```txt
函数结束语句 return表达式; return;   
case结束语句 break;   
异常结束语句 exit（异常代码）；
```

(8) 输入和输出语句有

```csv
输入语句 scanf([格式串],变量1，…，变量n);输出语句 printf([格式串],表达式1，…，表达式n)；
```

通常省略格式串。

(9）注释

单行注释 // 文字序列

（10）基本函数有

```txt
求最大值 max（表达式1，…，表达式n）  
求最小值 min（表达式1，…，表达式n）  
求绝对值 abs（表达式）  
求不足整数值 floor（表达式）  
求进位整数值 ceil（表达式）  
判定文件结束 eof（文件变量）或 eof  
判定行结束 eoln（文件变量）或 eoln
```

（11）逻辑运算约定

```txt
与运算&&：对于A&&B，当A的值为0时，不再对B求值。或运算||：对于A||B，当A的值为非0时，不再对B求值。
```

例1-7 抽象数据类型Triplet的表示和实现。

//- - - - - 采用动态分配的顺序存储结构 - - - - -

typedef ElemType *Triplet; // 由 InitTriplet 分配 3 个元素存储空间

// - - - - - 基本操作的函数原型说明 - - - - -

Status InitTriplet (Triplet &T, ElemType v1, ElemType v2, ElemType v3);

// 操作结果：构造了三元组 T，元素 e1, e2 和 e3 分别被赋以参数 v1, v2 和 v3 的值。

Status DestroyTriplet (Triplet &T);

// 操作结果：三元组T被销毁。

Status Get (Triplet T, int i, ElemType &e);

// 初始条件：三元组  $\mathbb{T}$  已存在，  $1\leqslant \mathrm{i}\leqslant 3$

// 操作结果：用 e 返回 T 的第 i 元的值。

Status Put (Triplet &T. int i, ElemType e);

// 初始条件：三元组  $\mathbf{T}$  已存在，  $1\leqslant i\leqslant 3$

// 操作结果：改变T的第i元的值为e。

Status IsAscending (Triplet T);

// 初始条件：三元组  $\mathbf{T}$  已存在。

// 操作结果：如果T的3个元素按升序排列，则返回1，否则返回0。

Status IsDescending (Triplet T);

// 初始条件：三元组  $\mathbf{T}$  已存在。

// 操作结果：如果T的3个元素按降序排列，则返回1，否则返回0。

Status Max (Triplet T, ElemType &e);

// 初始条件：三元组  $\mathbf{T}$  已存在。

// 操作结果：用 e 返回 T 的 3 个元素中的最大值。

Status Min (Triplet T, ElemType &e);

// 初始条件：三元组  $\mathbf{T}$  已存在。

// 操作结果：用  $\mathbf{e}$  返回  $\mathbf{T}$  的3个元素中的最小值。

//- - - - - 基本操作的实现 - - - - -

Status InitTriplet (Triplet &T, ElemType v1, ElemType v2, ElemType v3) {

//构造三元组T，依次置T的3个元素的初值为v1,v2和v3。

T = (ElemType *) malloc(3 * sizeof(ElemType)); // 分配 3 个元素的存储空间

if（!T）exit(OVERFLOW); //分配存储空间失败

$\mathrm{T}[0] = \mathrm{v1};$ $\mathrm{T}[1] = \mathrm{v2};\quad \mathrm{T}[2] = \mathrm{v3};$

return OK;

// InitTriplet

Status DestroyTriplet (Triplet &T) {

//销毁三元组T。

free(T); T = NULL;

return OK;

```java
} // DestroyTriplet

Status Get (Triplet T, int i, ElemType &e) {

//  $1 \leqslant i \leqslant 3$  ，用  $\mathbf{e}$  返回  $\mathrm{T}$  的第  $\dot{\mathrm{i}}$  元的值。

if  $(i < 1\parallel i > 3)$  return ERROR;

$\mathbf{e} = \mathrm{T}[i - 1]$

return OK;

Get

Status Put (Triplet &T, int i, ElemType e) {

//  $1 \leqslant \mathrm{i} \leqslant 3$ , 置  $\mathrm{T}$  的第  $\mathrm{i}$  元的值为  $\mathbf{e}$ 。

if  $(i < 1\parallel i > 3)$  return ERROR;

$\mathbf{T}[i - 1] = \mathbf{e}$

return OK;

```c
} // Put  
Status IsAscending (Triplet T) {  
// 如果T的3个元素按升序排列，则返回1，否则返回0。  
return (T[0] <= T[1]) && (T[1] <= T[2]);  
} // IsAscending  
Status IsDescending (Triplet T) {  
// 如果T的3个元素按降序排列，则返回1，否则返回0。  
return (T[0] >= T[1]) && (T[1] >= T[2]);  
} // IsDescending  
Status Max (Triplet T, ElemType &e) {  
// 用e返回指向T的最大元素的值。  
e = (T[0] >= T[1]) ? ((T[0] >= T[2]) ? T[0] : T[2]) : ((T[1] >= T[2]) ? T[1] : T[2]);  
return OK;  
} // Max  
Status Min (Triplet T, ElemType &e) {  
// 用e返回指向T的最小元素的值。  
e = (T[0] <= T[1]) ? ((T[0] <= T[2]) ? T[0] : T[2]) : ((T[1] <= T[2]) ? T[1] : T[2]);  
return OK;  
} // Min
```

# 1.4 算法和算法分析

# 1.4.1 算法

算法(algorithm)是对特定问题求解步骤的一种描述，它是指令的有限序列，其中每一条指令表示一个或多个操作；此外，一个算法还具有下列5个重要特性：

（1）有穷性 一个算法必须总是(对任何合法的输入值)在执行有穷步之后结束，且每一步都可在有穷时间①内完成。  
（2）确定性 算法中每一条指令必须有确切的含义，读者理解时不会产生二义性。并且，在任何条件下，算法只有惟一的一条执行路径，即对于相同的输入只能得出相同的输出。  
（3）可行性 一个算法是能行的，即算法中描述的操作都是可以通过已经实现的基本运算执行有限次来实现的。  
（4）输入 一个算法有零个或多个的输入，这些输入取自于某个特定的对象的集合。  
(5) 输出 一个算法有一个或多个的输出, 这些输出是同输入有着某些特定关系的量。

# 1.4.2 算法设计的要求

通常设计一个“好”的算法应考虑达到以下目标。

（1）正确性②（correctness）算法应当满足具体问题的需求。通常一个大型问题的

需求，要以特定的规格说明方式给出，而一个实习问题或练习题，往往就不那么严格，目前多数是用自然语言描述需求，它至少应当包括对于输入、输出和加工处理等的明确的无歧义性的描述。设计或选择的算法应当能正确地反映这种需求；否则，算法的正确与否的衡量准则就不存在了。

“正确”一词的含义在通常的用法中有很大差别, 大体可分为以下 4 个层次: a. 程序不含语法错误; b. 程序对于几组输入数据能够得出满足规格说明要求的结果; c. 程序对于精心选择的典型、苛刻而带有刁难性的几组输入数据能够得出满足规格说明要求的结果; d. 程序对于一切合法的输入数据都能产生满足规格说明要求的结果。显然, 达到第 d 层意义下的正确是极为困难的, 所有不同输入数据的数量大得惊人, 逐一验证的方法是不现实的。对于大型软件需要进行专业测试, 而一般情况下, 通常以第 c 层意义的正确性作为衡量一个程序是否合格的标准。

（2）可读性(readability）算法主要是为了人的阅读与交流，其次才是机器执行。可读性好有助于人对算法的理解；晦涩难懂的程序易于隐藏较多错误，难以调试和修改。  
(3) 镇壮性 (robustness) 当输入数据非法时, 算法也能适当地做出反应或进行处理, 而不会产生莫明其妙的输出结果。例如, 一个求凸多边形面积的算法, 是采用求各三角形面积之和的策略来解决问题的。当输入的坐标集合表示的是一个凹多边形时, 不应继续计算, 而应报告输入出错。并且, 处理出错的方法应是返回一个表示错误或错误性质的值, 而不是打印错误信息或异常, 并中止程序的执行, 以便在更高的抽象层次上进行处理。  
（4）效率与低存储量需求 通俗地说，效率指的是算法执行的时间。对于同一个问题如果有多个算法可以解决，执行时间短的算法效率高。存储量需求指算法执行过程中所需要的最大存储空间。效率与低存储量需求这两者都与问题的规模有关。求100个人的平均分与求1000个人的平均分所花的执行时间或运行空间显然有一定的差别。

# 1.4.3 算法效率的度量

算法执行时间需通过依据该算法编制的程序在计算机上运行时所消耗的时间来度量。而度量一个程序的执行时间通常有两种方法。

（1）事后统计的方法因为很多计算机内部都有计时功能，有的甚至可精确到毫秒级，不同算法的程序可通过一组或若干组相同的统计数据以分辨优劣。但这种方法有两个缺陷：一是必须先运行依据算法编制的程序；二是所得时间的统计量依赖于计算机的硬件、软件等环境因素，有时容易掩盖算法本身的优劣。因此人们常常采用另一种事前分析估算的方法。  
（2）事前分析估算的方法 一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列因素：

① 依据的算法选用何种策略；  
$②$  问题的规模，例如求100以内还是1000以内的素数；  
③ 书写程序的语言，对于同一个算法，实现语言的级别越高，执行效率就越低；  
④ 编译程序所产生的机器代码的质量；

⑤ 机器执行指令的速度。

显然，同一个算法用不同的语言实现，或者用不同的编译程序进行编译，或者在不同的计算机上运行时，效率均不相同。这表明使用绝对的时间单位衡量算法的效率是不合适的。撇开这些与计算机硬件、软件有关的因素，可以认为一个特定算法“运行工作量”的大小，只依赖于问题的规模（通常用整数量  $n$  表示），或者说，它是问题规模的函数。

一个算法是由控制结构(顺序、分支和循环3种)和原操作(指固有数据类型的操作)构成的, 则算法时间取决于两者的综合效果。为了便于比较同一问题的不同算法, 通常的做法是, 从算法中选取一种对于所研究的问题(或算法类型)来说是基本操作的原操作, 以该基本操作重复执行的次数作为算法的时间量度。

例如，在如下所示的两个  $N \times N$  矩阵相乘的算法中，“乘法”运算是“矩阵相乘问题”的基本操作。整个算法的执行时间与该基本操作(乘法)重复执行的次数  $n^3$  成正比，记作  $T(n) = O(n^3)$  ①。

$$
\begin{array}{r l} \text {f o r (i = 1 ; i <   = n ; + + i)} \\ \text {f o r (j = 1 ; j <   = n ; + + j) \left\{ \begin{array}{l} c [ i ] [ j ] = 0; \\ f o r (k = 1 ; k <   = n ; + + k) \\ c [ i ] [ j ] + = a [ i ] [ k ] * b [ k ] [ j ]; \end{array} \right.} \\ \text {f o r (k = 1 ; k <   = n ; + + k)} \\ \text {f o r (j = 1 ; j <   = n ; + + j) \left\{ \begin{array}{l} c [ i ] [ j ] = 0; \\ f o r (k = 1 ; k <   = n ; + + k) \\ c [ i ] [ j ] + = a [ i ] [ k ] * b [ k ] [ j ]; \end{array} \right.}, \end{array}
$$

一般情况下，算法中基本操作重复执行的次数是问题规模  $n$  的某个函数  $f(n)$ ，算法的时间量度记作

$$
T (n) = O (f (n)) \tag {1-5}
$$

它表示随问题规模  $n$  的增大, 算法执行时间的增长率和  $f(n)$  的增长率相同, 称做算法的渐近时间复杂度 (asymptotic time complexity), 简称时间复杂度。

显然，被称做问题的基本操作的原操作应是其重复执行次数和算法的执行时间成正比的原操作，多数情况下它是最深层循环内的语句中的原操作，它的执行次数和包含它的语句的频度相同。语句的频度(frequency count)指的是该语句重复执行的次数，例如，在下列3个程序段中：

(a)  $\{++x;s = 0;\}$  
(b) for  $(\mathrm{i} = 1;\mathrm{i}\leqslant \mathrm{n}; + + \mathrm{i})\{\mathrm{++x;s + = x;}\}$  
(c) for  $(j = 1; j <= n; ++j)$

$$
f o r (k = 1; k \leqslant n; + + k) \{+ + x; s + = x; \}
$$

含基本操作“ $x$  增  $1$ ”的语句的频度分别为  $1, n$  和  $n^2$ , 则这 3 个程序段的时间复杂度分别为  $O(1), O(n)$  和  $O(n^2)$ , 分别称为常量阶、线性阶和平方阶。算法还可能呈现的时间复杂度有对数阶  $O(\log n)$ 、指数阶  $O(2^n)$  等。不同数量级时间复杂度的性状如图 1.7 所示。从图中可见, 我们应该尽可能选用多项式阶  $O(n^k)$  的算法, 而不希望用指数阶的算法。

一般情况下，对一个问题(或一类算法)只需选择一种基本操作来讨论算法的时间复

![](images/347f684912dd55d666489d7ebf5674ab89f0f4b4af10850219a1c738fe2d9153.jpg)  
图1.7 常见函数的增长率

杂度即可, 有时也需要同时考虑几种基本操作, 甚至可以对不同的操作赋予不同权值, 以反映执行不同操作所需的相对时间, 这种做法便于综合比较解决同一问题的两种完全不同的算法。

由于算法的时间复杂度考虑的只是对于问题规模  $n$  的增长率, 则在难以精确计算基本操作执行次数(或语句频度)的情况下, 只需求出它关于  $n$  的增长率或阶即可。例如, 在下列程序段中:

$$
\begin{array}{l} \text {f o r} (i = 2; i <   = n; + + i) \\ f o r (j = 2; j <   = i - 1; + + j) \{+ + x; a [ i ] [ j ] = x; \} \\ \end{array}
$$

语句  $++\mathbf{x}$  的执行次数关于  $n$  的增长率为  $n^2$ ，它是语句频度表达式  $(n - 1)(n - 2) / 2$  中增长最快的项。

有的情况下，算法中基本操作重复执行的次数还随问题的输入数据集不同而不同。例如在下列起泡排序的算法中：

```c
void bubble_sort(int a[], int n) {
    // 将a中整数序列重新排列成自小至大有序的整数序列。
    for (i = n-1, change = TRUE; i >= 1 && change; --i) {
        change = FALSE;
        for (j = 0; j <= i; ++j)
            if (a[j] > a[j+1]) {a[j]←→a[j+1]; change = TRUE;} }
    } // bubble_sort
```

“交换序列中相邻两个整数”为基本操作。当a中初始序列为自小至大有序，基本操作的执行次数为0；当初始序列为自大至小有序时，基本操作的执行次数为  $n(n - 1) / 2$  。对这类算法的分析，一种解决的办法是计算它的平均值，即考虑它对所有可能的输入数据集的期望值，此时相应的时间复杂度为算法的平均时间复杂度。如假设a中初始输入数据可能出现  $n!$  种的排列情况的概率相等，则起泡排序的平均时间复杂度  $T_{\mathrm{org}}(n) = O(n^2)$ ，然而，在很多情况下，各种输入数据集出现的概率难以确定，算法的平均时间复杂度也就难以确定。因此，另一种更可行也更常用的办法是讨论算法在最坏情况下的时间复杂度，即分析最坏情况以估算算法执行时间的一个上界。例如，上述起泡排序的最坏情况为a中

初始序列为自大至小有序, 则起泡排序算法在最坏情况下的时间复杂度为  $T(n) = O(n^{2})$  。在本书以后各章中讨论的时间复杂度, 除特别指明外, 均指最坏情况下的时间复杂度。

实践中我们可以把事前估算和事后统计两种办法结合起来使用。以两个矩阵相乘为例，若上机运行两个  $10 \times 10$  的矩阵相乘，执行时间为  $12\mathrm{ms}$ ，则由算法的时间复杂度  $T(n) = O(n^{3})$  可估算两个  $31 \times 31$  的矩阵相乘所需时间大致为  $(31 / 10)^{3} \cdot 12\mathrm{ms} \approx 358\mathrm{ms}$ 。

# 1.4.4 算法的存储空间需求

类似于算法的时间复杂度，本书中以空间复杂度(space complexity)作为算法所需存储空间的量度，记作

$$
S (n) = O (f (n)) \tag {1-6}
$$

其中  $n$  为问题的规模(或大小)。一个上机执行的程序除了需要存储空间来寄存本身所用指令、常数、变量和输入数据外，也需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本身，和算法无关，则只需要分析除输入和程序之外的额外空间，否则应同时考虑输入本身所需空间（和输入数据的表示形式有关）。若额外空间相对于输入数据量来说是常数，则称此算法为原地工作，第10章讨论的有些排序算法就属于这类。又如果所占空间量依赖于特定的输入，则除特别指明外，均按最坏情况来分析。

# 第2章线性表

从第2章至第4章将讨论线性结构。线性结构的特点是：在数据元素的非空有限集中，(1)存在惟一的一个被称做“第一个”的数据元素；(2)存在惟一的一个被称做“最后一个”的数据元素；(3)除第一个之外，集合中的每个数据元素均只有一个前驱；(4)除最后一个之外，集合中每个数据元素均只有一个后继。

# 2.1 线性表的类型定义

线性表(linear_list)是最常用且最简单的一种数据结构。简言之，一个线性表是  $n$  个数据元素的有限序列。至于每个数据元素的具体含义，在不同的情况下各不相同，它可以是一个数或一个符号，也可以是一页书，甚至其他更复杂的信息。例如，26个英文字母的字母表：

$$
(A, B, C, \dots , Z)
$$

是一个线性表, 表中的数据元素是单个字母字符。又如, 某校从 1978 年到 1983 年各种型号的计算机拥有量的变化情况, 可以用线性表的形式给出:

$$
(6, 1 7, 2 8, 5 0, 9 2, 1 8 8)
$$

表中的数据元素是整数。

在稍复杂的线性表中，一个数据元素可以由若干个数据项(item)组成。在这种情况下，常把数据元素称为记录(record)，含有大量记录的线性表又称文件(file)。

例如，一个学校的学生健康情况登记表如图2.1所示，表中每个学生的情况为一个记录，它由姓名、学号、性别、年龄、班级和健康状况等6个数据项组成。

![](images/e5ce2fe066a7ab846a15db30288378d446b6ac4d43c2b5505c931793c341bcb6.jpg)  
图2.1 学生健康情况登记表

综合上述3个例子可见，线性表中的数据元素可以是各种各样的，但同一线性表中的元素必定具有相同特性，即属同一数据对象，相邻数据元素之间存在着序偶关系。若将线性表记为

$$
(a _ {1}, \dots , a _ {i - 1}, a _ {i}, a _ {i + 1}, \dots , a _ {n}) \tag {2-1}
$$

则表中  $a_{i-1}$  领先于  $a_i, a_i$  领先于  $a_{i+1}$ , 称  $a_{i-1}$  是  $a_i$  的直接前驱元素,  $a_{i+1}$  是  $a_i$  的直接后继元素。当  $i=1,2,\cdots,n-1$  时,  $a_i$  有且仅有一个直接后继, 当  $i=2,3,\cdots,n$  时,  $a_i$  有且仅有一个直接前驱。

线性表中元素的个数  $n(n\geqslant 0)$  定义为线性表的长度，  $n = 0$  时称为空表。在非空表中的每个数据元素都有一个确定的位置，如  $a_1$  是第一个数据元素，  $a_{n}$  是最后一个数据元素，  $a_{i}$  是第  $_i$  个数据元素，称  $\pmb{i}$  为数据元素  $a_{i}$  在线性表中的位序。

线性表是一个相当灵活的数据结构，它的长度可根据需要增长或缩短，即对线性表的数据元素不仅可以进行访问，还可进行插入和删除等。

抽象数据类型线性表的定义如下：

ADT List{  
```txt
数据对象：D={aiai∈ElemSet，i=1,2，…，n，n≥0}
```

基本操作：  
```txt
数据关系：  $\mathbb{R}1 = \{\langle a_{i - 1},a_i\rangle |a_{i - 1},a_i\in D,i = 2,\dots ,n\}$
```

```autoit
InitList(&L)
```

操作结果：构造一个空的线性表L。

```txt
DestroyList(&L)
```

初始条件：线性表  $\mathsf{L}$  已存在。

操作结果：销毁线性表L。

```txt
ClearList(&L)
```

初始条件：线性表  $\mathbf{L}$  已存在。

操作结果：将L重置为空表。

```txt
ListEmpty(L)
```

初始条件：线性表  $\mathbf{L}$  已存在。

操作结果：若L为空表，则返回TRUE，否则返回FALSE。

```txt
ListLength(L)
```

初始条件：线性表  $\mathbf{L}$  已存在。

操作结果：返回L中数据元素个数。

```csv
GetElem(L,i,&e)
```

初始条件：线性表L已存在，  $1\leqslant i\leqslant \mathrm{ListLength(L)}$

操作结果：用  $\mathbf{e}$  返回L中第i个数据元素的值。

```txt
LocateElem(L,e, compare())
```

初始条件：线性表L已存在，compare()是数据元素判定函数。

操作结果：返回L中第1个与e满足关系compare()的数据元素的位序。若这样的数据元素不存在，则返回值为0。

```csv
PriorElem(L,cur_e,&pre_e)
```

初始条件：线性表  $\mathbb{L}$  已存在。

操作结果：若cur_e是L的数据元素，且不是第一个，则用pre_e返回它的前驱，否则操作失败，pre_e无定义。

```txt
NextElem(L,cur_e,&next_e)
```

初始条件：线性表  $\mathbb{L}$  已存在。

操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后继，否则操作失败，next_e无定义。

```txt
ListInsert( &L, i, e)
```

初始条件：线性表L已存在，  $1\leqslant i\leqslant \mathrm{ListLength(L)} + 1$

操作结果：在L中第i个位置之前插入新的数据元素e，L的长度加1。

```javascript
ListDelete(&L, i, &e)
```

初始条件：线性表L已存在且非空，  $1\leqslant i\leqslant \mathrm{ListLength}(\mathbf{L})$

操作结果：删除L的第i个数据元素，并用e返回其值，L的长度减1。

ListTraverse(L, visit())

初始条件：线性表  $\mathbf{L}$  已存在。

操作结果：依次对  $\mathbf{L}$  的每个数据元素调用函数visit()。一旦visit()失败，则操作失败。\}ADTList

对上述定义的抽象数据类型线性表, 还可进行一些更复杂的操作, 例如, 将两个或两个以上的线性表合并成一个线性表; 把一个线性表拆开成两个或两个以上的线性表; 重新复制一个线性表等。

例2-1 假设利用两个线性表  $LA$  和  $LB$  分别表示两个集合  $A$  和  $B$  （即线性表中的数据元素即为集合中的成员），现要求一个新的集合  $A = A \cup B$  。这就要求对线性表作如下操作：扩大线性表  $LA$  ，将存在于线性表  $LB$  中而不存在于线性表  $LA$  中的数据元素插入到线性表  $LA$  中去。只要从线性表  $LB$  中依次取得每个数据元素，并依值在线性表  $LA$  中进行查访，若不存在，则插入之。上述操作过程可用下列算法描述之。

```javascript
voidunion(List&La，ListLb){ //将所有在线性表Lb中但不在La中的数据元素插入到La中 La_len  $\equiv$  ListLength(La);Lb_len  $\equiv$  ListLength(Lb)；//求线性表的长度 for（i=1;  $\mathrm{i} <   =$  Lb_len;  $\mathrm{i + + }$  ）{ GetElem(Lb,i,e); //取Lb中第i个数据元素赋给e if(!LocateElem(La,e,equal))ListInsert(La，  $+ +$  La_len①，e); //La中不存在和e相同的数据元素，则插入之 }//union
```

# 算法 2.1

例2-2 已知线性表  $LA$  和  $LB$  中的数据元素按值非递减有序排列，现要求将  $LA$  和  $LB$  归并为一个新的线性表  $LC$  ，且  $LC$  中的数据元素仍按值非递减有序排列。例如，设

$$
\begin{array}{l} L A = (3, 5, 8, 1 1) \\ L B = (2, 6, 8, 9, 1 1, 1 5, 2 0) \\ \end{array}
$$

则

$$
L C = (2, 3, 5, 6, 8, 8, 9, 1 1, 1 1, 1 5, 2 0)
$$

从上述问题要求可知,  $LC$  中的数据元素或是  $LA$  中的数据元素, 或是  $LB$  中的数据元素, 则只要先设  $LC$  为空表, 然后将  $LA$  或  $LB$  中的元素逐个插入到  $LC$  中即可。为使  $LC$  中元素按值非递减有序排列, 可设两个指针  $i$  和  $j$  分别指向  $LA$  和  $LB$  中某个元素, 若设  $i$  当前所指的元素为  $a$ ,  $j$  当前所指的元素为  $b$ , 则当前应插入到  $LC$  中的元素  $c$  为

$$
c = \left\{ \begin{array}{l l} a & \text {当} a \leqslant b \text {时} \\ b & \text {当} a > b \text {时} \end{array} \right.
$$

显然，指针  $i$  和  $j$  的初值均为1，在所指元素插入  $LC$  之后，在  $LA$  或  $LB$  中顺序后移。上述归并算法如算法2.2所示。

```c
void MergeList(List La, List Lb, List &Lc) {
// 已知线性表 La 和 Lb 中的数据元素按值非递减排列。
// 归并 La 和 Lb 得到新的线性表 Lc, Lc 的数据元素也按值非递减排列。
InitList(Lc);
i = j = 1; k = 0;
La_len = ListLength(La); Lb_len = ListLength(Lb);
while ((i <= La_len) && (j <= Lb_len)) { // La 和 Lb 均非空
    GetElem(La, i, ai); GetElem(Lb, j, bj);
    if (ai <= bj) { ListInsert(Lc, ++k, ai); ++i;} 
    else { ListInsert(Lc, ++k, bj); ++j;} 
} 
while (i <= La_len) {
    GetElem(La, i++, ai); ListInsert(Lc, ++k, ai); 
} 
while (j <= Lb_len) {
    GetElem(Lb, j++, bj); ListInsert(Lc, ++k, bj);}
```

# 算法 2.2

上述两个算法的时间复杂度取决于抽象数据类型List定义中基本操作的执行时间。假如GetElem和ListInsert这两个操作的执行时间和表长无关，LocateElem的执行时间和表长成正比，则算法2.1的时间复杂度为  $O(\text{ListLength}(LA) \times \text{ListLength}(LB))$  ，算法2.2的时间复杂度则为  $O(\text{ListLength}(LA) + \text{ListLength}(LB))$  。虽然算法2.2中含3个(while)循环语句，但只有当  $i$  和  $j$  均指向表中实际存在的数据元素时，才能取得数据元素的值并进行相互比较；并且当其中一个线性表的数据元素均已插入到线性表  $LC$  中后，只要将另外一个线性表中的剩余元素依次插入即可。因此，对于每一组具体的输入（ $LA$  和  $LB$  )，后两个(while)循环语句只执行一个循环体。

# 2.2 线性表的顺序表示和实现

线性表的顺序表示指的是用一组地址连续的存储单元依次存储线性表的数据元素。

假设线性表的每个元素需占用  $l$  个存储单元，并以所占的第一个单元的存储地址作为数据元素的存储位置。则线性表中第  $i + 1$  个数据元素的存储位置  $LOC(a_{i + 1})$  和第  $i$  个数据元素的存储位置  $LOC(a_i)$  之间满足下列关系：

$$
\operatorname {L O C} \left(a _ {i + 1}\right) = \operatorname {L O C} \left(a _ {i}\right) + l
$$

一般来说，线性表的第  $i$  个数据元素  $a_{i}$  的存储位置为

$$
\operatorname {L O C} \left(a _ {i}\right) = \operatorname {L O C} \left(a _ {1}\right) + (i - 1) \times l \tag {2-2}
$$

式中  $LOC(a_{1})$  是线性表的第一个数据元素  $a_{1}$  的存储位置，通常称做线性表的起始位置或基地址。

线性表的这种机内表示称做线性表的顺序存储结构或顺序映像（sequential mapping），通常，称这种存储结构的线性表为顺序表。它的特点是，为表中相邻的元素  $a_{i}$  和  $a_{i+1}$  赋以相邻的存储位置  $\mathbf{LOC}(a_{i})$  和  $\mathbf{LOC}(a_{i+1})$  。换句话说，以元素在计算机内“物理位置相邻”来表示线性表中数据元素之间的逻辑关系。每一个数据元素的存储位置都和线性表的起始位置相差一个和数据元素在线性表中的位序成正比的常数（见图2.2）。由此，只要确定了存储线性表的起始位置，线性表中任一数据元素都可随机存取，所以线性表的顺序存储结构是一种随机存取的存储结构。

![](images/a3901430ff569be79d21b983fa23f1804f942a49272c41560a29dba363e139f3.jpg)  
图2.2 线性表的顺序存储结构示意图

由于高级程序设计语言中的数组类型也有随机存取的特性，因此，通常都用数组来描述数据结构中的顺序存储结构。在此，由于线性表的长度可变，且所需最大存储空间随问题不同而不同，则在C语言中可用动态分配的一维数组，如下描述。

```c
//----线性表的动态分配顺序存储结构----  
#define LIST.INIT.SIZE 100 //线性表存储空间的初始分配量  
#define LISTINIncrement 10 //线性表存储空间的分配增量  
typedef struct{ElemType \*elem; //存储空间基址int length; //当前长度int sizeofElemType为单位）SqList;
```

在上述定义中，数组指针 elem 指示线性表的基地址，length 指示线性表的当前长度。顺序表的初始化操作就是为顺序表分配一个预定义大小的数组空间，并将线性表的当前长度设为“0”（参见算法 2.3）。listsize 指示顺序表当前分配的存储空间大小，一旦因插入

元素而空间不足时，可进行再分配，即为顺序表增加一个大小为存储LISTINIncrement个数据元素的空间。

```javascript
Status InitList.Sq(SqList&L){ //构造一个空的线性表L。 L.elem  $\equiv$  (ElemType\*)malloc(List_INIT_SIZE\*sizeof(ElemType)); if(!L.elem)exit(OVERFLOW); //存储分配失败 L.length  $= 0$  //空表长度为0 L.listsize  $\equiv$  LIST_INIT.SIZE; //初始存储容量 return OK;   
}//InitList.Sq
```

# 算法 2.3

在这种存储结构中，容易实现线性表的某些操作，如随机存取第i个数据元素等。只是要特别注意的是，C语言中数组的下标从“0”开始，因此，若  $L$  是SqList类型的顺序表，则表中第i个数据元素是L.elem[i-1]。下面重点讨论线性表的插入和删除两种操作在顺序存储表示时的实现方法。

如2.1节中所述，线性表的插入操作是指在线性表的第  $i - 1$  个数据元素和第  $i$  个数据元素之间插入一个新的数据元素，就是要使长度为  $\pmb{n}$  的线性表

$$
\left(a _ {1}, \dots , a _ {i - 1}, a _ {i}, \dots , a _ {n}\right)
$$

变成长度为  $n + 1$  的线性表

$$
(a _ {1}, \dots , a _ {i - 1}, b, a _ {i}, \dots , a _ {n})
$$

数据元素  $a_{i-1}$  和  $a_i$  之间的逻辑关系发生了变化。在线性表的顺序存储结构中，由于逻辑上相邻的数据元素在物理位置上也是相邻的，因此，除非  $i=n+1$ ，否则必须移动元素才能反映这个逻辑关系的变化。

![](images/524d0b6409ff52ee596351f7acc2ba0433b4ee4b18671f965a827acebde50c3f.jpg)  
图2.3 线性表插入 前后的状况

(a) 插入前  $n = 8$ ;  
（b）插入后  $n = 9$

![](images/4be37df4caceb8f33ec0f3e58c25ae45dd2fa3669c77aaec2215731960c0d28d.jpg)  
图2.4 线性表删除 前后的状况

(a) 删除前  $n = 8$  
(b) 删除后  $n = 7$

例如，图2.3表示一个线性表在进行插入操作的前、后，其数据元素在存储空间中的位置变化。为了在线性表的第4和第5个元素之间插入一个值为25的数据元素，则需将第5个至第8个数据元素依次往后移动一个位置。

一般情况下，在第  $i(1 \leqslant i \leqslant n)$  个元素之前插入一个元素时，需将第  $n$  至第  $i$  （共  $n - i + 1$ ）个元素向后移动一个位置，如算法2.4所示。

```javascript
Status Insert.Sq(SqList&L,int i,ElemType e) { //在顺序线性表L中第i个位置之前插入新的元素e， //i的合法值为  $1\leqslant i\leqslant$  ListLength.Sq(L)+1 if  $(\mathrm{i} <   1\parallel \mathrm{i} > \mathrm{L.length} + 1)$  returnERROR; //i值不合法 if（L.length  $\rightharpoondown$  L.listsize）{//当前存储空间已满，增加分配 newbase  $=$  (ElemType \*)realloc(L.elem, （L.listsize+LISTINCREMENT）\*sizeof(ElemType)); if(!newbase)exit(OVERFLOW); //存储分配失败 L.elem  $=$  newbase; //新基址 L.listsize  $+ =$  LISTINCREMENT; //增加存储容量 }  $\mathbf{q} = \& (\mathbf{L.elem}[\mathbf{i} - 1])$  ： //q为插入位置 for  $(p = \& (L.\text{elem}[L.\text{length} -1])$  .  $\mathfrak{p} > = \mathfrak{q}; - - \mathfrak{p})*(p + 1) = *p;$  //插入位置及之后的元素右移  $\ast q = e$  ： //插入e ++L.length; //表长增1 return OK;   
}//Insert.Sq
```

# 算法 2.4

反之，线性表的删除操作是使长度为  $n$  的线性表

$$
\left(a _ {1}, \dots , a _ {i - 1}, a _ {i}, a _ {i + 1}, \dots , a _ {n}\right)
$$

变成长度为  $n - 1$  的线性表

$$
(a _ {1}, \dots , a _ {i - 1}, a _ {i + 1}, \dots , a _ {n})
$$

数据元素  $a_{i-1}, a_i$  和  $a_{i+1}$  之间的逻辑关系发生变化，为了在存储结构上反映这个变化，同样需要移动元素。如图2.4所示，为了删除第4个数据元素，必须将从第5个至第8个元素都依次往前移动一个位置。

一般情况下，删除第  $i(1 \leqslant i \leqslant n)$  个元素时需将从第  $i + 1$  至第  $n$  （共  $n - i$  )个元素依次向前移动一个位置，如算法2.5所示。

```javascript
Status ListDelete_Sq(SqList &L, int i, ElemType &e) {
// 在顺序线性表 L 中删除第 i 个元素，并用 e 返回其值
// i 的合法值为  $1 \leqslant i \leqslant \text{ListLength} \cdot \text{Sq(L)}$  
if ((i < 1) || (i > L.length)) return ERROR; // i 值不合法
p = & (L.element[i - 1]); // p 为被删除元素的位置
e = *p; // 被删除元素的值赋给 e
q = L.element + L.length - 1; // 表尾元素的位置
for (++p; p <= q; ++p) * (p - 1) == *p; // 被删除元素之后的元素左移
```

--L.length; return OK; } // ListDelete.Sq

# 算法 2.5

从算法2.4和2.5可见，当在顺序存储结构的线性表中某个位置上插入或删除一个数据元素时，其时间主要耗费在移动元素上（换句话说，移动元素的操作为预估算法时间复杂度的基本操作），而移动元素的个数取决于插入或删除元素的位置。

假设  $p_i$  是在第  $i$  个元素之前插入一个元素的概率, 则在长度为  $n$  的线性表中插入一个元素时所需移动元素次数的期望值(平均次数)为

$$
E _ {i s} = \sum_ {i = 1} ^ {n + 1} p _ {i} (n - i + 1) \tag {2-3}
$$

假设  $q_{i}$  是删除第  $i$  个元素的概率, 则在长度为  $n$  的线性表中删除一个元素时所需移动元素次数的期望值(平均次数)为

$$
E _ {d l} = \sum_ {i = 1} ^ {n} q _ {i} (n - i) \tag {2-4}
$$

不失一般性，我们可以假定在线性表的任何位置上插入或删除元素都是等概率的，即

$$
p _ {i} = \frac {1}{n + 1}, q _ {i} = \frac {1}{n}
$$

则式(2-3)和(2-4)可分别简化为式(2-5)和(2-6)：

$$
E _ {i s} = \frac {1}{n + 1} \sum_ {i = 1} ^ {n + 1} (n - i + 1) = \frac {n}{2} \tag {2-5}
$$

$$
E _ {d l} = \frac {1}{n} \sum_ {i = 1} ^ {n} (n - i) = \frac {n - 1}{2} \tag {2-6}
$$

由式(2-5)和(2-6)可见，在顺序存储结构的线性表中插入或删除一个数据元素，平均约移动表中一半元素。若表长为  $n$  ，则算法ListInsert_Sq和ListDelete_Sq的时间复杂度为  $O(n)$  。

现在我们来讨论2.1节中例2-1和例2-2的操作在顺序存储结构的线性表中的实现方法和时间复杂度的分析。容易看出，顺序表的“求表长”和“取第  $i$  个数据元素的时间复杂度均为  $O(1)$  ，又这两个例子中进行的“插入”操作均在表尾进行，则不需要移动元素。因此，算法2.1的执行时间主要取决于查找函数LocateElem的执行时间。在顺序表  $L$  中查访是否存在和  $\pmb{e}$  相同的数据元素的最简便的方法是，令  $\pmb{e}$  和  $L$  中的数据元素逐个比较之，如算法2.6所示。从算法2.6中可见。基本操作是“进行两个元素之间的比较”，若 $L$  中存在和  $\pmb{e}$  相同的元素  $a_{i}$  ，则比较次数为  $i(1\leqslant i\leqslant L.$  length)，否则为L.length，即算法LocateElem_Sq的时间复杂度为  $O(L.$  length)。由此，对于顺序表  $La$  和  $Lb$  而言，union的时间复杂度为  $O(\mathrm{La.length}\times \mathrm{Lb.length})$  。

int LocateElem_Sq(SqList L, ElemType e, Status (*compare)(ElemType, ElemType)) { // 在顺序线性表L中查找第1个值与e满足compare()的元素的位序

```txt
// 若找到, 则返回其在 L 中的位序, 否则返回 0  
i = 1; // i 的初值为第 1 个元素的位序  
p = L.element; // p 的初值为第 1 个元素的存储位置  
while (i <= L.length && ! (* compare) (* p++, e)) ++ i;  
if (i <= L.length) return i;  
else return 0;  
} // LocateElem Sq
```

# 算法 2.6

对于“顺序表的合并”，则从算法2.2可直接写出形式上极其相似的算法2.7。显然，算法2.7中的基本操作为“元素赋值”，算法的时间复杂度为  $O(\text{La.length} + \text{Lb.length})$  。

```javascript
void MergeList. Sq(SqList La, SqList Lb, SqList &Lc) { //已知顺序线性表La和Lb的元素按值非递减排列 //归并La和Lb得到新的顺序线性表Lc,Lc的元素也按值非递减排列 pa = La.elem; pb = Lb.elem; Lc.size = Lc.length = La.length + Lb.length; pc = Lc.elem = (ElemType*)malloc(Lc.listsize * sizeof(ElemType)); if (!Lc.elem)exit(OVERFLOW); //存储分配失败 pa.last = La.elem + La.length - 1; pb.last = Lb.elem + Lb.length - 1; while (pa <= pa.last && pb <= pb.last) { //归并 if (*pa <= *pb) *pc ++ = *pa++; else *pc ++ = *pb++; } while (pa <= pa.last) *pc ++ = *pa++; //插入La的剩余元素 while (pb <= pb.last) *pc ++ = *pb++; //插入Lb的剩余元素 } //MergeList.Sq
```

# 算法 2.7

若对算法2.7中第一个循环语句的循环体作如下修改：以“开关语句”代替“条件语句”，即分出元素比较的第三种情况，当  $*\mathrm{pa} = *\mathrm{pb}$  时，只将两者中之一插入Lc，则该算法完成的操作和算法union完全相同，而时间复杂度却不同。算法2.7之所以有线性的时间复杂度，其原因有二：①由于La和Lb中元素依值递增(同一集合中元素不等)，则对Lb中每个元素，不需要在La中从表头至表尾进行全程搜索；②由于用新表Lc表示“并集”，则插入操作实际上是借助“复制”操作来完成的①。为得到元素依值递增(或递减)的有序表，可利用10.3节讨论的快速排序，其时间复杂度为  $O(n\log n)$  （其中  $n$  为待排序的元素个数）。由此可见，若以线性表表示集合并进行集合的各种运算，应先对表中元素进行排序。

# 2.3 线性表的链式表示和实现

从上一节的讨论中可见，线性表的顺序存储结构的特点是逻辑关系上相邻的两个元素在物理位置上也相邻，因此可以随机存取表中任一元素，它的存储位置可用一个简单、直观的公式来表示。然而，从另一方面来看，这个特点也铸成了这种存储结构的弱点：在作插入或删除操作时，需移动大量元素。本节我们将讨论线性表的另一种表示方法——链式存储结构，由于它不要求逻辑上相邻的元素在物理位置上也相邻，因此它没有顺序存储结构所具有的弱点，但同时也失去了顺序表可随机存取的优点。

# 2.3.1 线性链表

线性表的链式存储结构的特点是用一组任意的存储单元存储线性表的数据元素（这组存储单元可以是连续的，也可以是不连续的）。因此，为了表示每个数据元素  $a_{i}$  与其直接后继数据元素  $a_{i+1}$  之间的逻辑关系，对数据元素  $a_{i}$  来说，除了存储其本身的信息之外，还需存储一个指示其直接后继的信息（即直接后继的存储位置）。这两部分信息组成数据元素  $a_{i}$  的存储映像，称为结点（node）。它包括两个域：其中存储数据元素信息的域称为数据域；存储直接后继存储位置的域称为指针域。指针域中存储的信息称做指针或链。 $n$  个结点  $(a_{i} (1 \leqslant i \leqslant n)$  的存储映像）链结成一个链表，即为线性表

$$
(a _ {1}, a _ {2}, \dots , a _ {n})
$$

的链式存储结构。又由于此链表的每个结点中只包含一个指针域, 故又称线性链表或单链表。

例如，图2.5所示为线性表

$$
(Z H A O, Q I A N, S U N, L I, Z H O U, W U, Z H E N G, W A N G)
$$

的线性链表存储结构, 整个链表的存取必须从头指针开始进行, 头指针指示链表中第一个结点 (即第一个数据元素的存储映像) 的存储位置。同时, 由于最后一个数据元素没有直接后继, 则线性链表中最后一个结点的指针为“空”(NULL)。

![](images/39fb5d7985c846368affcc0fb00b05b7319c06e48e63cea0750264ee7094a830.jpg)  
图2.5 线性链表示例

用线性链表表示线性表时，数据元素之间的逻辑关系是由结点中的指针指示的。换句话说，指针为数据元素之间的逻辑关系的映像，则逻辑上相邻的两个数据元素其存储的

物理位置不要求紧邻，由此，这种存储结构为非顺序映像或链式映像。

通常我们把链表画成用箭头相链接的结点的序列，结点之间的箭头表示链域中的指针。如图2.5的线性链表可画成如图2.6所示的形式，这是因为在使用链表时，关心的只是它所表示的线性表中数据元素之间的逻辑顺序，而不是每个数据元素在存储器中的实际位置。

![](images/f95aa853693effa658488789e9d9d9592d0034502648d0a73de00d1d03c048e2.jpg)  
图2.6 线性链表的逻辑状态

由上述可见，单链表可由头指针惟一确定，在C语言中可用“结构指针”来描述。

```c
// -- -- - - 线性表的单链表存储结构 -- -- -- typedef struct LNode {
ElemType data;
struct LNode * next;
}LNode, *LinkList;
```

假设L是LinkList型的变量，则L为单链表的头指针，它指向表中第一个结点。若L为“空”(L=NULL)，则所表示的线性表为“空”表，其长度  $n$  为“零”。有时，我们在单链表的第一个结点之前附设一个结点，称之为头结点。头结点的数据域可以不存储任何信息，也可存储如线性表的长度等类的附加信息，头结点的指针域存储指向第一个结点的指针（即第一个元素结点的存储位置）。如图2.7(a)所示，此时，单链表的头指针指向头结点。若线性表为空表，则头结点的指针域为“空”，如图2.7(b)所示。

(a)  
(b)  
图2.7 带头结点的单链表  
![](images/fd3fafb212b23b3ee4363815f72f46249a386fa08fe4b73a8fd82344fca89015.jpg)  
(a)非空表； (b)空表

在线性表的顺序存储结构中，由于逻辑上相邻的两个元素在物理位置上紧邻，则每个元素的存储位置都可从线性表的起始位置计算得到。而在单链表中，任何两个元素的存储位置之间没有固定的联系。然而，每个元素的存储位置都包含在其直接前驱结点的信息之中。假设  $\mathfrak{p}$  是指向线性表中第  $\mathrm{i}$  个数据元素(结点  $\mathbf{a}_{\mathrm{i}}$ )①的指针，则  $\mathfrak{p} \longrightarrow \text{next}$  是指向第  $\mathrm{i} + 1$  个数据元素(结点  $\mathbf{a}_{\mathrm{i} + 1}$ )的指针。换句话说，若  $\mathfrak{p} \longrightarrow \text{data} = \mathbf{a}_{\mathrm{i}}$ ，则  $\mathfrak{p} \longrightarrow \text{next} \longrightarrow \text{data} = \mathbf{a}_{\mathrm{i} + 1}$ 。由此，在单链表中，取得第  $\mathrm{i}$  个数据元素必须从头指针出发寻找，因此，单链表是

表是非随机存取的存储结构。下面我们看函数GetElem在单链表中的实现。

```c
Status GetElem_L(LinkList L, int i, ElemType &e) {
// L为带头结点的单链表的头指针。
// 当第i个元素存在时，其值赋给e并返回OK，否则返回ERROR
p = L->next; j = 1; //初始化，p指向第一个结点，j为计数器
while (p && j<i) { //顺指针向后查找，直到p指向第i个元素或p为空
    p = p->next; ++j;
}
if (!p || j>i) return ERROR; //第i个元素不存在
e = p->data; //取第i个元素
return OK;
} //GetElem_L
```

# 算法 2.8

算法2.8的基本操作是比较  $j$  和  $i$  并后移指针  $\mathfrak{p}$ , while 循环体中的语句频度与被查元素在表中位置有关, 若  $1 \leqslant i \leqslant n$ , 则频度为  $i - 1$ , 否则频度为  $n$ , 因此算法2.8的时间复

杂度为  $O(n)$  。

在单链表中，又如何实现“插入”和“删除”操作呢？

假设我们要在线性表的两个数据元素a和b之间插入一个数据元素  $\mathbf{x}$  ，已知  $\mathfrak{p}$  为其单链表存储结构中指向结点a的指针。如图2.8(a)所示。

![](images/a86b3ced88a161d42cbad8a31392b3bb42b6e895a5e49930aeb5f93063bb19eb.jpg)  
图2.8 在单链表中插入结点时指针变化状况（a）插入前；（b）插入后

为插入数据元素  $\mathbf{x}$ , 首先要生成一个数据域为  $\mathbf{x}$  的结点, 然后插入在单链表中。根据插入操作的逻辑定义, 还需要修改结点 a 中的指针域, 令其指向结点 x, 而结点 x 中的指针域应指向结点 b, 从而实现 3 个元素 a、b 和 x 之间逻辑关系的变化。插入后的单链表如图 2.8(b) 所示。假设 s 为指向结点 x 的指针, 则上述指针修改用语句描述即为

```txt
s->next = p->next;  $\mathbf{p}\rightarrow$  next  $=$  s;
```

反之，如图2.9所示在线性表中删除元素b时，为在单链表中实现元素a、b和c之间

![](images/1799e63792789551721b54bff717ee36d49f400285acf0f2ecea100e69a3381a.jpg)  
图2.9 在单链表中删除结点时指针变化状况

逻辑关系的变化，仅需修改结点a中的指针域即可。假设p为指向结点a的指针，则修改指针的语句为

```txt
$\mathbf{p}\longrightarrow \mathbf{next} = \mathbf{p}\longrightarrow \mathbf{next}\longrightarrow \mathbf{next};$
```

可见，在已知链表中元素插入或删除的确切位置

的情况下，在单链表中插入或删除一个结点时，仅需修改指针而不需要移动元素。算法2.9和算法2.10分别为ListInsert和Delete在单链表中的实现。

```txt
Status ListInsert_L(LinkList &L, int i, ElemType e) {
```

// 在带头结点的单链线性表 L 中第 i 个位置之前插入元素 e

```txt
$\mathbf{p} = \mathbf{L};\quad \mathbf{j} = \mathbf{0};$
```

while  $(\mathfrak{p} \& \& \mathrm{j} < \mathrm{i} - 1)$ $\{\mathrm{p} = \mathrm{p} - > \mathrm{next}; + + \mathrm{j};\}$  //寻找第i-1个结点

```txt
if（!p||j>i-1）returnERROR; //i小于1或者大于表长加1s=(LinkList)malloc（sizeof(LNode)); //生成新结点s->data=e;s->next=p->next; //插入L中p->next=s; return OK;   
} //ListInsert_L
```

# 算法 2.9

```c
Status ListDelete_L(LinkList &L, int i, ElemType &e) {
// 在带头结点的单链线性表 L 中，删除第 i 个元素，并由 e 返回其值
p = L; j = 0;
while (p->next && j < i-1) {
p = p->next; ++j;
}
if (! (p->next) || j > i-1) return ERROR; // 删除位置不合理
q = p->next; p->next = q->next; // 删除并释放结点
e = q->data; free(q);
return OK;
} // ListDelete_L
```

# 算法 2.10

容易看出，算法2.9和算法2.10的时间复杂度均为  $O(n)$  。这是因为，为在第  $i$  个结点之前插入一个新结点或删除第  $i$  个结点，都必须首先找到第  $i - 1$  个结点，即需修改指针的结点，从算法2.8的讨论中，我们已经得知，它的时间复杂度为  $O(n)$  。

在算法2.9和2.10中，我们还分别引用了C语言中的两个标准函数malloc和free。通常，在设有“指针”数据类型的高级语言中均存在与其相应的过程或函数。假设p和q是LinkList型的变量，则执行  $\mathfrak{p} = (\mathrm{LinkList})\mathrm{malloc(sizeof(LNode))}$  的作用是由系统生成一个LNode型的结点，同时将该结点的起始位置赋给指针变量p；反之，执行  $\mathrm{free(q)}$  的作用是由系统回收一个LNode型的结点，回收后的空间可以备作再次生成结点时用。因此，单链表和顺序存储结构不同，它是一种动态结构。整个可用存储空间可为多个链表共同享用，每个链表占用的空间不需预先分配划定，而是可以由系统应需求即时生成。因此，建立线性表的链式存储结构的过程就是一个动态生成链表的过程。即从“空表”的初始状态起，依次建立各元素结点，并逐个插入链表。算法2.11是一个从表尾到表头逆向建立单链表的算法，其时间复杂度为  $O(n)$  。

```c
void CreateList_L(LinkList &L, int n) {
    // 逆位序输入  $n$  个元素的值，建立带表头结点的单链线性表 L。
    L = (LinkList) malloc (sizeof(LNode));
    L->next = NULL; // 先建立一个带头结点的单链表
    for (i = n; i > 0; --i) {
        p = (LinkList) malloc (sizeof(LNode)); // 生成新结点
```

```txt
scanf(&p->data); //输入元素值
p->next = L->next; L->next = p; //插入到表头
} // CreateList L
```

# 算法 2.11.

下面讨论如何将两个有序链表并为一个有序链表。

假设头指针为La和Lb的单链表分别为线性表LA和LB的存储结构，现要归并La和Lb得到单链表Lc，按照2.1节中算法MergeList的思想，需设立3个指针pa、pb和pc,其中pa和pb分别指向La表和Lb表中当前待比较插入的结点，而pc指向Lc表中当前最后一个结点，若pa->data≤pb->data，则将pa所指结点链接到pc所指结点之后，否则将pb所指结点链接到pc所指结点之后。显然，指针的初始状态为：当LA和LB为非空表时，pa和pb分别指向La和Lb表中第一个结点，否则为空；pc指向空表Lc中的头结点。由于链表的长度为隐含的，则第一个循环执行的条件是pa和pb皆非空，当其中一个为空时，说明有一个表的元素已归并完，则只要将另一个表的剩余段链接在pc所指结点之后即可。由此得到归并两个单链表的算法，如算法2.12所示。

```javascript
void MergeList.L(LinkList&La,LinkList&Lb,LinkList&Lc) { //已知单链线性表La和Lb的元素按值非递减排列。 //归并La和Lb得到新的单链线性表Lc,Lc的元素也按值非递减排列。 pa  $=$  La->next;pb  $=$  Lb->next;  $\mathrm{Lc} = \mathrm{pc} = \mathrm{La};$  //用La的头结点作为Lc的头结点 while（pa&&pb）{ if（pa->data  $<   =$  pb->data）{ pc->next  $\equiv$  pa;pc  $\equiv$  pa;pa  $\equiv$  pa->next; } else{pc->next  $\equiv$  pb;pc  $\equiv$  pb;pb  $\equiv$  pb->next:} 1 pc->next  $\equiv$  pa?pa:pb; //插入剩余段 free(Lb); //释放Lb的头结点   
}//MergeList.L
```

# 算法 2.12

读者容易看出，算法2.12的时间复杂度和算法2.7相同，但空间复杂度不同。在归并两个链表为一个链表时，不需要另建新表的结点空间，而只需将原来两个链表中结点之间的关系解除，重新按元素值非递减的关系将所有结点链接成一个链表即可。

有时，也可借用一维数组来描述线性链表，其类型说明如下所示：

```c
// -- -- -- 线性表的静态单链表存储结构 -- -- -- #define MAXSIZE 1000 // 链表的最大长度 typedef struct {
ElemType data;
int cur;
```

}component, SLinkList[MAXSIZE];

这种描述方法便于在不设“指针”类型的高级程序设计语言中使用链表结构。在如上描述的链表中，数组的一个分量表示一个结点，同时用游标（指示器cur）代替指针指示结点在数组中的相对位置。数组的第零分量可看成头结点，其指针域指示链表的第一个结点。例如图2.10(a)中所示为和图2.6相同的线性表。这种存储结构仍需要预先分配一个较大的空间，但在作线性表的插入和删除操作时不需移动元素，仅需修改指针，故仍具有链式存储结构的主要优点。例如，图2.10(b)展示了图2.10(a)所示线性表在插入数据元素“SHI”和删除数据元素“ZHENG”之后的状况。为了和指针型描述的线性链表相区别，我们给这种用数组描述的链表起名叫静态链表。

(a)  
图2.10 静态链表示例  
![](images/4d2ec3745bc08b6ccb765f272e05f3e4032273fce2944cad9c42efe072c8245c.jpg)  
(a) 修改前的状态；(b) 修改后的状态

![](images/3eb6234233d3a51949f9d29df962b54b6710c7850cf03a55df27df9b4338950b.jpg)  
(b)

假设S为SLinkList型变量，则  $\mathbf{S}[0]$  .cur指示第一个结点在数组中的位置，若设  $\mathrm{i} =$  S[0].cur，则S[i].data存储线性表的第一个数据元素，且S[i].cur指示第二个结点在数组中的位置。一般情况，若第i个分量表示链表的第k个结点，则S[i].cur指示第  $\mathbf{k + 1}$  个结点的位置。因此在静态链表中实现线性表的操作和动态链表相似，以整型游标i代替动态指针p，  $\mathrm{i} = \mathrm{S}[\mathrm{i}]$  .cur的操作实为指针后移(类似于  $\mathfrak{p} = \mathfrak{p}\longrightarrow$  next)，例如，在静态链表中实现的定位函数LocateElem如算法2.13所示。

```txt
int LocateElem_SL(SLinkList S, ElemType e) { // 在静态单链线性表 L 中查找第 1 个值为 e 的元素。
```

// 若找到, 则返回它在 L 中的位序, 否则返回 0 。

```javascript
$\mathrm{i} = \mathrm{S}[0].\mathrm{cur};$  //i指示表中第一个结点while（i&&S[i].data！=e）  $\mathbf{i} = \mathbf{S}[\mathbf{i}].\mathbf{cur};$  //在表中顺链查找return i;  
1//LocateElem.SL
```

# 算法 2.13

类似地可写出在静态链表中实现插入和删除操作的算法。从图2.10的例子可见，指针修改的操作和前面描述的单链表中的插入与删除的算法2.9、2.10类似，所不同的是，需由用户自己实现malloc和free这两个函数。为了辨明数组中哪些分量未被使用，解决的办法是将所有未被使用过以及被删除的分量用游标链成一个备用的链表，每当进行插入时便可从备用链表上取得第一个结点作为待插入的新结点；反之，在删除时将从链表中删除下来的结点链接到备用链表上。

现以集合运算  $(A - B) \cup (B - A)$  为例来讨论静态链表的算法。

例2-3 假设由终端输入集合元素，先建立表示集合  $A$  的静态链表  $S$  ，而后在输入集合B的元素的同时查找  $S$  表，若存在和  $B$  相同的元素，则从  $S$  表中删除之，否则将此元素插入  $S$  表。

为使算法清晰起见，我们先给出3个过程：①将整个数组空间初始化成一个链表；②从备用空间取得一个结点；③将空闲结点链结到备用链表上，分别如算法2.14、2.15和2.16所示。

```c
void InitSpace.SL(SLinkList &space) {
    // 将一维数组 space 中各分量链成一个备用链表, space[0].cur 为头指针,
    // “0”表示空指针
    for (i = 0; i < MAXSIZE - 1; ++i) space[i].cur = i + 1;
    space[MAXSIZE - 1].cur = 0;
} // InitSpace.SL
```

# 算法 2.14

```txt
intMalloc_SL(SLinkList&space){//若备用空间链表非空，则返回分配的结点下标，否则返回0i  $=$  space[0].cur;if(space[0].cur）space[0].cur  $=$  space[i].cur;return i;  
}//Malloc_SL
```

# 算法 2.15

```txt
void Free_SL(SLinkList &space, int k) {
    // 将下标为  $k$  的空闲结点回收到备用链表
    space[k].cur = space[0].cur; space[0].cur = k;
} // Free_SL
```

# 算法 2.16

```txt
void difference(SLinkList &space, int &S) {
    // 依次输入集合A和B的元素，在一维数组space中建立表示集合(A-B)∪(B-A)
    // 的静态链表，S为其头指针。假设备用空间足够大，space[0].cur为其头指针。
```

```txt
InitSpace.SL(space); //初始化备用空间  
 $\mathbf{S} = \mathbf{Malloc\_SL}(space)$  //生成S的头结点  
 $\mathbf{r} = \mathbf{S}$  //指向S的当前最后结点  
scanf(m,n); //输入A和B的元素个数  
for  $(j = 1; j <= m; ++j)$  { //建立集合A的链表  
i = Malloc.SL(space); //分配结点  
scanf(space[i].data); //输入A的元素值
```

```txt
$\begin{array}{rl} & {\mathrm{space}[r].\mathrm{cur} = 1;r = i;}\\ & {\mathrm{for}} \end{array}$  //插入到表尾  
} //for  
 $\mathrm{space}[r].\mathrm{cur} = 0;$  //尾结点的指针为空  
for（j=1;j<=n++;++j）{//依次输入B的元素，若不在当前表中，则插入，否则//删除  
 $\mathsf{scanf(b);p = S;k = space[S]cur; / / k}$  指向集合A中第一个结点while（k！  $=$  space[r]cur&&space[k].data！=b）{//在当前表中查找 $\mathsf{p} = \mathsf{k};\mathsf{k} = \mathsf{space}[\mathsf{k}]\mathsf{cur};$    
}//while  
if（k==space[r]cur）{//当前表中不存在该元素，插入在r所指结点之后，且r//的位置不变 $\mathbf{\Pi}_1 = \mathbf{Malloc\_SL}(\mathbf{space});$  （204 $\mathsf{space}[1]\mathsf{data} = \mathsf{b};$  （204 $\mathsf{space}[1]\mathsf{cur} = \mathsf{space}[\mathsf{r}]\mathsf{cur};$  （204 $\mathsf{space}[\mathsf{r}]\mathsf{cur} = \mathsf{\Pi}_{1};$    
}//if  
else{//该元素已在表中，删除之 $\mathsf{space[p].cur = space[k]cur;}$  （204Free SL(space,k);if（r==k）r=p; //若删除的是r所指结点，则需修改尾指针  
}//else  
}//for  
}//difference
```

# 算法 2.17

在算法2.17中，只有一个处于双重循环中的循环体（在集合  $A$  中查找依次输入的 $b)$  ，其最大循环次数为：外循环  $\pmb{n}$  次，内循环  $m$  次，故算法2.17的时间复杂度为 $(m\times n)$  。

图2.11 运算前后的静态链表  
![](images/6c9fb229b62a587bd4fe0e7c89094c4ade41fb40b84c4985a6b924ad034d720c.jpg)  
(a) 表示  $A$  的链表  $\mathbf{S}_1$ ；(b) 表示  $(A - B) \cup (B - A)$  的链表  $\mathbf{S}$

图2.11是算法2.17执行的示意图。假设集合  $A = (c, b, e, g, f, d)$ ， $B = (a, b, n, f)$ ，则图2.11(a)所示为输入集合  $A$  的元素之后建成的链表S和备用空间链表的状况。图2.11(b)所示为逐个输入集合  $B$  的元素并在链表S中依次插入  $a$ 、删除  $b$ 、插入  $n$ 、删除  $f$  后的状况。space[0].cur为备用链表的头指针， $r$  的值为7。

# 2.3.2 循环链表

循环链表(circular linked list)是另一种形式的链式存储结构。它的特点是表中最后一个结点的指针域指向头结点，整个链表形成一个环。由此，从表中任一结点出发均可找到表中其他结点，如图2.12所示为单链的循环链表。类似地，还可以有多重链的循环链表。

图2.12 单循环链表  
![](images/2d9834ef8af195beb73fe11861420975e8a07c58a62e921f7147848baa71fc23.jpg)  
(a)非空表；(b)空表

循环链表的操作和线性链表基本一致，差别仅在于算法中的循环条件不是  $\mathfrak{p}$  或

$\mathbf{p} - >$  next是否为空，而是它们是否等于头指针。但有的时候，若在循环链表中设立尾指针而不设头指针（如图2.13(a)所示），可使某些操作简化。例如将两个线性表合并成一个表时，仅需将一个表的表尾和另一个表的表头相接。当线性表以图2.13(a)的循环链表作存储结构时，这个操作仅需改变两个指针值即可，运算时间为  $O(1)$  。合并后的表如图2.13(b)所示。

![](images/ece2cbe340586f9443e22d599cc797b19a3d6fc41dbcf8eee210a3d45d29ee8c.jpg)

![](images/35d166c8142829420495a47d5634369e04ffef5c79f2a656e5658d4109801595.jpg)  
图2.13 仅设尾指针的循环链表

# 2.3.3 双向链表

以上讨论的链式存储结构的结点中只

有一个指示直接后继的指针域, 由此, 从某个结点出发只能顺指针往后寻查其他结点。若要寻查结点的直接前趋, 则需从表头指针出发。换句话说, 在单链表中, NextElem 的执行时间为  $O(1)$ , 而 PriorElem 的执行时间为  $O(n)$  。为克服单链表这种单向性的缺点, 可利用双向链表 (double linked list)。

顾名思义，在双向链表的结点中有两个指针域，其一指向直接后继，另一指向直接前趋，在C语言中可描述如下：

```txt
// -- -- -- 线性表的双向链表存储结构 -- -- -- typedef struct DuLNode {
ElemType data;
struct DuLNode *prior;
```

```txt
struct DuLNode \* next;   
}DuLNode，\*DuLinkList;
```

和单链的循环表类似，双向链表也可以有循环表，如图2.14(c)所示，链表中存有两个环，图2.14(b)所示为只有一个表头结点的空表。在双向链表中，若d为指向表中某一

图2.14 双向链表示例  
![](images/cd48d4e40939ed05fbafa3c06af3286b6c7f2d1326e6062e7b1819a11d6b55dd.jpg)  
(a) 结点结构；(b) 空的双向循环链表；(c) 非空的双向循环链表

![](images/54685d4c2c5689de32fc9d1aa79dfe8976a0a7c1834e0886faf7e603fdcd3ea0.jpg)

结点的指针（即  $\mathbf{d}$  为DuLinkList型变量），则显然有

$$
d \rightarrow n e x t \rightarrow p r i o r = d \rightarrow p r i o r \rightarrow n e x t = d
$$

这个表示式恰当地反映了这种结构的特性。

在双向链表中, 有些操作如: ListLength、GetElem 和 LocateElem 等仅需涉及一个方向的指针, 则它们的算法描述和线性链表的操作相同, 但在插入、删除时有很大的不同, 在双向链表中需同时修改两个方向上的指针, 图 2.15 和图 2.16 分别显示了删除和插入结点时指针修改的情况。它们的算法分别如算法 2.19 和 2.18 所示, 两者的时间复杂度均为  $O(n)$  。

![](images/2707431e3516c94394cf2761b3db9c7bec984ec44ad2bb54b0a6c3776066ef46.jpg)  
图2.15 在双向链表中删除结点时指针变化状况

![](images/35c4560635864a7fc1364e1719b3f659bd115eef19fa1f52d3a44d72efd10a1e.jpg)  
图2.16 在双向链表中插入一个结点时指针的变化状况

```c
Status Insert_DuL(DuLinkList &L, int i, ElemType e) {
// 在带头结点的双链循环线性表 L 中第 i 个位置之前插入元素 e,
// i 的合法值为 l <= i <= 表长 + 1。
if (! (p = GetElemP_DuL(L, i))) // 在 L 中确定插入位置
return ERROR; // p=NULL, 即插入位置不合法
if (! (s = (DuLinkList)malloc(sizeof(DuNode))) return ERROR;
s->data = e;
s->prior = p->prior; p->prior->next = s;
s->next = p; p->prior = s;
return OK;
} // ListInsert_DuL
```

# 算法 2.18

```txt
Status ListDelete.DuL(DuLinkList&L,int i,ElemType&e){ //删除带头结点的双链循环线性表L的第i个元素，i的合法值为  $1\leqslant i\leqslant$  表长 if（！  $(p = GetElemP.DuL(L,i))$  //在L中确定第i个元素的位置指针p returnERROR; //  $\mathfrak{p} = \mathbb{N}\mathbb{U}\mathbb{L}$  ，即第i个元素不存在 e=p->data; p->prior->next=p->next; p->next->prior=p->prior; free(p);return OK;   
}//ListDelete.DuL
```

# 算法 2.19

从本节的讨论中可见，由于链表在空间的合理利用上和插入、删除时不需要移动等的优点，因此在很多场合下，它是线性表的首选存储结构。然而，它也存在着实现某些基本操作，如求线性表的长度时不如顺序存储结构的缺点；另一方面，由于在链表中，结点之间的关系用指针来表示，则数据元素在线性表中的“位序”的概念已淡化，而被数据元素在线性链表中的“位置”所代替。为此，从实际应用角度出发重新定义线性链表及其基本操作。

一个带头结点的线性链表类型定义如下：

```c
typedef struct LNode{ //结点类型ElemType data;struct LNode \* next;} \*Link，\*Position;  
typedef struct{//链表类型Linkhead,tail; //分别指向线性链表中的头结点和最后一个结点intlen; //指示线性链表中数据元素的个数}LinkList;  
Status MakeNode( Link&p,ElemType e);//分配由p指向的值为e的结点，并返回OK；若分配失败，则返回ERRORvoidFreeNode(Link&p);//释放p所指结点  
Status InitList(LinkList&L);//构造一个空的线性链表L  
StatusDestroyList( LinkList&L);//销毁线性链表L,L不再存在  
StatusClearList( LinkList&L);//将线性链表L重置为空表，并释放原链表的结点空间  
StatusInsFirst( Linkh,Links);//已知h指向线性链表的头结点，将s所指结点插入在第一个结点之前  
StatusDelFirst( Linkh,Link&q);//已知h指向线性链表的头结点，删除链表中的第一个结点并以q返回  
Status Append( LinkList&L,Links);//将指针s所指(彼此以指针相链)的一串结点链接在线性链表L的最后一个结点/之后，并改变链表L的尾指针指向新的尾结点
```

```txt
Status Remove(LinkList&L,Link&q); //删除线性链表L中的尾结点并以q返回，改变链表L的尾指针指向新的尾结点  
Status InsBefore(LinkList&L,Link&p,Links); //已知p指向线性链表L中的一个结点，将s所指结点插入在p所指结点之前，//并修改指针p指向新插入的结点  
Status InsAfter(LinkList&L,Link&p,Links); //已知p指向线性链表L中的一个结点，将s所指结点插入在p所指结点之后，//并修改指针p指向新插入的结点  
Status SetCurElem(Link&p,ElemTypee); //已知p指向线性链表中的一个结点，用e更新p所指结点中数据元素的值  
ElemTypeGetCurElem(Linkp); //已知p指向线性链表中的一个结点，返回p所指结点中数据元素的值  
Status ListEmpty(LinkListL); //若线性链表L为空表，则返回TRUE.否则返回FALSE  
intListLength(LinkListL); //返回线性链表L中元素个数  
PositionGetHead(LinkListL); //返回线性链表L中头结点的位置  
PositionGetLast(LinkListL); //返回线性链表L中最后一个结点的位置  
PositionPriorPos(LinkListL,Linkp); //已知p指向线性链表L中的一个结点，返回p所指结点的直接前驱的位置，//若无前驱，则返回NULL  
PositionNextPos(LinkListL,Linkp); //已知p指向线性链表L中的一个结点，返回p所指结点的直接后继的位置，//若无后继，则返回NULL  
StatusLocatePos(LinkListL,inti,Link&p); //返回p指示线性链表L中第i个结点的位置并返回OK,i值不合法时返回ERROR  
PositionLocateElem(LinkListL,ElemTypee.Status(*compare)(ElemType,ElemType) //返回线性链表L中第1个与e满足函数compare()判定关系的元素的位置，//若不存在这样的元素，则返回NULL  
StatusListTraverse(LinkListL,Status(*visit))()); //依次对L的每个元素调用函数visit()。一旦visit()失败，则操作失败。
```

在上述定义的线性链表的基本操作中，除了DestroyList、ClearList、Remove、InsBefore、PriorPos、LocatePos、LocateElem和ListTraverse的时间复杂度和表长成正比之外，其他操作的时间复杂度都和表长无关，Append操作的时间复杂度则和插入的结点数成正比。利用这些基本操作，容易实现诸如在第  $i$  个元素之前插入元素或删除第  $i$  个元素或合并两个线性表等操作，如算法2.20和2.21所示。

```txt
Status ListInsert L(LinkList &L, int i, ElemType e) {
// 在带头结点的单链线性表 L 的第 i 个元素之前插入元素 e
if (! LocatePos(L.i-1,h)) return ERROR; // i 值不合法
if (!MakeNode(s,e)) return ERROR; // 结点存储分配失败
InsFirst(h.s); // 对于从第 i 个结点开始的链表, 第 i-1 个结点是它的头结点
return OK;
} // ListInsert L
```

# 算法 2.20

```c
Status MergeList_L(LinkList &La, LinkList &Lb, LinkList &Lc
int (* compare)(ElemType, ElemType)) {
// 已知单链线性表 La 和 Lb 的元素按值非递减排列。
// 归并 La 和 Lb 得到新的单链线性表 Lc, Lc 的元素也按值非递减排列。
if (!InitList(Lc)) return ERROR; // 存储空间分配失败
ha = GetHead(La); hb = GetHead(Lb); // ha 和 hb 分别指向 La 和 Lb 的头结点
pa = NextPos(La, ha); pb = NextPos(Lb, hb); // pa 和 pb 分别指向 La 和 Lb 中当前结点
while (pa && pb) {
a = GetCurElem(pa); b = GetCurElem(pb); // a 和 b 为两表中当前比较元素
if ((* compare)(a, b) <= 0) { // a <= b
DelFirst(ha, q); Append(Lc, q); pa = NextPos(La, ha);
}
else {
// a > b
DelFirst(hb, q); Append(Lc, q); pb = NextPos(Lb, hb);
}
} // while
if (pa) Append(Lc, pa); // 链接 La 中剩余结点
else Append(Lc, pb); // 链接 Lb 中剩余结点
FreeNode(ha); FreeNode(hb); // 释放 La 和 Lb 的头结点
return OK;
} // MergeList_L
```

# 算法 2.21

算法2.20和算法2.21分别为算法2.9和算法2.12的改写形式，它们的时间复杂度和前面讨论相同。

# 2.4 一元多项式的表示及相加

符号多项式的操作, 已经成为表处理的典型用例。在数学上, 一个一元多项式  $P_{n}(x)$  可按升幂写成:

$$
P _ {n} (x) = p _ {0} + p _ {1} x + p _ {2} x ^ {2} + \dots + p _ {n} x ^ {n}
$$

它由  $n + 1$  个系数惟一确定。因此，在计算机里，它可用一个线性表  $P$  来表示：

$$
P = \left(p _ {0}, p _ {1}, p _ {2}, \dots , p _ {n}\right)
$$

每一项的指数  $i$  隐含在其系数  $p_i$  的序号里。

假设  $Q_{m}(x)$  是一元  $m$  次多项式，同样可用线性表  $Q$  来表示：

$$
Q = \left(q _ {0}, q _ {1}, q _ {2}, \dots , q _ {m}\right)
$$

不失一般性，设  $m < n$  ，则两个多项式相加的结果  $R_{n}(x) = P_{n}(x) + Q_{m}(x)$  可用线性表  $R$  表示：

$$
R = \left(p _ {0} + q _ {0}, p _ {1} + q _ {1}, p _ {2} + q _ {2}, \dots , p _ {m} + q _ {m}, p _ {m + 1}, \dots , p _ {n}\right)
$$

显然，我们可以对  $P, Q$  和  $R$  采用顺序存储结构，使得多项式相加的算法定义十分简洁。至此，一元多项式的表示及相加问题似乎已经解决了。然而，在通常的应用中，多项式的次数可能很高且变化很大，使得顺序存储结构的最大长度很难确定。特别是在处理

式的次数可能很高且变化很大，使得顺序存储结构的最大长度很难确定。特别是在处理形如

$$
S (x) = 1 + 3 x ^ {1 0 0 0 0} + 2 x ^ {2 0 0 0 0}
$$

的多项式时, 就要用一长度为 20001 的线性表来表示, 表中仅有 3 个非零元素, 这种对内存空间的浪费是应当避免的, 但是如果只存储非零系数项则显然必须同时存储相应的指数。

一般情况下的一元  $n$  次多项式可写成

$$
P _ {n} (x) = p _ {1} x ^ {e _ {1}} + p _ {2} x ^ {e _ {2}} + \dots + p _ {m} x ^ {e _ {m}} \tag {2-7}
$$

其中，  $p_i$  是指数为  $e_i$  的项的非零系数，且满足

$$
0 \leqslant e _ {1} <   e _ {2} <   \dots <   e _ {m} = n
$$

若用一个长度为  $m$  且每个元素有两个数据项（系数项和指数项）的线性表

$$
\left(\left(p _ {1}, e _ {1}\right), \left(p _ {2}, e _ {2}\right), \dots , \left(p _ {m}, e _ {m}\right)\right) \tag {2-8}
$$

便可惟一确定多项式  $P_{n}(x)$  。在最坏情况下， $n + 1 (= m)$  个系数都不为零，则比只存储每项系数的方案要多存储一倍的数据。但是，对于  $S(x)$  类的多项式，这种表示将大大节省空间。

对应于线性表的两种存储结构，由式(2-8)定义的一元多项式也可以有两种存储表示方法。在实际的应用程序中取用哪一种，则要视多项式作何种运算而定。若只对多项式进行“求值”等不改变多项式的系数和指数的运算，则采用类似于顺序表的顺序存储结构即可，否则应采用链式存储表示。本节中将主要讨论如何利用线性链表的基本操作来实现一元多项式的运算。

抽象数据类型一元多项式的定义如下：

```txt
ADT Polynomial{数据对象：  $\mathsf{D} = \{\mathsf{a}_{\mathrm{i}}|\mathsf{a}_{\mathrm{i}}\in \mathsf{TermSet},\mathsf{i} = 1,2,\dots ,\mathsf{m},\quad \mathsf{m}\geqslant 0$  TermSet中的每个元素包含一个表示系数的实数和表示指数的整数}
```

数据关系：  $\mathbb{R}1 = \{\langle a_{i - 1},a_i\rangle |a_{i - 1},a_i\in D$  ，且  $a_{i - 1}$  中的指数值  $<  a_{i}$  中的指数值，  $i = 2,\dots ,n\}$  基本操作：

```txt
CreatPolyn  $(\& P,\mathfrak{m})$    
操作结果：输入  $\mathfrak{m}$  项的系数和指数，建立一元多项式P。DestroyPolyn  $(\& P)$
```

初始条件：一元多项式  $\mathbb{P}$  已存在。

```txt
操作结果：销毁一元多项式P。PrintPolyn（P）
```

初始条件：一元多项式  $\mathbb{P}$  已存在。

```txt
操作结果：打印输出一元多项式P。PolynLength(P)
```

初始条件：一元多项式  $\mathbb{P}$  已存在。

操作结果：返回一元多项式  $\mathbb{P}$  中的项数。

```txt
AddPolyn ( &Pa, &Pb)
```

初始条件：一元多项式Pa和Pb已存在。

操作结果：完成多项式相加运算，即：  $\mathrm{Pa} = \mathrm{Pa} + \mathrm{Pb}$  ，并销毁一元多项式  $\mathbf{Pb}$  。

```txt
SubtractPolyn ( &Pa, &Pb)
```

操作结果：完成多项式相减运算，即：  $\mathrm{Pa} = \mathrm{Pa} - \mathrm{Pb}$ ，并销毁一元多项式  $\mathrm{Pb}$ 。

MultiplyPolyn ( &Pa, &Pb)

初始条件：一元多项式Pa和Pb已存在。

操作结果：完成多项式相乘运算，即：  $\mathrm{Pa} = \mathrm{Pa}\times \mathrm{Pb}$  ，并销毁一元多项式Pb。

ADT Polynomial

实现上述定义的一元多项式，显然应采用链式存储结构。例如，图2.17中的两个线性链表分别表示一元多项式  $A_{17}(x) = 7 + 3x + 9x^8 + 5x^{17}$  和一元多项式  $B_8(x) = 8x + 22x^7 - 9x^8$  。从图中可见，每个结点表示多项式中的一项。

![](images/33a8c298f49de87ac2e3bffaafdf13cd805ab5cb0b33bd85407914b3a2acfbcb.jpg)  
图2.17 多项式表的单链存储结构

如何实现用这种线性链表表示的多相式的加法运算？

根据一元多项式相加的运算规则：对于两个一元多项式中所有指数相同的项，对应系数相加，若其和不为零，则构成“和多项式”中的一项；对于两个一元多项式中所有指数不相同的项，则分别复抄到“和多项式”中去。

在此，按照上述抽象数据类型Polynomial中基本操作的定义，“和多项式”链表中的结点无需另生成，而应该从两个多项式的链表中摘取。其运算规则如下：假设指针qa和qb分别指向多项式A和多项式B中当前进行比较的某个结点，则比较两个结点中的指数项，有下列3种情况：①指针qa所指结点的指数值  $<$  指针qb所指结点的指数值，则应摘取qa指针所指结点插入到“和多项式"链表中去；②指针qa所指结点的指数值  $\rightharpoondown$  指针qb所指结点的指数值，则应摘取指针qb所指结点插入到“和多项式"链表中去；③指针qa所指结点的指数值  $=$  指针qb所指结点的指数值，则将两个结点中的系数相加，若和数不为零，则修改qa所指结点的系数值，同时释放qb所指结点；反之，从多项式A的链表中删除相应结点，并释放指针qa和qb所指结点。例如，由图2.17中的两个链表表示的多项式相加得到的“和多项式"链表如图2.18所示，图中的长方框表示已被释放的结点。

![](images/5b3fdd3f60986c74b0be5545d9d2657385abdf2941136edd65e6d82b2f86bab9.jpg)  
图2.18 相加得到的和多项式

上述多项式的相加过程和上一节讨论的归并两个有序表的过程极其类似，不同之处仅在于，后者在比较数据元素时只出现两种情况。因此，多项式相加的过程也完全可以利用线性链表的基本操作来完成。

需要附加说明的是，在2.3节末定义的线性链表类型适用于一般的线性表，而表示一元多项式的应该是有序链表。有序链表的基本操作定义与线性链表有两处不同，一是

元多项式的应该是有序链表。有序链表的基本操作定义与线性链表有两处不同，一是LocateElem的职能不同，二是需增加按有序关系进行插入的操作OrderInsert，现说明如下：

```txt
Status LocateElem(LinkListL, ElemType e, Position&q, int(*compare)(ElemType, ElemType)); //若有序链表L中存在与e满足判定函数compare()取值为0的元素，则q指示L中第一个//值为e的结点的位置，并返回TRUE;否则q指示第一个与e满足判定函数compare()取//值>0的元素的前驱的位置，并返回FALSE  
StatusOrderInsert(LinkList&L, ElemType e,int(*compare)(ElemType, ElemType)); //按有序判定函数compare()的约定，将值为e的结点插入到有序链表L的适当位置上
```

# 例2-4 抽象数据类型Polynomial的实现。

```txt
typedef struct{ //项的表示，多项式的项作为LinkList的数据元素float coef; //系数int  $\mathbf{expn}$  //指数}term，ElemType；//两个类型名：term用于本ADT,ElemType为LinkList的数据对象名typedef LinkList polynomial; //用带表头结点的有序链表表示多项式  
//---基本操作的函数原型说明---void CreatPolyn（polynomial&P,int m）;//输入m项的系数和指数，建立表示一元多项式的有序链表PvoidDestroyPolyn（polynomial&P);//销毁一元多项式Pvoid PrintPolyn（polynomial P);//打印输出一元多项式Pint PolynLength（polynomial P);//返回一元多项式P中的项数void AddPolyn（polynomial&Pa，polynomial&Pb）;//完成多项式相加运算，即：  $\mathrm{Pa} = \mathrm{Pa} + \mathrm{Pb}$  ，并销毁一元多项式Pbvoid SubtractPolyn（polynomial&Pa，polynomial&Pb）;//完成多项式相减运算，即：  $\mathrm{Pa} = \mathrm{Pa} - \mathrm{Pb}$  ，并销毁一元多项式Pbvoid MultiplyPolyn（polynomial&Pa，polynomial&Pb）;//完成多项式相乘运算，即：  $\mathrm{Pa} = \mathrm{Pa}\times \mathrm{Pb}$  ，并销毁一元多项式Pb  
//---基本操作的算法描述(部分）--int cmp（term a,term b）;//依a的指数值  $<  <   (\text{或} = )$  （或  $\rightharpoondown$  )b的指数值，分别返回-1、0和+1  
void CreatPolyn（polynomial&P,int m）{//输入m项的系数和指数，建立表示一元多项式的有序链表PInitList(P); h  $=$  GetHead(P);e.coef  $= 0.0$  e.expn  $= -1$  SetCurElem(h,e)；//设置头结点的数据元素for（i=1;i<=m；++i）{//依次输入m个非零项scanf(e.coef,e.expn);if(!LocateElem(P,e,q，\*cmp()））{//当前链表中不存在该指数项if（MakeNode(s,e))InsFirst(q,s)；//生成结点并插入链表}
```

} // CreatPolyn

# 算法 2.22

```txt
void AddPolyn (polynomial &Pa, polynomial &Pb) {
// 多项式加法: Pa = Pa + Pb, 利用两个多项式的结点构成“和多项式”。
ha = GetHead(Pa); hb = GetHead(Pb); // ha 和 hb 分别指向 Pa 和 Pb 的头结点
qa = NextPos(Pa,ha); qb = NextPos(Pb,hb); // qa 和 qb 分别指向 Pa 和 Pb 中当前结点
while (qa && qb) { // qa 和 qb 均非空
    a = GetCurElem(qa); b = GetCurElem(qb); // a 和 b 为两表中当前比较元素
    switch (*cmp(a,b)) {
        case -1; // 多项式 PA 中当前结点的指数值小
        ba = qa; qa = NextPos(Pa,qa); break;
        case 0; // 两者的指数值相等
            sum = a.coef + b.coc;
            if (sum != 0.0) { // 修改多项式 PA 中当前结点的系数值
                SetCurElem(qa,sum); ha = qa; }
            else {
                DelFirst(ha,qa); FreeNode(qa); }
            DelFirst(hb, QB); FreeNode(qb); qb = NextPos(Pb,hb);
            qa = NextPos(Pa,ha); break;
        case 1; // 多项式 PB 中当前结点的指数值小
            DelFirst(hb, QB); InsFirst(ha, QB);
            qb = NextPos(Pb,hb); ha = NextPos(Pa,ha);break;
        } // switch
    } // while
if (!ListEmpty(Pb)) Append(Pa, QB); // 链接 Pb 中剩余结点
FreeNode(hb): // 释放 Pb 的头结点
} // AddPolyn
```

# 算法 2.23

两个一元多项式相乘的算法，可以利用两个一元多项式相加的算法来实现，因为乘法运算可以分解为一系列的加法运算。假设  $A(x)$  和  $B(x)$  为式(2-7)的多项式，则

$$
\begin{array}{l} M (x) = A (x) \times B (x) \\ = A (x) \times \left[ b _ {1} x ^ {e _ {1}} + b _ {2} x ^ {e _ {2}} + \dots + b _ {n} x ^ {e _ {n}} \right] \\ = \sum_ {i = 1} ^ {n} b _ {i} A (x) x ^ {\epsilon_ {i}} \\ \end{array}
$$

其中，每一项都是一个一元多项式。

# 第3章 栈和队列

栈和队列是两种重要的线性结构。从数据结构角度看，栈和队列也是线性表，其特殊性在于栈和队列的基本操作是线性表操作的子集，它们是操作受限的线性表，因此，可称为限定性的数据结构。但从数据类型角度看，它们是和线性表大不相同的两类重要的抽象数据类型。由于它们广泛应用在各种软件系统中，因此在面向对象的程序设计中，它们是多型数据类型。本章除了讨论栈和队列的定义、表示方法和实现外，还将给出一些应用的例子。

# 3.1 栈

# 3.1.1 抽象数据类型栈的定义

栈（stack）是限定仅在表尾进行插入或删除操作的线性表。因此，对栈来说，表尾端有其特殊含义，称为栈顶(top)，相应地，表头端称为栈底(bottom)。不含元素的空表称为空栈。

假设栈  $S = (a_{1}, a_{2}, \dots, a_{n})$ ，则称  $a_{1}$  为栈底元素， $a_{n}$  为栈顶元素。栈中元素按  $a_{1}, a_{2}, \dots, a_{n}$  的次序进栈，退栈的第一个元素应为栈顶元素。换句话说，栈的修改是按后进先出的原则进行的（如图3.1(a)所示）。因此，栈又称为后进先出(last in first out)的线性表(简称LIFO结构)，它的这个特点可用图3.1(b)所示的铁路调度站形象地表示。

(a)  
图3.1 栈  
![](images/2cb92ac5a17995acc8452d19150e1032845cecbbe28f9aeb01eda0f025fb9ca9.jpg)  
（a）栈的示意图；（b）用铁路调度站表示栈

![](images/602ab0e79fe04434950e5bd63899c87e8d0dafe7d2f73a4bf43c5aad3c8c445d.jpg)  
(b)

栈的基本操作除了在栈顶进行插入或删除外，还有栈的初始化、判空及取栈顶元素等。下面给出栈的抽象数据类型的定义：

ADT Stack {

数据对象：  $\mathbf{D} = \{\mathbf{a}_i\mid \mathbf{a}_i\in \mathrm{ElemSet},i = 1,2,\dots ,n,\quad n\geqslant 0\}$

数据关系：  $\mathbb{R}1 = \{\langle <  a_{i - 1},a_i > |a_{i - 1},a_i\in D,i = 2,\dots ,n\}$  约定  $\mathbf{a}_{\mathrm{n}}$  端为栈顶，  $a_1$  端为栈底。

基本操作：

InitStack(&S)

操作结果：构造一个空栈 S。

DestroyStack(&S)

初始条件：栈S已存在。

操作结果：栈S被销毁。

ClearStack(&S)

初始条件：栈S已存在。

操作结果：将S清为空栈。

StackEmpty(S)

初始条件：栈S已存在。

操作结果：若栈S为空栈，则返回TRUE，否则FALSE。

StackLength(S)

初始条件：栈S已存在。

操作结果：返回S的元素个数，即栈的长度。

GetTop(S, &e)

初始条件：栈S已存在且非空。

操作结果：用  $\mathbf{e}$  返回S的栈顶元素。

Push(&S, e)

初始条件：栈S已存在。

操作结果：插入元素e为新的栈顶元素。

Pop(&S, &e)

初始条件：栈S已存在且非空。

操作结果：删除S的栈顶元素，并用e返回其值。

StackTraverse(S,visit())

初始条件：栈S已存在且非空。

操作结果：从栈底到栈顶依次对S的每个数据元素调用函数visit()。一旦visit()失败，则操作失效。

ADT Stack

本书在以后各章中引用的栈大多为如上定义的数据类型，栈的数据元素类型在应用程序内定义，并称插入元素的操作为入栈，删除栈顶元素的操作为出栈。

# 3.1.2 栈的表示和实现

和线性表类似，栈也有两种存储表示方法。

顺序栈, 即栈的顺序存储结构是利用一组地址连续的存储单元依次存放自栈底到栈顶的数据元素, 同时附设指针 top 指示栈顶元素在顺序栈中的位置。通常的习惯做法是以  $\mathrm{top} = 0$  表示空栈, 鉴于 C 语言中数组的下标约定从 0 开始, 则当以 C 作描述语言时, 如此设定会带来很大不便; 另一方面, 由于栈在使用过程中所需最大空间的大小很难估计, 因此, 一般来说, 在初始化设空栈时不应限定栈的最大容量。一个较合理的做法是: 先为栈分配一个基本容量, 然后在应用过程中, 当栈的空间不够使用时再逐段扩大。为此, 可

设定两个常量：STACK_INIT_SIZE(存储空间初始分配量)和STACKINCREMENT（存储空间分配增量），并以下述类型说明作为顺序栈的定义。

```txt
typedef struct {  
    SelemType * base;  
    SelemType * top;  
    int stacksize;  
} SqStack;
```

其中，stacksize 指示栈的当前可使用的最大容量。栈的初始化操作为：按设定的初始分配量进行第一次存储分配，base 可称为栈底指针，在顺序栈中，它始终指向栈底的位置，若 base 的值为 NULL，则表明栈结构不存在。称 top 为栈顶指针，其初值指向栈底，即 top = base 可作为栈空的标记，每当插入新的栈顶元素时，指针 top 增 1；删除栈顶元素时，指针 top 减 1，因此，非空栈中的栈顶指针始终在栈顶元素的下一个位置上。图 3.2 展示了顺序栈中数据元素和栈顶指针之间的对应关系。

![](images/229af32dd7ae2d56fc0adf82b9dd4e872406d857a92bea5e45a7768b13dfbe41.jpg)  
图3.2 栈顶指针和栈中元素之间的关系

以下是顺序栈的模块说明。

```c
//  $= = = = =$  ADTStack的表示与实现  $= = = = =$    
//-----栈的顺序存储表示  
#defineSTACK.INIT.SIZE 100; //存储空间初始分配量  
#defineSTACKINCREMENT 10; //存储空间分配增量  
typedef struct{SElemType \*base; //在栈构造之前和销毁之后，base的值为NULLSElemType \*top; //栈顶指针intstacksize; //当前已分配的存储空间，以元素为单位}SqStack;  
//----基本操作的函数原型说明----  
StatusInitStack(SqStack&S);//构造一个空栈S  
StatusDestroyStack(SqStack&S);//销毁栈S,S不再存在  
StatusClearStack(SqStack&S);//把S置为空栈  
StatusStackEmpty(SqStackS);//若栈S为空栈，则返回TRUE，否则返回FALSE
```

int StackLength (SqStack S);

// 返回 S 的元素个数, 即栈的长度

Status GetTop (SqStack S, SElemType &e);

// 若栈不空, 则用 e 返回 S 的栈顶元素, 并返回 OK; 否则返回 ERROR

Status Push (SqStack &S, SElemType e);

// 插入元素 e 为新的栈顶元素

Status Pop (SqStack &S, SElemType &e);

// 若栈不空, 则删除 S 的栈顶元素, 用 e 返回其值, 并返回 OK; 否则返回 ERROR

Status StackTraverse(SqStack S, Status (*visit)));

// 从栈底到栈顶依次对栈中每个元素调用函数 visit()。一旦 visit() 失败，则操作失败

//----基本操作的算法描述（部分）----

Status InitStack (SqStack &S) {

//构造一个空栈S

S.base  $=$  (SElemType \*)malloc(STACK_INIT_SIZE \* sizeof(SElemType));

if（!S.base）exit(OVERFLOW); //存储分配失败

S.top  $=$  S.base;

S.stacksize  $=$  STACK.INIT.SIZE;

return OK;

```java
} // InitStack

Status GetTop(SqStack S, SElemType &e) {

// 若栈不空, 则用 e 返回 S 的栈顶元素, 并返回 OK; 否则返回 ERROR

if (S.top == S.base) return ERROR;

$\mathbf{e} = \star (\mathbf{S}.top - 1)$

return OK;

} // GetTop

Status Push (SqStack &S, SElemType e) {

//插入元素e为新的栈顶元素

if (S.top - S.base >= S.stacksize) { //栈满，追加存储空间

S.base  $=$  (SElemType \*) realloc(S.base,

(S.stacksize + STACKINCREMENT) * sizeof(SElemType));

if（!S.base）exit（OVERFLOW）; //存储分配失败

S.top = S.base + S.stacksize;

S.stacksize  $+ =$  STACKINCREMENT;

}

$\star S.\mathrm{top} + + = \mathrm{e};$

return OK;

} //Push

Status Pop (SqStack &S, SElemType &e) {

// 若栈不空，则删除 S 的栈顶元素，用 e 返回其值，并返回

OK; 否则返回 ERROR

if (S.top == S.base) return ERROR;

e = * -- S.top;

return OK;

} // Pop

![](images/1ae3ab6ea988ffa467227e3d6c25a1173c0141bd8149e0c48d0912187eab728e.jpg)  
图3.3 链栈示意图

栈的链式表示——链栈如图3.3所示。由于栈的操作是线性表操作的特例，则链栈的操作易于实现，在此不作详细讨论。

# 3.2 栈的应用举例

由于栈结构具有后进先出的固有特性，致使栈成为程序设计中的有用工具。本节将讨论几个栈应用的典型例子。

# 3.2.1 数制转换

十进制数  $N$  和其他  $d$  进制数的转换是计算机实现计算的基本问题, 其解决方法很多, 其中一个简单算法基于下列原理:

$N = (N \operatorname{div} d) \times d + N \bmod d$  （其中： $\operatorname{div}$  为整除运算， $\bmod$  为求余运算）

例如：  $(1348)_{10} = (2504)_{8}$  ，其运算过程如下：

<table><tr><td>N</td><td>N div 8</td><td>N mod 8</td></tr><tr><td>1348</td><td>168</td><td>4</td></tr><tr><td>168</td><td>21</td><td>0</td></tr><tr><td>21</td><td>2</td><td>5</td></tr><tr><td>2</td><td>0</td><td>2</td></tr></table>

假设现要编制一个满足下列要求的程序：对于输入的任意一个非负十进制整数，打印输出与其等值的八进制数。由于上述计算过程是从低位到高位顺序产生八进制数的各个数位，而打印输出，一般来说应从高位到低位进行，恰好和计算过程相反。因此，若将计算过程中得到的八进制数的各位顺序进栈，则按出栈序列打印输出的即为与输入对应的八进制数。

```javascript
void conversion（）{ //对于输入的任意一个非负十进制整数，打印输出与其等值的八进制数InitStack(S); //构造空栈 scanf("%d",N); while(N){ Push(S,N&8);  $\mathrm{N} = \mathrm{N} / 8$  1 } while(!StackEmpty(s)){ Pop(S,e); printf("%d",e); } }//conversion
```

# 算法 3.1

这是利用栈的后进先出特性的最简单的例子。在这个例子中，栈操作的序列是直线

式的, 即先一味地入栈, 然后一味地出栈。也许, 有的读者会提出疑问: 用数组直接实现不也很简单吗? 仔细分析上述算法不难看出, 栈的引入简化了程序设计的问题, 划分了不同的关注层次, 使思考范围缩小了。而用数组不仅掩盖了问题的本质, 还要分散精力去考虑数组下标增减等细节问题。

# 3.2.2 括号匹配的检验

假设表达式中允许包含两种括号：圆括号和方括号，其嵌套的顺序随意，即  $([]()$  或 $\left[\left[\right]\right]$  等为正确的格式，[（）或  $\left[\left(\right)\right.$  或  $(\textbf{\textit{()}})$  均为不正确的格式。检验括号是否匹配的方法可用“期待的急迫程度”这个概念来描述。例如考虑下列括号序列：

[（[]）]

12345678

当计算机接受了第一个括号后，它期待着与其匹配的第八个括号的出现，然而等来的却是第二个括号，此时第一个括号“[”只能暂时靠边，而迫切等待与第二个括号相匹配的、第七个括号“）”的出现，类似地，因等来的是第三个括号“[”，其期待匹配的程度较第二个括号更急迫，则第二个括号也只能靠边，让位于第三个括号，显然第二个括号的期待急迫性高于第一个括号；在接受了第四个括号之后，第三个括号的期待得到满足，消解之后，第二个括号的期待匹配就成为当前最急迫的任务了，……，依次类推。可见，这个处理过程恰与栈的特点相吻合。由此，在算法中设置一个栈，每读入一个括号，若是右括号，则或者使置于栈顶的最急迫的期待得以消解，或者是不合法的情况；若是左括号，则作为一个新的更急迫的期待压入栈中，自然使原有的在栈中的所有未消解的期待的急迫性都降了一级。另外，在算法的开始和结束时，栈都应该是空的。此算法将留给读者作为习题完成。

# 3.2.3 行编辑程序

一个简单的行编辑程序的功能是：接受用户从终端输入的程序或数据，并存入用户的数据区。由于用户在终端上进行输入时，不能保证不出差错，因此，若在编辑程序中，“每接受一个字符即存入用户数据区”的做法显然不是最恰当的。较好的做法是，设立一个输入缓冲区，用以接受用户输入的一行字符，然后逐行存入用户数据区。允许用户输入出差错，并在发现有误时可以及时更正。例如，当用户发现刚刚键入的一个字符是错的时，可补进一个退格符“#”，以表示前一个字符无效；如果发现当前键入的行内差错较多或难以补救，则可以键入一个退行符“@”，以表示当前行中的字符均无效。例如，假设从终端接受了这样两行字符：

```txt
whli # # itr#e(s#  $\ast$  s) outcha@putchar(  $\ast$  s  $=$  #++）;
```

则实际有效的是下列两行：

```txt
while  $(\ast s)$  putchar  $(\ast s + + )$
```

为此，可设这个输入缓冲区为一个栈结构，每当从终端接受了一个字符之后先作如下

判别：如果它既不是退格符也不是退行符，则将该字符压入栈顶；如果是一个退格符，则从栈顶删去一个字符；如果它是一个退行符，则将字符栈清为空栈。上述处理过程可用算法3.2描述。

```javascript
void LineEdit() { //利用字符栈S，从终端接收一行并传送至调用过程的数据区。 InitStack(S); //构造空栈S ch  $=$  getchar(); //从终端接收第一个字符 while  $(\mathrm{ch}! = \mathrm{EOF})$  {//EOF为全文结束符 while  $(\mathrm{ch}! = \mathrm{EOF}\& \& \mathrm{ch}! = '\backslash \mathrm{n}')$  { switch(ch){ case'#:Pop(S,c); break; //仅当栈非空时退栈 case'@:ClearStack(S); break; //重置S为空栈 default:Push(S,ch); break; //有效字符进栈，未考虑栈满情形 } ch  $=$  getchar(); //从终端接收下一个字符 } 将从栈底到栈顶的栈内字符传送至调用过程的数据区； ClearStack(S); //重置S为空栈 if  $(\mathrm{ch}! = \mathrm{EOF})$  ch  $=$  getchar(); } DestroyStack(S); } //LineEdit
```

# 算法 3.2

# 3.2.4 迷宫求解

求迷宫中从入口到出口的所有路径是一个经典的程序设计问题。由于计算机解迷宫

时, 通常用的是“穷举求解”的方法, 即从人口出发, 顺某一方向向前探索, 若能走通, 则继续往前走; 否则沿原路退回, 换一个方向再继续探索, 直至所有可能的通路都探索到为止。为了保证在任何位置上都能沿原路退回, 显然需要用一个后进先出的结构来保存从入口到当前位置的路径。因此, 在求迷宫通路的算法中应用“栈”也就是自然而然的事了。

首先，在计算机中可以用如图3.4所示的方块图表示迷宫。图中的每个方块或为通道（以空白方块表示），或为墙（以带阴影线的方块表示）。所求路径必须是简单路径，即在求得的路径上不能重复出现同一通道块。

![](images/bb191c3ffdaf76d781f6ef813a8bdd1205981f454f46196b97b7c357fe0fb815.jpg)  
图3.4 迷宫

假设“当前位置”指的是“在搜索过程中某一时刻所在图中某个方块位置”，则求迷宫中一条路径的算法的基本思想是：若当前位置“可通”，则纳入“当前路径”，并继续朝“下一位置”探索，即切换“下一位置”为“当前位置”，如此重复直至到达出口；若当前位置“不可

通”，则应顺着“来向”退回到“前一通道块”，然后朝着除“来向”之外的其他方向继续探索；若该通道块的四周4个方块均“不可通”，则应从“当前路径”上删除该通道块。所谓“下一位置”指的是“当前位置”四周4个方向（东、南、西、北）上相邻的方块。假设以栈S记录“当前路径”，则栈顶中存放的是“当前路径上最后一个通道块”。由此，“纳入路径”的操作即为“当前位置入栈”；“从当前路径上删除前一通道块”的操作即为“出栈”。

求迷宫中一条从入口到出口的路径的算法可简单描述如下：

设定当前位置的初值为入口位置；

do{若当前位置可通，  
则{将当前位置插入栈顶； //纳入路径若该位置是出口位置，则结束； //求得路径存放在栈中否则切换当前位置的东邻方块为新的当前位置；否则，若栈不空且栈顶位置尚有其他方向未经探索，则设定新的当前位置为沿顺时针方向旋转找到的栈顶位置的下一相邻块；若栈不空但栈顶位置的四周均不可通，则{删去栈顶位置； //从路径中删去该通道块若栈不空，则重新测试新的栈顶位置，直至找到一个可通的相邻块或出栈至栈空；}while（栈不空）；

在此，尚需说明一点的是，所谓当前位置可通，指的是未曾走到过的通道块，即要求该方块位置不仅是通道块，而且既不在当前路径上（否则所求路径就不是简单路径），也不是曾经纳入过路径的通道块（否则只能在死胡同内转圈）。

typedef struct{ int ord; //通道块在路径上的"序号" PosType seat; //通道块在迷宫中的"坐标位置" int di; //从此通道块走向下一通道块的"方向" }SElemType; //栈的元素类型

Status MazePath（MazeType maze，PosType start，PosType end）{  
//若迷宫maze中存在从入口start到出口end的通道，则求得一条存放在栈中（从栈底到栈  
//顶)，并返回TRUE;否则返回FALSEInitStack(S)；curpos  $\equiv$  start; //设定"当前位置"为"入口位置"curstep  $= 1$  ： //探索第一步do{if（Pass（curpos））{//当前位置可以通过，即是未曾走到过的通道块FootPrint（curpos); //留下足迹e  $=$  （curstep，curpos，1）;Push(S,e); //加入路径if（curpos  $\equiv =$  end）return（TRUE); //到达终点（出口）curpos  $\equiv$  NextPos（curpos，1）; //下一位置是当前位置的东邻curstep++; //探索下一步

```txt
} // if
else { // 当前位置不能通过
if (!StackEmpty(S)) {
Pop (S, e);
while (e.di == 4 && !StackEmpty(S)) {
MarkPrint (e.seat); Pop (S, e); // 留下不能通过的标记，并退回一步
} // while
if (e.di < 4) {
e.di++; Push (S, e); // 换下一个方向探索
curpos = NextPos (e.seat e.di); // 设定当前位置是该新方向上的相邻块
} // if
} // else
} while (!StackEmpty(S));
return (FALSE);
} // MazePath
```

# 算法 3.3

# 3.2.5 表达式求值

表达式求值是程序设计语言编译中的一个最基本问题。它的实现是栈应用的又一个典型例子。这里介绍一种简单直观、广为使用的算法，通常称为“算符优先法”。

要把一个表达式翻译成正确求值的一个机器指令序列, 或者直接对表达式求值, 首先要能够正确解释表达式。例如, 要对下面的算术表达式求值:

$$
4 + 2 \times 3 - 1 0 / 5
$$

首先要了解算术四则运算的规则。即：

（1）先乘除，后加减；  
（2）从左算到右；  
（3）先括号内，后括号外。

由此，这个算术表达式的计算顺序应为

$$
4 + 2 \times 3 - 1 0 / 5 = 4 + 6 - 1 0 / 5 = 1 0 - 1 0 / 5 = 1 0 - 2 = 8
$$

算符优先法就是根据这个运算优先关系的规定来实现对表达式的编译或解释执行的。

任何一个表达式都是由操作数(operand)、运算符 operator)和界限符 ( delimiter) 组成的, 我们称它们为单词。一般地, 操作数既可以是常数也可以是被说明为变量或常量的标识符; 运算符可以分为算术运算符、关系运算符和逻辑运算符 3 类; 基本界限符有左右括号和表达式结束符等。为了叙述的简洁, 我们仅讨论简单算术表达式的求值问题。这种表达式只含加、减、乘、除 4 种运算符。读者不难将它推广到更一般的表达式上。

我们把运算符和界限符统称为算符，它们构成的集合命名为  $OP$  。根据上述3条运算规则，在运算的每一步中，任意两个相继出现的算符  $\theta_{1}$  和  $\theta_{2}$  之间的优先关系至多是下面3种关系之一；

$\theta_{1} < \theta_{2}$ $\theta_{1}$  的优先权低于  $\theta_{2}$

$\theta_{1} = \theta_{2}$ $\theta_{1}$  的优先权等于  $\theta_{2}$

$\theta_{1} > \theta_{2}$ $\theta_{1}$  的优先权高于  $\theta_{2}$

表3.1定义了算符之间的这种优先关系。

表 3.1 算符间的优先关系  

<table><tr><td>θ2θ1</td><td>+</td><td>-</td><td>*</td><td>/</td><td>(</td><td>)</td><td>#</td></tr><tr><td>+</td><td>&gt;</td><td>&gt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&gt;</td><td>&gt;</td></tr><tr><td>-</td><td>&gt;</td><td>&gt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&gt;</td><td>&gt;</td></tr><tr><td>*</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td>&lt;</td><td>&gt;</td><td>&gt;</td></tr><tr><td>/</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td>&lt;</td><td>&gt;</td><td>&gt;</td></tr><tr><td>(</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>±</td><td></td></tr><tr><td>)</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td>&gt;</td><td></td><td>&gt;</td><td>&gt;</td></tr><tr><td>#</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td>&lt;</td><td></td><td>=</td></tr></table>

由规则(3)，+、一、*和/为  $\theta_{1}$  时的优先性均低于“（"但高于“）”，由规则(2)，当  $\theta_{1} =$ $\theta_{2}$  时，令  $\theta_{1} > \theta_{2}$  ，“#”是表达式的结束符。为了算法简洁，在表达式的最左边也虚设一个“#”构成整个表达式的一对括号。表中的“  $(\mathbf{\theta}) = \mathbf{\theta})$  ”表示当左右括号相遇时，括号内的运算已经完成。同理，“#”  $=$  “#”表示整个表达式求值完毕。“)”与“（"、“#”与“）”以及“（"与“#”之间无优先关系，这是因为表达式中不允许它们相继出现，一旦遇到这种情况，则可以认为出现了语法错误。在下面的讨论中，我们暂假定所输入的表达式不会出现语法错误。

为实现算符优先算法，可以使用两个工作栈。一个称做OPTR，用以寄存运算符；另一个称做OPND，用以寄存操作数或运算结果。算法的基本思想是：

（1）首先置操作数栈为空栈，表达式起始符“#”为运算符栈的栈底元素；  
(2) 依次读入表达式中每个字符, 若是操作数则进 OPND 栈, 若是运算符则和 OPTR 栈的栈顶运算符比较优先权后作相应操作, 直至整个表达式求值完毕 (即 OPTR 栈的栈顶元素和当前读入的字符均为“#”)。

算法3.4描述了这个求值过程。

```javascript
OperandType EvaluateExpression() { // 算术表达式求值的算符优先算法。设OPTR和OPND分别为运算符栈和运算数栈， // OP为运算符集合。 InitStack(OPTR); Push(OPTR,'#'); initStack(OPND); c = getchar(); while  $(c! = '\# '||$  GetTop(OPTR)!='#') { if(!In(c,OP)){Push((OPND,c);c = getchar();} //不是运算符则进栈 else switch(Precede(GetTop(OPTR),c)){ case  $<  <   :$  //栈顶元素优先权低 Push(OPTR,c)；c = getchar(); break; case  $= ^{\prime}$  ：//脱括号并接收下一字符 Pop(OPTR,x); c = getchar(); break;
```

```txt
case  $^\prime >$  ：//退栈并将运算结果入栈Pop(OPTR，theta);Pop(OPND，b)；Pop(OPND，a);Push(OPND，Operate(a，theta，b));break;}//switch} //whilereturnGetTop(OPND);}//EvaluateExpression
```

# 算法 3.4

算法中还调用了两个函数。其中Precede是判定运算符栈的栈顶运算符  $\theta_{1}$  与读入的运算符  $\theta_{2}$  之间优先关系的函数；Operate为进行二元运算  $a\theta b$  的函数，如果是编译表达式，则产生这个运算的一组相应指令并返回存放结果的中间变量名；如果是解释执行表达式，则直接进行该运算，并返回运算的结果。

例3-1利用算法EvaluateExpressionreduced对算术表达式  $3*(7 - 2)$  求值，操作过程如下所示。

<table><tr><td>步骤</td><td>OPTR栈</td><td>OPND栈</td><td>输入字符</td><td>主要操作</td></tr><tr><td>1</td><td>#</td><td></td><td>3*(7-2)#</td><td>PUSH(OPND,&#x27;3&#x27;)</td></tr><tr><td>2</td><td>#</td><td>3</td><td>*(7-2)#</td><td>PUSH(OPTR,&#x27;*&#x27;)</td></tr><tr><td>3</td><td>#*</td><td>3</td><td>(7-2)#</td><td>PUSH(OPTR,&#x27;(&#x27;)</td></tr><tr><td>4</td><td>#*(</td><td>3</td><td>7-2)#</td><td>PUSH(OPND,&#x27;7&#x27;)</td></tr><tr><td>5</td><td>#*(</td><td>37</td><td>-2)#</td><td>PUSH(OPTR,&#x27;--&#x27;)</td></tr><tr><td>6</td><td>#*(--</td><td>37</td><td>2)#</td><td>PUSH(OPND,&#x27;2&#x27;)</td></tr><tr><td>7</td><td>#*(--</td><td>372</td><td>2)#</td><td>operate(&#x27;7&#x27;,&#x27;--&#x27;, &#x27;2&#x27;)</td></tr><tr><td>8</td><td>#*(</td><td>35</td><td>) #</td><td>POP(OPTR){消去一对括号}</td></tr><tr><td>9</td><td>#*</td><td>35</td><td>#</td><td>operate(&#x27;3&#x27;,&#x27;*&#x27;,&#x27;5&#x27;)</td></tr><tr><td>10</td><td>#</td><td>15</td><td>#</td><td>RETURN(GETTOP(OPND))</td></tr></table>

# 3.3 栈与递归的实现

栈还有一个重要应用是在程序设计语言中实现递归。一个直接调用自己或通过一系列的调用语句间接地调用自己的函数，称做递归函数。

递归是程序设计中一个强有力的工具。其一，有很多数学函数是递归定义的，如大家熟悉的阶乘函数

$$
\operatorname {F a c t} (n) = \left\{ \begin{array}{l l} 1 & \text {若} n = 0 \\ n \cdot \operatorname {F a c t} (n - 1) & \text {若} n > 0 \end{array} \right. \tag {3-1}
$$

2阶 Fibonacci数列

$$
\operatorname {F i b} (n) = \left\{ \begin{array}{l l} 0 & \text {若} n = 0 \\ 1 & \text {若} n = 1 \\ \operatorname {F i b} (n - 1) + \operatorname {F i b} (n - 2) & \text {其 他 情 形} \end{array} \right. \tag {3-2}
$$

和Ackerman函数

$$
\operatorname {A c k} (m, n) = \left\{ \begin{array}{l l} n + 1 & \text {若} m = 0 \\ \operatorname {A c k} (m - 1, 1) & \text {若} n = 0 \\ \operatorname {A c k} (m - 1, \operatorname {A c k} (m, n - 1)) & \text {其 他 情 形} \end{array} \right. \tag {3-3}
$$

等;其二,有的数据结构,如二叉树、广义表等,由于结构本身固有的递归特性,则它们的操作可递归地描述;其三,还有一类问题,虽然问题本身没有明显的递归结构,但用递归求解比迭代求解更简单,如八皇后问题、Hanoi塔问题等。

例3-2（ $n$  阶Hanoi塔问题)假设有3个分别命名为X、Y和Z的塔座，在塔座X上

![](images/388986163ef5f158c0e261d28efd89830653968423592353ec78dcc03b382ab6.jpg)  
图3.5 3阶Hanoi塔问题的初始状态

插有  $n$  个直径大小各不相同、依小到大编号为  $1,2,\dots ,n$  的圆盘(如图3.5所示)。现要求将  $\mathbf{X}$  轴上的  $n$  个圆盘移至塔座Z上并仍按同样顺序叠排，圆盘移动时必须遵循下列规则：

（1）每次只能移动一个圆盘；  
（2）圆盘可以插在  $\mathbf{X},\mathbf{Y}$  和  $\mathbf{Z}$  中的任一塔座上；  
（3）任何时刻都不能将一个较大的圆盘压在较小的圆盘之上。

如何实现移动圆盘的操作呢？当  $n = 1$  时，问题比较简单，只要将编号为1的圆盘从塔座X直接移至塔座Z上即可；当  $n > 1$  时，需利用塔座Y作辅助塔座，若能设法将压在编号为  $\pmb{n}$  的圆盘之上的  $n - 1$  个圆盘从塔座X(依照上述法则)移至塔座Y上，则可先将编号为  $\pmb{n}$  的圆盘从塔座X移至塔座Z上，然后再将塔座Y上的  $n - 1$  个圆盘（依照上述法则）移至塔座Z上。而如何将  $n - 1$  个圆盘从一个塔座移至另一个塔座的问题是一个和原问题具有相同特征属性的问题，只是问题的规模小1，因此可以用同样的方法求解。由此可得如算法3.5所示的求解  $\pmb{n}$  阶Hanoi塔问题的C函数。

```txt
void hanoi(int n, char x, char y, char z) //将塔座  $\pmb{x}$  上按直径由小到大且自上而下编号为1至n的n个圆盘按规则搬到//塔座z上，y可用作辅助塔座。 //搬动操作move(x,n,z）可定义为(c是初值为0的全局变量，对搬动计数）：//printf("%i.Moveldisk%ifrom%c to%c\n"，++c，n,x,z);  
1{  
2 if  $(\mathfrak{n} = = 1)$    
3 move(x,1,z); //将编号为1的圆盘从  $\mathbf{x}$  移到z  
4 else{  
5 hanoi(n-1,x,z,y); //将  $\mathbf{x}$  上编号为1至n-1的圆盘移到y，z作辅助塔  
6 move(x,n,z); //将编号为n的圆盘从  $\mathbf{x}$  移到z  
7 hanoi(n-1,y,x,z); //将y上编号为1至n-1的圆盘移到z，x作辅助塔  
8 }  
9}
```

# 算法 3.5

显然，这是一个递归函数，在函数的执行函数中，需多次进行自我调用。那末，这个递归函数是如何执行的？先看任意两个函数之间进行调用的情形。

与汇编程序设计中主程序和子程序之间的链接及信息交换相类似，在高级语言编制

的程序中，调用函数和被调用函数①之间的链接及信息交换需通过栈来进行。

通常，当在一个函数的运行期间调用另一个函数时，在运行被调用函数之前，系统需先完成3件事：(1)将所有的实在参数、返回地址等信息传递给被调用函数保存；(2)为被调用函数的局部变量分配存储区；(3)将控制转移到被调函数的入口。而从被调用函数返回调用函数之前，系统也应完成3件工作：(1)保存被调函数的计算结果；(2)释放被调函数的数据区；(3)依照被调函数保存的返回地址将控制转移到调用函数。当有多个函数构成嵌套调用时，按照“后调用先返回”的原则，上述函数之间的信息传递和控制转移必须通过“栈”来实现，即系统将整个程序运行时所需的数据空间安排在一个栈中，每当调用一个函数时，就为它在栈顶分配一个存储区，每当从一个函数退出时，就释放它的存储区，则当前正运行的函数的数据区必在栈顶。例如，在图3.6(c)所示主函数main中调用了函数first，而在函数first中又调用了函数second，则图3.6(a)展示了当前正在执行函数second中某个语句时栈的状态，而图3.6(b)展示从函数second退出之后正执行函数first中某个语句时栈的状态（图中以语句标号表示返回地址）。

![](images/9e042ad7f5c5d1f6636b6dab3aa8cd1083567f9c26c2372e82e0106230f5a7c0.jpg)  
(a)

![](images/f8d71ceda37ee9a646f4f790429aefbcf1e275fd283461cde2442f700f4735d1.jpg)

![](images/541248ba58a4eedb21022deb35db8591bad48d5eb8258737c8a2ef34a1cae91f.jpg)  
(c)

![](images/b90a5e4ef3ef8deb7499ce442664a50871280d1aa46ba90ca5ee8fc6fffa78f6.jpg)  
(b)  
图3.6 主函数main执行期间运行栈的状态

一个递归函数的运行过程类似于多个函数的嵌套调用，只是调用函数和被调用函数是同一个函数，因此，和每次调用相关的一个重要的概念是递归函数运行的“层次”。假设调用该递归函数的主函数为第0层，则从主函数调用递归函数为进入第1层；从第  $i$  层递归调用本函数为进入“下一层”，即第  $i + 1$  层。反之，退出第  $i$  层递归应返回至“上一层”，

即第  $i - 1$  层。为了保证递归函数正确执行，系统需设立一个“递归工作栈”①作为整个递归函数运行期间使用的数据存储区。每一层递归所需信息构成一个“工作记录”，其中包括所有的实在参数、所有的局部变量以及上一层的返回地址。每进入一层递归，就产生一个新的工作记录压入栈顶。每退出一层递归，就从栈顶弹出一个工作记录，则当前执行层的工作记录必是递归工作栈栈顶的工作记录，称这个记录为“活动记录”，并称指示活动记录的栈顶指针为“当前环境指针”。

例如，图3.7展示了语句

$$
\operatorname {h a n o i} (3, \mathrm {a}, \mathrm {b}, \mathrm {c}) \tag {3-4}
$$

执行过程(从主函数进入递归函数到退出递归函数而返回至主函数)中递归工作栈状态的变化情况。由于算法3.5所示的递归函数中只含4个值参数，则每个工作记录包含5个数据项：返回地址和4个实在参数，并以递归函数中的语句行号表示返回地址，同时假设主函数的返回地址为0。图3.7中  $\triangleright$  表示栈顶指针。

实际上，在调用函数和被调用函数之间不一定传递参数的值，也可以传递参数的地址。通常，每个程序设计语言都有它自己约定的传递方法（包括被调用函数的执行结果如何返回调用函数等），读者将会在后续课程中学到其细节。

由于递归函数结构清晰，程序易读，而且它的正确性容易得到证明，因此，利用允许递归调用的语言（例如C语言）进行程序设计时，给用户编制程序和调试程序带来很大方便。因为对这样一类递归问题编程时，不需用户自己而由系统来管理递归工作栈。

![](images/fdcd2a0d711e7e021f53472b7b9318d54da5371da17b19b8eae8b6c081f1aa78.jpg)  
图3.7 Hanoi塔的递归函数运行示意图

<table><tr><td>递归运行的层次</td><td>运行语句行号</td><td>递归工作栈状态(返址,n值,x值,y值,z值)</td><td>塔与圆盘的状态</td><td>说 明</td></tr><tr><td>3</td><td>1,2,3,9</td><td>8,1,c,a,b6,2,a,c,b0,3,a,b,c</td><td rowspan="2">a b c3 2</td><td>将1号圆盘由c移至b后,从语句(行)9退出第三层,返回至第二层的语句(行)8。</td></tr><tr><td>2</td><td>8,9</td><td>6,2,a,c,b0,3,a,b,c</td><td>从语句(行)9退出第二层,返回至第一层的语句(行)6。</td></tr><tr><td>1</td><td>6,7</td><td>0,3,a,b,c</td><td rowspan="2">a b c2 3</td><td>将3号圆盘由a移至c后,从语句(行)7进入下一层递归。</td></tr><tr><td>2</td><td>1,2,4,5</td><td>8,2,b,a,c0,3,a,b,c</td><td>从第二层的语句(行)5进入第三层递归。</td></tr><tr><td>3</td><td>1,2,3,9</td><td>6,1,b,c,a8,2,b,a,c0,3,a,b,c</td><td>a b c1 2 3</td><td>将1号圆盘由b移至a后,从语句(行)9退出第三层递归,返回至第二层语句(行)6。</td></tr><tr><td>2</td><td>6,7</td><td>8,2,b,a,c0,3,a,b,c</td><td>a b c1 2 3</td><td>将2号圆盘由b移至c后,从语句(行)7进入下一层递归。</td></tr><tr><td>3</td><td>1,2,3,9</td><td>8,1,a,b,c8,2,b,a,c0,3,a,b,c</td><td rowspan="4">a b c2 3</td><td>将1号圆盘由a移至c后,从语句(行)9退出第三层,返回至第二层语句(行)8。</td></tr><tr><td>2</td><td>8,9</td><td>8,2,b,a,c0,3,a,b,c</td><td>从语句(行)9退出第二层,返回至第一层语句(行)8。</td></tr><tr><td>1</td><td>8,9</td><td>0,3,a,b,c</td><td>从语句(行)9退出递归函数,返回至主函数。</td></tr><tr><td>0</td><td></td><td>栈空</td><td>继续运行主函数。</td></tr></table>

图3.7（续）

# 3.4 队列

# 3.4.1 抽象数据类型队列的定义

和栈相反，队列(queue)是一种先进先出(first in first out,缩写为FIFO)的线性表。它只允许在表的一端进行插入，而在另一端删除元素。这和我们日常生活中的排队是一

致的, 最早进入队列的元素最早离开。在队列中, 允许插入的一端叫做队尾(rear), 允许

删除的一端则称为队头(front)。假设队列为  $q = (a_{1}, a_{2}, \dots, a_{n})$ ，那么， $a_{1}$  就是队头元素， $a_{n}$  则是队尾元素。队列中的元素是按照  $a_{1}, a_{2}, \dots, a_{n}$  的顺序进入的，退出队列也只能按照这个次序依次退出，也就是说，只有在  $a_{1}, a_{2}, \dots, a_{n-1}$  都离开队列之后， $a_{n}$  才能退出队列。图3.8是队列的示意图。

![](images/657c3bc976c6363b3989ed8c75b16d186b28ad8b8a650f28588fa5a80d29cb3b.jpg)  
图3.8 队列的示意图

队列在程序设计中也经常出现。一个最典型的例子就是操作系统中的作业排队。在允许多道程序运行的计算机系统中，同时有几个作业运行。如果运行的结果都需要通过通道输出，那就要按请求输出的先后次序排队。每当通道传输完毕可以接受新的输出任务时，队头的作业先从队列中退出作输出操作。凡是申请输出的作业都从队尾进入队列。

队列的操作与栈的操作类似，也有8个，不同的是删除是在表的头部(即队头)进行。

下面给出队列的抽象数据类型定义：

```javascript
ADT Queue{数据对象：  $\mathsf{D} = \{\mathsf{a}_{\mathsf{i}}|\mathsf{a}_{\mathsf{i}}\in \mathsf{ElemSet},\mathsf{i} = 1,2,\dots ,\mathsf{n},\mathsf{n}\geqslant 0\}$  数据关系：  $\mathbb{R}1 = \{\langle a_{i - 1},a_i\rangle |a_{i - 1},a_i\in D,i = 2,\dots ,n\}$  约定其中  $a_1$  端为队列头，  $a_{n}$  端为队列尾。
```

基本操作：

```txt
InitQueue(&Q)操作结果：构造一个空队列Q。  
DestroyQueue(&Q)初始条件：队列Q已存在。操作结果：队列Q被销毁，不再存在。  
ClearQueue(&Q)初始条件：队列Q已存在。操作结果：将Q清为空队列。  
QueueEmpty(Q)初始条件：队列Q已存在。操作结果：若Q为空队列，则返回TRUE，否则FALSE。QueueLength(Q)初始条件：队列Q已存在。操作结果：返回Q的元素个数，即队列的长度。GetHead(Q, &e)初始条件：Q为非空队列。操作结果：用e返回Q的队头元素。EnQueue(&Q, e)初始条件：队列Q已存在。操作结果：插入元素e为Q的新的队尾元素。DeQueue(&Q, &e)初始条件：Q为非空队列。操作结果：删除Q的队头元素，并用e返回其值。
```

QueueTraverse(Q,visit())

初始条件：Q已存在且非空。

操作结果：从队头到队尾，依次对  $Q$  的每个数据元素调用函数 visit()。一旦 visit() 失败，则操作失败。

}ADT Queue

和栈类似，在本书以后各章中引用的队列都应是如上定义的队列类型。队列的数据元素类型在应用程序内定义。

除了栈和队列之外，还有一种限定性数据结构是双端队列(deque)。

双端队列是限定插入和删除操作在表的两端进行的线性表。这两端分别称做端点1和端点2(如图3.9(a)所示)。也可像栈一样，可以用一个铁道转轨网络来比喻双端队列，如图3.9(b)所示。在实际使用中，还可以有输出受限的双端队列（即一个端点允许插入和删除，另一个端点只允许插入的双端队列）和输入受限的双端队列（即一个端点允许插入和删除，另一个端点只允许删除的双端队列）。而如果限定双端队列从某个端点插入的元素只能从该端点删除，则该双端队列就蜕变为两个栈底相邻接的栈了。

图3.9 双端队列示意图  
![](images/fb60525fb7ebcaef290693d7fb0b5ca57da7743ebe02f2b7ecc99d4cd945459e.jpg)  
（a）双端队列； （b）铁道转轨网

尽管双端队列看起来似乎比栈和队列更灵活，但实际上在应用程序中远不及栈和队列有用，故在此不作详细讨论。

# 3.4.2 链队列——队列的链式表示和实现

和线性表类似，队列也可以有两种存储表示。

用链表表示的队列简称为链队列，如图3.10所示。一个链队列显然需要两个分别指示队头和队尾的指针（分别称为头指针和尾指针）才能惟一确定。这里，和线性表的单链表一样，为了操作方便起见，我们也给链队列添加一个头结点，并令头指针指向头结点。由此，空的链队列的判决条件为头指针和尾指针均指向头结点，如图3.11(a)所示。

链队列的操作即为单链表的插入和删除操作的特殊情况，只是尚需修改尾指针或头指针，图3.11(b)～(d)展示了这两种操作进行时指针变化的情况。下面给出链队列类型的模块说明。

![](images/4da0abfbb1cd038a286b1df3627c8750d8f99604b98d63915ad8e39799440854.jpg)  
图3.10 链队列示意图

![](images/00bfa0d704dcefb52ce6b59f29eaf04ae660267b84076f09de198028678aa153.jpg)  
(a)

![](images/f7800d3bc75f25ed0577c585ebbd3d1ec76a1153bcaf88fb7888dffac735c2b4.jpg)  
(b)

![](images/857a7a29713acb6b5bcabd76f7e85ab541aebdfffb71a196e2d6b7c1b0f9345c.jpg)

![](images/21c44f277ba5e34a5591f7e0c16c0202eb9740fa96981b343dc09156fa5309dc.jpg)  
(d)  
图3.11 队列运算指针变化状况

(a) 空队列； (b) 元素  $\mathbf{x}$  入队列；

(c) 元素  $\mathbf{y}$  入队列；(d) 元素  $\mathbf{x}$  出队列

```javascript
//  $= = = = =$  ADT Queue 的表示与实现  $= = = = =$
```

```scss
//----单链队列——队列的链式存储结构----
```

```txt
typedef struct QNode{
```

```txt
QElonType data;
```

```txt
struct QNode \* next;
```

```txt
}QNode, * QueuePtr;
```

```txt
typedef struct{
```

```javascript
QueuePtr front; // 队头指针
```

```txt
QueuePtr rear; // 队尾指针
```

```txt
}LinkQueue;
```

```txt
// - - - - 基本操作的函数原型说明 - - - -
```

```autoit
Status InitQueue(LinkQueue &Q)
```

```txt
//构造一个空队列Q
```

```autoit
Status DestroyQueue(LinkQueue &Q)
```

```txt
//销毁队列Q，Q不再存在
```

```txt
Status ClearQueue(LinkQueue &Q)
```

```txt
//将Q清为空队列
```

```txt
Status QueueEmpty (LinkQueue Q)
```

```txt
// 若队列 Q 为空队列, 则返回 TRUE, 否则返回 FALSE
```

```txt
int QueueLength (LinkQueue Q)
```

```txt
//返回  $\mathbb{Q}$  的元素个数，即为队列的长度
```

```txt
Status GetHead(LinkQueue Q, QElemType &e)
```

```txt
// 若队列不空，则用 e 返回 Q 的队头元素，并返回 OK；否则返回 ERROR
```

```txt
Status EnQueue(LinkQueue &Q, QElemType e)
```

```txt
//插入元素e为Q的新的队尾元素
```

```txt
Status DeQueue(LinkQueue &Q, QElemType &e)
```

```txt
// 若队列不空，则删除  $Q$  的队头元素，用  $\mathbf{e}$  返回其值，并返回 OK；
```

```txt
// 否则返回 ERROR
```

Status QueueTraverse(LinkQueue Q, visit())

// 从队头到队尾依次对队列Q中每个元素调用函数visit()。一旦visit失败，则操作失败。

// - - - - 基本操作的算法描述（部分）

```c
Status InitQueue(LinkQueue&Q){ //构造一个空队列Q Q.front  $=$  Q.rear  $=$  (QueuePtr)malloc(sizeof(QNode)); if(!Q.front)exit(OVERFLOW); //存储分配失败 Q.front->next  $\equiv$  NULL; return OK;   
1
```

StatusDestroyQueue(LinkQueue&Q）{//销毁队列Q

```javascript
while (Q.front) { Q.rear  $=$  Q.front->next; free(Q.front); Q.front  $=$  Q.rear;   
}   
return OK;
```

```c
StatusEnQueue(LinkQueue&Q, QElemType e) { //插入元素e为Q的新的队尾元素 p = (QueuePtr) malloc(sizeof(QNode)); if(!p) exit(OVERFLOW); //存储分配失败 p->data = e; p->next = NULL; Q.rear->next = p; Q.rear = p; return OK; }
```

Status DeQueue(LinkQueue&Q, QElemType&e) {
// 若队列不空，则删除Q的队头元素，用e返回其值，并返回OK;

//否则返回ERROR

if (Q.front == Q.rear) return ERROR;

$\mathbf{p} = \mathbf{Q}$  .front->next;

$\mathbf{e} = \mathbf{p} - >$  data;

Q.front->next  $=$  p->next;

if (Q.rear = p) Q.rear = Q.front;

free (p);

return OK;

在上述模块的算法描述中, 请读者注意删除队列头元素算法中的特殊情况。一般情况下, 删除队列头元素时仅需修改头结点中的指针, 但当队列中最后一个元素被删后, 队

列尾指针也丢失了，因此需对队尾指针重新赋值（指向头结点）。

# 3.4.3 循环队列——队列的顺序表示和实现

和顺序栈相类似，在队列的顺序存储结构中，除了用一组地址连续的存储单元依次存放从队列头到队列尾的元素之外，尚需附设两个指针 front 和 rear 分别指示队列头元素及队列尾元素的位置。为了在 C 语言中描述方便起见，在此我们约定：初始化建空队列时，令 front = rear = 0，每当插入新的队列尾元素时，“尾指针增 1”；每当删除队列头元素时，“头指针增 1”。因此，在非空队列中，头指针始终指向队列头元素，而尾指针始终指向队列尾元素的下一个位置，如图 3.12 所示。

图3.12头、尾指针和队列中元素之间的关系  
![](images/11b3926a8a7a7867e3c8a5dc5598b837db2cc9b7cc832b3853b98d3c8f69837b.jpg)  
(a) 空队列；(b)  $\mathrm{J}_1, \mathrm{~J}_2$  和  $\mathrm{J}_3$  相继入队列；(c)  $\mathrm{J}_1$  和  $\mathrm{J}_2$  相继被删除；

假设当前为队列分配的最大空间为6，则当队列处于图3.12(d)的状态时不可再继续插入新的队尾元素，否则会因数组越界而遭致程序代码被破坏。然而此时又不宜如顺序栈那样，进行存储再分配扩大数组空间，因为队列的实际可用空间并未占满。一个较巧妙

的办法是将顺序队列臆造为一个环状的空间，如图3.13所示，称之为循环队列。指针和队列元素之间关系不变，如图3.14(a)所示循环队列中，队列头元素是  $\mathbf{J}_3$  ，队列尾元素是  $\mathrm{J}_{5}$  ，之后  $\mathrm{J}_6\setminus \mathrm{J}_7$  和  $\mathrm{J_8}$  相继插入，则队列空间均被占满，如图3.14（b）所示，此时Q.front  $=$  Q.rear；反之，若  $\mathrm{J}_3,\mathrm{J}_4$  和  $\mathrm{J}_5$  相继从图3.14(a)的队列中删除，使队列呈“空”的状态，如图3.14(c)所示。此时也存在关系式Q.front  $=$  Q.rear，由此可见，只凭等式Q.front  $=$  Q.rear无法

图3.13 循环队列示意图  
![](images/16480ddc6466e702d3153916eec76fcf86460dc323e946f385f267cdb09437eb.jpg)  
(d)  $\mathrm{J}_4, \mathrm{~J}_5$  和  $\mathrm{J}_6$  相继插入队列之后  $\mathrm{J}_3$  及  $\mathrm{J}_4$  被删除

判别队列空间是“空”还是“满”。可有两种处理方法：其一是另设一个标志位以区别队列是“空”还是“满”；其二是少用一个元素空间，约定以“队列头指针在队列尾指针的下一位置（指环状的下一位置）上”作为队列呈“满”状态的标志。

从上述分析可见，在C语言中不能用动态分配的一维数组来实现循环队列。如果用户的应用程序中设有循环队列，则必须为它设定一个最大队列长度；若用户无法预估所用

![](images/66fe4f68ade15e97d6b4d922cb46b06428436ba3658e7380db38dfc8e3802865.jpg)

图3.14 循环队列的头尾指针  
![](images/ba073b435cce98a9e0af7baf5c05790b0d8600b2f63ff3a5eef75f6e78f0b441.jpg)  
(a) 一般情况；(b) 队列满时；(c) 空队列

![](images/822fc1bc2d2179eb31d6bf17c7131cee81cf79e3c74cd0ea387998db67923ef6.jpg)

队列的最大长度，则宜采用链队列。

循环队列类型的模块说明如下：

```c
//----- 循环队列——队列的顺序存储结构
#define MAXQSIZE 100 //最大队列长度
typedef struct {
    QElemType * base; //初始化的动态分配存储空间
    int front; //头指针,若队列不空,指向队列头元素
    int rear; //尾指针,若队列不空,指向队列尾元素的下一个位置
} SqQueue;
//----- 循环队列的基本操作的算法描述
Status InitQueue (SqQueue &Q) {
    //构造一个空队列Q
    Q.base = (QElemType *) malloc (MAXQSIZE * sizeof (QElemType));
    if (!Q.base) exit (OVERFLOW); //存储分配失败
    Q.front = Q.rear = 0;
    return OK;
}
int QueueLength (SqQueue Q) {
    //返回Q的元素个数,即队列的长度
    return (Q.rear - Q.front + MAXQSIZE) % MAXQSIZE;
}
```

```javascript
StatusEnQueue（SqQueue&Q.QElemTypee）{//插入元素  $\mathbf{e}$  为  $Q$  的新的队尾元素if（(Q.rear+1)%MAXQSIZE  $= =$  Q.front）returnERROR;//队列满Q.base[Q.rear]=e;Q.rear=(Q.rear+1)%MAXQSIZE:returnOK;  
}  
StatusDeQueue（SqQueue&Q.QElemType&e）{//若队列不空，则删除  $Q$  的队头元素.用  $\mathbf{e}$  返回其值，并返回OK;否则返回ERRORif(Q.front  $= =$  Q.rear）returnERROR;  $\mathrm{e} = \mathrm{Q}$  .base[Q.front]；Q.front=(Q.front+1)%MAXQSIZE:returnOK;
```

# 3.5 离散事件模拟

在日常生活中，我们经常会遇到许多为了维护社会正常秩序而需要排队的情景。这样一类活动的模拟程序通常需要用到队列和线性表之类的数据结构，因此是队列的典型应用例子之一。这里将向读者介绍一个银行业务的模拟程序。

假设某银行有4个窗口对外接待客户，从早晨银行开门起不断有客户进入银行。由于每个窗口在某个时刻只能接待一个客户，因此在客户人数众多时需在每个窗口前顺次排队，对于刚进入银行的客户，如果某个窗口的业务员正空闲，则可上前办理业务；反之，若4个窗口均有客户所占，他便会排在人数最少的队伍后面。现在需要编制一个程序以模拟银行的这种业务活动并计算一天中客户在银行逗留的平均时间。

为了计算这个平均时间，我们自然需要掌握每个客户到达银行和离开银行这两个时刻，后者减去前者即为每个客户在银行的逗留时间。所有客户逗留时间的总和被一天内进入银行的客户数除便是所求的平均时间。称客户到达银行和离开银行这两个时刻发生的事情为“事件”，则整个模拟程序将按事件发生的先后顺序进行处理，这样一种模拟程序称做事件驱动模拟。算法3.6描述的正是上述银行客户的离散事件驱动模拟程序。

```txt
void Bank Simulation(int CloseTime) {
    // 银行业务模拟，统计一天内客户在银行逗留的平均时间。
    OpenForDay();
    while (MoreEvent) {
        EventDriven(OccurTime.EventType); // 初始化
        switch (EventType) {
            case 'A': CustomerArrived(); break; // 处理客户到达事件
            case 'D': CustomerDeparture(); break; // 处理客户离开事件
            default: Invalid(); }
        } // switch
```

```txt
} // while CloseForDay; } // Bank.Simulation
```

// 计算平均逗留时间

# 算法 3.6

下面讨论模拟程序的实现，首先要讨论模拟程序中需要的数据结构及其操作。

算法3.6处理的主要对象是“事件”，事件的主要信息是事件类型和事件发生的时刻。算法中处理的事件有两类：一类是客户到达事件；另一类是客户离开事件。前一类事件发生的时刻随客户到来自然形成；后一类事件发生时刻则由客户事务所需时间和等待所耗时间而定。由于程序驱动是按事件发生时刻的先后顺序进行，则事件表应是有序表，其主要操作是插入和删除事件。

模拟程序中需要的另一种数据结构是表示客户排队的队列，由于前面假设银行有4个窗口，因此程序中需要4个队列，队列中有关客户的主要信息是客户到达的时刻和客户办理事务所需的时间。每个队列中的队头客户即为正在窗口办理事务的客户，他办完事务离开队列的时刻就是即将发生的客户离开事件的时刻，这就是说，对每个队头客户都存在一个将要驱动的客户离开事件。因此，在任何时刻即将发生的事件只有下列5种可能：(1)新的客户到达；(2)1号窗口客户离开；(3)2号窗口客户离开；(4)3号窗口客户离开；(5)4号窗口客户离开。

从以上分析可见，在这个模拟程序中只需要两种数据类型：有序链表和队列。它们的数据元素类型分别定义如下：

```txt
typedef struct{ intOcccurTime; //事件发生时刻 int NType; //事件类型，0表示到达事件，1至4表示四个窗口的离开事件 }Event,ElemType; //事件类型，有序链表LinkList的数据元素类型 typedef LinkList EventList //事件链表类型，定义为有序链表 typedef struct{ int ArrivalTime; //到达时刻 int Duration; //办理事务所需时间 }QElemType; //队列的数据元素类型
```

现在我们详细分析算法3.6中的两个主要操作步骤是如何实现的。

先看对新客户到达事件的处理。

由于在实际的银行中，客户到达的时刻及其办理事务所需时间都是随机的，在模拟程序中可用随机数来代替。不失一般性，假设第一个顾客进门的时刻为0，即是模拟程序处理的第一个事件，之后每个客户到达的时刻在前一个客户到达时设定。因此在客户到达事件发生时需先产生两个随机数：其一为此时刻到达的客户办理事务所需时间durtime；其二为下一客户将到达的时间间隔intertime，假设当前事件发生的时刻为occurtime，则下一个客户到达事件发生的时刻为occurtime+intertime。由此应产生一个新的客户到达事件插入事件表；刚到达的客户则应插入到当前所含元素最少的队列中；若该队列在插

入前为空，则还应产生一个客户离开事件插入事件表。

客户离开事件的处理比较简单。首先计算该客户在银行逗留的时间，然后从队列中删除该客户后查看队列是否空，若不空则设定一个新的队头客户离开事件。

最后我们给出在上述数据结构下实现的银行事件驱动模拟程序，如算法3.7所示。

// 程序中用到的主要变量  
```txt
EventList ev; //事件表  
Event en; //事件  
LinkQueue q[5]; //4个客户队列  
Q ElemType customer; //客户记录  
int TotalTime, CustomerNum; //累计客户逗留时间，客户数
```

```javascript
int cmp(Event a, Event b); //依事件a的发生时刻<或  $=$  或  $\rightharpoonup$  事件b的发生时刻分别返回-1或0或1
```

```txt
void OpenForDay() {
// 初始化操作
TotalTime = 0; CustomerNum = 0; // 初始化累计时间和客户数为0
InitList(ev); // 初始化事件链表为空表
enOcccurTime = 0; en.NType = 0; // 设定第一个客户到达事件
OrderInsert(ev, en, cmp); // 插入事件表
for (i = 1; i <= 4; ++i) InitQueue(q[i]); // 置空队列
} // OpenForDay
```

// 设定第  $i$  队列的一个离开事件并插入事件表  
```javascript
void CustomerArrived(){ //处理客户到达事件，en.NType  $= 0$  +  $^+$  CustomerNum; Random(durtime,intertime); //生成随机数 t  $\equiv$  en.OccurTime  $^+$  intertw; //下一客户到达时刻 if(t<CloseTime) //银行尚未关门，插入事件表 OrderInsert (ev,(t,0)，cmp);  $\dot{\mathbf{i}} =$  Minimum(q); //求长度最短队列 EnQueue(q[i]，(en.OccurTime,durtime)); if(Queuelength(q[i])==1) OrderInsert (ev,(en.OccurTime+durtime,i),cmp);
```

```txt
} // CustomerArrived  
void CustomerDeparture() { // 处理客户离开事件，en.NType  $>0$ 。 i = en.NType; DelQueue(q[i], customer); // 删除第i队列的排头客户 TotalTime += en.OccurTime - customer.ArrivalTime; // 累计客户逗留时间 if (!QueueEmpty(q[i])) { // 设定第i队列的一个离开事件并插入到 GetHead(q[i], customer); OrderInsert(ev, (en.OccurTime + curtomer.Duration, i), (*cmp()))); }
```

```java
} // CustomerDeparture  
void Bank.Simulation(int CloseTime) {  
    OpenForDay(); // 初始化  
    while (!ListEmpty(ev)) {  
        DelFirst(GetHead(ev).p): en = GetCurElem(p);  
        if (en.TYPE == 0)  
            CustomerArrived(); // 处理客户到达事件  
        else CustomerDeparture(); // 处理客户离开事件  
    }  
// 计算并输出平均逗留时间  
printf("The Average Time is %f\n", (float)TotalTime / CustomerNum);  
} // Bank Simulation
```

# 算法 3.7

例3-3 假设每个客户办理业务的时间不超过30分钟；两个相邻到达银行的客户的时间间隔不超过5分钟。模拟程序从第一个客户到达时间为“0”开始起运行。

删除事件表上第一个结点，得到en.OccurTime  $= 0$  ，因为en.NType  $= 0$  ，则随即得到两个随机数(23.4)，生成一个下一客户到达银行的事件（OccurTime  $= 4$  ，NType  $= 0$  )插入事件表：刚到的第一位客户排在第一个窗口的队列中(ArrivalTime  $= 0$  ,Duration  $= 23$  ).由于他是排头，故生成一个客户将离开的事件（OccurTime  $= 23$  ，NType  $= 1$  )插入事件表。

删除事件表上第一个结点，仍是新客户到达事件（因为en.NType  $= 0$ ），en.OccurTime  $= 4$ 。得到随机数为(3,1)，则下一客户到达银行的时间为OccurTime  $= 4 + 1 = 5$ ，由于此时第二个窗口是空的，则刚到的第二位客户为第二个队列的队头(ArrivalTime  $= 4$ ，Duration  $= 3$ ）。因而生成一个客户将离开的事件(OccurTime  $= 7$ ，NType  $= 2$ ）插入事件表。

删除事件表上第一个结点，仍是新客户到达事件，en. OccurTime = 5，得到随机数（11.5），则插入事件表的新事件为（OccurTime = 8，NType = 0），同时，刚到的第三位客户成为第三个队列的队头（ArrivalTime = 5，Duration = 11），因而插入事件表的新事件为（OccurTime = 16，NType = 3）。

删除事件表的第一个结点，因为 NType = 2，说明是第二个窗口的客户离开银行 en. OccurTime = 7，删去第二个队列的队头，curstomer. ArrivalTime = 4，则他在银行的逗留时间为 3 分钟。

依次类推，在模拟开始后的一段时间内，事件表和队列的状态如图3.15所示，ev.first为链表头指针。

![](images/ccaa1370de60f07731880f3f815600ebb73ff83a540ece2bd0e6eeb2abc046c1.jpg)  
图3.15 事件驱动模拟(算法3.7)过程中事件表和队列状态变化状况

# 第4章 串

计算机上的非数值处理的对象基本上是字符串数据。在较早的程序设计语言中, 字符串是作为输入和输出的常量出现的。随着语言加工程序的发展, 产生了字符串处理。这样, 字符串也就作为一种变量类型出现在越来越多的程序设计语言中, 同时也产生了一系列字符串的操作。字符串一般简称为串。在汇编和语言的编译程序中, 源程序和目标程序都是字符串数据。在事务处理程序中, 顾客的姓名和地址以及货物的名称、产地和规格等一般也是作为字符串处理的。又如信息检索系统、文字编辑程序、问答系统、自然语言翻译系统以及音乐分析程序等, 都是以字符串数据作为处理对象的。

然而，现今我们使用的计算机的硬件结构主要是反映数值计算的需要的，因此，在处理字符串数据时比处理整数和浮点数要复杂得多。而且，在不同类型的应用中，所处理的字符串具有不同的特点，要有效地实现字符串的处理，就必须根据具体情况使用合适的存储结构。这一章，我们将讨论一些基本的串处理操作和几种不同的存储结构。

# 4.1 串类型的定义

串 (string) (或字符串) 是由零个或多个字符组成的有限序列, 一般记为

$$
s = ^ {\prime} a _ {1} a _ {2} \dots a _ {n} ^ {\prime} \quad (n \geqslant 0) \tag {4-1}
$$

其中， $s$  是串的名，用单引号括起来的字符序列是串的值； $a_i (1 \leqslant i \leqslant n)$  可以是字母、数字或其他字符；串中字符的数目  $n$  称为串的长度。零个字符的串称为空串（null string），它的长度为零。

串中任意个连续的字符组成的子序列称为该串的子串。包含子串的串相应地称为主串。通常称字符在序列中的序号为该字符在串中的位置。子串在主串中的位置则以子串的第一个字符在主串中的位置来表示。

例如，假设  $a, b, c, d$  为如下的4个串：

$$
\begin{array}{l} a = ^ {\prime} \mathrm {B E I} ^ {\prime}, \quad b = ^ {\prime} \mathrm {J I N G} ^ {\prime} \\ c = ^ {\prime} \text {B E I J I N G} ^ {\prime}, d = ^ {\prime} \text {B E I J I N G} ^ {\prime} \\ \end{array}
$$

则它们的长度分别为3、4、7和8；并且  $a$  和  $b$  都是  $c$  和  $d$  的子串， $a$  在  $c$  和  $d$  中的位置都是1，而  $b$  在  $c$  中的位置是4，在  $d$  中的位置则是5。

称两个串是相等的，当且仅当这两个串的值相等。也就是说，只有当两个串的长度相等，并且各个对应位置的字符都相等时才相等。例如上例中的串  $a, b, c$  和  $d$  彼此都不相等。

值得一提的是，串值必须用一对单引号括起来，但单引号本身不属于串，它的作用只是为了避免与变量名或数的常量混淆而已。

例如在程序设计语言中

$$
\mathbf {x} = ^ {\prime} 1 2 3 ^ {\prime};
$$

则表明  $\mathbf{x}$  是一个串变量名，赋给它的值是字符序列123。又如

$$
\text {t s i n g} = ^ {\prime} \text {T S I N G} ^ {\prime}
$$

中，tsing 是一个串变量名，而字符序列 TSING 是其值。

在各种应用中，空格常常是串的字符集合中的一个元素，因而可以出现在其他字符中间。由一个或多个空格组成的串'称为空格串（blank string，请注意：此处不是空串）。它的长度为串中空格字符的个数。为了清楚起见，以后我们用符号“ $\varnothing$ ”来表示“空串”。

串的逻辑结构和线性表极为相似，区别仅在于串的数据对象约束为字符集。然而，串的基本操作和线性表有很大差别。在线性表的基本操作中，大多以“单个元素”作为操作对象，例如在线性表中查找某个元素、求取某个元素、在某个位置上插入一个元素和删除一个元素等；而在串的基本操作中，通常以“串的整体”作为操作对象，例如在串中查找某个子串、求取一个子串、在串的某个位置上插入一个子串以及删除一个子串等。

串的抽象数据类型的定义如下：

ADT String{

数据对象：D={a|ai∈CharacterSet，i=1,2,…,n，n≥0}

数据关系：  $\mathbb{R}_1 = \{\langle a_{i - 1},a_i\rangle |a_{i - 1},a_i\in D,i = 2,\dots ,n\}$

基本操作：

StrAssign (&T, chars)

初始条件：chars是字符串常量。

操作结果：生成一个其值等于 chars 的串 T。

StrCopy (&T, S)

初始条件：串  $S$  存在。

操作结果：由串S复制得串T。

StrEmpty (S)

初始条件：串S存在。

操作结果：若S为空串，则返回TRUE，否则返回FALSE。

StrCompare (S, T)

初始条件：串S和T存在。

操作结果：若  $\mathbf{S} > \mathbf{T}$  ，则返回值  $>0$  ；若  $\mathbf{S} = \mathbf{T}$  ，则返回值  $= 0$  ；若  $\mathbf{S} < \mathbf{T}$  ，则返回值  $< 0$  。

StrLength (S)

初始条件：串S存在。

操作结果：返回S的元素个数，称为串的长度。

ClearString (&S)

初始条件：串S存在。

操作结果：将S清为空串。

Concat ( &T, S1, S2)

初始条件：串S1和S2存在。

操作结果：用T返回由S1和S2联接而成的新串。

SubString (&Sub, S, pos, len)

初始条件：串S存在，  $1\leqslant \mathrm{pos}\leqslant \mathrm{StrLength}(\mathrm{S})$  且  $0\leqslant \mathrm{len}\leqslant \mathrm{StrLength}(\mathrm{S}) - \mathrm{pos} + 1$

操作结果：用 Sub 返回串 S 的第 pos 个字符起长度为 len 的子串。

Index (S, T, pos)

初始条件：串S和T存在，T是非空串，  $1\leqslant \mathrm{pos}\leqslant \mathrm{StrLength}(\mathrm{S})$

操作结果：若主串S中存在和串T值相同的子串，则返回它在主串S中第pos个字符之后第一次出现的位置；否则函数值为0。

```txt
Replace (&S, T, V)  
初始条件：串 S, T 和 V 存在，T 是非空串。  
操作结果：用 V 替换主串 S 中出现的所有与 T 相等的不重叠的子串。StrInsert (&S, pos, T)  
初始条件：串 S 和 T 存在，1 <= pos <= StrLength(S) + 1。  
操作结果：在串 S 的第 pos 个字符之前插入串 T。StrDelete (&S, pos, len)  
初始条件：串 S 存在，1 <= pos <= StrLength(S) - len + 1。  
操作结果：从串 S 中删除第 pos 个字符起长度为 len 的子串。DestroyString (&S)  
初始条件：串 S 存在。  
操作结果：串 S 被销毁。}ADT String
```

对于串的基本操作集可以有不同的定义方法, 读者在使用高级程序设计语言中的串类型时, 应以该语言的参考手册为准。在上述抽象数据类型定义的 13 种操作中, 串赋值 StrAssign、串比较 StrCompare、求串长 StrLength、串联接 Concat 以及求子串 SubString5 种操作构成串类型的最小操作子集。即这些操作不可能利用其他串操作来实现, 反之, 其他串操作 (除串清除 ClearString 和串销毁 DestroyString 外) 均可在这个最小操作子集上实现。

例如，可利用判等、求串长和求子串等操作实现定位函数Index(S,T,pos)。算法的基本思想为：在主串S中取从第i(i的初值为pos)个字符起、长度和串T相等的子串和串T比较，若相等，则求得函数值为i，否则i值增1直至串S中不存在和串T相等的子串为止，如算法4.1所示。

```javascript
intIndex(StringS,StringT,intpos){//T为非空串。若主串S中第pos个字符之后存在与  $\mathbf{T}$  相等的子串，//则返回第一个这样的子串在S中的位置，否则返回0if  $(\mathrm{pos} > 0)$  {n  $=$  StrLength(S);  $\texttt{m} =$  StrLength(T);  $\texttt{i} =$  pos;while（i<=n-m+1）{SubString(sub,S,i,m);if(StrCompare(sub,T)!=0） ++i;elsereturni; //返回子串在主串中的位置}//while}//ifreturn0; //S中不存在与T相等的子串}//Index
```

# 算法 4.1

# 4.2 串的表示和实现

如果在程序设计语言中，串只是作为输入或输出的常量出现，则只需存储此串的串值，即字符序列即可。但在多数非数值处理的程序中，串也以变量的形式出现。

串有3种机内表示方法，分别介绍如下。

# 4.2.1 定长顺序存储表示

类似于线性表的顺序存储结构，用一组地址连续的存储单元存储串值的字符序列。在串的定长顺序存储结构中，按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区，则可用定长数组如下描述之。

// - - - - - 串的定长顺序存储表示 - - - - -

define MAXSTRLEN 255 //用户可在255以内定义最大串长

typedef unsigned char SString[MAXSTRLEN + 1]; //0号单元存放串的长度

串的实际长度可在这预定义长度的范围内随意，超过预定义长度的串值则被舍去，称之为“截断”。对串长有两种表示方法：一是如上述定义描述的那样，以下标为0的数组分量存放串的实际长度，如PASCAL语言中的串类型采用这种表示方法；二是在串值后面加一个不计入串长的结束标记字符，如在有的C语言中以“\0”表示串值的终结。此时的串长为隐含值，显然不便于进行某些串操作。

在这种存储结构表示时如何实现串的操作，下面以串联接和求子串为例讨论之。

# 1. 串联接Concat(&T,S1,S2)

假设S1、S2和T都是CString型的串变量，且串T是由串S1联结串S2得到的，即串T的值的前一段和串S1的值相等，串T的值的后一段和串S2的值相等，则只要进行相应的“串值复制”操作即可，只是需按前述约定，对超长部分实施“截断”操作。基于串S1和S2长度的不同情况，串T值的产生可能有如下3种情况：（1） $\mathrm{S1[0] + S2[0] \leqslant MAXSTRLEN}$ ，如图4.10(a)所示，得到的串T是正确的结果；（2） $\mathrm{S1[0] < MAXSTRLEN}$  而  $\mathrm{S1[0] + S2[0] > MAXSTRLEN}$ ，则将串S2的一部分截断，得到的串T只包含串S2的一个子串，如图4.1(b)所示；（3） $\mathrm{S1[0] = MAXSTRLEN}$ ，则得到的串T并非联接结果，而和串S1相等。上述算法描述如算法4.2所示。

```javascript
Status Concat(SSString &T,SSstring S1,SString S2) { //用T返回由S1和S2联接而成的新串。若未截断，则返回TRUE，否则FALSE。 if  $(\mathrm{S1}[0] + \mathrm{S2}[0] <   =$  MAXSTRLEN）{//未截断  $\mathrm{T[1..S1[0]]} = \mathrm{S1[1..S1[0]]};$ $\mathrm{T[S1[0] + 1..S1[0] + S2[0]]} = \mathrm{S2[1..S2[0]]};$ $\mathrm{T[0]} = \mathrm{S1[0] + S2[0]}$  uncut  $=$  TRUE; } else if (S1[0]<MAXSTRLEN）{//截断  $\mathrm{T[1..S1[0]]} = \mathrm{S1[1..S1[0]]};$ $\mathrm{T[S1[0] + 1..MAXSTRLEN] = S2[1..MAXSTRLEN - S1[0]]};$ $\mathrm{T[0]} = \mathrm{MAXSTRLEN}$  ; uncut  $=$  FALSE; } else{//截断(仅取S1)  $\mathrm{T[0..MAXSTRLEN]} = \mathrm{S1[0..MAXSTRLEN]};$  //T[0]=S1[0]=MAXSTRLEN
```

```javascript
uncut  $=$  FALSE;   
} return uncut;   
}//Concat
```

![](images/c549f6b20e9e2fafc1fb0143827f8e3751aa3b8dd11527299adcbfdddbf98410.jpg)  
算法 4.2  
(a)

![](images/0e54ba57bf673b3904817abd6b3e28dd590194c8f5be474b7b6c9e0c05f07916.jpg)  
(b)

![](images/1ce644e1ba5c1b422a3d188993df25c4bbc9db67056f2ad9aaa06056520268be.jpg)  
(c)  
图4.1 串的联结操作Concat(T,S1,S2)示意图

(a)  $\mathrm{S1}[0] + \mathrm{S2}[0]\leqslant \mathrm{MAXSTRLEN}$  
(b)  $S1[0] < \text{MAXSTRLEN}$  而  $S1[0] + S2[0] > \text{MAXSTRLEN}$ ;  
(c)  $\mathbf{S1}[0] = \mathbf{MAXSTRLEN}$

# 2. 求子串 SubString(& Sub, S, pos, len)

求子串的过程即为复制字符序列的过程，将串S中从第pos个字符开始长度为len的字符序列复制到串Sub中。显然，本操作不会有需截断的情况，但有可能产生用户给出的参数不符合操作的初始条件，当参数非法时，返回ERROR。其算法描述如算法4.3所示。

```txt
Status SubString(SSstring&Sub, SString S, int pos, int len) {
// 用 Sub 返回串 S 的第 pos 个字符起长度为 len 的子串。
// 其中，1 <= pos <= StrLength(S) 且 0 <= len <= StrLength(S) - pos + 1。
if (pos < 1 || pos > S[0] || len < 0 || len > S[0] - pos + 1)
return ERROR;
Sub[1..len] = S[pos..pos + len - 1];
Sub[0] = len; return OK;
} // SubString
```

# 算法 4.3

综上两个操作可见，在顺序存储结构中，实现串操作的原操作为“字符序列的复制”，操作的时间复杂度基于复制的字符序列的长度。另一操作特点是，如果在操作中出现串值序列的长度超过上界MAXSTRLEN时，约定用截尾法处理，这种情况不仅在求联接串时可能发生，在串的其他操作中，如插入、置换等也可能发生。克服这个弊病惟有不限定串长的最大长度，即动态分配串值的存储空间。

# 4.2.2 堆分配存储表示

这种存储表示的特点是，仍以一组地址连续的存储单元存放串值字符序列，但它们的存储空间是在程序执行过程中动态分配而得。在C语言中，存在一个称之为“堆”的自由存储区，并由C语言的动态分配函数malloc()和free()来管理。利用函数malloc()为每个新产生的串分配一块实际串长所需的存储空间，若分配成功，则返回一个指向起始地址的指针，作为串的基址，同时，为了以后处理方便，约定串长也作为存储结构的一部分。

```txt
// -- -- -- 串的堆分配存储表示 -- -- -- typedef struct { char *ch; // 若是非空串,则按串长分配存储区,否则 ch为 NULL int length; // 串长度 }HString;
```

这种存储结构表示时的串操作仍是基于“字符序列的复制”进行的。例如，串复制操作StrCopy(&T,S)的实现算法是，若串T已存在，则先释放串T所占空间，当串S不空时，首先为串T分配大小和串S长度相等的存储空间，然后将串S的值复制到串T中；又如串插入操作StrInsert(&S, pos,T)的实现算法是，为串S重新分配大小等于串S和串T长度之和的存储空间，然后进行串值复制，如算法4.4所示。

```java
Status StrInsert(HString &S, int pos, HString T) {
// 1 <= pos <= StrLength(S) + 1。在串 S 的第 pos 个字符之前插入串 T。
if (pos < 1 || pos > S.length + 1) return ERROR; // pos 不合法
if (T.length) // T 非空, 则重新分配空间, 插入 T
if (! (S.ch = (char *) realloc(S.ch, (S.length + T.length) * sizeof(char)))) exit(OVERFLOW);
for (i = S.length - 1; i >= pos - 1; --i) // 为插入 T 而腾出位置
S.ch[i + T.length] = S.ch[i];
S.ch[pos - 1..pos + T.length - 2] = T.ch[0..T.length - 1]; // 插入 T
```

```javascript
S.length  $^+\equiv$  T.length; } return OK;   
} // StrInsert
```

# 算法 4.4

以上两种存储表示通常为高级程序设计语言所采用。由于堆分配存储结构的串既有顺序存储结构的特点，处理方便，操作中对串长又没有任何限制，更显灵活，因此在串处理的应用程序中也常被选用。以下所示为只含最小操作子集的 String 串类型的模块说明。

```c
//  $= = = = =$  ADT String 的表示与实现  $= = = = =$    
//----串的堆分配存储表示  
typedef struct{char \*ch; //若是非空串，则按串长分配存储区，否则ch为NULLint length; //串长度}HString;  
//---基本操作的函数原型说明---  
Status StrAssign (HString&T, char \* chars);//生成一个其值等于串常量chars的串Tint StrLength (HString S);//返回S的元素个数，称为串的长度。int StrCompare(HString S,HString T) //若S>T,则返回值>0；若S=T,则返回值=0；若S<T,则返回值<0Status ClearString (HString&S);//将S清为空串，并释放S所占空间。Status Concat (HString&T,HString S1,HString S2);//用T返回由S1和S2联接而成的新串。HString SubString (HString S,int pos,int len);//1≤pos≤StrLength(S)且0≤len≤StrLength(S)-pos+1。//返回串S的第pos个字符起长度为len的子串。///--基本操作的算法描述--  
Status StrAssign(HString&T,char\*chars){//生成一个其值等于串常量chars的串Tif(T.ch)free(T.ch); //释放T原有空间for  $(i = 0,c =$  chars;c; ++i，++c）; //求chars的长度iif(!i){T.ch  $\equiv$  NULL; T.length  $= 0$  ；}else{if(!(T.ch=(char*)malloc(i\*sizeof(char))))exit(OVERFLOW);T.ch[0..i-1]= chars[0..i-1];T.length  $=$  i;1return OK;
```

```txt
} // StrAssign  
int StrLength(HString S) { // 返回S的元素个数，称为串的长度。 return S.length; } // StrLength  
int StrCompare(HString S, HString T) { // 若  $\mathrm{S} > \mathrm{T}$ ，则返回值  $> 0$ ；若  $\mathrm{S} = \mathrm{T}$ ，则返回值  $= 0$ ；若  $\mathrm{S} < \mathrm{T}$ ，则返回值  $< 0$  for (i = 0; i < S.length && i < T.length; ++i) if (S.ch[i] != T.ch[i]) return S.ch[i] - T.ch[i]; return S.length-T.length; } // StrCompare  
Status ClearString(HString &S) { // 将S清为空串。 if (S.ch) {free(S.ch); S.ch = NULL;} S.length = 0; return OK; } // ClearString  
Status Concat(HString &T, HString S1, HString S2) { // 用T返回由S1和S2联接而成的新串。 if (T.ch) free(T.ch); //释放旧空间 if (!T.ch = (char*) malloc((S1.length + S2.length) * sizeof(char)))) exit (OVERFLOW); T.ch[0..S1.length-1] = S1.ch[0..S1.length-1]; T.length = S1.length + S2.length; T.ch[S1.length..T.length-1] = S2.ch[0..S2.length-1]; return OK; } // Concat  
Status SubString(HString &Sub, HString S, int pos, int len) { // 用Sub返回串S的第pos个字符起长度为len的子串。 // 其中，1≤pos≤StrLength(S)且0≤len≤StrLength(S)-pos+1。 if (pos<1 || pos>S.length || len<0 || len>S.length-pos+1) return ERROR; if (Sub.ch) free(Sub.ch); //释放旧空间 if (!len) {Sub.ch = NULL; Sub.length = 0;} //空子串 else { //完整子串 Sub.ch = (char *)malloc(len * sizeof(char)); Sub.ch[0..len-1] = S.ch[pos-1..pos+len-2]; Sub.length = len; } return OK; } // SubString
```

# 4.2.3 串的块链存储表示

和线性表的链式存储结构相类似, 也可采用链表方式存储串值。由于串结构的特殊性——结构中的每个数据元素是一个字符, 则用链表存储串值时, 存在一个“结点大小”的问题, 即每个结点可以存放一个字符, 也可以存放多个字符。例如, 图4.2(a)是结点大小为4(即每个结点存放4个字符)的链表, 图4.2(b)是结点大小为1的链表。当结点大小大于1时, 由于串长不一定是结点大小的整倍数, 则链表中的最后一个结点不一定全被串值占满, 此时通常补上“#”或其他的非串值字符(通常“#”不属于串的字符集, 是一个特殊的符号)。

图4.2 串值的链表存储方式  
![](images/748203143b2266519a1f31f889d530ae133f0498f0dc47092d339d7cd24f06d9.jpg)  
(a) 结点大小为 4 的链表；(b) 结点大小为 1 的链表

为了便于进行串的操作，当以链表存储串值时，除头指针外还可附设一个尾指针指示链表中的最后一个结点，并给出当前串的长度。称如此定义的串存储结构为块链结构，说明如下：

```c
//  $= = = = = =$  串的块链存储表示  $\equiv = = = = =$  #define CHUNKSIZE 80 //可由用户定义的块大小 typedef struct Chunk { char ch[CHUNKSIZE]; struct Chunk \* next; }Chunk; typedef struct { Chunk \*head,\*tail; //串的头和尾指针 int curlen; //串的当前长度 }LString;
```

由于在一般情况下，对串进行操作时，只需要从头向尾顺序扫描即可，则对串值不必建立双向链表。设尾指针的目的是为了便于进行联结操作，但应注意联结时需处理第一个串尾的无效字符。

在链式存储方式中，结点大小的选择和顺序存储方式的格式选择一样都很重要，它直接影响着串处理的效率。在各种串的处理系统中，所处理的串往往很长或很多，例如，一本书的几百万个字符，情报资料的成千上万个条目。这要求我们考虑串值的存储密度。存储密度可定义为

$$
\text {存 储 密 度} = \frac {\text {串 值 所 占 的 存 储 位}}{\text {实 际 分 配 的 存 储 位}}
$$

显然，存储密度小（如结点大小为1时），运算处理方便，然而，存储占用量大。如果在串处理过程中需进行内、外存交换的话，则会因为内外存交换操作过多而影响处理的总效率。应该看到，串的字符集的大小也是一个重要因素。一般地，字符集小，则字符的机内编码就短，这也影响串值的存储方式的选取。

串值的链式存储结构对某些串操作，如联接操作等有一定方便之处，但总的来说不如另外两种存储结构灵活，它占用存储量大且操作复杂。此外，串值在链式存储结构时串操作的实现和线性表在链表存储结构中的操作类似，故在此不作详细讨论。

# 4.3 串的模式匹配算法

# 4.3.1 求子串位置的定位函数 Index(S, T, pos)

子串的定位操作通常称做串的模式匹配（其中  $\mathrm{T}$  称为模式串），是各种串处理系统中最重要的操作之一。在4.1节中曾借用串的其他基本操作给出了定位函数的一种算法。根据算法4.1的基本思想，采用定长顺序存储结构，可以写出不依赖于其他串操作的匹配算法，如算法4.5所示。

```txt
int Index(String S, String T, int pos) {
    // 返回子串T在主串S中第pos个字符之后的位置。若不存在，则函数值为
    // 其中，T非空，1≤pos≤StrLength(S)。
    i = pos; j = 1;
    while (i <= S[0] && j <= T[0]) {
        if (S[i] == T[j]) { ++i; ++j;} // 继续比较后继字符
        else { i = i - j + 2; j = 1;} // 指针后退重新开始匹配
    }
    if (j > T[0]) return i - T[0];
    else return 0;
} // Index
```

# 算法 4.5

在算法4.5的函数过程中，分别利用计数指针i和j指示主串S和模式串T中当前正待比较的字符位置。算法的基本思想是：从主串S的第pos个字符起和模式的第一个字符比较之，若相等，则继续逐个比较后续字符；否则从主串的下一个字符起再重新和模式的字符比较之。依次类推，直至模式T中的每个字符依次和主串S中的一个连续的字符序列相等，则称匹配成功，函数值为和模式T中第一个字符相等的字符在主串S中的序号，否则称匹配不成功，函数值为零。图4.3展示了模式  $\mathrm{T} = {}^{\prime}$  abcac'和主串S的匹配过程  $(\mathrm{pos} = 1)$  。

算法4.5的匹配过程易于理解，且在某些应用场合，如文本编辑等，效率也较高，例如，在检查模式'STING'是否存在于下列主串中时，

'A STRING SEARCHING EXAMPLE CONSISTING OF SIMPLE TEXT' 上述算法中的 WHILE 循环次数（即进行单个字符比较的次数）为 41，恰好为  $(\text{Index} + \text{T})$

$[0] - 1) + 4$  ，这就是说，除了主串中呈黑体的4个字符，每个字符比较了两次以外，其他字符均只和模式进行一次比较。在这种情况下，此算法的时间复杂度为  $O(n + m)$  。其中

$n$  和  $m$  分别为主串和模式的长度。然而，在有些情况下，该算法的效率却很低。例如，当模式串为‘00000001'，而主串为‘0000000000000000000000000000000000000000000000000000000000000000000’时，由于模式中前7个字符均为“0”，又，主串中前52个字符均为“0”，每趟比较都在模式的最后一个字符出现不等，此时需将指针i回溯到  $\mathrm{i}-6$  的位置上，并从模式的第一个字符开始重新比较，整个匹配过程中指针i需回溯45次，则WHILE循环次数为  $46*8(index*m)$  。可见，算法4.5在最坏情况下的时间复杂度为  $O(n*m)$  。这种情况在只有  $0,1$  两种字符的文本串处理中经常出现，因为在主串中可能存在多个和模式串“部分匹配”的子串，因而引起指针i的多次回溯。01串可以用在许多应用之中。比如，一些计算机的图形显示就是把画面表示为一个01串，一页书就是一个几百万个0和1组成的串。在二进位计算机上实际处理的都是01串。

i=3 第一趟匹配 ababcacababab a b c  $j = 3$

$\downarrow i = 2$  第二趟匹配ababcaccabab a  $\dagger j = 1$

$\frac{1}{4} i = 7$  第三趟匹配 ababcacbabab abcac  $\text{喜} _ { j } = 5$

$i = 4$  第四趟匹配 ababcbaccabab a  $j = 1$

$\downarrow i = 5$  第五趟匹配 ababcabcacbab a  $\uparrow j = 1$

$\downarrow i = 11$  第六趟匹配 ababcaccbab a b c a c

一个字符的 ASCII 码也可以看成是 8 个二进位的 01 串。包括汉字存储在计算机中处理时也是作为一个 01 串和其他的字符串一样看待。因此在下一节, 我们将介绍另一种较好的模式匹配算法。

# 4.3.2 模式匹配的一种改进算法

这种改进算法是D.E.Knuth与V.R.Pratt和J.H.Morris同时发现的，因此人们称它为克努特一莫里斯一普拉特操作(简称为KMP算法)。此算法可以在  $O(n + m)$  的时间

![](images/693baae3f905871b209cc7c01b0d44538f7c7905c0d8f38092d5c66bf8c1a3b9.jpg)  
图4.3 算法4.5的匹配过程  
图4.4 改进算法的匹配过程示例

数量级上完成串的模式匹配操作。其改进在于：每当一趟匹配过程中出现字符比较不等时，不需回溯i指针，而是利用已经得到的“部分匹配”的结果将模式向右“滑动”尽可能远的一段距离后，继续进行比较。下面先从具体例子看起。

回顾图4.3中的匹配过程示例，在第三趟的匹配中，当  $i = 7,j = 5$  字符比较不等时，又从  $i = 4,j = 1$  重新开始比较。然后，经仔细观察可发现，在  $i = 4$

和  $j = 1, i = 5$  和  $j = 1$  以及  $i = 6$  和  $j = 1$  这3次比较都是不必进行的。因为从第三趟部分匹配的结果就可得出，主串中第4、5和6个字符必然是  $\mathbf{b}^{\prime}, \mathbf{c}^{\prime}$  和  $\mathbf{a}^{\prime}$  （即模式串中第2、3和4个字符）。因为模式中的第一个字符是  $a$  ，因此它无需再和这3个字符进行比较，而仅需

将模式向右滑动3个字符的位置继续进行  $i = 7,j = 2$  时的字符比较即可。同理，在第一趟匹配中出现字符不等时，仅需将模式向右移动两个字符的位置继续进行  $i = 3,j = 1$  时的字符比较。由此，在整个匹配的过程中， $i$  指针没有回溯，如图4.4所示。

现在讨论一般情况。假设主串为  $s_1 s_2 \cdots s_n'$ ，模式串为  $p_1 p_2 \cdots p_m'$ ，从上例的分析可知，为了实现改进算法，需要解决下述问题：当匹配过程中产生“失配”（即  $s_i \neq p_j$ ）时，模式串“向右滑动”可行的距离多远，换句话说，当主串中第  $i$  个字符与模式中第  $j$  个字符“失配”（即比较不等）时，主串中第  $i$  个字符（ $i$  指针不回溯）应与模式中哪个字符再比较？

假设此时应与模式中第  $k(k < j)$  个字符继续比较，则模式中前  $k - 1$  个字符的子串必须满足下列关系式(4-2)，且不可能存在  $k' > k$  满足下列关系式(4-2)

$$
^ {\prime} p _ {1} p _ {2} \dots p _ {k - 1} ^ {\prime} = ^ {\prime} s _ {i - k + 1} s _ {i - k + 2} \dots s _ {i - 1} ^ {\prime} \tag {4-2}
$$

而已经得到的“部分匹配”的结果是

$$
p _ {j - k + 1} p _ {j - k + 2} \dots p _ {j - 1} ^ {\prime} = ^ {\prime} s _ {i - k + 1} s _ {i - k + 2} \dots s _ {i - 1} ^ {\prime} \tag {4-3}
$$

由式(4-2)和式(4-3)推得下列等式

$$
^ {\prime} p _ {1} p _ {2} \dots p _ {k - 1} ^ {\prime} = ^ {\prime} p _ {j - k + 1} p _ {j - k + 2} \dots p _ {j - 1} ^ {\prime} \tag {4-4}
$$

反之，若模式串中存在满足式(4-4)的两个子串，则当匹配过程中，主串中第  $i$  个字符与模式中第  $j$  个字符比较不等时，仅需将模式向右滑动至模式中第  $k$  个字符和主串中第  $i$  个字符对齐，此时，模式中头  $k - 1$  个字符的子串  ${}^{\prime}p_{1}p_{2}\dots p_{k - 1}$  必定与主串中第  $i$  个字符之前长度为  $k - 1$  的子串  ${}^{\prime}s_{i - k + 1}s_{i - k + 2}\dots s_{i - 1}$  相等，由此，匹配仅需从模式中第  $k$  个字符与主串中第  $i$  个字符比较起继续进行。

若令  $next[j] = k$ ，则  $next[j]$  表明当模式中第  $j$  个字符与主串中相应字符“失配”时，在模式中需重新和主串中该字符进行比较的字符的位置。由此可引出模式串的  $next$  函数的定义：

$$
n e x t [ j ] = \left\{ \begin{array}{l l} 0 & \text {当} j = 1 \text {时} \\ \operatorname {M a x} \left\{k \mid 1 <   k <   j \text {且} ^ {\prime} p _ {1} \dots p _ {k - 1} ^ {\prime} = ^ {\prime} p _ {j - k + 1} \dots p _ {j - 1} ^ {\prime} \right\} \\ & \text {当 此 集 合 不 空 时} \\ 1 & \text {其 他 情 况} \end{array} \right. \tag {4-5}
$$

由此定义可推出下列模式串的 next 函数值：

<table><tr><td>j</td><td>1 2 3 4 5 6 7 8</td></tr><tr><td>模式串</td><td>a b a a b c a c</td></tr><tr><td>next[j]</td><td>0 1 1 2 2 3 1 2</td></tr></table>

在求得模式的 next 函数之后, 匹配可如下进行: 假设以指针 \(i\) 和 \(j\) 分别指示主串和模式中正待比较的字符, 令 \(i\) 的初值为 \(pos\), \(j\) 的初值为 1。若在匹配过程中 \(s_i = p_j\), 则 \(i\) 和 \(j\) 分别增 1, 否则, \(i\) 不变, 而 \(j\) 退到 next \([j]\) 的位置再比较, 若相等, 则指针各自增 1, 否则 \(j\) 再退到下一个 next 值的位置, 依次类推, 直至下列两种可能: 一种是 \(j\) 退到某个 next 值 (next \([next[\cdots next[j]...\)]\)) 时字符比较相等, 则指针各自增 1, 继续进行匹配; 另一种是 \(j\) 退到值为零 (即模式的第一个字符“失配”), 则此时需将模式继续向右滑动一个位置, 即从主串的下一个字符 \(s_{i+1}\) 起和模式重新开始匹配。图 4.5 所示正是上述匹配过程的一个例子。

KMP算法如算法4.6所示，它在形式上和算法4.5极为相似。不同之处仅在于：当

![](images/29191bfd3bc01049d215d82715c3a29b59b8ecd0c1e25afef22ade50bd6eb833.jpg)  
图4.5 利用模式的next函数进行匹配的过程示例

匹配过程中产生“失配”时，指针  $i$  不变，指针  $j$  退回到 next[j] 所指示的位置上重新进行比较，并且当指针  $j$  退至零时，指针  $i$  和指针  $j$  需同时增 1。即若主串的第  $i$  个字符和模式的第 1 个字符不等，应从主串的第  $i + 1$  个字符起重新进行匹配。

```javascript
intIndex_KMP(SSStringS，SSstringT,intpos){//利用模式串T的next函数求T在主串S中第pos个字符之后的位置的//KMP算法。其中，T非空，  $1\leqslant \mathrm{pos}\leqslant \mathrm{StrLength}(\mathrm{S})$  0i=pos; j=1;while（i<=S[0]&&j<=T[O]）{//继续比较后继字符if（j=0||S[i]=T[j]){++i；++j;}elsej=next[j];//模式串向右移动1if（j>T[0])return i-T[O];//匹配成功else return 0;}//Index_KMP
```

# 算法 4.6

KMP算法是在已知模式串的next函数值的基础上执行的，那么，如何求得模式串的next函数值呢？

从上述讨论可见，此函数值仅取决于模式串本身而和相匹配的主串无关。我们可从分析其定义出发用递推的方法求得 next 函数值。

由定义得知

$$
\operatorname {n e x t} [ 1 ] = 0 \tag {4-6}
$$

设  $next[j] = k$  ，这表明在模式串中存在下列关系：

$$
^ {\prime} p _ {1} \dots p _ {k - 1} ^ {\prime} = ^ {\prime} p _ {j - k + 1} \dots p _ {j - 1} ^ {\prime} \tag {4-7}
$$

其中  $k$  为满足  $1 < k < j$  的某个值，并且不可能存在  $k' > k$  满足等式（4-7）。此时  $\text{next}[j + 1] = ?$  可能有两种情况：

（1）若  $p_k = p_j$  ，则表明在模式串中

$$
^ {\prime} p _ {1} \dots p _ {k} ^ {\prime} = ^ {\prime} p _ {j - k + 1} \dots p _ {j} ^ {\prime} \tag {4-8}
$$

并且不可能存在  $k^{\prime} > k$  满足等式(4-8)，这就是说  $\text{next}[j + 1] = k + 1$  ，即

$$
\operatorname {n e x t} [ j + 1 ] = \operatorname {n e x t} [ j ] + 1 \tag {4-9}
$$

（2）若  $p_k \neq p_j$ ，则表明在模式串中

$$
^ {\prime} p _ {1} \dots p _ {k} ^ {\prime} \neq^ {\prime} p _ {j - k + 1} \dots p _ {j} ^ {\prime}
$$

此时可把求 next 函数值的问题看成是一个模式匹配的问题, 整个模式串既是主串又是模式串, 而当前在匹配的过程中, 已有  $p_{j-k+1} = p_1$ ,  $p_{j-k+2} = p_2$ ,  $\cdots$ ,  $p_{j-1} = p_{k-1}$ , 则当  $p_j \neq p_k$  时应将模式向右滑动至以模式中的第 next[k] 个字符和主串中的第  $j$  个字符相比较。若 next[k] = k', 且  $p_j = p_{k'}$ , 则说明在主串中第  $j+1$  个字符之前存在一个长度为  $k'$  (即 next[k]) 的最长子串, 和模式串中从首字符起长度为  $k'$  的子串相等, 即

$$
p _ {1} \dots p _ {k ^ {\prime}} = p _ {j - k ^ {\prime} + 1} \dots p _ {j} \quad (1 <   k ^ {\prime} <   k <   j) \tag {4-10}
$$

这就是说  $n \times t[j + 1] = k' + 1$  即

$$
\operatorname {n e x t} [ j + 1 ] = \operatorname {n e x t} [ k ] + 1 \tag {4-11}
$$

同理，若  $p_j \neq p_{k'}$ ，则将模式继续向右滑动直至将模式中第 next  $[k']$  个字符和  $p_j$  对齐，依次类推，直至  $p_j$  和模式中某个字符匹配成功或者不存在任何  $k' (1 < k' < j)$  满足等式(4-10)，则

$$
\operatorname {n e x t} [ j + 1 ] = 1 \tag {4-12}
$$

例如，图4.6中的模式串，已求得前6个字符的next函数值，现求  $next[7]$ ，因为  $next[6] = 3$ ，又  $p_6 \neq p_3$ ，则需比较  $p_6$  和  $p_1$  （因为  $next[3] = 1$ ），这相当于将子串模式向右滑动。

由于  $p_6 \neq p_1$ ，而且  $next[1] = 0$ ，所以  $next[7] = 1$ ，而因为  $p_7 = p_1$ ，则  $next[8] = 2$ 。

根据上述分析所得结果（式(4-6)、(4-9)、(4-11)和(4-12))，仿照KMP算法，可得到求next函数值的算法，如算法4.7所示。

$$
\begin{array}{c c c} j & 1 2 3 4 5 6 & 7 8 \\ \text {模 式} & \mathrm {a b a a b c} & \mathrm {a c} \\ n e x t [ j ] & 0 1 1 2 2 3 & 1 2 \\ & (\mathrm {a b a}) & \\ & & (\mathrm {a}) \end{array}
$$

图4.6 模式串的next函数值

```c
void get_next(SSString T, int next[]) { // 求模式串T的next函数值并存入数组next。 i = 1; next[1] = 0; j = 0; while (i < T[0]) { if (j == 0 || T[i] == T[j]) { ++i; ++j; next[i] = j;} else j = next[j]; } } // get_next
```

# 算法 4.7

算法4.7的时间复杂度为  $O(m)$  。通常，模式串的长度  $m$  比主串的长度  $n$  要小得多，因此，对整个匹配算法来说，所增加的这点时间是值得的。

最后，要说明两点：

（1）虽然算法4.5的时间复杂度是  $O(n * m)$ ，但在一般情况下，其实际的执行时间近

似于  $O(n + m)$ , 因此至今仍被采用。KMP算法仅当模式与主串之间存在许多“部分匹配”的情况下才显得比算法4.5快得多。但是KMP算法的最大特点是指示主串的指针不需回溯, 整个匹配过程中, 对主串仅需从头至尾扫描一遍, 这对处理从外设输入的庞大文件很有效, 可以边读入边匹配, 而无需回头重读。

（2）前面定义的next函数在某些情况下尚有缺陷。例如模式  $a a a b$  在和主串  $a a b a a a a b$  匹配时，当  $i = 4, j = 4$  时s.ch[4]  $\neq$  t.ch[4]，由  $next[j]$  的指示还需进行

$i = 4,j = 3,i = 4,j = 2,i = 4,j = 1$  这3次比较。实际上，因为模式中第1、2、3个字符和第4个字符都相等，因此不需要再和主串中第4个字符相比较，而可以将模式一气向右滑动4个字符的位置直接进行  $i = 5,j = 1$  时的字符比较。这就

<table><tr><td>j</td><td>1 2 3 4 5</td></tr><tr><td>模式</td><td>a a a a b</td></tr><tr><td>next[j]</td><td>0 1 2 3 4</td></tr><tr><td>nextval[j]</td><td>0 0 0 0 4</td></tr></table>

是说，若按上述定义得到  $next[j] = k$  ，而模式中  $p_j = p_k$  ，则当主串中字符  $s_i$  和  $p_j$  比较不等时，不需要再和  $p_k$  进行比较，而直接和  $P_{next[k]}$  进行比较，换句话说，此时的  $next[j]$  应和  $next[k]$  相同。由此可得计算 next 函数修正值的算法如算法 4.8 所示。此时匹配算法不变。

```c
void get_nextval(SSString T, int nextval[]) {
// 求模式串T的next函数修正值并存入数组nextval。
i = 1; nextval[1] = 0; j = 0;
while (i < T[0]) {
if (j == 0 || T[i] == T[j]) {
++i; ++j;
if (T[i] != T[j]) nextval[i] = j;
else nextval[i] = nextval[j];
}
else j = nextval[j];
} // get_nextval
```

# 算法 4.8

# 4.4 串操作应用举例

# 4.4.1 文本编辑

文本编辑程序是一个面向用户的系统服务程序，广泛用于源程序的输入和修改，甚至用于报刊和书籍的编辑排版以及办公室的公文书信的起草和润色。文本编辑的实质是修改字符数据的形式或格式。虽然各种文本编辑程序的功能强弱不同，但是其基本操作是一致的，一般都包括串的查找、插入和删除等基本操作。

为了编辑的方便，用户可以利用换页符和换行符把文本划分为若干页，每页有若干行（当然，也可不分页而把文件直接划成若干行）。我们可以把文本看成是一个字符串，称为文本串。页则是文本串的子串，行又是页的子串。

比如有下列一段源程序：

```javascript
main(){ float a,b,max; scanf("%f,%f",&a,&b); if  $a > b$  max=a; else max=b;   
}；
```

我们可以把此程序看成是一个文本串。输入到内存后如图4.7所示。图中“J”为换行符。

201

<table><tr><td>m</td><td>a</td><td>i</td><td>n</td><td>(</td><td>)</td><td>{</td><td>」</td><td></td><td></td><td>f</td><td>l</td><td>o</td><td>a</td><td>t</td><td></td><td>a</td><td>,</td><td>b</td><td>,</td></tr><tr><td>m</td><td>a</td><td>x</td><td>;</td><td>」</td><td></td><td></td><td>s</td><td>c</td><td>a</td><td>n</td><td>f</td><td>(</td><td>＂</td><td>%</td><td>f</td><td>,</td><td>%</td><td>f</td><td>＂</td></tr><tr><td>,</td><td>＆</td><td>a</td><td>,</td><td>＆</td><td>b</td><td>)</td><td>;</td><td>」</td><td></td><td></td><td>i</td><td>f</td><td></td><td>a</td><td>&gt;</td><td>b</td><td></td><td></td><td>im</td></tr><tr><td>a</td><td>x</td><td>=</td><td>a</td><td>;</td><td>」</td><td></td><td></td><td>e</td><td>l</td><td>s</td><td>e</td><td></td><td></td><td>m</td><td>a</td><td>x</td><td>=</td><td>b</td><td>;</td></tr><tr><td>」</td><td>}</td><td>」</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

图4.7 文本格式示例

为了管理文本串的页和行, 在进入文本编辑的时候, 编辑程序先为文本串建立相应的页表和行表, 即建立各子串的存储映像。页表的每一项给出了页号和该页的起始行号。而行表的每一项则指示每一行的行号、起始地址和该行子串的长度。假设图 4.7 所示文本串只占一页, 且起始行号为 100, 则该文本串的行表如图 4.8 所示。

<table><tr><td>行号</td><td>起始地址</td><td>长度</td></tr><tr><td>100</td><td>201</td><td>8</td></tr><tr><td>101</td><td>209</td><td>17</td></tr><tr><td>102</td><td>226</td><td>24</td></tr><tr><td>103</td><td>250</td><td>17</td></tr><tr><td>104</td><td>267</td><td>15</td></tr><tr><td>105</td><td>282</td><td>2</td></tr></table>

图4.8 图4.7所示文本串的行表

文本编辑程序中设立页指针、行指针和字符指针，分别指示当前操作的页、行和字符。如果在某行内插入或删除若干字符，则要修改行表中该行的长度。若该行的长度超出了分配给它的存储空间，则要为该行重新分配存储空间，同时还要修改该行的起始位置。如果要插入或删除一行，就要涉及行表的插入或删除。若被删除的行是所在页的起始行，则还要修改页表中相应页的起始行号（修改为下一行的行号）。为了查找方便，行表是按行号递增顺序存储的，因此，对行表进行的插入或删除运算需移动操作位置以后的全部表项。页表的维护与行表类似，在此不再赘述。由于访问是以页表和行表作为索引的，所以在作行和页的删除操作时，可以只对行表和页表作相应的修改，不必删除所涉及的字符。这可以节省不少时间。

以上概述了文本编辑程序中的基本操作。其具体的算法，读者可在学习本章之后自行编写。

# 4.4.2 建立词索引表

信息检索是计算机应用的重要领域之一。由于信息检索的主要操作是在大量的存放在磁盘上的信息中查询一个特定的信息，为了提高查询效率，一个重要的问题是建立一个好的索引系统。例如我们在1.1节中提到过的图书馆书目检索系统中有3张索引表，分别可按书名、作者名和分类号编排。在实际系统中，按书名检索并不方便，因为很多内容相似的书籍其书名不一定相同。因此较好的办法是建立“书名关键词索引”。

例如，与图4.9(a)中书目相应的关键词索引表如图4.9(b)所示，读者很容易从关键词索引表中查询到他所感兴趣的书目。为了便于查询，可设定此索引表为按词典有序的线性表。下面要讨论的是如何从书目文件生成这个有序词表。

<table><tr><td>书号</td><td>书名</td></tr><tr><td>005</td><td>Computer Data Structures</td></tr><tr><td>010</td><td>Introduction to Data Structures</td></tr><tr><td>023</td><td>Fundamentals of Data Structures</td></tr><tr><td>034</td><td>The Design and Analysis of Computer Algorithms</td></tr><tr><td>050</td><td>Introduction to Numerical Analysis</td></tr><tr><td>067</td><td>Numerical Analysis</td></tr></table>

(a)  

<table><tr><td>关键词</td><td>书号索引</td></tr><tr><td>algorithms</td><td>034</td></tr><tr><td>analysis</td><td>034,050,067</td></tr><tr><td>computer</td><td>005,034</td></tr><tr><td>data</td><td>005,010,023</td></tr><tr><td>design</td><td>034</td></tr><tr><td>fundamentals</td><td>023</td></tr><tr><td>introduction</td><td>010,050</td></tr><tr><td>numerical</td><td>050,067</td></tr><tr><td>structures</td><td>005,010,023</td></tr></table>

(b)

图4.9 书目文件及其关键词索引表

(a) 书目文件；(b) 关键词索引表

重复下列操作直至文件结束：

（1）从书目文件中读入一个书目串；  
（2）从书目串中提取所有关键词插入词表；  
（3）对词表中的每一个关键词，在索引表中进行查找并作相应的插入操作。

为识别从书名串中分离出来的单词是否是关键词，需要一张常用词表（在英文书名中的“常用词”指的是诸如“an”、“a”、“of”、“the”等词）。顺序扫描书名串，首先分离单词，然后查找常用词表，若不和表中任一词相等，则为关键词，插入临时存放关键词的词表中。

在索引表中查询关键词时可能出现两种情况：其一是索引表上已有此关键词的索引项，只要在该项中插入书号索引即可；其二是需在索引表中插入此关键词的索引项，插入应按字典有序原则进行。下面就重点讨论这第三个操作的具体实现。

首先设定数据结构。

词表为线性表，只存放一本书的书名中若干关键词，其数量有限，则采用顺序存储结构即可，其中每个词是一个字符串。

索引表为有序表，虽是动态生成，在生成过程中需频繁进行插入操作，但考虑索引表

主要为查找用，为了提高查找效率(采用第9章中将讨论的折半查找)，宜采用顺序存储结构；表中每个索引项包含两个内容：其一是关键词，因索引表为常驻结构，则应考虑节省存储，采用堆分配存储表示的串类型；其二是书号索引，由于书号索引是在索引表的生成过程中逐个插入，且不同关键词的书号索引个数不等，甚至可能相差很多，则宜采用链表结构的线性表。

```c
define MaxBookNum 1000 //假设只对1000本书建索引表
#define MaxKeyNum 2500 //索引表的最大容量
#define MaxLineLen 500 //书目串的最大长度
#define MaxWordNum 10 //词表的最大容量
```

```c
typedef struct{ char \*item[]; //字符串的数组 int last; //词表的长度   
}WordListType; //词表类型(顺序表)   
typedef int ElemType; //定义链表的数据元素类型为整型（书号类型）   
typedef struct{ HString key; //关键词 LinkList bnolist; //存放书号索引的链表   
}IdxTermType; //索引项类型   
typedef struct{ IdxTermType item[MaxKeyNum + 1]; int last;   
}IdxListType; //索引表类型(有序表)
```

```txt
// 主要变量  
char *buf; // 书目串缓冲区  
WordListType wdlist; // 词表
```

```txt
//基本操作  
void InitIdxList(IdxelistType&idxlist); //初始化操作，置索引表idxlist为空表，且在idxlist.item[0]设一空串  
void GetLine(FILE f); //从文件f读入一个书目信息到书目串缓冲区buf  
void ExtractKeyWord(ElemType&bno); //从buf中提取书名关键词到词表wdlist，书号存入bno  
Status InsIdxList(IdxelistType&idxlist，ElemTypebno); //将书号为bno的书名关键词按词典顺序插入索引表idxlist  
void PutText(FILE g，IdxelistTypeidxlist); //将生成的索引表idxlist输出到文件g
```

```javascript
void main(){//主函数  
if  $(\mathsf{f} =$  openf("BookInfo.txt","r"))  
if  $(\mathsf{g} =$  openf("BookIdx.txt,"w")){InitIdxList(idxlist); //初始化索引表idxlist为空表while(!feof(f)){GetLine(f); //从文件f读入一个书目信息到bufExtractKeyWord(BookNo); //从buf提取关键词到词表，书号存入BookNo
```

```javascript
InsIdxList(idxlist, BookNo); //将书号为BookNo的关键词插入索引表
}PutText(g, idxlist); //将生成的索引表idxlist输出到文件g
}// main
```

# 算法 4.9

为实现在索引表上进行插入，要先实现下列操作：

```c
void GetWord (int i, HString &wd); //用wd返回词表wdlist中第i个关键词。  
int Locate(IdxDListType idxlist, HString wd, Boolean &b); //在索引表idxlist中查询是否存在与wd相等的关键词。若存在，则返回其在索引表//中的位置，且b取值TRUE；否则返回插入位置，且b取值FALSE  
void InsertNewKey(IdxDListType&idxlist，inti，HStringwd); //在索引表idxlist的第i项上插入新关键词wd，并初始化书号索引的链表为空表  
StatusInsertBook(IdxDListType&idxlist，inti，intbno); //在索引表idxlist的第i项中插入书号为bno的索引
```

由此可得索引表的插入算法如算法4.10所示。

```txt
Status InsIdxList (IdxelistType &idxlist, int bno) {  
for (i = 0; i < wdlist.last; ++i) {  
    GetWord(i, wd); j = Locate(idxlist, wd, b);  
    if (!b) InsertNewKey(idxlist, j, wd); // 插入新的索引项  
    if (!InsertBook(idxlist, j, bno)) return OVERFLOW; // 插入书号索引  
}  
return OK;  
} // InsertIdxList
```

# 算法 4.10

其中4个操作的具体实现分别如算法4.11、4.12、4.13和4.14所示。

```javascript
void GetWord (int i, HString &wd) {
    p = *(wdlist.item + i); // 取词表中第i个字符串
    Assign(wd, p); // 生成关键字字符串
} // GetWord
```

# 算法 4.11

```objectivec
intLocate（IdxListType&idxlist，HStringwd，Boolean&b）{for（i=idxlist.last-1;  $(\mathfrak{m} =$  StrCompare（idxlist.item[i].key，wd)）>0；--i）;if  $(\mathfrak{m} = = 0)$  {b  $=$  TRUE; return i; //找到else  $\{\mathrm{b} =$  FALSE; return  $\mathrm{i + 1}$  ；}
```

# 算法 4.12

```javascript
void InsertNewKey (int i, StrType wd) {
    for (j = idxlist.last - 1; j >= i; --j) //后移索引项
        idxlist.item[j + 1] = idxlist.item[j];
    //插入新的索引项
    StrCopy(idxlist.item[i].key, wd); //串赋值
    InitList(idxlist.item[i].bnolist); //初始化书号索引表为空表
    ++idxlist.last;
} //InsertNewKey
```

# 算法 4.13

```txt
Status InsertBook (IdxListType &idxlist, int i, int bno). { if (!MakeNode(p, bno)) return ERROR; //分配失败 Append (idxlist.item[i].bnolist, p); //插入新的书号索引 return OK; } //InsertBook
```

# 算法 4.14

# 第5章 数组和广义表

前几章讨论的线性结构中的数据元素都是非结构的原子类型，元素的值是不再分解的。本章讨论的两种数据结构——数组和广义表可以看成是线性表在下述含义上的扩展：表中的数据元素本身也是一个数据结构。

数组是读者已经很熟悉的一种数据类型，几乎所有的程序设计语言都把数组类型设定为固有类型。本章以抽象数据类型的形式讨论数组的定义和实现，使读者加深对数组类型的理解。

# 5.1 数组的定义

类似于线性表，抽象数据类型数组可形式地定义为：

ADT Array{

数据对象：  $\mathbf{j}_{\mathrm{i}} = 0,\dots ,\mathbf{b}_{\mathrm{i}} - 1$  ，  $\mathbf{i} = 1,2,\dots ,\mathbf{n}$

$\mathbf{D} = \{\mathbf{a}_{j_1j_2\dots j_n}\mid n(>0)$  称为数组的维数，  $\mathbf{b}_{i}$  是数组第  $i$  维的长度，

$\mathbf{j}_{i}$  是数组元素的第  $i$  维下标，  $\mathbf{a}_{j_1j_2\dots j_n}\in \mathbf{ElemSet}\}$

数据关系：  $\mathbb{R} = \{\mathbb{R}1$  ，R2，…，Rn}

$$
R i = \left\{\left. <   a _ {j _ {1} \dots j _ {i} \dots j _ {n}}, a _ {j _ {1} \dots j _ {i} + 1 \dots j _ {n}} > \right| \right.
$$

$0 \leqslant j_{k} \leqslant b_{k} - 1, \quad 1 \leqslant k \leqslant n$  且  $k \neq i$ ,

$$
\begin{array}{l} 0 \leqslant j _ {i} \leqslant b _ {i} - 2, \\ \left. \mathbf {a} _ {j _ {1} \dots j _ {i} \dots j _ {n}}, \mathbf {a} _ {j _ {1} \dots j _ {i} + 1 \dots j _ {n}} \in D, i = 2, \dots , n \right\} \\ \end{array}
$$

基本操作：

InitArray(&A, n, bound1, ..., boundn)

操作结果：若维数  $n$  和各维长度合法，则构造相应的数组 A，并返回 OK。

DestroyArray(&A)

操作结果：销毁数组A。

Value(A, &e, index1, ..., indexm)

初始条件：A是  $\mathfrak{n}$  维数组，e为元素变量，随后是  $\mathfrak{n}$  个下标值。

操作结果：若各下标不超界，则e赋值为所指定的A的元素值，并返回OK。

Assign(&A, e, index1, ..., indexn)

初始条件：A是  $\mathbf{n}$  维数组，e为元素变量，随后是  $\pmb{\mathrm{n}}$  个下标值。

操作结果：若下标不超界，则将  $\mathbf{e}$  的值赋给所指定的A的元素，并返回OK。

} ADT Array

这是一个C语言风格的定义。从上述定义可见， $n$  维数组中含有  $\prod_{i=1}^{n} b_i$  个数据元素，每个元素都受着  $n$  个关系的约束。在每个关系中，元素  $a_{j_1 j_2 \cdots j_n} (0 \leqslant j_i \leqslant b_i - 2)$  都有一个直接后继元素。因此，就其单个关系而言，这  $n$  个关系仍是线性关系。和线性表一样，所有的数据元素都必须属于同一数据类型。数组中的每个数据元素都对应于一组下标  $(j_1, j_2, \cdots, j_n)$ 。

$j_{2}, \cdots, j_{n}$ ), 每个下标的取值范围是  $0 \leqslant j_{i} \leqslant b_{i} - 1, b_{i}$  称为第  $i$  维的长度  $(i = 1, 2, \cdots, n)$  。显然, 当  $n = 1$  时,  $n$  维数组就退化为定长的线性表。反之,  $n$  维数组也可以看成是线性表的推广。由此, 我们也可以从另一个角度来定义  $n$  维数组。

我们可以把二维数组看成是这样一个定长线性表：它的每个数据元素也是一个定长线性表。例如。图5.1(a)所示是一个二维数组，以  $m$  行  $n$  列的矩阵形式表示。它可以看成是一个线性表

$$
A = \left(\alpha_ {0}, \alpha_ {1}, \dots , \alpha_ {p}\right) \quad (p = m - 1 \text {或} n - 1)
$$

其中每个数据元素  $\alpha_{j}$  是一个列向量形式的线性表

$$
\alpha_ {j} = \left(a _ {0 j}, a _ {1 j}, \dots , a _ {m - 1, j}\right) \quad 0 \leqslant j \leqslant n - 1
$$

（如图5.1(b)所示）或者  $\alpha_{i}$  是一个行向量形式的线性表

$$
\alpha_ {i} = \left(a _ {i 0}, a _ {i 1}, \dots , a _ {i, n - 1}\right) \quad 0 \leqslant i \leqslant m - 1
$$

（如图5.1(c)所示）。在C语言中，一个二维数组类型可以定义为其分量类型为一维数组类型的一维数组类型，也就是说，

$$
\text {t y p e d e f} \quad \text {E l e m T y p e} \quad \text {A r r a y 2 [ m ] [ n ]};
$$

等价于

$$
\begin{array}{l} \text {t y p e d e f} \quad \text {E l e m T y p e} \quad \text {A r r a l y 1 [ n ]}; \\ \begin{array}{l l} \text {t y p e d e f} & \text {A r r a y 1} \\ & \text {A r r a y 2 [ m ]}; \end{array} \\ \end{array}
$$

同理，一个  $n$  维数组类型可以定义为其数据元素为  $n - 1$  维数组类型的一维数组类型。

$$
A _ {m \times n} = \left[ \begin{array}{c c c c c} a _ {0 0} & a _ {0 1} & a _ {0 2} & \dots & a _ {0, n - 1} \\ a _ {1 0} & a _ {1 1} & a _ {1 2} & \dots & a _ {1, n - 1} \\ \vdots & \vdots & \vdots & & \vdots \\ a _ {m - 1, 0} & a _ {m - 1, 1} & a _ {m - 1, 2} & \dots & a _ {m - 1, n - 1} \end{array} \right], A _ {m \times n} = \left[ \begin{array}{c} \left[ \begin{array}{l} a _ {0 0} \\ a _ {1 0} \\ \vdots \\ a _ {m - 1, 0} \end{array} \right] \left[ \begin{array}{l} a _ {0 1} \\ a _ {1 1} \\ \vdots \\ a _ {m - 1, 1} \end{array} \right] \dots \left[ \begin{array}{l} a _ {0, n - 1} \\ a _ {1, n - 1} \\ \vdots \\ a _ {m - 1, n - 1} \end{array} \right] \end{array} \right]
$$

(a)

(b)

$$
A _ {m \times n} = \left(\left(a _ {0 0} a _ {0 1} \dots a _ {0, n - 1}\right), \left(a _ {1 0} a _ {1 1} \dots a _ {1, n - 1}\right), \dots , \left(a _ {m - 1, 0} a _ {m - 1, 1} \dots a _ {m - 1, n - 1}\right)\right)
$$

(c)

图5.1 二维数组图例

(a) 矩阵形式表示；(b) 列向量的一维数组；(c) 行向量的一维数组

数组一旦被定义，它的维数和维界就不再改变。因此，除了结构的初始化和销毁之外，数组只有存取元素和修改元素值的操作。

# 5.2 数组的顺序表示和实现

由于数组一般不作插入或删除操作，也就是说，一旦建立了数组，则结构中的数据元素个数和元素之间的关系就不再发生变动。因此，采用顺序存储结构表示数组是自然的事了。

由于存储单元是一维的结构，而数组是个多维的结构，则用一组连续存储单元存放数组的数据元素就有个次序约定问题。例如图5.1（a）的二维数组可以看成如图5.1(c)的

一维数组, 也可看成如图 5.1(b) 的一维数组。对应地, 对二维数组可有两种存储方式: 一种以列序为主序 (column major order) 的存储方式, 如图 5.2(a) 所示; 一种是以行序为主序 (row major order) 的存储方式, 如图 5.2(b) 所示。在扩展 BASIC、PL/1、COBOL、PASCAL 和 C 语言中, 用的都是以行序为主序的存储结构, 而在 FORTRAN 语言中, 用的是以列序为主序的存储结构。

图5.2 二维数组的两种存储方式  
![](images/fb80c0963db3f6e1914da7deed40f9c2fd6c9d96c7250de99257a077183c733a.jpg)  
(a) 以列序为主序；(b) 以行序为主序

由此，对于数组，一旦规定了它的维数和各维的长度，便可为它分配存储空间。反之，只要给出一组下标便可求得相应数组元素的存储位置。下面仅用以行序为主序的存储结构为例予以说明。

假设每个数据元素占  $L$  个存储单元, 则二维数组  $A$  中任一元素  $a_{ij}$  的存储位置可由下式确定

$$
\operatorname {L O C} (i, j) = \operatorname {L O C} (0, 0) + (b _ {2} \times i + j) L \tag {5-1}
$$

式中， $\mathrm{LOC}(i,j)$  是  $a_{ij}$  的存储位置； $\mathrm{LOC}(0,0)$  是  $a_{00}$  的存储位置，即二维数组  $A$  的起始存储位置，也称为基地址或基址。

将式(5-1)推广到一般情况，可得到  $n$  维数组的数据元素存储位置的计算公式：

$$
\begin{array}{l} \operatorname {L O C} \left(j _ {1}, j _ {2}, \dots , j _ {n}\right) = \operatorname {L O C} (0, 0, \dots , 0) + \left(b _ {2} \times \dots \times b _ {n} \times j _ {1} + b _ {3} \times \dots \times b _ {n} \times j _ {2} \right. \\ + \dots + b _ {n} \times j _ {n - 1} + j _ {n}) L \\ = \operatorname {L O C} (0, 0, \dots , 0) + \left(\sum_ {i = 1} ^ {n - 1} j _ {i} \prod_ {k = i + 1} ^ {n} b _ {k} + j _ {n}\right) L \\ \end{array}
$$

可缩写成

$$
\operatorname {L O C} \left(j _ {1}, j _ {2}, \dots , j _ {n}\right) = \operatorname {L O C} (0, 0, \dots , 0) + \sum_ {i = 1} ^ {n} c _ {i} j _ {i} \tag {5-2}
$$

其中  $c_{n} = L, c_{i - 1} = b_{i}\times c_{i},\quad 1 <   i\leqslant n_{\circ}$

式(5-2)称为  $n$  维数组的映像函数。容易看出，数组元素的存储位置是其下标的线性函数，一旦确定了数组的各维的长度， $c_{i}$  就是常数。由于计算各个元素存储位置的时间相等，所以存取数组中任一元素的时间也相等。我们称具有这一特点的存储结构为随机存储结构。

下面是数组的顺序存储表示和实现。

//----数组的顺序存储表示---  
include<stdio.h> //标准头文件，提供宏va_start、va_arg和va_end, //用于存取变长参数表 #define MAX_ARRAY_DIM 8 //假设数组维数的最大值为8 typedef struct{ ElemType \*base; //数组元素基址，由InitArray分配 int dim; //数组维数 int \* bounds; //数组维界基址，由InitArray分配 int \*constants; //数组映像函数常量基址，由InitArray分配 }Array;

//- - - - - 基本操作的函数原型说明 - - - -  
Status InitArray(Array &A, int dim, ...); // 若维数 dim 和随后的各维长度合法，则构造相应的数组 A，并返回 OK。  
Status DestroyArray(Array &A); // 销毁数组 A。  
Status Value(Array A, ElemType &e, ...); // A 是 n 维数组，e 为元素变量，随后是 n 个下标值。 // 若各下标不超界，则 e 赋值为所指定的 A 的元素值，并返回 OK。  
Status Assign(Array &A, ElemType e, ...); // A 是 n 维数组，e 为元素变量，随后是 n 个下标值。 // 若下标不超界，则将 e 的值赋给所指定的 A 的元素，并返回 OK。  
// ---- 基本操作的算法描述 ----  
Status InitArray(Array &A, int dim, ...) { // 若维数 dim 和各维长度合法，则构造相应的数组 A，并返回 OK. if (dim < 1 || dim > MAX_ARRAY_DIM) return ERROR; A.dim = dim; A.bounds = (int *)malloc(dim * sizeof(int)); if (!A.bounds) exit(OVERFLOW); // 若各维长度合法，则存入 A.bounds，并求出 A 的元素总数 elemtotal elemtotal = 1;

```javascript
va_start(ap, dim); // ap为va.list类型，是存放变长参数表信息的数组  
for  $(i = 0; i <   \dim ; + + i)$  {A.bounds[i]  $=$  va_arg(ap,int);if(A.bounds[i]<0) return UNDERFLOW;elemtotal  $\ast =$  A.bounds[i];}va_end(ap);A.base  $=$  (ElemType \*)malloc(elemtotal \* sizeof(ElemType));if(!A.base)exit(OVERFLOW);//求映像函数的常数  $c_{i}$  ，并存入A Constants[i-1],  $i = 1,\dots ,$  dimA CONSTANTS  $=$  (int  $\ast$  )malloc(dim  $\ast$  sizeof(int));if(!A CONSTANTS)exit(OVERFLOW);A CONSTANTS[dim-1]=1; //L=1,指针的增减以元素的大小为单位for（  $i = \mathrm{dim} - 2$  ：  $\dot{\mathbf{l}} > = 0$  ：--i）A CONSTANTS[i]  $=$  A.bounds[i+1]\*A CONSTANTS[i+1];return OK;  
}  
StatusDestroyArray(Array &A){//销毁数组A。if(!A.base) return ERROR;free(A.base); A.base  $=$  NULL;if!(A.bounds) return ERROR;free(A.bounds); A.bounds  $=$  NULL;if!(A CONSTANTS) return ERROR;free(A CONSTANTS); A CONSTANTS  $=$  NULL;return OK;  
}  
StatusLocate(Array A,va_list ap,int&off){//若ap指示的各下标值合法，则求出该元素在A中相对地址offoff  $= 0$  for  $(\mathrm{i} = 0;\quad \mathrm{i} <   \mathrm{A.dim};\quad + + \mathrm{i})$  {ind  $=$  va_arg(ap,int);if(ind<0||ind>=A.bounds[i]) return OVERFLOW;off  $+ =$  A CONSTANTS[i]\*ind;}return OK;  
}  
StatusValue(Array A,ElemType&e,…）{//A是n维数组,e为元素变量，随后是n个下标值。//若各下标不超界，则e赋值为所指定的A的元素值，并返回OK。va start(ap,e);if((result  $=$  Locate(A,ap,off))  $<   = 0$  ）return result;e  $=$  \*(A.base  $^+$  off);return OK;
```

```javascript
}Status Assign(Array&A,ElemTypee，…）{//A是n维数组，e为元素变量，随后是  $\mathbf{n}$  个下标值。//若下标不超界，则将e的值赋给所指定的A的元素，并返回OK。va.start(ap,e);if((result  $=$  Locate(A,ap,off))  $<   = 0$  ）return result;\*（A.base  $^+$  off）=e;return OK;  
1
```

# 5.3 矩阵的压缩存储

矩阵是很多科学与工程计算问题中研究的数学对象。在此，我们感兴趣的不是矩阵本身，而是如何存储矩阵的元，从而使矩阵的各种运算能有效地进行。

通常，用高级语言编制程序时，都是用二维数组来存储矩阵元。有的程序设计语言中还提供了各种矩阵运算，用户使用时都很方便。

然而，在数值分析中经常出现一些阶数很高的矩阵，同时在矩阵中有许多值相同的元素或者是零元素。有时为了节省存储空间，可以对这类矩阵进行压缩存储。所谓压缩存储是指：为多个值相同的元只分配一个存储空间；对零元不分配空间。

假若值相同的元素或者零元素在矩阵中的分布有一定规律，则我们称此类矩阵为特殊矩阵；反之，称为稀疏矩阵。下面分别讨论它们的压缩存储。

# 5.3.1 特殊矩阵

若  $n$  阶矩阵  $A$  中的元满足下述性质

$$
a _ {i j} = a _ {j i} \quad 1 \leqslant i, j \leqslant n
$$

则称为  $n$  阶对称矩阵。

对于对称矩阵，我们可以为每一对对称元分配一个存储空间，则可将  $n^2$  个元压缩存储到  $n(n + 1) / 2$  个元的空间中。不失一般性，我们可以行序为主序存储其下三角（包括对角线）中的元。

假设以一维数组  $sa[n(n + 1) / 2]$  作为  $n$  阶对称矩阵  $A$  的存储结构，则  $sa[k]$  和矩阵元 $a_{ij}$  之间存在着一一对应的关系：

$$
k = \left\{ \begin{array}{l l} \frac {i (i - 1)}{2} + j - 1 & \text {当} i \geqslant j \\ \frac {j (j - 1)}{2} + i - 1 & \text {当} i <   j \end{array} \right. \tag {5-3}
$$

对于任意给定一组下标  $(i,j)$ , 均可在  $sa$  中找到矩阵元  $a_{ij}$ , 反之, 对所有的  $k = 0,1,2,\dots, \frac{n(n + 1)}{2} - 1$ , 都能确定  $sa[k]$  中的元在矩阵中的位置  $(i,j)$  。由此, 称  $sa[n(n + 1)/2]$  为  $n$  阶对称矩阵  $A$  的压缩存储(见图5.3)。

![](images/1e8f7c0f5ab7b424ad0a7e9d48b0eb7282eaefc3540fce40893798b7cbba3fe6.jpg)  
图5.3对称矩阵的压缩存储

这种压缩存储的方法同样也适用于三角矩阵。所谓下(上)三角矩阵是指矩阵的上(下)三角(不包括对角线)中的元均为常数  $c$  或零的  $n$  阶矩阵。则除了和对称矩阵一样，只存储其下(上)三角中的元之外，再加一个存储常数  $c$  的存储空间即可。

在数值分析中经常出现的还有另一类特殊矩阵是对角矩阵。在这种矩阵中，所有的非零元都集中在以主对角线为中心的带状区域中。即除了主对角线上和直接在对角线上、下方若干条对角线上的元之外，所有其他的元皆为零。如图5.4所示。对这种矩阵，我们也可按某个原则(或以行为主，或以对角线的顺序)将其压缩存储到一维数组上。

图5.4 对角矩阵  
![](images/4ff016d24a0f541311f9ef15e1d1f943131588dfcdff3f4879db896278c484db.jpg)  
(a) 一般情形；(b) 三对角矩阵

在所有这些我们统称为特殊矩阵的矩阵中，非零元的分布都有一个明显的规律，从而我们都可将其压缩存储到一维数组中，并找到每个非零元在一维数组中的对应关系。

然而，在实际应用中我们还经常会遇到另一类矩阵，其非零元较零元少，且分布没有一定规律，我们称之为稀疏矩阵。这类矩阵的压缩存储就要比特殊矩阵复杂。这就是下一节我们要讨论的问题。

# 5.3.2 稀疏矩阵

什么是稀疏矩阵？人们无法给出确切的定义，它只是一个凭人们的直觉来了解的概念。假设在  $m \times n$  的矩阵中，有  $t$  个元素不为零。令  $\delta = \frac{t}{m \times n}$ ，称  $\delta$  为矩阵的稀疏因子。通常认为  $\delta \leqslant 0.05$  时称为稀疏矩阵。矩阵运算的种类很多，在下列抽象数据类型稀疏矩阵的定义中，只列举了几种常见的运算。

抽象数据类型稀疏矩阵的定义如下：

```txt
ADTSparseMatrix{数据对象  $:\mathbf{D} = \{\mathsf{a}_{i,j}\mid i = 1,2,\dots ,m;j = 1,2,\dots ,n;$ $a_{i,j}\in \mathsf{ElemSet},\mathsf{m}$  和  $\mathsf{n}$  分别称为矩阵的行数和列数}
```

数据关系：  $\mathbf{R} = \{\mathrm{Row},\mathrm{Col}\}$

$$
\operatorname {R o w} = \left\{\left. <   a _ {i, j}, a _ {i, j + 1} > \right| 1 \leqslant i \leqslant m, \quad 1 \leqslant j \leqslant n - 1 \right\}
$$

$$
\operatorname {C o l} = \left\{\left. <   a _ {i, j}, a _ {i + 1, j} > \right| 1 \leqslant i \leqslant m - 1, \quad 1 \leqslant j \leqslant n \right\}
$$

基本操作：

CreateSMatrix(&M);

操作结果：创建稀疏矩阵  $\mathbf{M}$ 。

DestroySMatrix(&M);

初始条件：稀疏矩阵  $\mathbf{M}$  存在。

操作结果：销毁稀疏矩阵M。

PrintSMatrix(M);

初始条件：稀疏矩阵M存在。

操作结果：输出稀疏矩阵M。

CopySMatrix(M, &T);

初始条件：稀疏矩阵M存在。

操作结果：由稀疏矩阵M复制得到T。

AddSMatrix(M,N,&Q);

初始条件：稀疏矩阵  $\mathbf{M}$  与  $\mathbb{N}_i$  的行数和列数对应相等。

操作结果：求稀疏矩阵的和  $Q = M + N$

SubMatrix(M, N, &Q);

初始条件：稀疏矩阵  $\mathbf{M}$  与  $\mathbf{N}$  的行数和列数对应相等。

操作结果：求稀疏矩阵的差  $Q = M - N$ 。

MultSMatrix(M,N,&Q);

初始条件：稀疏矩阵  $\mathbf{M}$  的列数等于  $\mathbf{N}$  的行数。

操作结果：求稀疏矩阵乘积  $Q = M \times N$ 。

TransposeSMatrix(M, &T);

初始条件：稀疏矩阵  $\mathbf{M}$  存在。

操作结果：求稀疏矩阵  $\mathbf{M}$  的转置矩阵  $\mathbf{T}$ 。

ADT SparseMatrix

如何进行稀疏矩阵的压缩存储呢？

按照压缩存储的概念，只存储稀疏矩阵的非零元。因此，除了存储非零元的值之外，还必须同时记下它所在行和列的位置  $(i,j)$  。反之，一个三元组  $(i,j,a_{ij})$  惟一确定了矩阵  $A$  的一个非零元。由此，稀疏矩阵可由表示非零元的三元组及其行列数惟一确定。例如，下列三元组表

$(1,2,12),(1,3,9),(3,1,-3),(3,6,14),(4,3,24),(5,2,18),(6,1,15),(6,4,-7))$

加上(6,7)这一对行、列值便可作为图5.5中矩阵  $M$  的另一种描述。而由上述三元组表的不同表示方法可引出稀疏矩阵不同的压缩存储方法。

$$
M = \left[ \begin{array}{c c c c c c c} 0 & 1 2 & 9 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ - 3 & 0 & 0 & 0 & 0 & 1 4 & 0 \\ 0 & 0 & 2 4 & 0 & 0 & 0 & 0 \\ 0 & 1 8 & 0 & 0 & 0 & 0 & 0 \\ 1 5 & 0 & 0 & - 7 & 0 & 0 & 0 \end{array} \right] \quad T = \left[ \begin{array}{c c c c c c} 0 & 0 & - 3 & 0 & 0 & 1 5 \\ 1 2 & 0 & 0 & 0 & 1 8 & 0 \\ 9 & 0 & 0 & 2 4 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & - 7 \\ 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 4 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 \end{array} \right]
$$

图5.5 稀疏矩阵  $M$  和  $\pmb{T}$

# 1. 三元组顺序表

假设以顺序存储结构来表示三元组表，则可得稀疏矩阵的一种压缩存储方式——我们称之为三元组顺序表。

```c
// -- -- -- 稀疏矩阵的三元组顺序表存储表示 -- -- --  
#define MAXSIZE 12500 // 假设非零元个数的最大值为 12500  
typedef struct {  
    int i, j; // 该非零元的行下标和列下标  
    ElemType e;  
} Triple;  
typedef struct {  
    Triple data[MAXSIZE + 1]; // 非零元三元组表，data[0]未用  
    int mu, nu, tu; // 矩阵的行数、列数和非零元个数  
} TSMatrix;
```

在此，data域中表示非零元的三元组是以行序为主序顺序排列的，从下面的讨论中读者容易看出这样做将有利于进行某些矩阵运算。下面将讨论在这种压缩存储结构下如何实现矩阵的转置运算。

转置运算是一种最简单的矩阵运算。对于一个  $m \times n$  的矩阵  $M$ ，它的转置矩阵  $T$  是一个  $n \times m$  的矩阵，且  $T(i, j) = M(j, i)$ ， $1 \leqslant i \leqslant n$ ， $1 \leqslant j \leqslant m$ 。例如，图5.5中的矩阵  $M$  和  $T$  互为转置矩阵。

显然，一个稀疏矩阵的转置矩阵仍然是稀疏矩阵。假设  $a$  和  $b$  是  $\mathrm{TSMatrix}$  型的变量，分别表示矩阵  $M$  和  $T$  。那么，如何由  $a$  得到  $b$  呢？

从分析  $a$  和  $b$  之间的差异可见只要做到：(1)将矩阵的行列值相互交换；(2)将每个三元组中的  $i$  和  $j$  相互调换；(3)重排三元组之间的次序便可实现矩阵的转置。前二条是容易做到的，关键是如何实现第三条。即如何使 b.data 中的三元组是以  $T$  的行 (M 的列)为主序依次排列的。

<table><tr><td>i</td><td>j</td><td>v</td></tr><tr><td>1</td><td>2</td><td>12</td></tr><tr><td>1</td><td>3</td><td>9</td></tr><tr><td>3</td><td>1</td><td>-3</td></tr><tr><td>3</td><td>6</td><td>14</td></tr><tr><td>4</td><td>3</td><td>24</td></tr><tr><td>5</td><td>2</td><td>18</td></tr><tr><td>6</td><td>1</td><td>15</td></tr><tr><td>6</td><td>4</td><td>-7</td></tr></table>

a. data  

<table><tr><td>i</td><td>j</td><td>v</td></tr><tr><td>1</td><td>3</td><td>-3</td></tr><tr><td>1</td><td>6</td><td>15</td></tr><tr><td>2</td><td>1</td><td>12</td></tr><tr><td>2</td><td>5</td><td>18</td></tr><tr><td>3</td><td>1</td><td>9</td></tr><tr><td>3</td><td>4</td><td>24</td></tr><tr><td>4</td><td>6</td><td>-7</td></tr><tr><td>6</td><td>3</td><td>14</td></tr></table>

b.data

可以有两种处理方法：

(1) 按照 b.data 中三元组的次序依次在 a.data 中找到相应的三元组进行转置。换句话说, 按照矩阵  $M$  的列序来进行转置。为了找到  $M$  的每一列中所有的非零元素, 需要对其三元组表 a.data 从第一行起整个扫描一遍, 由于 a.data 是以  $M$  的行序为主序来存放每个非零元的, 由此得到的恰是 b.data 应有的顺序。其具体算法描述如算法 5.1 所示。

```javascript
Status TransposeSMatrix(TSMatrix M,TSMatrix&T) { //采用三元组表存储表示，求稀疏矩阵M的转置矩阵  $\mathbf{T}_{\circ}$    
T.mu  $=$  M.nu; T.nu  $=$  M.mu; T.tu  $=$  M.tu; if（T.tu）{ q=1; for  $(\mathrm{col} = 1;\mathrm{col} <   = \mathrm{M.nu}; + + \mathrm{col})$  for  $(p = 1;p <   = M.tu; + + p)$  if(M.data[p].j  $= =$  col）{ T.data[q].i  $=$  M.data[p].j; T.data[q].j  $=$  M.data[p].i; T.data[q].e  $=$  M.data[p].e; ++q;} } return OK;   
}// TransposeSMatrix
```

# 算法 5.1

分析这个算法, 主要的工作是在  $\mathfrak{p}$  和  $\operatorname{col}$  的两重循环中完成的, 故算法的时间复杂度为  $O(\mathrm{nu} \cdot \mathrm{tu})^{1}$ , 即和  $M$  的列数及非零元的个数的乘积成正比。我们知道, 一般矩阵的转置算法为

```javascript
for  $(\mathrm{col} = 1;\mathrm{col} <   = \mathrm{nu}; + + \mathrm{col})$  for  $(\mathrm{row} = 1;\mathrm{row} <   = \mathrm{mu}; + + \mathrm{row})$ $\mathrm{T[col][row] = M[row][col]};$
```

其时间复杂度为  $O(\mathrm{mu} \times \mathrm{nu})$  。当非零元的个数  $\mathrm{tu}$  和  $\mathrm{mu} \times \mathrm{nu}$  同数量级时，算法5.1的时间复杂度就为  $O(\mathrm{mu} \times \mathrm{nu}^2)$  了（例如，假设在  $100 \times 500$  的矩阵中有  $\mathrm{tu} = 10000$  个非零元），虽然节省了存储空间，但时间复杂度提高了，因此算法5.1仅适于  $\mathrm{tu} \ll \mathrm{mu} \times \mathrm{nu}$  的情况。

（2）按照a.data中三元组的次序进行转置，并将转置后的三元组置入  $b$  中恰当的位置。如果能预先确定矩阵  $M$  中每一列(即  $T$  中每一行)的第一个非零元在b.data中应有的位置，那么在对a.data中的三元组依次作转置时，便可直接放到b.data中恰当的位置上去。为了确定这些位置，在转置前，应先求得  $M$  的每一列中非零元的个数，进而求得每一列的第一个非零元在b.data中应有的位置。

在此，需要附设 num 和 cpot 两个向量。num[col]表示矩阵  $M$  中第 col 列中非零元的个数，cpot[col]指示  $M$  中第 col 列的第一个非零元在 b.data 中的恰当位置。显然有

$$
\left\{ \begin{array}{l} \operatorname {c p o t} [ 1 ] = 1; \\ \operatorname {c p o t} [ \operatorname {c o l} ] = \operatorname {c p o t} [ \operatorname {c o l} - 1 ] + \operatorname {n u m} [ \operatorname {c o l} - 1 ] \quad 2 \leqslant \operatorname {c o l} \leqslant \mathrm {a . n u} \end{array} \right. \tag {5-4}
$$

例如，对图5.5的矩阵  $M$  ，num和cpot的值如表5.1所示。

表 5.1 矩阵  $M$  的向量 cpot 的值  

<table><tr><td>col</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr><tr><td>num[col]</td><td>2</td><td>2</td><td>2</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>cpot[col]</td><td>1</td><td>3</td><td>5</td><td>7</td><td>8</td><td>8</td><td>9</td></tr></table>

这种转置方法称为快速转置，其算法如算法5.2所示。

```txt
Status FastTransposeSMatrix(TSMatrix M, TSMatrix &T) {
// 采用三元组顺序表存储表示，求稀疏矩阵M的转置矩阵T。
T.mu = M.nu; T.nu = M.mu; T.tu = M.tu;
if (T.tu) {
    for (col = 1; col <= M.nu; ++ col) num[col] = 0;
    for (t = 1; t <= M.tu; ++ t) ++ num[M.data[t].j]; // 求M中每一列含非零元个数
    cpot[1] = 1;
    // 求第col列中第一个非零元在b.data中的序号
    for (col = 2; col <= M.nu; ++ col) cpot[col] = cpot[col-1] + num[col-1];
    for (p = 1; p <= M.tu; ++ p) {
        col = M.data[p].j; q = cpot[col];
        T.data[q].i = M.data[p].j; T.data[q].j = M.data[p].i;
        T.data[q].e = M.data[p].e; ++ cpot[col];
    } // for
} // if
return OK;
} // FastTransposeSMatrix
```

# 算法 5.2

这个算法仅比前一个算法多用了两个辅助向量①。从时间上看，算法中有4个并列的单循环，循环次数分别为nu和tu，因而总的时间复杂度为  $O(\mathrm{nu} + \mathrm{tu})$  。在M的非零元个数tu和  $\mathbf{mu}\times \mathbf{nu}$  等数量级时，其时间复杂度为  $O(\mathrm{mu}\times \mathrm{nu})$  ，和经典算法的时间复杂度相同。

三元组顺序表又称有序的双下标法，它的特点是，非零元在表中按行序有序存储，因此便于进行依行顺序处理的矩阵运算。然而，若需按行号存取某一行的非零元，则需从头开始进行查找。

# 2. 行逻辑链接的顺序表

为了便于随机存取任意一行的非零元，则需知道每一行的第一个非零元在三元组表中的位置。为此，可将上节快速转置矩阵的算法中创建的，指示“行”信息的辅助数组cpot固定在稀疏矩阵的存储结构中。称这种“带行链接信息”的三元组表为行逻辑链接的顺序表，其类型描述如下：

```txt
typedef struct{ Triple data[MAXSIZE + 1]; //非零元三元组表 int rpos[MAXRC + 1]; //各行第一个非零元的位置表 int mu, nu, tu; //矩阵的行数、列数和非零元个数 }RLSMatrix;
```

在下面讨论的两个稀疏矩阵相乘的例子中，容易看出这种表示方法的优越性。

两个矩阵相乘的经典算法也是大家所熟悉的。若设

$$
Q = M \times N
$$

其中，  $M$  是  $m_{1}\times n_{1}$  矩阵，  $N$  是  $m_2\times n_2$  矩阵。当  $n_1 = m_2$  时有：

$$
\begin{array}{r l} & {\text {f o r (i = 1 ; i <   = m 1 ; + + i)}} \\ & {\quad \text {f o r (j = 1 ; j <   = n 2 ; + + j) \left\{\right.}} \\ & {\qquad \qquad \qquad \qquad \qquad Q [ i ] [ j ] = 0;} \\ & {\quad \text {f o r (k = 1 ; k <   = n 1 ; + + k) Q [ i ] [ j ] + = M [ i ] [ k ] * N [ k ] [ j ]};} \\ & {\quad \left. \right\}} \end{array}
$$

此算法的时间复杂度是  $O(m_{1} \times n_{1} \times n_{2})$ 。

当  $M$  和  $N$  是稀疏矩阵并用三元组表作存储结构时，就不能套用上述算法。假设  $M$  和  $N$  分别为

$$
M = \left( \begin{array}{r r r r} 3 & 0 & 0 & 5 \\ 0 & - 1 & 0 & 0 \\ 2 & 0 & 0 & 0 \end{array} \right) \quad N = \left( \begin{array}{r r} 0 & 2 \\ 1 & 0 \\ - 2 & 4 \\ 0 & 0 \end{array} \right) \tag {5-5}
$$

则  $Q = M \times N$  为

$$
Q = \left[ \begin{array}{c c} 0 & 6 \\ - 1 & 0 \\ 0 & 4 \end{array} \right]
$$

它们的三元组M.data、N.data和Q.data分别为：

<table><tr><td>i</td><td>j</td><td>e</td></tr><tr><td>1</td><td>1</td><td>3</td></tr><tr><td>1</td><td>4</td><td>5</td></tr><tr><td>2</td><td>2</td><td>-1</td></tr><tr><td>3</td><td>1</td><td>2</td></tr></table>

M. data  

<table><tr><td>i</td><td>j</td><td>e</td></tr><tr><td>1</td><td>2</td><td>2</td></tr><tr><td>2</td><td>1</td><td>1</td></tr><tr><td>3</td><td>1</td><td>-2</td></tr><tr><td>3</td><td>2</td><td>4</td></tr></table>

N.data  

<table><tr><td>i</td><td>j</td><td>e</td></tr><tr><td>1</td><td>2</td><td>6</td></tr><tr><td>2</td><td>1</td><td>-1</td></tr><tr><td>3</td><td>2</td><td>4</td></tr></table>

Q. data

那么如何从  $M$  和  $N$  求得  $Q$  呢？

（1）乘积矩阵  $Q$  中元素

$$
Q (i, j) = \sum_ {k = 1} ^ {n _ {1}} M (i, k) \times N (k, j) \quad \begin{array}{l l} 1 \leqslant i \leqslant m _ {1} \\ 1 \leqslant j \leqslant n _ {2} \end{array} \tag {5-6}
$$

在经典算法中, 不论  $M(i, k)$  和  $N(k, j)$  的值是否为零, 都要进行一次乘法运算, 而实际上, 这两者有一个值为零时, 其乘积也为零。因此, 在对稀疏矩阵进行运算时, 应免去这种无效操作, 换句话说, 为求  $Q$  的值, 只需在 M.data 和 N.data 中找到相应的各对元素 (即 M.data 中的  $j$  值和 N.data 中的  $i$  值相等的各对元素) 相乘即可。

例如，M.data[1]表示的矩阵元(1,1,3)只要和N.data[1]表示的矩阵元(1,2,2)相乘；而M.data[2]表示的矩阵元(1,4,5)则不需和N中任何元素相乘，因为N.data中没有i为4的元素。由此可见，为了得到非零的乘积，只要对M.data[1..M.tu]中的每个元

素  $(i, k, M(i, k))$  （ $1 \leqslant i \leqslant m_1, 1 \leqslant k \leqslant n_1$ ），找到 N. data 中所有相应的元素  $(k, j, N(k, j))$ （ $1 \leqslant k \leqslant m_2, 1 \leqslant j \leqslant n_2$ ）相乘即可，为此需在 N. data 中寻找矩阵  $N$  中第  $k$  行的所有非零元。在稀疏矩阵的行逻辑链接的顺序表中，N. rpos 为我们提供了有关信息。例如，式 (5-5) 中的矩阵  $N$  的 rpos 值如表 5.2 所示。

表 5.2 矩阵  $\mathbf{N}$  的 rpos 值  

<table><tr><td>row</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>rpos[row]</td><td>1</td><td>2</td><td>3</td><td>5</td></tr></table>

并且, 由于  $\text{rpos[row]}$  指示矩阵  $N$  的第 row 行中第一个非零元在 N.data 中的序号, 则  $\text{rpos[row+1]} - 1$  指示矩阵  $N$  的第 row 行中最后一个非零元在 N.data 中的序号。而最后一行中最后一个非零元在 N.data 中的位置显然就是 N.tu 了。

（2）稀疏矩阵相乘的基本操作是：对于  $M$  中每个元素  $\mathbf{M}$  data[p]  $(p = 1,2,\dots ,M.$  tu)，找到  $N$  中所有满足条件M.data[p].j=N.data[q].i的元素N.data[q]，求得M.data[p].v和N.data[q].v的乘积，而从式(5-6)得知，乘积矩阵  $Q$  中每个元素的值是个累计和，这个乘积M.data[p].v×N.data[q].v只是Q[i][j]中的一部分。为便于操作，应对每个元素设一累计和的变量，其初值为零，然后扫描数组  $M$  ，求得相应元素的乘积并累加到适当的求累计和的变量上。

（3）两个稀疏矩阵相乘的乘积不一定是稀疏矩阵。反之，即使式(5-6)中每个分量值  $M(i,k)\times N(k,j)$  不为零，其累加值  $\mathbf{Q}[\mathrm{i}][\mathrm{j}]$  也可能为零。因此乘积矩阵  $Q$  中的元素是否为非零元，只有在求得其累加和后才能得知。由于  $Q$  中元素的行号和  $M$  中元素的行号一致，又  $M$  中元素排列是以  $M$  的行序为主序的，由此可对  $Q$  进行逐行处理，先求得累计求和的中间结果  $(Q$  的一行)，然后再压缩存储到 Q.data 中去。

由此，两个稀疏矩阵相乘  $(Q = M\times N)$  的过程可大致描述如下：

Q初始化；

```txt
if（Q是非零矩阵）{//逐行求积for  $(\mathrm{arrow} = 1$  ；  $arow <   = M.mu$  ；  $+ + arow)$  { //处理M的每一行ctemp[]  $= 0$  ： //累加器清零计算Q中第arow行的积并存入ctemp[]中；将ctemp[]中非零元压缩存储到Q.data;}//for arow  
//if
```

算法5.3是上述过程求精的结果。

```javascript
StatusMultSMatrix(RLSMatrixM，RLSMatrixN，RLSMatrix&Q）{//求矩阵乘积  $\mathbf{Q} = \mathbf{M}\times \mathbf{N}$  ，采用行逻辑链接存储表示。if（M.nu！=N.mu）returnERROR;Q.mu=M.mu；Q.nu=N.nu；Q.tu=0; //Q初始化if(M.tu*N.tu！=0）{//Q是非零矩阵for（arow=1；arow<=M.mu；++arow）{//处理M的每一行ctemp[]=0; //当前行各元素累加器清零
```

```javascript
Q.rpos[arow] = Q.tu + 1;  
if(arow < M.mu) tp = M.rpos[arow + 1];  
else{tp = M.tu + 1;}  
for (p = M.rpos[arow]; p < tp; ++p) { // 对当前行中每一个非零元  
brow = M.data[p].j; // 找到对应元在 N 中的行号  
if (brow < N.mu) t = N.rpos[brow + 1];  
else {t = N.tu + 1;}  
for (q = N.rpos[brow]; q < t; ++q) {  
    ccol = N.data[q].j; // 乘积元素在 Q 中列号  
    ctemp[ccol] += M.data[p].e * N.data[q].e;  
} // for q  
} // 求得 Q 中第 crow( = arow) 行的非零元  
for (ccol = 1; ccol <= Q.nu; ++ccol) // 压缩存储该行非零元  
if (ctemp[ccol]) {  
    if (++Q.tu > MAXSIZE) return ERROR;  
    Q.data[Q.tu] = (arow, ccol, ctemp[ccol]);  
} // if  
} // for arow  
} // if  
return OK;
```

# 算法 5.3

分析上述算法的时间复杂度有如下结果：累加器 ctemp 初始化的时间复杂度为  $O(\mathbf{M}.\mathbf{mu}\times \mathbf{N}.\mathbf{nu})$  ，求  $Q$  的所有非零元的时间复杂度为  $O(\mathbf{M}.t\mathbf{u}\times \mathbf{N}.t\mathbf{u} / \mathbf{N}.m\mathbf{u})$  ，进行压缩存储的时间复杂度为  $O(\mathbf{M}.m\mathbf{u}\times \mathbf{N}.n\mathbf{u})$  ，因此，总的时间复杂度就是  $O(\mathbf{M}.m\mathbf{u}\times \mathbf{N}.n\mathbf{u}$ $+\mathbf{M}.t\mathbf{u}\times \mathbf{N}.t\mathbf{u} / \mathbf{N}.m\mathbf{u})$  。

若  $M$  是  $m$  行  $n$  列的稀疏矩阵,  $N$  是  $n$  行  $p$  列的稀疏矩阵, 则  $M$  中非零元的个数  $\mathbf{M}.\mathrm{tu} = \delta_{\mathbf{M}}\times \mathbf{m}\times \mathbf{n}, N$  中非零元的个数  $\mathbf{N}.\mathrm{tu} = \delta_{\mathbf{N}}\times \mathbf{n}\times \mathbf{p}$ , 此时算法5.3的时间复杂度就是  $O(m\times p\times (1 + n\delta_{M}\delta_{N}))$ , 当  $\delta_{M} < 0.05$  和  $\delta_N < 0.05$  及  $n < 1000$  时, 算法5.3的时间复杂度就相当于  $O(m\times p)$ , 显然, 这是一个相当理想的结果。

如果事先能估算出所求乘积矩阵  $Q$  不再是稀疏矩阵, 则以二维数组表示  $Q$ , 相乘的算法也就更简单了。

# 3. 十字链表

当矩阵的非零元个数和位置在操作过程中变化较大时，就不宜采用顺序存储结构来表示三元组的线性表。例如，在作“将矩阵  $B$  加到矩阵  $A$  上”的操作时，由于非零元的插入或删除将会引起 A.data 中元素的移动。为此，对这种类型的矩阵，采用链式存储结构表示三元组的线性变更为恰当。

在链表中, 每个非零元可用一个含 5 个域的结点表示, 其中  $i, j$  和  $e$  这 3 个域分别表示该非零元所在的行、列和非零元的值, 向右域 right 用以链接同一行中下一个非零元, 向下域 down 用以链接同一列中下一个非零元。同一行的非零元通过 right 域链接成一个线性链表, 同一列的非零元通过 down 域链接成一个线性链表, 每个非零元既是某个行链表中的一个结点, 又是某个列链表中的一个结点, 整个矩阵构成了一个十字交叉的链表, 故称这样的存储结构为十字链表, 可用两个分别存储行链表的头指针和列链表的头指针

的一维数组表示之。例如，式（5-5）中的矩阵  $M$  的十字链表如图5.6所示。

![](images/c49ffd80198d7aa85c90c3a8b98a8c57ab94b64470930fb27378abc23306ac54.jpg)  
图5.6 稀疏矩阵  $M$  的十字链表

算法5.4是稀疏矩阵的十字链表表示和建立十字链表的算法。

```c
//----稀疏矩阵的十字链表存储表示----  
typedef struct OLNode{int i,j; //该非零元的行和列下标ElemType e;struct OLNode \*right，\*down; //该非零元所在行表和列表的后继链域}OLNode；\*OLink;  
typedef struct{OLink \*rhead,\*chead; //行和列链表头指针向量基址由CreateSMatrix分配. int mu,nu,tu; //稀疏矩阵的行数、列数和非零元个数}CrossList;  
Status CreateSMatrix_OL(CrossList&M){//创建稀疏矩阵M。采用十字链表存储表示。if(M)free(M);scanf(&m,&n,&t); //输入M的行数、列数和非零元个数M.mu:=m；M.nu:=n；M.tu:=t;if(!(M.rhead=(OLink\*)malloc((m+1)\*sizeof(OLink))))exit(OVERFLOW);if(!(M.chead=(OLink\*)malloc((n+1)\*sizeof(OLink))))exit(OVERFLOW);M.rhead[]=M.chead[]=NULL; //初始化行列头指针向量；各行列链表为空链表forscanf(&i,&j,&e);i=0;scanf(&i,&j,&e)){//按任意次序输入非零元if(!p=(OLNode\*)malloc(sizeof(OLNode)))exit(OVERFLOW);p->i=i；p->j=j；p->e=e; //生成结点if(M.rhead[i]=NULL||M.rhead[i] -> j>j）{p->right=M.rhead[i];M.rhead[i]=p;}else{//寻查在行表中的插入位置for(q=M.rhead[i]；(q->right)&&q->right->j<；q=q->right);p->right=q->right;q->right=p; //完成行插入if(M.chead[j]=NULL||M.chead[j] ->i>i) {p->down=M.chead[j];M.chead[j]=p;}else{//寻查在列表中的插入位置for(q=M.chead[j]；(q->down)&&q->down->i<；q=q->down);p->down=q->down；q->down=p; //完成列插入}
```

return OK;   
} // CreateSMatrix_OL

# 算法 5.4

对于  $m$  行  $n$  列且有  $t$  个非零元的稀疏矩阵，算法5.4的执行时间为  $O(t \times s)$ ， $s = \max \{m, n\}$ ，这是因为每建立一个非零元的结点时都要寻查它在行表和列表中的插入位置，此算法对非零元输入的先后次序没任何要求。反之，若按以行序为主序的次序依次输入三元组，则可将建立十字链表的算法改写成  $O(t)$  数量级的（ $t$  为非零元的个数）。

下面我们讨论在十字链表表示稀疏矩阵时，如何实现“将矩阵  $B$  加到矩阵  $A$  上”的运算。

两个矩阵相加和第2章中讨论的两个一元多项式相加极为相似，所不同的是一元多项式中只有一个变元(即指数项)，而矩阵中每个非零元有两个变元(行值和列值)，每个结点既在行表中又在列表中，致使插入和删除时指针的修改稍为复杂，故需更多的辅助指针。

假设两个矩阵相加后的结果为  $A^{\prime}$ , 则和矩阵  $A^{\prime}$  中的非零元  $a_{ij}$  只可能有 3 种情况。它或者是  $a_{ij} + b_{ij}$ ; 或者是  $a_{ij}(b_{ij} = 0$  时); 或者是  $b_{ij}(a_{ij} = 0$  时)。由此, 当将  $B$  加到  $A$  上去时, 对  $A$  矩阵的十字链表来说, 或者是改变结点的 val 域值  $(a_{ij} + b_{ij} \neq 0)$ , 或者不变  $(b_{ij} = 0)$ , 或者插入一个新结点  $(a_{ij} = 0)$  。还有一种可能的情况是: 和  $A$  矩阵中的某个非零元相对应, 和矩阵  $A^{\prime}$  中是零元, 即对  $A$  的操作是删除一个结点  $(a_{ij} + b_{ij} = 0)$  。由此, 整个运算过程可从矩阵的第一行起逐行进行。对每一行都从行表头出发分别找到  $A$  和  $B$  在该行中的第一个非零元结点后开始比较, 然后按上述 4 种不同情况分别处理之。

假设非空指针 pa 和 pb 分别指向矩阵  $A$  和  $B$  中行值相同的两个结点， $pa = = \mathbf{NULL}$  表明矩阵  $A$  在该行中没有非零元，则上述 4 种情况的处理过程为：

（1）若  $\mathrm{pa} = =\mathrm{NULL}$  或  $\mathrm{pa} - > \mathrm{j} > \mathrm{pb} - > \mathrm{j}$ ，则需要在  $A$  矩阵的链表中插入一个值为  $\mathbf{b}_{\mathrm{ij}}$  的结点。此时，需改变同一行中前一结点的 right 域值，以及同一列中前一结点的 down 域值。  
（2）若  $\mathrm{pa}\longrightarrow \mathrm{j} <   \mathrm{pb}\longrightarrow \mathrm{j}$  ，则只要将pa指针往右推进一步。  
(3) 若  $\mathrm{pa} \rightarrow \mathrm{j} = \mathrm{pb} \rightarrow \mathrm{j}$  且  $\mathrm{pa} \rightarrow \mathrm{e} + \mathrm{pb} \rightarrow \mathrm{e}! = 0$ ，则只要将  $\mathbf{a}_{\mathrm{ij}} + \mathbf{b}_{\mathrm{ij}}$  的值送到 pa 所指结点的 e 域即可，其他所有域的值都不变。  
（4）若  $\mathrm{pa} - > \mathrm{j} = = \mathrm{pb} - > \mathrm{j}$  且  $\mathrm{pa} - > \mathrm{e} + \mathrm{pb} - > \mathrm{e} = = 0$  ，则需要在  $A$  矩阵的链表中删除pa所指的结点。此时，需改变同一行中前一结点的right域值，以及同一列中前一结点的down域值。

为了便于插入和删除结点，还需要设立一些辅助指针。其一是，在  $A$  的行链表上设pre指针，指示pa所指结点的前驱结点；其二是，在  $A$  的每一列的链表上设一个指针hl[j]，它的初值和列链表的头指针相同，即  $\mathrm{hl}[\mathrm{j}] = \mathrm{head}[\mathrm{j}]$  。

下面对将矩阵  $B$  加到矩阵  $A$  上的操作过程作一个概要的描述。

（1）初始，令pa和pb分别指向  $A$  和  $B$  的第一行的第一个非零元素的结点，即

$$
\mathrm {p a} = \mathrm {A . r h e a d} [ 1 ]; \quad \mathrm {p b} = \mathrm {B . r h e a d} [ 1 ]; \quad \mathrm {p r e} = \mathrm {N U L L};
$$

且令hl初始化

$$
\text {f o r} (j = 1; j <   = A. n u; + + j) \quad h l [ j ] = A. c h e a d [ j ];
$$

(2) 重复本步骤, 依次处理本行结点, 直到  $B$  的本行中无非零元素的结点, 即  $\mathfrak{pb} = \mathbf{NULL}$  为止:

① 若  $\mathfrak{pa} = =\mathbf{NULL}$  或  $\mathfrak{pa} \rightarrow \mathfrak{j} > \mathfrak{pb} \rightarrow \mathfrak{j}$  (即  $A$  的这一行中非零元素已处理完), 则需在  $A$  中插入一个  $\mathfrak{pb}$  所指结点的复制结点。假设新结点的地址为  $\mathfrak{p}$ , 则  $A$  的行表中的指针作如下变化:

```javascript
if(pre  $\equiv$  NULL) A.rhead[p->i]=p; else{pre->right=p;} p->right=pa; pre=p;
```

$A$  的列链表中的指针也要作相应的改变。首先需从  $\mathrm{hl}[\mathrm{p} \rightarrow \mathrm{j}]$  开始找到新结点在同一列中的前驱结点，并让  $\mathrm{hl}[\mathrm{p} \rightarrow \mathrm{j}]$  指向它，然后在列链表中插入新结点：

```txt
if(!A.chead[p->j]||A.chead[p->j]->i>p->i)  
{p->down=A.chead[p->j]; A.chead[p->j]=p;}  
else{p->down=hl[p->j]->down; hl[p->j]->down=p;}  
hl[p->j]=p;
```

② 若  $\mathfrak{pa}! = \mathsf{NULL}$  且  $\mathfrak{pa} \rightarrow \mathfrak{j} < \mathfrak{pb} \rightarrow \mathfrak{j}$ ，则令 pa 指向本行下一个非零元结点，即

```javascript
pre=pa; pa=pa->right;
```

③ 若  $\mathrm{pa} \rightarrow \mathrm{j} = \mathrm{pb} \rightarrow \mathrm{j}$ , 则将 B 中当前结点的值加到 A 中当前结点上, 即

```txt
pa->e+=pb->e;
```

此时若  $\mathfrak{pa} \longrightarrow \mathfrak{e}! = 0$  ，则指针不变，否则删除  $A$  中该结点，即行表中指针变为

```c
if(pre  $\equiv$  NULL) A. rhead[pa->i]  $\coloneqq$  pa->right; else{pre->right  $\equiv$  pa->right;}  $\mathfrak{p} = \mathfrak{pa}$  .pa=pa->right;
```

同时，为了改变列表中的指针，需要先找到同一列中的前驱结点，且让  $\mathsf{hl}[\mathsf{pa} - > \mathsf{j}]$  指向该结点，然后如下修改相应指针：

```javascript
if (A. head[p->j] == p) A. head[p->j] = hl[p->j] = p->down; else {hl[p->j] -> down = p->down;} free(p);
```

(3) 若本行不是最后一行, 则令 pa 和 pb 指向下一行的第一个非零元结点, 转 (2); 否则结束。

通过对这个算法的分析可以得出下述结论：从一个结点来看，进行比较、修改指针所需的时间是一个常数；整个运算过程在于对  $A$  和  $B$  的十字链表逐行扫描，其循环次数主要取决于  $A$  和  $B$  矩阵中非零元素的个数 ta 和 tb；由此算法的时间复杂度为  $O(\mathrm{ta} + \mathrm{tb})$ 。

# 5.4 广义表的定义

顾名思义，广义表是线性表的推广。也有人称其为列表(lists，用复数形式以示与统称的表list的区别)。广泛地用于人工智能等领域的表处理语言LISP语言，把广义表作

为基本的数据结构，就连程序也表示为一系列的广义表。

抽象数据类型广义表的定义如下：

```txt
ADT GList{
```

数据对象：  $D = \{e_i\mid i = 1,2,\dots ,n;\quad n\geqslant 0;\quad e_i\in \mathsf{AtomSet}$  或  $\mathbf{e}_i\in \mathsf{GL}$  ist，

AtomSet为某个数据对象}

数据关系：  $\mathbb{R}1 = \{\langle \mathbf{e}_{i - 1},\mathbf{e}_i\rangle |\mathbf{e}_{i - 1},\mathbf{e}_i\in D,\quad 2\leqslant i\leqslant n\}$

基本操作：

```txt
InitGList(&L);
```

操作结果：创建空的广义表L。

```javascript
CreateGList(&L, S);
```

初始条件：S是广义表的书写形式串。

操作结果：由S创建广义表L。

```javascript
DestroyGList(&L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：销毁广义表L。

```javascript
CopyGList(&T, L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：由广义表  $\mathbb{L}$  复制得到广义表T。

```javascript
GListLength(L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：求广义表L的长度，即元素个数。

```txt
GListDepth(L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：求广义表L的深度。

```txt
ListEmpty(L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：判定广义表  $\mathbf{L}$  是否为空。

```javascript
GetHead(L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：取广义表L的头。

```txt
GetTail(L);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：取广义表L的尾。

```javascript
InsertFirst.GL(&L, e);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：插入元素 e 作为广义表 L 的第一元素。

```javascript
DeleteFirst.GL(&L, &e);
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：删除广义表L的第一元素，并用e返回其值。

```javascript
Traverse.GL(L,Visit());
```

初始条件：广义表  $\mathbf{L}$  存在。

操作结果：遍历广义表L，用函数Visit处理每个元素。

ADT GList

广义表一般记作

$$
L S = \left(\alpha_ {1}, \alpha_ {2}, \dots , \alpha_ {n}\right)
$$

其中， $LS$  是广义表  $(\alpha_{1}, \alpha_{2}, \dots, \alpha_{n})$  的名称， $n$  是它的长度。在线性表的定义中， $a_{i} (1 \leqslant i \leqslant n)$  只限于是单个元素。而在广义表的定义中， $\alpha_{i}$  可以是单个元素，也可以是广义表，分别称为广义表  $LS$  的原子和子表。习惯上，用大写字母表示广义表的名称，用小写字母表示原子。当广义表  $LS$  非空时，称第一个元素  $\alpha_{1}$  为  $LS$  的表头（Head），称其余元素组成的表  $(\alpha_{2}, \alpha_{3}, \dots, \alpha_{n})$  是  $LS$  的表尾（Tail）。

显然，广义表的定义是一个递归的定义，因为在描述广义表时又用到了广义表的概念。下面列举一些广义表的例子。

(1)  $A = ()$  —— $A$  是一个空表, 它的长度为零。  
(2)  $B = (e)$  ——列表  $B$  只有一个原子  $e, B$  的长度为 1。  
(3)  $C = (a, (b, c, d))$  ——列表  $C$  的长度为 2，两个元素分别为原子  $a$  和子表  $(b, c, d)$ 。  
(4) \(D = (A, B, C)\) ——列表 \(D\) 的长度为 3, 3 个元素都是列表。显然，将子表的值代入后，则有 \(D = ((\cdot), (\cdot), (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, (\cdot, \(\left(a, (b, c, d)\right))))\).  
(5)  $E = (a, E)$  ——这是一个递归的表，它的长度为2。 $E$  相当于一个无限的列表  $E = (a, (a, (a, \dots)))$ 。

从上述定义和例子可推出列表的3个重要结论：

（1）列表的元素可以是子表，而子表的元素还可以是子表……由此，列表是一个多层次的结构，可以用图形象地表示。例如图5.7表示的是列表  $D$  。图中以圆圈表示列表，以方块表示原子。  
（2）列表可为其他列表所共享。例如在上述例子中，列表  $A, B$  和  $C$  为  $D$  的子表，则在  $D$  中可以不必列出子表的值，而是通过子表的名称来引用。  
（3）列表可以是一个递归的表，即列表也可以是其本身的一个子表。例如列表  $E$  就是一个递归的表。

根据前述对表头、表尾的定义可知：任何一个非空列表其表头可能是原子，也可能是列表，而其表尾必定为列表。例如：

![](images/48e1623e09b0973bb6ae2c3e419066431114dbbefa757d93f22044bb4cf6d6c1.jpg)  
图5.7 列表的图形表示

$$
\operatorname {G e t H e a d} (\mathrm {B}) = \mathrm {e}, \quad \operatorname {G e t T a i l} (\mathrm {B}) = (\quad),
$$

$$
\operatorname {G e t H e a d} (D) = A, \quad \operatorname {G e t T a i l} (D) = (B, C),
$$

由于(B，C)为非空列表，则可继续分解得到：

$$
\operatorname {G e t H e a d} ((B, C)) = B, \quad \operatorname {G e t T a i l} ((B, C)) = (C),
$$

值得提醒的是列表（）和（））不同。前者为空表，长度  $n = 0$ ；后者长度  $n = 1$ ，可分解得到其表头、表尾均为空表（）。

# 5.5 广义表的存储结构

由于广义表  $(\alpha_{1},\alpha_{2},\dots ,\alpha_{n})$  中的数据元素可以具有不同的结构（或是原子，或是列表），因此难以用顺序存储结构表示，通常采用链式存储结构，每个数据元素可用一个结点表示。

如何设定结点的结构？由于列表中的数据元素可能为原子或列表，由此需要两种结构的结点：一种是表结点，用以表示列表；一种是原子结点，用以表示原子。从上节得知：若列表不空，则可分解成表头和表尾；反之，一对确定的表头和表尾可惟一确定列表。由此，一个表结点可由3个域组成：标志域、指示表头的指针域和指示表尾的指针域；而原子结点只需两个域：标志域和值域（如图5.8所示）。其形式定义说明如下：

![](images/ff1a1656467a6b04154a22cf00500a97f5066c2f1233f3f056915328484830d2.jpg)  
表结点

![](images/3ba087952a165c2091a8267b44e7706f513c413281093923b282e508ab6f52a4.jpg)  
原子结点  
图5.8 列表的链表结点结构  
图5.9 广义表的存储结构示例

```javascript
//----广义表的头尾链表存储表示-----  
typedefenum{ATOM，LIST}ElemTag; //ATOM  $= = 0$  ：原子，LIST  $= = 1$  ：子表  
typedefstructGLNode{ElemTagtag; //公共部分，用于区分原子结点和表结点union{ //原子结点和表结点的联合部分AtomTypeatom; //atom是原子结点的值域，AtomType由用户定义struct{structGLNode \*hp，\*tp;}ptr;//ptr是表结点的指针域，ptr.hp和ptr,tp分别指向表头和表尾};\*GList; //广义表类型A=NIL111A0e111110b0c0d
```

上节中曾列举了广义表的例子，它们的存储结构如图5.9所示。在这种存储结构中有几种情况：(1)除空表的表头指针为空外，对任何非空列表，其表头指针均指向一个表结点，且该结点中的hp域指示列表表头（或为原子结点，或为表结点），tp域指向列表表尾（除非表尾为空，则指针为空，否则必为表结点）；(2)容易分清列表中原子和子表所在层次。如在列表  $D$  中，原子  $a$  和  $e$  在同一层次上，而  $b, c$  和  $d$  在同一层次且比  $a$  和  $e$  低一

层,  $B$  和  $C$  是同一层的子表; (3)最高层的表结点个数即为列表的长度。以上 3 个特点在某种程度上给列表的操作带来方便。也可采用另一种结点结构的链表表示列表, 如图 5.10 和图 5.11 所示。其形式定义说明如下:

```c
//----广义表的扩展线性链表存储表示----  
typedef enum{ATOM，LIST}ElemTag; //  $\mathrm{ATOM} = = 0$  ：原子，LIST  $= = 1$  ：子表  
typedef struct GLNode{ElemTag tag; //公共部分，用于区分原子结点和表结点union{ //原子结点和表结点的联合部分AtomType atom; //原子结点的值域structGLNode \*hp; //表结点的表头指针};structGLNode \*tp; //相当于线性链表的next，指向下一个元素结点\*GList; //广义表类型GList是一种扩展的线性链表
```

对于列表的这两种存储结构，读者只要根据自己的习惯掌握其中一种结构即可。

![](images/11af825f587e435f254022b68e79c19bd191510ad95c356f5848903832708de7.jpg)  
图5.10 列表的另一种结点结构

![](images/2cb57c7a508368c1de413c3b8dc95868c06cc32dc2597c8a96159656c1bf6dfb.jpg)

![](images/e1fcd9f2fc49898004ecda414d58df6528d78ee84702a95ddaf2d3e9841b1d25.jpg)  
图5.11 列表的另一种链表表示

# 5.6  $m$  元多项式的表示

在一般情况下使用的广义表多数既非是递归表，也不为其他表所共享。对广义表可以这样来理解，广义表中的一个数据元素可以是另一个广义表，一个  $m$  元多项式的表示就是广义表的这种应用的典型实例。

在第2章中，我们曾作为线性表的应用实例讨论了一元多项式，一个一元多项式可以用一个长度为  $m$  且每个数据元素有两个数据项(系数项和指数项)的线性表来表示。

这里，将讨论如何表示  $m$  元多项式。一个  $m$  元多项式的每一项，最多有  $m$  个变元。如果用线性表来表示，则每个数据元素需要  $m + 1$  个数据项，以存储一个系数值和  $m$  个指数值。这将产生两个问题：一是无论多项式中各项的变元数是多是少，若都按  $m$  个变元分配存储空间，则将造成浪费；反之，若按各项实际的变元数分配存储空间，就会造成结点的大小不匀，给操作带来不便。二是对  $m$  值不同的多项式，线性表中的结点大小也不同，这同样会引起存储管理的不便。因此，由于  $m$  元多项式中每一项的变化数目的不均匀性和变元信息的重要性，故不适于用线性表表示。例如三元多项式

$$
P (x, y, z) = x ^ {1 0} y ^ {3} z ^ {2} + 2 x ^ {6} y ^ {3} z ^ {2} + 3 x ^ {5} y ^ {2} z ^ {2} + x ^ {4} y ^ {4} z + 6 x ^ {3} y ^ {4} z + 2 y z + 1 5
$$

其中各项的变元数目不尽相同，而  $y^3, z^2$  等因子又多次出现，如若改写为

$$
P (x, y, z) = \left((x ^ {1 0} + 2 x ^ {6}) y ^ {3} + 3 x ^ {5} y ^ {2}\right) z ^ {2} + \left(\left(x ^ {4} + 6 x ^ {3}\right) y ^ {4} + 2 y\right) z + 1 5
$$

情况就不同了。现在，我们再来看这个多项式  $P$  ，它是变元  $\pmb{z}$  的多项式，即  $A z^{2} + B z + 15 z^{0}$  ，只是其中  $A$  和  $B$  本身又是一个  $(x, y)$  的二元多项式，15是  $\pmb{z}$  的零次项的系数。进一步考察  $A(x, y)$  ，又可把它看成是  $\pmb{y}$  的多项式。  $C y^{3} + D y^{2}$  ，而其中  $C$  和  $D$  为  $X$  的一元多项式。循此以往，每个多项式都可看作是由一个变量加上若干个系数指数偶对组成。

任何一个  $m$  元多项式都可如此做：先分解出一个主变元，随后再分解出第二个变元，等等。由此，一个  $m$  元的多项式首先是它的主变元的多项式，而其系数又是第二变元的多项式，由此可用广义表来表示  $m$  元多项式。例如上述三元多项式可用式(5-7)的广义表表示，广义表的深度即为变元个数。

$$
P = z ((A, 2), (B, 1), (1 5, 0)) ^ {\text {①}} \tag {5-7}
$$

其中  $A = y((C,3),(D,2))$

$$
C = x ((1, 1 0), (2, 6))
$$

$$
D = x ((3, 5))
$$

$$
B = y ((E, 4), (F, 1))
$$

$$
E = x ((1, 4), (6, 3))
$$

$$
F = x ((2, 0))
$$

可类似于广义表的第二种存储结构来定义表示  $m$  元多项式的广义表的存储结构。链表的结点结构为：

<table><tr><td>tag=1</td><td>exp</td><td>hp</td><td>tp</td></tr></table>

表结点  

<table><tr><td>tag=0</td><td>exp</td><td>coef</td><td>tp</td></tr></table>

原子结点

其中  $\exp$  为指数域, coef 为系数域, hp 指向其系数子表, tp 指向同一层的下一结点。其形式定义说明如下:

```txt
typedef struct MPNode{ElemTag tag; //区分原子结点和表结点int exp; //指数域union{float coef; //系数域
```

```txt
struct MPNode \*hp; //表结点的表头指针}；struct MPNode \*tp; //相当于线性链表的next,指向下一个元素结点\* MPList; //m元多项式广义表类型
```

式(5-7)的广义表的存储结构如图5.12所示，在每一层上增设一个表头结点并利用exp指示该层的变元，可用一维数组存储多项式中所有变元，故exp域存储的是该变元在一维数组中的下标。头指针p所指表结点中exp的值3为多项式中变元的个数。可见，这种存储结构可表示任何元的多项式。

![](images/bd67076607b33caf734f9d3df88e36e3b2d4988fb93475471d20872d20cc723f.jpg)  
图5.12 三元多项式  $p(x,y,z)$  的存储结构示意图

# 5.7 广义表的递归算法

在第3章中曾提及，递归函数结构清晰、程序易读，且容易证明正确性，因此是程序设计的有力工具，但有时递归函数的执行效率很低，因此使用递归应扬长避短。在程序设计的过程中，我们并不一味追求递归。如果一个问题的求解过程有明显的递推规律，我们也很容易写出它的递推过程（如求阶乘函数  $f(n) = n!$  的值），则不必要使用“递归”。反之，在对问题进行分解、求解的过程中得到的是和原问题性质相同的子问题（如Hanoi塔问题），由此自然得到一个递归算法，且它比利用栈实现的非递归算法更符合人们的思维逻辑，因而更易于理解。但是要熟练掌握递归算法的设计方法也不是件轻而易举的事情。在本节中，我们不打算全面讨论如何设计递归算法，只是以广义表为例，讨论如何利用“分治法”(Divide and Conquer)进行递归算法设计的方法。

对这类问题设计递归算法时，通常可以先写出问题求解的递归定义。和第二数学归纳法类似，递归定义由基本项和归纳项两部分组成。

递归定义的基本项描述了一个或几个递归过程的终结状态。虽然一个有限的递归（且无明显的迭代）可以描述一个无限的计算过程，但任何实际应用的递归过程，除错误情况外，必定能经过有限层次的递归而终止。所谓终结状态指的是不需要继续递归而可直

接求解的状态。如例3-3的  $n$  阶Hanoi塔问题，在  $n = 1$  时可以直接求得解，即将圆盘从X塔座移动到Z塔座上。一般情况下，若递归参数为  $n$  ，则递归的终结状态为  $n = 0$  或 $n = 1$  等。

递归定义的归纳项描述了如何实现从当前状态到终结状态的转化。递归设计的实质是：当一个复杂的问题可以分解成若干子问题来处理时，其中某些子问题与原问题有相同的特征属性，则可利用和原问题相同的分析处理方法；反之，这些子问题解决了，原问题也就迎刃而解了。递归定义的归纳项就是描述这种原问题和子问题之间的转化关系。仍以Hanoi塔问题为例。原问题是将  $n$  个圆盘从X塔座移至Z塔座上，可以把它分解成3个子问题：(1)将编号为1至  $n - 1$  的  $n - 1$  个圆盘从X塔座移至Y塔座；(2)将编号为  $n$  的圆盘从X塔座移至Z塔座；(3)将编号为1至  $n - 1$  的圆盘从Y塔座移至Z塔座。其中(1)和(3)的子问题和原问题特征属性相同，只是参数  $(n - 1$  和  $n)$  不同，由此实现了递归。

由于递归函数的设计用的是归纳思维的方法，则在设计递归函数时，应注意：(1)首先应书写函数的首部和规格说明，严格定义函数的功能和接口（递归调用的界面），对求精函数中所得的和原问题性质相同的子问题，只要接口一致，便可进行递归调用；(2)对函数中的每一个递归调用都看成只是一个简单的操作，只要接口一致，必能实现规格说明中定义的功能，切忌想得太深太远。正如用第二数学归纳法证明命题时，由归纳假设进行归纳证明时绝不能怀疑归纳假设是否正确。

下面讨论广义表的3种操作。首先约定所讨论的广义表都是非递归表且无共享子表。

# 5.7.1 求广义表的深度

广义表的深度定义为广义表中括弧的重数，是广义表的一种量度。例如，多元多项式广义表的深度为多项式中变元的个数。

设非空广义表为

$$
L S = \left(\alpha_ {1}, \alpha_ {2}, \dots , \alpha_ {n}\right)
$$

其中  $\alpha_{i}(i = 1,2,\dots ,n)$  或为原子或为  $LS$  的子表，则求  $LS$  的深度可分解为  $n$  个子问题，每个子问题为求  $\alpha_{i}$  的深度，若  $\alpha_{i}$  是原子，则由定义其深度为零，若  $\alpha_{i}$  是广义表，则和上述一样处理，而  $LS$  的深度为各  $\alpha_{i}(i = 1,2,\dots ,n)$  的深度中最大值加1。空表也是广义表，并由定义可知空表的深度为1。

由此可见，求广义表的深度的递归算法有两个终结状态：空表和原子，且只要求得  $\alpha_{i}(i = 1,2,\dots ,n)$  的深度，广义表的深度就容易求得了。显然，它应比子表深度的最大值多1。

广义表

$$
L S = \left(\alpha_ {1}, \alpha_ {2}, \dots , \alpha_ {n}\right)
$$

的深度  $\mathrm{DEPTH}(LS)$  的递归定义为

基本项：  $\mathrm{DEPTH}(LS) = 1$  当  $LS$  为空表时

DEPTH  $(LS) = 0$  当  $LS$  为原子时

归纳项：  $\mathrm{DEPTH}(LS) = 1 + \max_{1\leqslant i\leqslant n}\{\mathrm{DEPTH}(\alpha_i)\} \quad n\geqslant 1$

由此定义容易写出求深度的递归函数。假设  $\mathbf{L}$  是GList型的变量，则  $\mathrm{L} = \mathrm{NULL}$  表明广义表为空表，  $\mathrm{L} \rightarrow \mathrm{tag} = 0$  表明是原子。反之，  $\mathbf{L}$  指向表结点，该结点中的hp指针指向表头，即为  $\mathbf{L}$  的第一个子表，而结点中的tp指针所指表尾结点中的hp指针指向  $\mathbf{L}$  的第二个子表。在第一层中由tp相连的所有尾结点中的hp指针均指向  $\mathbf{L}$  的子表。由此，求广义表深度的递归函数如算法5.5所示。

```txt
int GListDepth(GList L) { // 采用头尾链表存储结构，求广义表L的深度。 if (!L) return 1; // 空表深度为1 if (L->tag == ATOM) return 0; // 原子深度为0 for (max = 0, pp = L; pp; pp = pp->ptr.tp) { dep = GListDepth(pp->ptr.tp); // 求以pp->ptr.tp为头指针的子表深度 if (dep > max) max = dep; } return max + 1; // 非空表的深度是各元素的深度的最大值加1 } // GListDepth
```

# 算法 5.5

上述算法的执行过程实质上是遍历广义表的过程，在遍历中首先求得各子表的深度，然后综合得到广义表的深度。例如，图5.13展示了求广义表  $D$  的深度的过程。图中用虚线示意遍历过程中指针L的变化状况，在指向结点的虚线旁标记的是将要遍历的子

![](images/930956a8802584bbcbbb3bd59ff699500e78392bdf52b22821fd3effcd049f16.jpg)  
图5.13 求广义表  $D$  的深度的过程

表, 而在从结点射出的虚线旁标记的数字是刚求得的子表的深度, 从图中可见广义表  $D = (A, B, C) = ((\cdot), (\epsilon), (a, (b, c, d)))$  的深度为 3。若按递归定义分析广义表  $D$  的深度, 则有:

```latex
$\mathrm{DEPTH}(\mathrm{D}) = 1 + \mathrm{Max}\{\mathrm{DEPTH}(\mathrm{A}),\mathrm{DEPTH}(\mathrm{B}),\mathrm{DEPTH}(\mathrm{C})\}$ $\mathrm{DEPTH}(\mathrm{A}) = 1;$ $\mathrm{DEPTH}(\mathrm{B}) = 1 + \mathrm{Max}\{\mathrm{DEPTH}(\mathrm{e})\} = 1 + 0 = 1;$ $\mathrm{DEPTH}(\mathrm{C}) = 1 + \mathrm{Max}\{\mathrm{DEPTH}(\mathrm{a}),\mathrm{DEPTH}((\mathrm{b},\mathrm{c},\mathrm{d}))\} = 2$ $\mathrm{DEPTH}(\mathrm{a}) = 0$
```

```latex
$\begin{array}{rl} & \mathrm{DEPTH}((b,c,d)) = 1 + \mathrm{Max}\left\{\mathrm{DEPTH}(a),\mathrm{DEPTH}(b),\mathrm{DEPTH}(c)\right\} \\ & \qquad = 1 + 0 = 1 \end{array}$
```

由此，  $\mathrm{DEPTH}(D) = 1 + \mathrm{Max}\{1,1,2\} = 3$

# 5.7.2 复制广义表

在5.5节中曾提及，任何一个非空广义表均可分解成表头和表尾，反之，一对确定的表头和表尾可惟一确定一个广义表。由此，复制一个广义表只要分别复制其表头和表尾，然后合成即可。假设LS是原表，NEWLS是复制表，则复制操作的递归定义如下。

基本项：InitGList(NEWLS) {置空表}, 当 LS 为空表时。

归纳项：COPY(GetHead(LS) -> GetHead(NewLS)) {复制表头}  
COPY(GetTail(LS) -> GetTail(NewLs)) {复制表尾}

若原表以图5.9的链表表示，则复制表的操作便是建立相应的链表。只要建立和原表中的结点一一对应的新结点，便可得到复制表的新链表。由此可写出复制广义表的递归算法如算法5.6所示。

```cpp
Status CopyGList(GList &T, GList L) {
// 采用头尾链表存储结构，由广义表L复制得到广义表T。
if (!L) T = NULL; // 复制空表
else {
if (!(T = (GList)malloc(sizeof(GLNode))) exit(OVERFLOW); // 建表结点
T->tag = L->tag;
if (L->tag == ATOM) T->atom = L->atom; // 复制单原子
else {CopyGList(T->ptr. hp, L->ptr. hp);
// 复制广义表L->ptr. hp的一个副本T->ptr. hp
CopyGList(T->ptr. tp, L->ptr. tp);
// 复制广义表L->ptr. tp的一个副本T->ptr. tp}
} // else
} // else
return OK;
} // CopyGList
```

# 算法 5.6

注意，这里使用了变参，使得这个递归函数简单明了，直截了当地反映出广义表的复制过程，读者可试以广义表  $C$  为例循序察看过程，以便得到更深刻的了解。

# 5.7.3 建立广义表的存储结构

从上述两种广义表操作的递归算法的讨论中可以发现：在对广义表进行的操作下递归定义时，可有两种分析方法。一种是把广义表分解成表头和表尾两部分；另一种是把广义表看成是含有  $n$  个并列子表(假设原子也视作子表)的表。在讨论建立广义表的存储结构时，这两种分析方法均可。

假设把广义表的书写形式看成是一个字符串  $S$  ，则当  $S$  为非空白串时广义表非空。此时可以利用5.4节中定义的取列表表头GetHead和取列表表尾GetTail两个函数建立

广义表的链表存储结构。这个递归算法和复制的递归算法极为相似，读者可自行试之。下面就第二种分析方法进行讨论。

广义表字符串  $S$  可能有两种情况：（1） $S = \text{(')}$  （2） $S = (\alpha_{1}, \alpha_{2}, \dots, \alpha_{n})$ ，其中  $\alpha_{i} (i = 1, 2, \dots, n)$  是  $S$  的子串。对应于第一种情况  $S$  的广义表为空表，对应于第二种情况  $S$  的广义表中含有  $n$  个子表，每个子表的书写形式即为子串  $\alpha_{i} (i = 1, 2, \dots, n)$ 。此时可类似于求广义表的深度，分析由  $S$  建立的广义表和由  $\alpha_{i} (i = 1, 2, \dots, n)$  建立的子表之间的关系。假设按图5.8所示结点结构来建立广义表的存储结构，则含有  $n$  个子表的广义表中有  $n$  个表结点序列。第  $i (i = 1, 2, \dots, n - 1)$  个表结点中的表尾指针指向第  $i + 1$  个表结点。第  $n$  个表结点的表尾指针为 NULL，并且，如果把原子也看成是子表的话，则第  $i$  个表结点的表头指针 hp 指向由  $\alpha_{i}$  建立的子表  $(i = 1, 2, \dots, n)$ 。由此，由  $S$  建广义表的问题可转化为由  $\alpha_{i} (i = 1, 2, \dots, n)$  建子表的问题。又， $\alpha_{i}$  可能有3种情况：（1）带括弧的空白串；（2）长度为1的单字符串；（3）长度  $>1$  的字符串。显然，前两种情况为递归的终结状态，子表为空表或只含一个原子结点，后一种情况为递归调用。由此，在不考虑输入字符串可能出错的前提下，可得下列建立广义表链表存储结构的递归定义。

基本项： 置空广义表

当  $S$  为空表串时

建原子结点的子表

当  $S$  为单字符串时

归纳项：假设sub为脱去  $S$  中最外层括弧的子串，记为  ${}^{\prime}s_{1},s_{2},\dots ,s_{n}{}^{\prime}$  ，其中  $s_i (i = 1,2,\dots ,n)$  为非空字符串。对每一个  $s_i$  建立一个表结点，并令其hp域的指针为由  $s_i$  建立的子表的头指针，除最后建立的表结点的尾指针为NULL外，其余表结点的尾指针均指向在它之后建立的表结点。

假定函数 sever(str, hstr) 的功能为, 从字符串 str 中取出第一个“,”之前的子串赋给 hstr, 并使 str 成为删去子串 hstr 和 ‘,'之后的剩余串, 若串 str 中没有字符 ‘,' , 则操作后的 hstr 即为操作前的 str, 而操作后的 str 为空串 NULL。根据上述递归定义可得到建广义表存储结构的递归函数如算法 5.7 所示。函数 sever 如算法 5.8 所示。

```txt
StatusCreateGList(GLList&L，SStringS）{//采用头尾链表存储结构，由广义表的书写形式串S创建广义表L。设emp  $= "$  ）"if（StrCompare(S，emp)）  $\mathrm{L} = \mathrm{NULL}$  ； //创建空表else{if（！(L  $=$  （GList）malloc（sizeof(GLNode)))）exit(OVERFLOW)；//建表结点if（StrLength(S)  $\equiv = 1$  ）{L->>tag  $\equiv$  ATOM; L->>atom  $\equiv$  S;} //创建单原子广义表else{L->>tag  $\equiv$  LIST;  $\mathfrak{p} = \mathbb{L}$  ：字符串(sub,S,2，StrLength(S)-2); //脱外层括号do{//重复建n个子表sever(sub,hsub); //从sub中分离出表头串hsubCreateGList(p->ptr.hp,hsub);  $\mathbf{q} = \mathbf{p}$  ·if（！StrEmpty(sub)){//表尾不空if（!(p  $=$  （GLNode\*）malloc（sizeof(GLNode))))exit(OVERFLOW);p->>tag  $\equiv$  LIST; q->>ptr.tp  $\equiv$  p;}//if
```

```javascript
}while(!StrEmpty(sub));  $\mathrm{q - > ptr,tp = NULL};$  1 else }//else return OK;   
}//CreateGList
```

# 算法 5.7

```txt
Status sever(String&str, String&hstr) {
// 将非空串 str 分割成两部分：hsub 为第一个'，之前的子串，str 为之后的子串
n = StrLength(str); i = 0; k = 0; // k 记尚未配对的左括号个数
do {
// 搜索最外层的第一个逗号
++i;
SubString(ch, str, i, l);
if (ch == '(' + +k;
else if (ch == ')' --k;
} while (i<n && (ch != ':', || k != 0));
if (i<n)
{SubString(hstr, str, l, i-1); SubString(str, str, i+1, n-i)}
else {StrCopy(hstr, str); ClearString(str)}
} // sever
```

# 算法 5.8

# 第6章 树和二叉树

树型结构是一类重要的非线性数据结构。其中以树和二叉树最为常用, 直观看来, 树是以分支关系定义的层次结构。树结构在客观世界中广泛存在, 如人类社会的族谱和各种社会组织机构都可用树来形象表示。树在计算机领域中也得到广泛应用, 如在编译程序中, 可用树来表示源程序的语法结构。又如在数据库系统中, 树形结构也是信息的重要组织形式之一。本章重点讨论二叉树的存储结构及其各种操作, 并研究树和森林与二叉树的转换关系, 最后介绍几个应用例子。

# 6.1 树的定义和基本术语

树(Tree)是  $n(n\geqslant 0)$  个结点的有限集。在任意一棵非空树中：（1）有且仅有一个特

定的称为根(Root)的结点；(2）当  $n > 1$  时，其余结点可分为  $m(m > 0)$  个互不相交的有限集  $T_{1}, T_{2}, \dots, T_{m}$ ，其中每一个集合本身又是一棵树，并且称为根的子树(SubTree)。例如，在图6.1中，（a）是只有一个根结点的树；（b）是有13个结点的树，其中  $A$  是根，其余结点分成3个互不相交的子集： $T_{1} = \{B, E, F, K, L\}$ ， $T_{2} = \{C, G\}$ ， $T_{3} = \{D, H, I, J, M\}$ ； $T_{1}, T_{2}$  和  $T_{3}$  都是根  $A$  的子树，且本身也是一棵树。例如  $T_{1}$ ，其根为  $B$ ，其余结点分为两个互不相交的子集； $T_{11} = \{E, K, L\}$ ， $T_{12} =$

图6.1 树的示例  
![](images/7c9ab6fc113b715d4edab60c183565ebcf71c60809b89da9c28b8410b763c25e.jpg)  
(a) 只有根结点的树；(b) 一般的树

$\{F\}$  。  $T_{11}$  和  $T_{12}$  都是  $\pmb{B}$  的子树。而  $T_{11}$  中  $\pmb{E}$  是根，  $\{K\}$  和  $\{L\}$  是  $\pmb{E}$  的两棵互不相交的子树，其本身又是只有一个根结点的树。

上述树的结构定义加上树的一组基本操作就构成了抽象数据类型树的定义。

ADT Tree{

数据对象D:D是具有相同特性的数据元素的集合。

数据关系  $\mathbb{R}$  ：若D为空集，则称为空树；

若D仅含一个数据元素，则R为空集，否则  $\mathbb{R} = \{\mathbb{H}\}$  ，H是如下二元关系：

（1）在D中存在惟一的称为根的数据元素root，它在关系H下无前驱；  
(2) 若  $\mathsf{D} - \{\mathsf{root}\} \neq \Phi$ ，则存在  $\mathsf{D} - \{\mathsf{root}\}$  的一个划分  $\mathsf{D}_1, \mathsf{D}_2, \dots, \mathsf{D}_m (m > 0)$ ，对任意  $j \neq k (1 \leqslant j, k \leqslant m)$  有  $\mathsf{D}_j \cap \mathsf{D}_k = \Phi$ ，且对任意的  $i (1 \leqslant i \leqslant m)$ ，惟一存在数据元素  $\mathbf{x}_i \in \mathsf{D}_i$ ，有  $<\mathsf{root}, \mathbf{x}_i> \in \mathsf{H}$ ；  
（3）对应于  $\mathsf{D} - \{\mathsf{root}\}$  的划分，  $\mathsf{H} - \{\langle \mathsf{root},\mathbf{x}_1\rangle ,\dots ,\langle \mathsf{root},\mathbf{x}_n\rangle \}$  有惟一的一个划分  $\mathbb{H}_{\mathrm{i}}$  ， $\mathbb{H}_2,\dots ,\mathbb{H}_m(m > 0)$  ，对任意  $j\neq k(1\leqslant j,k\leqslant m)$  有  $\mathbb{H}_j\bigcap \mathbb{H}_k = \Phi$  ，且对任意  $i(1\leqslant i\leqslant m)$  ，  $\mathbb{H}_{\mathrm{i}}$  是 $\mathsf{D}_{\mathrm{i}}$  上的二元关系，  $(\mathsf{D_i},\{\mathsf{H_i}\})$  是一棵符合本定义的树，称为根root的子树。

# 基本操作P：

InitTree(&T);

操作结果：构造空树T。

DestroyTree(&T);

初始条件：树  $\mathrm{T}$  存在。

操作结果：销毁树T。

CreateTree(&T, definition):

初始条件：definition给出树T的定义。

操作结果：按definition构造树T。

ClearTree(&T);

初始条件：树  $\mathbb{T}$  存在。

操作结果：将树T清为空树。

TreeEmpty(T):

初始条件：树  $\mathrm{T}$  存在。

操作结果：若T为空树，则返回TRUE，否则FALSE。

TreeDepth(T):

初始条件：树  $\mathrm{T}$  存在。

操作结果：返回T的深度。

Root(T):

初始条件：树  $\mathrm{T}$  存在。

操作结果：返回  $\mathbb{T}$  的根。

Value(T.cur e):

初始条件：树T存在，cur.e是T中某个结点。

操作结果：返回 cur_e 的值。

Assign(T, cur_e, value);

初始条件：树T存在，cur.e是T中某个结点。

操作结果：结点cur.e赋值为value。

Parent(T.cur e);

初始条件：树T存在，cur_e是T中某个结点。

操作结果：若cur_e是T的非根结点，则返回它的双亲，否则函数值为“空”。

LeftChild(T.cur.e);

初始条件：树T存在，cur_e是T中某个结点。

操作结果：若cur_e是T的非叶子结点，则返回它的最左孩子，否则返回“空”。

RightSibling(T.cur e);

初始条件：树T存在，cur.e是T中某个结点。

操作结果：若cur_e有右兄弟，则返回它的右兄弟，否则函数值为“空”。

InsertChild(&T. &p. i.c);

初始条件：树  $\mathbf{T}$  存在， $\mathbf{p}$  指向  $\mathbf{T}$  中某个结点， $1 \leqslant i \leqslant p$  所指结点的度  $+1$ ，非空树  $\mathbf{c}$  与  $\mathbf{T}$  不相交。

操作结果：插入c为T中p指结点的第i棵子树。

DeleteChild(&T. &p. i);

初始条件：树T存在，p指向T中某个结点，  $1\leqslant i\leqslant p$  指结点的度。

操作结果：删除T中p所指结点的第i棵子树。

TraverseTree(T.Visit());

初始条件：树T存在，Visit是对结点操作的应用函数。

操作结果：按某种次序对 T 的每个结点调用函数 visit() 一次且至多一次。

一旦visit()失败，则操作失败。

树的结构定义是一个递归的定义，即在树的定义中又用到树的概念，它道出了树的固有特性。树还可有其他的表示形式，如图6.2所示为图6.1(b)中树的各种表示。其中(a)是以嵌套集合(即是一些集合的集体，对于其中任何两个集合，或者不相交，或者一个包含另一个)的形式表示的；(b)是以广义表的形式表示的。根作为由子树森林组成的表的名字写在表的左边；(c)用的是凹入表示法(类似书的编目)。表示方法的多样化，正说明了树结构在日常生活中及计算机程序设计中的重要性。一般说来，分等级的分类方案都可用层次结构来表示，也就是说，都可导致一个树结构。

![](images/d030d301601c41d23fb73f2e1ec77d30c6eeb43071023519d62021a6a40776e6.jpg)  
图6.2 树的其他3种表示法

下面列出树结构中的一些基本术语。

树的结点包含一个数据元素及若干指向其子树的分支。结点拥有的子树数称为结点的度(Degree)。例如，在图6.1(b)中，A的度为3，C的度为1，F的度为0。度为0的结点称为叶子(Leaf)或终端结点。图6.1(b)中的结点K、L、F、G、M、I、J都是树的叶子。度不为0的结点称为非终端结点或分支结点。除根结点之外，分支结点也称为内部结点。树的度是树内各结点的度的最大值。如图6.1(b)的树的度为3。结点的子树的根称为该结点的孩子(Child)，相应地，该结点称为孩子的双亲(Parent)。例如，在图6.1(b)所示的树中，D为A的子树  $\mathbf{T}_{3}$  的根，则D是A的孩子，而A则是D的双亲，同一个双亲的孩子之间互称兄弟(Sibling)。例如，H、I和J互为兄弟。将这些关系进一步推广，可认为D是M的祖父。结点的祖先是从根到该结点所经分支上的所有结点。例如，M的祖先为A、D和H。反之，以某结点为根的子树中的任一结点都称为该结点的子孙。如B的子孙为E、K、L和F。

结点的层次(Level)从根开始定义起，根为第一层，根的孩子为第二层。若某结点在第  $l$  层，则其子树的根就在第  $l + 1$  层。其双亲在同一层的结点互为堂兄弟。例如，结点G与E、F、H、I、J互为堂兄弟。树中结点的最大层次称为树的深度(Depth)或高度。图6.1(b)所示的树的深度为4。

如果将树中结点的各子树看成从左至右是有次序的（即不能互换），则称该树为有序树，否则称为无序树。在有序树中最左边的子树的根称为第一个孩子，最右边的称为最后

一个孩子。

森林(Forest)是  $m(m \geqslant 0)$  棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。由此，也可以森林和树相互递归的定义来描述树。

就逻辑结构而言，任何一棵树是一个二元组  $Tree = (root, F)$ ，其中：root 是数据元素，称做树的根结点； $F$  是  $m (m \geqslant 0)$  棵树的森林， $F = (T_1, T_2, \dots, T_m)$ ，其中  $T_i = (r_i, F_i)$  称做根 root 的第  $i$  棵子树；当  $m \neq 0$  时，在树根和其子树森林之间存在下列关系：

$$
R F = \{<   r o o t, r _ {i} > | i = 1, 2, \dots , m, m > 0 \}
$$

这个定义将有助于得到森林和树与二叉树之间转换的递归定义。

树的应用广泛，在不同的软件系统中树的基本操作集不尽相同。

# 6.2 二叉树

在讨论一般树的存储结构及其操作之前，我们首先研究一种称为二叉树的抽象数据类型。

# 6.2.1 二叉树的定义

二叉树(Binary Trec)是另一种树型结构，它的特点是每个结点至多只有两棵子树（即二叉树中不存在度大于2的结点），并且，二叉树的子树有左右之分，其次序不能任意颠倒。

抽象数据类型二叉树的定义如下：

ADT BinaryTree{

数据对象D：D是具有相同特性的数据元素的集合。

数据关系R：

若  $\mathrm{D} = \Phi$  ，则  $\mathbb{R} = \Phi$  ，称BinaryTree为空二叉树：

若  $\mathbf{D} \neq \Phi$ ，则  $\mathbf{R} = \{\mathbf{H}^k, \mathbf{H}\}$  是如下二元关系：

（1）在D中存在惟一的称为根的数据元素root.它在关系H下无前驱；  
（2）若  $\mathrm{D} - \{\mathrm{root}\} \neq \Phi$  ，则存在  $\mathrm{D} - \{\mathrm{root}\} = \{\mathrm{D}_1, \mathrm{D}_r\}$  且  $\mathrm{D}_1 \cap \mathrm{D}_r = \Phi$  
（3）若  $\mathbf{D}_i\neq \Phi$  ，则  $\mathrm{D}_{\mathrm{i}}$  中存在惟一的元素  $x_{1}, <   \text{root}, x_{1} > \in H.$  且存在  $\mathbf{D}$  上的关系  $\mathrm{H}_{1}\subset \mathrm{H}$  ；若  $\mathrm{D_r}\neq \Phi$  ，则  $\mathrm{D_r}$  中存在惟一的元素  $\mathbf{x}_{r}, <   \text{root},\mathbf{x}_{r} > \in H.$  且存在  $\mathrm{D_r}$  上的关系  $\mathrm{H}_{\mathrm{r}}\subset \mathrm{H};\mathrm{H} = \{\langle \text{root},\mathbf{x}_{\mathrm{r}}\rangle , <   \text{root},\mathbf{x}_{\mathrm{r}}\rangle ,\mathrm{H}_{\mathrm{r}},\mathrm{H}_{\mathrm{r}}\}$  
（4） $(D_{r}, \{H_{r}\})$  是一棵符合本定义的二叉树，称为根的左子树， $(D_{r}, \{H_{r}\})$  是一棵符合本定义的二叉树，称为根的右子树。

基本操作P：

```txt
InitBiTree(&T);  
操作结果：构造空二叉树T。  
DestroyBiTree(&T);  
初始条件：二叉树T存在。  
操作结果：销毁二叉树T。  
CreateBiTree(&T, definition);
```

初始条件：definition给出二叉树T的定义。

操作结果；按 definition 构造二叉树 T。

ClearBiTree(&T);

初始条件：二叉树  $\mathbf{T}$  存在。

操作结果：将二叉树T清为空树。

BiTreeEmpty(T);

初始条件：二叉树  $\mathbf{T}$  存在。

操作结果：若T为空二叉树，则返回TRUE，否则FALSE。

BiTreeDepth(T);

初始条件：二叉树  $\mathbf{T}$  存在。

操作结果：返回  $\mathbf{T}$  的深度。

Root(T);

初始条件：二叉树  $\mathrm{T}$  存在。

操作结果：返回  $\mathbf{T}$  的根。

Value(T.e);

初始条件：二叉树  $\mathbf{T}$  存在，e是T中某个结点。

操作结果：返回e的值。

Assign(T. &e, value);

初始条件：二叉树T存在，e是T中某个结点。

操作结果：结点e赋值为value。

Parent(T.e);

初始条件：二叉树  $\mathbf{T}$  存在，e是  $\mathbf{T}$  中某个结点。

操作结果：若  $\mathbf{e}$  是  $\mathrm{T}$  的非根结点，则返回它的双亲，否则返回“空”。

LeftChild(T, e);

初始条件：二叉树T存在，e是T中某个结点。

操作结果：返回e的左孩子。若e无左孩子，则返回“空”。

RightChild(T.e);

初始条件：二叉树  $\mathbf{T}$  存在，e是T中某个结点。

操作结果：返回e的右孩子。若e无右孩子，则返回“空”。

LeftSibling(T.e);

初始条件：二叉树  $\mathbf{T}$  存在，e是T中某个结点。

操作结果：返回 e 的左兄弟。若 e 是 T 的左孩子或无左兄弟，则返回“空”。

RightSibling(T.e):

初始条件：二叉树T存在，e是T中某个结点。

操作结果：返回e的右兄弟。若e是T的右孩子或无右兄弟，则返回“空”。

InsertChild(T.p.LR.c);

初始条件：二叉树  $\mathbf{T}$  存在， $\mathbf{p}$  指向  $\mathbf{T}$  中某个结点，LR为0或1，非空二叉树c与  $\mathbf{T}$  不相交且右子树为空。

操作结果：根据LR为0或1，插入c为T中p所指结点的左或右子树。p所指结点的原有左或右子树则成为c的右子树。

DeleteChild(T.p.LR);

初始条件：二叉树T存在，p指向T中某个结点，LR为0或1。

操作结果：根据LR为0或1，删除T中p所指结点的左或右子树。

PreOrderTraverse(T, Visit());

初始条件：二叉树T存在。Visit是对结点操作的应用函数

操作结果：先序遍历  $\mathbf{T}$ ，对每个结点调用函数 Visit 一次且仅一次。一旦 visit() 失败，则操作失败。

InOrderTraverse(T.Visit());

初始条件：二叉树T存在，Visit是对结点操作的应用函数

操作结果：中序遍历T，对每个结点调用函数Visit一次且仅一次。一旦visit()失败，则操作失败。

PostOrderTraverse(T,Visit());

初始条件：二叉树T存在，Visit是对结点操作的应用函数

操作结果：后序遍历T，对每个结点调用函数Visit一次且仅一次。一旦visit()失败，则操作失败。

LevelOrderTraverse(T, Visit());

初始条件：二叉树T存在，Visit是对结点操作的应用函数。

操作结果：层序遍历T，对每个结点调用函数Visit一次且仅一次。一旦visit()失败，则操作失败。

}ADTBinaryTree

上述数据结构的递归定义表明二叉树或为空，或是由一个根结点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。由于这两棵子树也是二叉树，则山二叉树的定义，它们也可以是空树。由此，二叉树可以有5种基本形态，如图6.3所示。

![](images/33c8b8a11a01fa149aeecddff15d338fcefc8bdecfc9adc2ab23f9555666ab2f.jpg)  
(a)

![](images/b52410d75d7abe376906aae3fb94ef788162cbf898f1f9e7afe3d910b438d6ba.jpg)  
(b)

![](images/ca4cfcef2ce6eef123d7a57d5301f5063115e3fb53a11b5837daad58ebfa56f3.jpg)  
(c)

![](images/db9a04913f2387227e1e7132face5b31ffa982ff80ee585a95731752ea8deb25.jpg)  
(d)

![](images/a6d2bf0b2aa6eb914e491b9a88a3181c8035d2ea9256c8a4d8194acef0f94b73.jpg)  
(c)  
图6.3 二叉树的5种基本形态

(a) 空二叉树；(b) 仅有根结点的二叉树；(c) 右子树为空的二叉树；

(d) 左、右子树均非空的二叉树；(c) 左子树为空的二叉树

6.1节中引入的有关树的术语也都适用于二叉树。

# 6.2.2 二叉树的性质

二叉树具有下列重要特性。

性质1 在二叉树的第  $i$  层上至多有  $2^{i-1}$  个结点  $(i \geqslant 1)$ 。

利用归纳法容易证得此性质。

$i = 1$  时，只有一个根结点。显然，  $2^{i - 1} = 2^0 = 1$  是对的。

现在假定对所有的  $j, 1 \leqslant j < i$ , 命题成立, 即第  $j$  层上至多有  $2^{i-1}$  个结点。那么, 可以证明  $j = i$  时命题也成立。

由归纳假设：第  $i - 1$  层上至多有  $2^{i - 2}$  个结点。由于二叉树的每个结点的度至多为2，

故在第  $i$  层上的最大结点数为第  $i - 1$  层上的最大结点数的2倍，即  $2 \times 2^{i - 2} = 2^{i - 1}$ 。

性质2 深度为  $k$  的二叉树至多有  $2^{k} - 1$  个结点， $(k \geqslant 1)$ 。

由性质1可见，深度为  $k$  的二叉树的最大结点数为

$$
\sum_ {i = 1} ^ {k} (\text {第} i \text {层 上 的 最 大 结 点 数}) = \sum_ {i - 1} ^ {k} 2 ^ {i - 1} = 2 ^ {k} - 1
$$

性质3 对任何一棵二叉树  $T$ ，如果其终端结点数为  $n_0$ ，度为2的结点数为  $n_2$ ，则  $n_0 = n_2 + 1$ 。

设  $n_1$  为二叉树  $T$  中度为1的结点数。因为二叉树中所有结点的度均小于或等于2，所以其结点总数为

$$
n = n _ {0} + n _ {1} + n _ {2} \tag {6-1}
$$

再看二叉树中的分支数。除了根结点外，其余结点都有一个分支进入，设  $B$  为分支总数，则  $n = B + 1$  。由于这些分支是由度为1或2的结点射出的，所以又有  $B = n_{1} + 2n_{2}$  。于是得

$$
n = n _ {1} + 2 n _ {2} + 1 \tag {6-2}
$$

由式(6-1)和(6-2)得

$$
n _ {1 1} = n _ {2} + 1
$$

完全二叉树和满二叉树是两种特殊形态的二叉树。

一棵深度为  $k$  且有  $2^k - 1$  个结点的二叉树称为满二叉树。如图6.4(a)所示是一棵深度为1的满二叉树，这种树的特点是每一层上的结点数都是最大结点数。

可以对满二叉树的结点进行连续编号, 约定编号从根结点起, 自上而下, 白左至右。由此可引出完全二叉树的定义。深度为  $k$  的, 有  $n$  个结点的二叉树, 当且仅当其每一个结点都与深度为  $k$  的满二叉树中编号从 1 至  $n$  的结点一一对应时, 称之为完全二叉树。如图 6.4(b) 所示为一棵深度为 4 的完全二叉树。显然, 这种树的特点是: (1) 叶子结点只可能在层次最大的两层上出现; (2) 对任一结点, 若其右分支下的子孙的最大层次为  $l$ , 则其左分支下的子孙的最大层次必为  $l$  或  $l + 1$  。如图 6.4 中(c) 和(d) 不是完全二叉树。

完全二叉树将在很多场合下出现，下面介绍完全二叉树的两个重要特性。

性质4 具有  $n$  个结点的完全二叉树的深度为  $\lfloor \log_2 n \rfloor + 1^{\frac{n}{2}}$ 。

证明：假设深度为  $k$  ，则根据性质2和完全二叉树的定义有

$$
2 ^ {k} \quad - 1 <   n \leqslant 2 ^ {k} - 1 \qquad {\text {或}} \quad 2 ^ {k} \quad - 1 \leqslant n <   2 ^ {k}
$$

于是  $k - 1 \leqslant \log_2 n < k$ ，因为  $k$  是整数，所以  $k = \lfloor \log_2 n \rfloor + 1$ 。

性质5 如果对一棵有  $n$  个结点的完全二叉树（其深度为  $\lfloor \log_2 n \rfloor + 1$ ) 的结点按层序编号（从第1层到第  $\lfloor \log_2 n \rfloor + 1$  层，每层从左到右），则对任一结点  $i (1 \leqslant i \leqslant n)$ ，有

（1）如果  $i = 1$  ，则结点  $i$  是二叉树的根，无双亲；如果  $i > 1$  ，则其双亲PARENT(i)是结点  $\lfloor i / 2\rfloor$  。  
（2）如果  $2i > n$ ，则结点  $i$  无左孩子(结点  $i$  为叶子结点)；否则其左孩子 LCHILD(i)

![](images/18207d863a3651732e29d4f013fbbad5427cb7a5ba03f000c7a96454162a15f5.jpg)  
(a)

![](images/43cd63ad14d6c7b3589f0fb0fa6bb808883a4001dc5a266d8d6b970b2263f434.jpg)  
(b)

(c)  
![](images/dbbba491c96af4b1208f591abcdc930fd276d04462d73d31dda7ee95f77dac24.jpg)  
（a）满二叉树；（b）完全二叉树；（c）和(d)非完全二叉树

![](images/528e3f28084a1b2e4e17884b83f395ca87a36773b23094ca5b84a14b2da571d8.jpg)  
(d)

是结点  $2i$  。

（3）如果  $2i + 1 > n$  ，则结点  $i$  无右孩子；否则其右孩子RCHILD(i)是结点  $2i + 1$  。

我们只要先证明(2)和(3)，便可以从(2)和(3)导出(1)。

对于  $i = 1$  ，由完全二叉树的定义，其左孩子是结点2。若  $2 > n$  ，即不存在结点2，此时结点  $i$  无左孩子。结点  $i$  的右孩子也只能是结点3，若结点3不存在，即  $3 > n$  ，此时结点  $i$  无右孩子。

对于  $i > 1$  可分两种情况讨论：(1)设第  $j$ $(1\leqslant j\leqslant \lfloor \log_2n\rfloor)$  层的第一个结点的编号为  $i$  （由二叉树的定义和性质2可知  $i = 2^{j - 1}$  ，则其左孩子必为第  $j + 1$  层的第一个结点，其编号为  $2^{j} = 2(2^{j - 1}) = 2i$  ，若  $2i > n$  ，则无左孩子；其右孩子必为第  $j + 1$  层的第二个结点，其编号为  $2i + 1$  ，若  $2i + 1 > n$  ，则无右孩子；（2）假设第  $j(1\leqslant j\leqslant \lfloor \log_2n\rfloor)$  层上某个结点的编号为 $i(2^{j - 1}\leqslant i <   2^j -1)$  ，且  $2i + 1 <   n$  ，则其左孩子为 $2i$  ，右孩子为  $2i + 1$  ，又编号为  $i + 1$  的结点是编号为  $i$  的结点的右兄弟或者堂兄弟，若它有左孩子，则编号必为  $2i + 2 = 2(i + 1)$  ，若它有右孩子，则其编号必为  $2i + 3 = 2(i + 1) + 1_{\circ}$

![](images/63e916eff00b91d9c8c7f8d4cb46a5016f2cbe3a24c97ba1ed4e18dfc2357982.jpg)  
图6.4 特殊形态的二叉树

![](images/5ca1ab7a1ba768fcf89e8ec44fb837025017df4da829ba0a56ef517c3d945014.jpg)  
(a)  
图6.5 完全二叉树中结点  $i$  和  $i + 1$  的左、右孩子

(a) 结点  $i$  和  $i + 1$  在同一层上；  
(b) 结点  $i$  和  $i + 1$  不在同一层上

所示为完全二叉树上结点及其左、右孩子结点之间的关系。

# 6.2.3 二叉树的存储结构

# 1. 顺序存储结构

```txt
// -- -- -- 二叉树的顺序存储表示 -- -- -- #define MAX TREE SIZE 100 //二叉树的最大结点数 typedef TElemType SqBiTree[ MAX TREE SIZE]; //0号单元存储根结点 SqBiTree bt;
```

按照顺序存储结构的定义，在此约定，用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树上的结点元素，即将完全二叉树上编号为  $i$  的结点元素存储在如上定义的一维数组中下标为  $i - 1$  的分量中。例如，图6.6(a)所示为图6.1(b)所示完全二叉树的顺序存储结构。对于一般二叉树，则应将其每个结点与完全二叉树上的结点相对照，存储在一维数组的相应分量中，如图6.4(c）所示二叉树的顺序存储结构如图6.6(b)所示，图中以“0”表示不存在此结点。由此可见，这种顺序存储结构仅适用于完全

图6.6 二叉树的顺序存储结构  
![](images/e34812cbf682c012f74931b71443b58bdd498cc80bd249ed8cc68f3c2f4e9a45.jpg)  
(a) 完全二叉树；(b) 一般二叉树

二叉树。因为，在最坏的情况下，一个深度为  $k$  且只有  $k$  个结点的单支树（树中不存在度为2的结点）却需要长度为  $2^{k} - 1$  的一维数组。

# 2.链式存储结构

设计不同的结点结构可构成不同形式的链式存储结构。由二叉树的定义得知，二叉树的结点（如图6.7(a)所示）由一个数据元素和分别指向其左、右子树的两个分支构成，则表示二叉树的链表中的结点至少包含3个域：数据域和左、右指针域，如图6.7(b)所示。有时，为了便于找到结点的双亲，则还可在结点结构中增加一个指向其双亲结点的指针域，如图6.7(c)所示。利用这两种结点结构所得二叉树的存储结构分别称之为二叉链表和三叉链表，如图6.8所示。链表的头指针

图6.7 二叉树的结点及其存储结构（a）二叉树的结点；  
![](images/4edb0ae3f2ca68214b48611c17bd1018860949e0a27a365d42593d1aa1eb051f.jpg)  
（b）含有两个指针域的结点结构；  
（c）含有三个指针域的结点结构

指向二叉树的根结点。容易证得，在含有  $n$  个结点的二叉链表中有  $n + 1$  个空链域。在6.3节中我们将会看到可以利用这些空链域存储其他有用信息，从而得到另一种链式存储结构——线索链表。以下是二叉链表的定义和部分基本操作的函数原型说明。

//- - - - - 二叉树的二叉链表存储表示

typedef struct BiTNode{

TElemType data;

struct BiTNode * lchild. * rchild; // 左右孩子指针

}BiTreeNode. \*BiTree;

// - - - - - 基本操作的函数原型说明（部分）- - - -

Status CreateBiTree(BiTree &T);

// 按先序次序输入二叉树中结点的值（一个字符），空格字符表示空树。  
//构造二叉链表表示的二叉树T。

Status PreOrderTraversc(BiTree T.Status（  $\text{一}$  Visit）（TEIemTypee））：

//采用二叉链表存储结构，Visit是对结点操作的应用函数。  
// 先序遍历二叉树 T. 对每个结点调用函数 Visit 一次且仅一次  
//一旦visit()失败，则操作失败。

Status InOrderTraverse(BiTree T, Status (*Visit)(TElemType e));

//采用二叉链表存储结构，Visit是对结点操作的应用函数。  
//中序遍历二叉树T，对每个结点调用函数Visit一次且仅一次。  
//一旦visit()失败，则操作失败。

Status PostOrderTraverse(BiTree T, Status (*Visit)(TElemType e)):

//采用二叉链表存储结构，Visit是对结点操作的应用函数  
//后序遍历二叉树T，对每个结点调用函数Visit一次且仅一次  
//一旦visit()失败，则操作失败。

Status LevelOrderTraverse(BiTree T. Status (*Visit)(TElemType e));

// 采用二叉链表存储结构,Visit是对结点操作的应用函数  
//层序遍历二叉树T，对每个结点调用函数Visit一次且仅一次  
//一旦visit()失败，则操作失败。

![](images/15bc77e23e76656021fa066d7cac9a1e9b2bc82c7eb49169be8243e9d7d44c37.jpg)  
(a)

(b)  
图6.8 链表存储结构  
![](images/d2c45787f23001621ff51f279e0d4678cf9e5e3da39f46ecd9a842bd2f733bd9.jpg)  
(a) 单支树的二叉链表；(b) 二叉链表；(c) 二叉链表

![](images/4dd3c880a37a89c12bfc3ea1a616012ee3756f133b26b76189b53dd902d67f65.jpg)  
(c)

在不同的存储结构中，实现二叉树的操作方法也不同，如找结点  $\mathbf{x}$  的双亲PARENT(T,e)，在三叉链表中很容易实现，而在二叉链表中则需从根指针出发巡查。由此，在具体应用中采用什么存储结构，除根据二叉树的形态之外还应考虑需进行何种操作。读者可试以6.2节中定义的各种操作对以上3种存储结构进行比较。

# 6.3 遍历二叉树和线索二叉树

# 6.3.1 遍历二叉树

在二叉树的一些应用中，常常要求在树中查找具有某种特征的结点，或者对树中全部结点逐一进行某种处理。这就提出了一个遍历二叉树(traversing binary tree)的问题，即如何按某条搜索路径巡访树中每个结点，使得每个结点均被访问一次，而且仅被访问一次。“访问”的含义很广，可以是对结点作各种处理，如输出结点的信息等。遍历对线性结构来说，是一个容易解决的问题。而对二叉树则不然，由于二叉树是一种非线性结构，每个结点都可能有两棵子树，因而需要寻找一种规律，以便使二叉树上的结点能排列在一个线性队列上，从而便于遍历。

回顾二叉树的递归定义可知，二叉树是由3个基本单元组成：根结点、左子树和右子树。因此，若能依次遍历这三部分，便是遍历了整个二叉树。假如以L、D、R分别表示遍历左子树、访问根结点和遍历右子树，则可有DLR、LDR、LRD、DRL、RDL、RLD这6种遍历二叉树的方案。若限定先左后右，则只有前3种情况，分别称之为先(根)序遍历、中(根)序遍历和后(根)序遍历。基于二叉树的递归定义，可得下述遍历二叉树的递归算法定义。

先序遍历二叉树的操作定义为：

若二叉树为空，则空操作；否则

（1）访问根结点：  
（2）先序遍历左子树：  
（3）先序遍历右子树。

中序遍历二叉树的操作定义为：

若二叉树为空，则空操作；否则

（1）中序遍历左子树：  
（2）访问根结点；  
（3）中序遍历右子树。

后序遍历二叉树的操作定义为：

若二叉树为空，则空操作；否则

（1）后序遍历左子树；  
（2）后序遍历右子树；  
（3）访问根结点。

算法6.1给出了先序遍历二叉树基本操作的递归算法在二叉链表上的实现。读者可类似地实现中序遍历和后序遍历的递归算法，此处不再一一列举。

```cpp
Status PreOrderTraverse(BiTree T.Status（\*Visit)(TElemType e)){//采用二叉链表存储结构，Visit是对数据元素操作的应用函数，//先序遍历二叉树T的递归算法，对每个数据元素调用函数Visit。//最简单的Visit函数是：Status PrintElement(TElemType e）{//输出元素e的值//printf(e); //实用时，加上格式串//return OK;  
//}  
//调用实例:PreOrderTraverse(T,PrintElement):if(T){if(Visit(T->data))if(PreOrderTraverse(T->lchild.Visit))if(PreOrderTraverse(T->rchild,Visit)) return OK;return ERROR;}else return OK;  
}//PreOrderTraverse
```

# 算法 6.1

例如图6.9所示的二叉树①表示下述表达式

$$
a + b * (c - d) - e / f
$$

若先序遍历此二叉树，按访问结点的先后次序将结点排列起来，可得到二叉树的先序序列为

$$
- + a * b - c d / e f \tag {6-3}
$$

类似地，中序遍历此二叉树，可得此二叉树的中序序列为

$$
a + b * c - d - e / f \tag {6-4}
$$

后序遍历此二叉树，可得此二叉树的后序序列为

$$
\operatorname {a b c d} - * + \operatorname {e f} / - \tag {6-5}
$$

从表达式来看，以上3个序列(6-3)、(6-4)和(6-5)恰好为表达式的前缀表示（波兰式）、中缀表示和后缀表示（逆波兰式）。

从上述二叉树遍历的定义可知，3种遍历算法之不同处仅在于访问根结点和遍历左、右子树的先后关系。如果在算法中暂且抹去和递归无关的Visit语句，则3个遍历算法完全相同。由此，从递归执行过程的角度来看先序、中序和后序遍历也是完全相同的。图6.10(b)中用带箭头的虚线表示了这3种遍历

算法的递归执行过程。其中，向下的箭头表示更深一层的递归调用，向上的箭头表示从递归调用退出返回；虚线旁的三角形、圆形和方形内的字符分别表示在先序、中序和后序遍

![](images/fa1b060edd32165f5bdf9f37101625872ad6ff594464c76c514fdb63b998ae8f.jpg)  
图6.9 表达式  $(a + b)^x$  （c-d）-e/f)的二叉树

图6.10 3种遍历过程示意图  
![](images/5820186d3b0cf8b95ceaf65e914a935da0d8eba33e1c711f1ef8532f4887f1e9.jpg)  
(a) 表达式  $(a * b - c)$  的二叉树；(b) 遍历的递归执行过程

历二叉树过程中访问结点时输出的信息。例如，由于中序遍历中访问结点是在遍历左子树之后、遍历右子树之前进行，则带圆形的字符标在向左递归返回和向右递归调用之间。由此，只要沿虚线从1出发到2结束，将沿途所见的三角形(或圆形、或方形)内的字符记下，便得遍历二叉树的先序（或中序、或后序）序列。例如，从图6.10(b)分别可得图6.10(a)所示表达式的前缀表示  $(-\ast \mathrm{abc})$  、中缀表示  $(\mathbf{a}*\mathbf{b} - \mathbf{c})$  和后缀表示  $(\mathtt{ab*c - })$  。

仿照递归算法执行过程中递归工作栈的状态变化状况可直接写出相应的非递归算法。例如，从中序遍历递归算法执行过程中递归工作栈的状态可见：(1)工作记录中包含两项，其一是递归调用的语句编号，其二是指向根结点的指针，则当栈顶记录中的指针非空时，应遍历左子树，即指向左子树根的指针进栈；(2)若栈顶记录中的指针值为空，则应退至上一层，若是从左子树返回，则应访问当前层即栈顶记录中指针所指的根结点；(3)若是从右子树返回，则表明当前层的遍历结束，应继续退栈。从另一角度看，这意味着遍历右子树时不再需要保存当前层的根指针，可直接修改栈顶记录中的指针即可。由此可得两个中序遍历二叉树的非递归算法如算法6.2和6.3所示，供读者分析比较，以加深理解。

```c
Status InOrderTraverse(BiTree T, Status (*Visit)(TElemType e)) {
// 采用二叉链表存储结构，Visit 是对数据元素操作的应用函数。
// 中序遍历二叉树 T 的非递归算法，对每个数据元素调用函数 Visit。
InitStack(S): Push(S, T); // 根指针进栈
while (!StackEmpty(S)) {
    while (GetTop(S, p) && p) Push(S, p->lchild); // 向左走到尽头
    Pop(S, p); // 空指针退栈
    if (!StackEmpty(S)) { // 访问结点，向右一步
        Pop(S, p); if (!Visit(p->data)) return ERROR;
        Push(S, p->rchild);
    } // if
} // While
```

```javascript
return OK;   
}//InOrderTraverse
```

# 算法 6.2

```c
Status InOrderTraverse(BiTree T, Status (*Visit)(TElemType e)) {
// 采用二叉链表存储结构，Visit 是对数据元素操作的应用函数。
// 中序遍历二叉树 T 的非递归算法，对每个数据元素调用函数 Visit。
InitStack(S); p = T;
while (p || !StackEmpty(S)) {
if (p) {Push(S, p); p = p->lchild;} // 根指针进栈，遍历左子树
else {
// 根指针退栈，访问根结点，遍历右子树
Pop(S, p); if (!Visit(p->data)) return ERROR;
p = p->rchild;
} // else
} // While
return OK;
} // InOrderTraverse
```

# 算法 6.3

“遍历”是二叉树各种操作的基础，可以在遍历过程中对结点进行各种操作，如：对于一棵已知树可求结点的双亲，求结点的孩子结点，判定结点所在层次等，反之，也可在遍历过程中生成结点，建立二叉树的存储结构。例如，算法6.4是一个按先序序列建立二叉树的二叉链表的过程。对图6.8(b)所示二叉树，按下列次序顺序读入字符

ABCΦDEΦGΦΦFΦΦ

（其中  $\Phi$  表示空格字符）可建立相应的二叉链表。

```c
Status CreateBiTree(BiTree &T) { // 按先序次序输入二叉树中结点的值(一个字符), 空格字符表示空树, // 构造二叉链表表示的二叉树 T。  
scanf(&ch);  
if (ch == '') T = NULL;  
else {  
    if (!T = (BiTreeNode *)malloc(sizeof(BiTNode))) exit(OVERFLOW);  
    T->data = ch; // 生成根结点  
CreateBiTree(T->lchild); // 构造左子树  
CreateBiTree(T->rchild); // 构造右子树  
}  
return OK;  
} // CreateBiTree
```

# 算法 6.4

对二叉树进行遍历的搜索路径除了上述按先序、中序或后序外，还可从上到下、从左到右按层次进行。

显然，遍历二叉树的算法中的基本操作是访问结点，则不论按哪一种次序进行遍历，对含  $n$  个结点的二叉树，其时间复杂度均为  $O(n)$  。所需辅助空间为遍历过程中栈的最大容量，即树的深度，最坏情况下为  $n$ ，则空间复杂度也为  $O(n)$  。遍历时也可采用二叉树的

其他存储结构，如带标志域的三叉链表（参见算法6.13），此时因存储结构中已存有遍历所需足够信息，则遍历过程中不需另设栈，也可和8.5节将讨论的遍历广义表的算法相类似，采用带标志域的二叉链表作存储结构，并在遍历过程中利用指针域暂存遍历路径，也可省略栈的空间，但这样做将使时间上有很大损失。

# 6.3.2 线索二叉树

从上节的讨论得知：遍历二叉树是以一定规则将二叉树中结点排列成一个线性序列，得到二叉树中结点的先序序列或中序序列或后序序列。这实质上是对一个非线性结构进行线性化操作，使每个结点（除第一个和最后一个外）在这些线性序列中有且仅有一个直接前驱和直接后继（在不至于混淆的情况，我们省去直接二字）①。例如在图6.9所示的二叉树的结点的中序序列  $a + b*c - d - e/f$  中  $c'$  的前驱是  $*'$ ，后继是  $-'$ 。

但是，当以二叉链表作为存储结构时，只能找到结点的左、右孩子信息，而不能直接得到结点在任一序列中的前驱和后继信息，这种信息只有在遍历的动态过程中才能得到。

如何保存这种在遍历过程中得到的信息呢？一个最简单的办法是在每个结点上增加两个指针域 fwd 和 bkwd，分别指示结点在依任一次序遍历时得到的前驱和后继信息。显然，这样做使得结构的存储密度大大降低。另一方面，在有  $n$  个结点的二叉链表中必定存在  $n + 1$  个空链域。由此设想能否利用这些空链域来存放结点的前驱和后继的信息。

试作如下规定：若结点有左子树，则其 lchild 域指示其左孩子，否则令 lchild 域指示其前驱；若结点有右子树，则其 rchild 域指示其右孩子，否则令 rchild 域指示其后继。为了避免混淆，尚需改变结点结构，增加两个标志域

<table><tr><td>lchild</td><td>L Tag</td><td>data</td><td>R Tag</td><td>rchild</td></tr></table>

其中：

$$
\mathrm {L T a g} = \left\{ \begin{array}{l l} 0 & \text {l c h i l d 域 指 示 结 点 的 左 孩 子} \\ 1 & \text {l c h i l d 域 指 示 结 点 的 前 驱} \end{array} \right.
$$

$$
\mathrm {R T a g} = \left\{ \begin{array}{l l} 0 & \text {r c h i l d 域 指 示 结 点 的 右 孩 子} \\ 1 & \text {r c h i l d 域 指 示 结 点 的 后 继} \end{array} \right.
$$

以这种结点结构构成的二叉链表作为二叉树的存储结构，叫做线索链表，其中指向结点前驱和后继的指针，叫做线索。加上线索的二叉树称之为线索二叉树( Threaded Binary Tree)。例如图6.11(a)所示为中序线索二叉树，与其对应的中序线索链表如图6.11(b)所示。其中实线为指针（指向左、右子树），虚线为线索（指向前驱和后继）。对二叉树以某种次序遍历使其变为线索二叉树的过程叫做线索化。

在线索树上进行遍历，只要先找到序列中的第一个结点，然后依次找结点后继直至其后继为空时而止。

如何在线索树中找结点的后继？以图6.11的中序线索树为例来看，树中所有叶子结点的右链是线索，则右链域直接指示了结点的后继，如结点b的后继为结点\*。树中所有

图6.11 线索二叉树及其存储结构  
![](images/fa9f26d4dfc29f812016771c1c4ec5f544c835a3cd78034ff79f5eb4a94511dc.jpg)  
（a）中序线索二叉树；（b）中序线索链表

非终端结点的右链均为指针, 则无法由此得到后继的信息。然而, 根据中序遍历的规律可知, 结点的后继应是遍历其右子树时访问的第一个结点, 即右子树中最左下的结点。例如在找结点 * 的后继时, 首先沿右指针找到其右子树的根结点“一”, 然后顺其左指针往下直至其左标志为 1 的结点, 即为结点 * 的后继, 在图中是结点 c。反之, 在中序线索树中找结点前驱的规律是: 若其左标志为“1”, 则左链为线索, 指示其前驱, 否则遍历左子树时最后访问的一个结点 (左子树中最右下的结点) 为其前驱。

在后序线索树中找结点后继较复杂些，可分3种情况：（1)若结点  $\mathbf{x}$  是二叉树的根，则其后继为空；(2)若结点  $\mathbf{x}$  是其双亲的右孩子或是其双亲的左孩子且其双亲没有右子树，则其后继即为双亲结点；（3）若结点  $\mathbf{x}$  是其双亲的左孩子，且其双亲有右子树，则其后继为双亲的右子树上按后序遍历列出的第一个结点。例如图6.12所示为后序后继线索二叉树，结点B的后继为结点C，结点C的后继为结点D.结点F的后继为结点G，而结点D的后继为结点E。可见，在后序线索化树上找后继时需知道结点双亲，即需带标志域的三叉链表作存储结构。

![](images/4550732776151dedc0a2371357b5bcfd094361fbbe9b3870682dff8e5a56d75a.jpg)  
图6.12 后序后继线索二叉树

可见，在中序线索二叉树上遍历二叉树，虽则时间复杂度亦为

$O(n)$ , 但常数因子要比上节讨论的算法小, 且不需要设栈。因此, 若在某程序中所用二叉树需经常遍历或查找结点在遍历所得线性序列中的前驱和后继, 则应采用线索链表作存储结构。

//二叉树的二叉线索存储表示

typedef enum PointerTag : Link, Thread }; // Link == 0: 指针, Thread == 1: 线索

typedef struct BiThrNode{

TElemType data;

struct BiThrNode * lchild. * rchild; 左右孩子指针

```txt
PointerTag LTag.RTag: //左右标志}BiThrNode. \*BiThrTree:
```

为方便起见，仿照线性表的存储结构，在二叉树的线索链表上也添加一个头结点，并令其 lchild 域的指针指向二叉树的根结点，其 rchild 域的指针指向中序遍历时访问的最后一个结点；反之，令二叉树中序序列中的第一个结点的 lchild 域指针和最后一个结点 rchild 域的指针均指向头结点。这好比为二叉树建立了一个双向线索链表，既可从第一个结点起顺后继进行遍历，也可从最后一个结点起顺前驱进行遍历（如图 6.11(b) 所示）。下述算法 6.5 正是以双向线索链表为存储结构时对二叉树进行遍历的算法。

```c
Status InOrderTraverse Thr(BiThrTree T. Status (*Visit)(TElemType e)) {
// T指向头结点，头结点的左链 lchild 指向根结点，可参见线索化算法。
// 中序遍历二叉线索树 T 的非递归算法，对每个数据元素调用函数 Visit。
p = T->lchild; // p指向根结点
while (p != T) {
while (p->LTag == Link) p = p->lchild;
if (!Visit(p->data)) return ERROR; // 访问其左子树为空的结点
while (p->RTag == Thread && p->rchild != T) {
p = p->rchild; Visit(p->data); // 访问后继结点
}
p = p->rchild;
}
return OK;
} // InOrderTraverse. Thr
```

# 算法 6.5

那么，又如何进行二叉树的线索化呢？由于线索化的实质是将二叉链表中的空指针改为指向前驱或后继的线索，而前驱或后继的信息只有在遍历时才能得到，因此线索化的过程即为在遍历的过程中修改空指针的过程。为了记下遍历过程中访问结点的先后关系，附设一个指针 pre 始终指向刚刚访问过的结点，若指针 p 指向当前访问的结点，则 pre 指向它的前驱。由此可得中序遍历建立中序线索化链表的算法如算法 6.6 和 6.7 所示。

```c
Status InOrderThreading(BiThrTree & Thrt. BiThrTree T) {
// 中序遍历二叉树T.并将其中序线索化.Thrt指向头结点。
if (!(Thrt = (BiThrTree)malloc(sizeof(BiThrNode))) exit (OVERFLOW);
Thrt->LTag = Link: Thrt->RTag = Thread; // 建头结点
Thrt->rchild = Thrt; // 右指针回指
if (!T) Thrt->lchild = Thrt; // 若二叉树空,则左指针回指
else {
Thrt->lchild = T; pre = Thrt;
InThreading(T); // 中序遍历进行中序线索化
pre->rchild = Thrt; pre->RTag = Thread; // 最后一个结点线索化
Thrt->rchild = pre;
}
return OK;
} // InOrderThreading
```

# 算法 6.6

```txt
void InThreading(BiThrTree p) {  
if (p) {  
    InThreading(p->lchild); // 左子树线索化  
    if (!p->lchild) {p->LTag = Thread; p->lchild = pre;} // 前驱线索  
    if (!pre->rchild) {pre->RTag = Thread; pre->rchild = p;} // 后继线索  
    pre = p; // 保持 pre 指向 p 的前驱  
    InThreading(p->rchild); // 右子树线索化  
}  
}// InThreading
```

# 算法 6.7

# 6.4 树和森林

这一节我们将讨论树的表示及其遍历操作，并建立森林与二叉树的对应关系。

# 6.4.1 树的存储结构

在大量的应用中，人们曾使用多种形式的存储结构来表示树。这里，我们介绍3种常用的链表结构。

# 1. 双亲表示法

假设以一组连续空间存储树的结点，同时在每个结点中附设一个指示器指示其双亲结点在链表中的位置，其形式说明如下：

```txt
// -- -- 树的双亲表存储表示 -- -- #define MAX_tree_SIZE 100 typedef struct PTNode { // 结点结构 TelemType data; int parent; // 双亲位置域 }PTNode; typedef struct { // 树结构 PTNode nodes[MAX_tree_SIZE]; int r,n; // 根的位置和结点数 }PTree;
```

例如，图6.13展示一棵树及其双亲表示的存储结构。

这种存储结构利用了每个结点（除根以外）只有惟一的双亲的性质。PARENT(T, x) 操作可以在常量时间内实现。反复调用 PARENT 操作，直到遇见无双亲的结点时，便找到了树的根，这就是 ROOT

![](images/aa2bc3b1029e3e9a02c9f2e5073132cb41451030768740f13b439c018f38a51d.jpg)  
图6.13 树的双亲表示法示例

(x) 操作的执行过程。但是, 在这种表示法中, 求结点的孩子时需要遍历整个结构。

# 2. 孩子表示法

由于树中每个结点可能有多棵子树，则可用多重链表，即每个结点有多个指针域，其

中每个指针指向一棵子树的根结点，此时链表中的结点可以有如下两种结点格式：

<table><tr><td>data</td><td>child1</td><td>child2</td><td>...</td><td>childd</td><td></td></tr><tr><td colspan="5"></td><td></td></tr><tr><td>data</td><td>degree</td><td>child1</td><td>child2</td><td>...</td><td>childd</td></tr></table>

若采用第一种结点格式，则多重链表中的结点是同构的，其中d为树的度。由于树中很多结点的度小于d，所以链表中有很多空链域，空间较浪费，不难推出，在一棵有n个结点度为k的树中必有  $\mathbf{n}(\mathbf{k} - 1) + 1$  个空链域。若采用第二种结点格式，则多重链表中的结点是不同构的，其中d为结点的度，degree域的值同d。此时，虽能节约存储空间，但操作不方便。

另一种办法是把每个结点的孩子结点排列起来，看成是一个线性表，且以单链表作存储结构，则  $n$  个结点有  $n$  个孩子链表（叶子的孩子链表为空表）。而  $n$  个头指针又组成一个线性表，为了便于查找，可采用顺序存储结构。这种存储结构可形式地说明如下：

```objectivec
// -- -- 树的孩子链表存储表示 -- -- --  
typedef struct CTNode { // 孩子结点  
int child;  
struct CTNode * next;  
} * ChildPtr;  
typedef struct {  
TEleamType data;  
ChildPtr firstchild; // 孩子链表头指针  
}CTBox;  
typedef struct {  
CTBox nodes[MAX_ROOT_SIZE];  
int n, r; // 结点数和根的位置；  
}CTree;
```

图6.14(a)是图6.13中的树的孩子表示法。与双亲表示法相反，孩子表示法便于那些涉及孩子的操作的实现，却不适用于PARENT(T,x)操作。我们可以把双亲表示法和孩子表示法结合起来，即将双亲表示和孩子链表合在一起。图6.14(b)就是这种存储结构的一例，它和图6.14(a)表示的是同一棵树。

# 3. 孩子兄弟表示法

又称二叉树表示法，或二叉链表表示法。即以二叉链表作树的存储结构。链表中结点的两个链域分别指向该结点的第一个孩子结点和下一个兄弟结点，分别命名为 firstchild 域和 nextSibling 域。

```txt
//----树的二叉链表(孩子-兄弟)存储表示---- typedef struct CSNode{ ElemType data; struct CSNode \*firstchild，\*nextSibling; }CSNode，\*CSTree;
```

图6.15是图6.13中的树的孩子兄弟链表。利用这种存储结构便于实现各种树的操作。首先易于实现找结点孩子等的操作。例如：若要访问结点  $\mathbf{x}$  的第i个孩子，则只要先

![](images/77e0e7033766d5da7b1565e964319db26a26a0b2b0b5562366daca1fd7c18a84.jpg)  
(a)

![](images/3a96ae693a162a155319c03c5c251fe283216abfd857a96580a7cf21451267bc.jpg)  
(b)

从 firstchild 域找到第 1 个孩子结点, 然后沿着孩子结点的 nextSibling 域连续走 i-1 步, 便可找到 x 的第 i 个孩子。当然, 如果为每个结点增设一个 PARENT 域, 则同样能方便地实现 PARENT(T, x) 操作。

# 6.4.2 森林与二叉树的转换

由于二叉树和树都可用二叉链表作为存储结构, 则以二叉链表作为媒介可导出树与二叉树之间的一个对应关系。也就是说, 给定一棵树, 可以找到惟一的一棵二叉树与之对应, 从物理结构来看, 它们的二叉链表是相同的, 只是解释不同而已。图6.16直观地展示了树与二叉树之间的对应关系。

从树的二叉链表表示的定义可知，任何一棵和树对

图6.14 图6.13的树的另外两种表示法  
图6.15 图6.13中树的二叉链表表示法  
![](images/d2b9e071e01406282c7134c9fdb704caa76aa179933817e5ae0a640dcf35fdad.jpg)  
(a) 孩子链表；(b) 带双亲的孩子链表

![](images/829a78dbab0aa0c24814ada7bb9166352822f45d757c7e473fc0ed30c3164a7d.jpg)  
图6.16 树与二叉树的对应关系示例

应的二叉树, 其右子树必空。若把森林中第二棵树的根结点看成是第一棵树的根结点的兄弟, 则同样可导出森林和二叉树的对应关系。

例如，图6.17展示了森林与二叉树之间的对应关系。

![](images/02c519f835004c6abfba2dcb47b02243fb7a9499607767d99a5de9b638ee1f69.jpg)  
图6.17 森林与二叉树的对应关系示例

这个一一对应的关系导致森林或树与二叉树可以相互转换，其形式定义如下：

# 1. 森林转换成二叉树

如果  $F = \{T_{1}, T_{2}, \dots, T_{m}\}$  是森林，则可按如下规则转换成一棵二叉树  $B = (root, LB, RB)$ 。

（1）若  $F$  为空，即  $m = 0$  ，则  $B$  为空树；  
(2) 若  $F$  非空, 即  $m \neq 0$ , 则  $B$  的根 root 即为森林中第一棵树的根  $ROOT(T_{1})$ ;  $B$  的左子树  $LB$  是从  $T_{1}$  中根结点的子树森林  $F_{1} = \{T_{11}, T_{12}, \dots, T_{1m1}\}$  转换而成的二叉树; 其右子树  $RB$  是从森林  $F' = \{T_{2}, T_{3}, \dots, T_{m}\}$  转换而成的二叉树。

# 2. 二叉树转换成森林

如果  $B = (root, LB, RB)$  是一棵二叉树，则可按如下规则转换成森林  $F = \{T_1, T_2, \dots, T_m\}$ ：

（1）若  $B$  为空，则  $F$  为空；  
(2) 若  $B$  非空, 则  $F$  中第一棵树  $T_{1}$  的根  $ROOT(T_{1})$  即为二叉树  $B$  的根 root;  $T_{1}$  中根结点的子树森林  $F_{1}$  是由  $B$  的左子树  $LB$  转换而成的森林;  $F$  中除  $T_{1}$  之外其余树组成的森林  $F^{\prime} = \{T_{2}, T_{3}, \dots, T_{m}\}$  是由  $B$  的右子树  $RB$  转换而成的森林。

从上述递归定义容易写出相互转换的递归算法。同时，森林和树的操作亦可转换成二叉树的操作来实现。

# 6.4.3 树和森林的遍历

由树结构的定义可引出两种次序遍历树的方法：一种是先根(次序)遍历树，即：先访问树的根结点，然后依次先根遍历根的每棵子树；另一种是后根(次序)遍历，即：先依次后根遍历每棵子树，然后访问根结点。

例如，对图6.16的树进行先根遍历，可得树的先根序列为

ABCDE

若对此树进行后根遍历，则得树的后根序列为

BDCEA

按照森林和树相互递归的定义，我们可以推出森林的两种遍历方法：

# 1. 先序遍历森林

若森林非空，则可按下述规则遍历之：

（1）访问森林中第一棵树的根结点；  
（2）先序遍历第一棵树中根结点的子树森林；  
（3）先序遍历除去第一棵树之后剩余的树构成的森林。

# 2. 中序遍历森林

若森林非空，则可按下述规则遍历之：

（1）中序遍历森林中第一棵树的根结点的子树森林；  
（2）访问第一棵树的根结点；  
（3）中序遍历除去第一棵树之后剩余的树构成的森林。

若对图6.17中森林进行先序遍历和中序遍历，则分别得到森林的先序序列为

ABCDEFGHIJ

中序序列为

BCDAFEHJIG

由上节森林与二叉树之间转换的规则可知，当森林转换成二叉树时，其第一棵树的子树森林转换成左子树，剩余树的森林转换成右子树，则上述森林的先序和中序遍历即为其对应的二叉树的先序和中序遍历。若对图6.17中和森林对应的二叉树分别进行先序和中序遍历，可得和上述相同的序列。

由此可见，当以二叉链表作树的存储结构时，树的先根遍历和后根遍历可借用二叉树的先序遍历和中序遍历的算法实现之。

# 6.5 树与等价问题

在离散数学中，对等价关系和等价类的定义是：

如果集合  $S$  中的关系  $R$  是自反的、对称的和传递的，则称它为一个等价关系。

设  $R$  是集合  $S$  的等价关系。对任何  $x \in S$ ，由  $[x]_R = \{y | y \in S \land xRy\}$  给出的集合  $[x]_R \subseteq S$  称为由  $x \in S$  生成的一个  $R$  等价类。

若  $R$  是集合  $S$  上的一个等价关系, 则由这个等价关系可产生这个集合的惟一划分。即可以按  $R$  将  $S$  划分为若干不相交的子集  $S_{1}, S_{2}, \cdots$ , 它们的并即为  $S$ , 则这些子集  $S_{i}$  便称为  $S$  的  $R$  等价类。

等价关系是现实世界中广泛存在的一种关系，许多应用问题可以归结为按给定的等价关系划分某集合为等价类，通常称这类问题为等价问题。

例如在FORTRAN语言中，可以利用EQUIVALENCE语句使数个程序变量共享同

一存储单位, 这问题实质就是按 EQUIVALENCE 语句确定的关系对程序中的变量集合进行划分, 所得等价类的数目即为需要分配的存储单位, 而同一等价类中的程序变量可被分配到同一存储单位中去。此外, 划分等价类的算法思想也可用于求网络的最小生成树等图的算法中。

应如何划分等价类呢？假设集合  $S$  有  $n$  个元素， $m$  个形如  $(x, y) (x, y \in S)$  的等价偶对确定了等价关系  $R$ ，需求  $S$  的划分。

确定等价类的算法可如下进行：

（1）令  $S$  中每个元素各自形成一个只含单个成员的子集，记作  $S_{1}, S_{2}, \dots, S_{n}$ 。  
（2）重复读入  $m$  个偶对，对每个读人的偶对  $(x,y)$  ，判定  $x$  和  $y$  所属子集。不失一般性，假设  $x\in S_i,y\in S_j$  ，若  $S_{i}\neq S_{j}$  ，则将  $S_{i}$  并入  $S_{j}$  并置  $S_{i}$  为空(或将  $S_{j}$  并入  $S_{i}$  并置  $S_{j}$  为空)。则当  $m$  个偶对都被处理过后，  $S_{1},S_{2},\dots ,S_{n}$  中所有非空子集即为  $s$  的  $R$  等价类。

从上述可见，划分等价类需对集合进行的操作有3个：其一是构造只含单个成员的集合；其二是判定某个单元素所在子集；其三是归并两个互不相交的集合为一个集合。由此，需要一个包含上述3种操作的抽象数据类型MFSet。

ADT MFSet{

数据对象：若设S是MFSet型的集合，则它由  $\mathfrak{n}(\mathfrak{n} > 0)$  个子集  $S_{1}(i = 1,2,\dots ,n)$  构成，每个子集的成员都是子界[-maxnumber..maxnumber]内的整数；

数据关系：  $\mathbf{S}_1\bigcup \mathbf{S}_2\bigcup \dots \bigcup \mathbf{S}_n = \mathbf{S}\quad \mathbf{S}_i\subset \mathbf{S}(\mathrm{i} = 1,2,\dots ,\mathrm{n})$

基本操作：

Initial(&S.n,  $\mathbf{x}_1$  ，  $\mathbf{x}_2,\dots ,\mathbf{x}_n)$

操作结果：初始化操作。构造一个由  $\mathbf{n}$  个子集（每个子集只含单个成员  $\mathbf{x}_i$ ）构成的集合  $S$ 。Find(S, x)；

初始条件：S是已存在的集合，x是S中某个子集的成员。

操作结果：查找函数。确定S中  $\mathbf{x}$  所属子集  $S_{1}$  。

Merge(&S,i,j);

初始条件： $\mathbf{S}_i$  和  $\mathbf{S}_j$  是  $\mathbf{S}$  中的两个互不相交的非空集合。

操作结果：归并操作。将  $S_{i}$  和  $S_{j}$  中的一个并入另一个中。

}ADT MFSet;

以集合为基础(结构)的抽象数据类型可用多种实现方法, 如用位向量表示集合或用有序表表示集合等。如何高效地实现以集合为基础的抽象数据类型, 则取决于该集合的大小以及对此集合所进行的操作。根据MFSet类型中定义的查找函数和归并操作的特点, 我们可利用树型结构表示集合。约定: 以森林  $F = (T_{1}, T_{2}, \dots, T_{n})$  表示MFSet型的集合  $S$ , 森林中的每一棵树  $T_{i} (i = 1, 2, \dots, n)$  表示  $S$  中的一个元素——子集  $S_{i} (S_{i} \subset S, i = 1, 2, \dots, n)$ , 树中每个结点表示子集中的一个成员  $x$ , 为操作方便起见, 令每个结点中含有一个指向其双亲的指针, 并约定根结点的成员兼作子集的名称。例如, 图6.18(a)和(b)中的两棵树分别表示子集  $S_{1} = \{1, 3, 6, 9\}$  和  $S_{2} = \{2, 8, 10\}$  。显然, 这样的树形结构易于实现上述两种集合的操作。由于各子集中的成员均不相同, 则实现集合的“并”操作, 只要将一棵子集树的根指向另一棵子集树的根即可。例如: 图6.18(c)中  $S_{3} = S_{1} \cup S_{2}$  。同时, 完成找某个成员所在集合的操作, 只要从该成员结点出发, 顺链而进, 直至找到树的根结点为止。

(a)  
![](images/1ab48e0594be2f06747c7eeaa143e3ad9e97f815acb0cab4a19abfbc80c0cb26.jpg)  
(a)  $\mathbf{S}_1 = \{1,3,6,9\}$ ; (b)  $\mathbf{S}_2 = \{2,8,10\}$ ; (c)  $\mathbf{S}_3 = \mathbf{S}_1 \cup \mathbf{S}_2$

![](images/7ea0a63f4e0d8eb6b60043deaf8e9d47a4d1d35f3b3906b2d077251d21447339.jpg)  
(b)

![](images/eeaff6c80dfc941c9fa3c25dc0b4bbd0d6ec53a970d84b1cd3ede443f3d6d60e.jpg)  
(c)  
图6.18 集合的一种表示法

为便于实现这样两种操作，应采用双亲表示法作存储结构，如下所示：

```txt
//---ADT MFSet的树的双亲表存储表示---- typedef PTree MFSet;
```

此时，查找函数和归并操作的实现如算法6.8和算法6.9所示。

```txt
int find_mfset(MFSet S, int i) {
    // 找集合 S 中 i 所在子集的根。
    if (i < 1 || i > S.n) return -1; // i 不属 S 中任一子集
    for (j = i; Snodes[j].parent > 0; j = Snodes[j].parent);
    return j;
} // find_mfset
```

# 算法 6.8

```c
Status merge_mfset(MFSet &S, int i, int j) {
// Snodes[i]和Snodes[j]分别为S的互不相交的两个子集Si和Sj的根结点。
// 求并集Si∪Sj。
if (i<1 || i>S.n || j<1 || j>S.n) return ERROR;
Snodes[i].parent = j;
return OK;
} // merge_mfset
```

# 算法 6.9

算法6.8和算法6.9的时间复杂度分别为  $O(d)$  和  $O(1)$ ，其中  $d$  是树的深度。从前面的讨论可知，这种表示集合的树的深度和树形成的过程有关。试看一个极端的例子。假设有  $n$  个子集  $S_{1}, S_{2}, \cdots, S_{n}$ ，每个子集只有一个成员  $S_{i} = \{i\} (i = 1, 2, \cdots, n)$ ，可用  $n$  棵只有一个根结点的树表示，如图6.19(a)表示。现作  $n - 1$  次“并”操作，并假设每次都是含成员多的根结点指向含成员少的根结点，则最后得到的集合树的深度为  $n$ ，如图6.19(b)所示。如果再加上在每次“并”操作之后都要进行查找成员“1”所在子集的操作，则全部操作的时间便是  $O(n^{2})$  了。

改进的办法是在作“并”操作之前先判别子集中所含成员的数目，然后令含成员少的子集树根结点指向含成员多的子集的根。为此，需相应地修改存储结构：令根结点的parent域存储子集中所含成员数目的负值。修改后的“并”操作算法如算法6.10所示。

```c
void mix_mfset(MFSet& S, int i, int j) {
// Snodes[i]和Snodes[j]分别为S的互不相交
// 的两个子集Si和Sj的根结点。求并集Si∪Sj
if (i<1 || i>S.n || j<1 || j>S.n)
return ERROR;
if (Snodes[i].parent>Snodes[j].parent) {
// Si所含成员数比Sj少
Snodes[j].parent += Snodes[i].parent;
Snodes[i].parent = j;
}else {
Snodes[i].parent += Snodes[j].parent;
Snodes[j].parent = i;
}
return OK;
} // mix_mfset
```

![](images/6b4433f4dc945c911ccd9548c986adb5ede255aac87fc686e5f0cd7cc95b94c6.jpg)  
图6.19“并”操作的一种极端情形（a）n个集合；（b）“并”操作

# 算法 6.10

可以证明，按算法6.10进行“并”操作得到的集合树，其深度不超过  $\lfloor \log_2n\rfloor +1$  ，其中  $n$  为集合  $S$  中所有子集所含成员数的总和。

由此，利用算法 find_mfset 和 mix_mfset 解等价问题的时间复杂度为  $O(n \log_2 n)$ （当集合中有  $n$  个元素时，至多进行  $n - 1$  次 mix 操作）。

例6-1 假设集合  $S = \{x \mid 1 \leqslant x \leqslant n$  是正整数\},  $R$  是  $S$  上的一个等价关系。

$$
R = \{(1, 2), (3, 4), (5, 6), (7, 8), (1, 3), (5, 7), (1, 5), \dots \}
$$

现求  $S$  的等价类。

以 MFSet 类型的变量 S 表示集合 S, S 中成员个数为 S.n。开始时, 由于每个成员自成一个等价类, 则 S.nodes[i].parent 的值均为 -1。之后, 每处理一个等价偶对  $(i, j)$ , 首先必须确定  $i$  和  $j$  各自所属集合, 若这两个集合相同, 则说明此等价关系是多余的, 无需作处理; 否则就合并这两个集合。图 6.20 展示了处理 R 中前 7 个等价关系时 S 的变化状况 (图中省去了结点的数据域), 图 6.21(a) 所示为和最后一个 S 状态相应的树的形态。显然, 随着子集逐对合并, 树的深度也越来越大, 为了进一步减少确定元素所在集合的时间, 我们还可进一步将算法 6.8 改进为算法 6.11。当所查元素  $i$  不在树的第二层时, 在算法中增加一个“压缩路径”的功能, 即将所有从根到元素  $i$  路径上的元素都变成树根的孩子。

![](images/0e6c9418acf66fa75e5519cb47c1d2a08e1ea0913908cf3dc5b8441f66e8e7e7.jpg)  
图6.20 求等价类过程示例

图6.21 表示集合的树  
![](images/e2b3e994fb402e07482b5cd36515cf65d2da5d5a5c41d4443b6c7144029925b7.jpg)  
(a) 压缩路径之前；(b) 压缩路径之后

```c
int fix_mfset(MFSet &S, int i) {
// 确定 i 所在子集，并将从 i 至根路径上所有结点都变成根的孩子结点。
if (i < 1 || i > S.n) return -1; // i 不是 S 中任一子集的成员
for (j = i; Snodes[j].parent > 0; j = Snodes[j].parent);
for (k = i; k != j; k = t) {
    t = Snodes[k].parent; Snodes[k].parent = j;
}
return j;
} // fix_mfset
```

# 算法 6.11

假设例6-1中  $R$  的第8个等价偶对为(8,9)，则在执行  $\mathrm{fix}(s,8)$  的操作之后图6.21(a)的树就变成图6.21(b)的树。

已经证明，利用算法  $\operatorname{fix}$ 、 $\operatorname{mfset}$  和  $\operatorname{mix}$ 、 $\operatorname{mfset}$  划分大小为  $n$  的集合为等价类的时间复杂度为  $O(n\alpha(n))^{[6]}$ 。其中  $\alpha(n)$  是一个增长极其缓慢的函数，若定义单变量的阿克曼函数为  $A(x) = A(x, x)$ ，则函数  $\alpha(n)$  定义为  $A(x)$  的拟逆，即  $\alpha(n)$  的值是使  $\dot{A}(x) \geqslant n$  成立的最小  $x$ 。所以，对于通常所见到的正整数  $n$  而言， $\alpha(n) \leqslant 4$ 。

# 6.6 赫夫曼树及其应用

赫夫曼(Huffman)树, 又称最优树, 是一类带权路径长度最短的树, 有着广泛的应用。本节先讨论最优二叉树。

# 6.6.1 最优二叉树(赫夫曼树)

首先给出路径和路径长度的概念。从树中一个结点到另一个结点之间的分支构成这两个结点之间的路径，路径上的分支数目称做路径长度。树的路径长度是从树根到每一结点的路径长度之和。6.2.1节中定义的完全二叉树就是这种路径长度最短的二叉树。

若将上述概念推广到一般情况，考虑带权的结点。结点的带权路径长度为从该结点到树根之间的路径长度与结点上权的乘积。树的带权路径长度为树中所有叶子结点的带权路径长度之和，通常记作  $WPL = \sum_{k=1}^{n} w_k l_k$ 。

假设有  $n$  个权值  $\{w_{1}, w_{2}, \dots, w_{n}\}$ , 试构造一棵有  $n$  个叶子结点的二叉树, 每个叶子结点带权为  $\omega_{i}$ , 则其中带权路径长度 WPL 最小的二叉树称做最优二叉树或赫夫曼树。

例如, 图 6.22 中的 3 棵二叉树, 都有 4 个叶子结点 a、b、c、d, 分别带权 7、5、2、4, 它们的带权路径长度分别为

(a)  $WPL = 7 \times 2 + 5 \times 2 + 2 \times 2 + 4 \times 2 = 36$  
(b)  $WPL = 7 \times 3 + 5 \times 3 + 2 \times 1 + 4 \times 2 = 46$  
(c)  $WPL = 7 \times 1 + 5 \times 2 + 2 \times 3 + 4 \times 3 = 35$

其中以(c)树的为最小。可以验证，它恰为赫夫曼树，即其带权路径长度在所有带权为7、5、2、1的4个叶子结点的二叉树中居最小。

![](images/9ab45d9ff378c9c772d58576678f11ecce3fc9f42724e8444eff9fcd4ad996cb.jpg)  
(a)

![](images/851f6a7bce9af25d598dab46ce030361d20ef00abd3ecbc63433acf344273d80.jpg)  
(b)

![](images/9bc2cc954e7c9b7f417f6835852efdf571d6e176235a4511582a77c049436d5e.jpg)  
(c)  
图6.22 具有不同带权路径长度的二叉树

在解某些判定问题时，利用赫夫曼树可以得到最佳判定算法。例如，要编制一个将百分制转换成五级分制的程序。显然，此程序很简单，只要利用条件语句便可完成。如：

```txt
if  $(a <   60)$ $b =$  "bad";   
else if  $(a <   70)$ $b =$  "pass"; else if  $(a <   80)$ $b =$  "general"; else if  $(a <   90)$ $b =$  "good"; else  $b =$  "excellent";
```

这个判定过程可以图6.23(a)的判定树来表示。如果上述程序需反复使用，而且每次的输入量很大，则应考虑上述程序的质量问题，即其操作所需时间。因为在实际生活中，学生的成绩在5个等级上的分布是不均匀的。假设其分布规律如下表所示：

<table><tr><td>分数</td><td>0-59</td><td>60-69</td><td>70-79</td><td>80-89</td><td>90-100</td></tr><tr><td>比例数</td><td>0.05</td><td>0.15</td><td>0.40</td><td>0.30</td><td>0.10</td></tr></table>

则  $80\%$  以上的数据需进行3次或3次以上的比较才能得出结果。假定以5,15,40,30和10为权构造一棵有5个叶子结点的赫夫曼树，则可得到如图6.23(b)所示的判定过程，它可使大部分的数据经过较少的比较次数得出结果。但由于每个判定框都有两次比较，将这两次比较分开，我们得到如图6.23(c)所示的判定树，按此判定树可写出相应的程序。假设现有10000个输入数据，若按图6.23(a)的判定过程进行操作，则总共需进行31500次比较；而若按图6.23(c)的判定过程进行操作，则总共仅需进行22000次比较。

![](images/03bd52f559df12193932f5a7438d5ced5abf2b64dbd08301fb76e4872455d540.jpg)  
(a)

![](images/1d21fb1d4101c2d7bcf09552d891c258ed434ac6c8a4fd75b495cc134f4f5c1d.jpg)  
(b)

![](images/dfb927bcce403fa46b90d488a6a7d70cc399183a453d442eb0f465413037d658.jpg)  
(c)  
图6.23 转换五级分制的判定过程

那么，如何构造赫夫曼树呢？赫夫曼最早给出了一个带有一般规律的算法，俗称赫夫曼算法。现叙述如下：

（1）根据给定的  $n$  个权值  $\{w_{1}, w_{2}, \dots, w_{n}\}$  构成  $n$  棵二叉树的集合  $F = \{T_{1}, T_{2}, \dots, T_{n}\}$ ，其中每棵二叉树  $T_{i}$  中只有一个带权为  $w_{i}$  的根结点，其左右子树均空。  
（2）在  $F$  中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树，且置新的二叉树的根结点的权值为其左、右子树上根结点的权值之和。  
（3）在  $F$  中删除这两棵树，同时将新得到的二叉树加入  $F$  中。  
（1）重复(2)和(3)，直到  $F$  只含一棵树为止。这棵树便是赫夫曼树。

例如, 图 6.24 展示了图 6.22(c) 的赫夫曼树的构造过程。其中, 根结点上标注的数字是所赋的权。

![](images/0d0f19d39a2c903b4bf1652c31ddee2cbd874dda4bc8268a17bf74e5b1701527.jpg)

算法的具体描述和实际问题所采用的存储结构有关，将留在下节进行讨论。

![](images/b65a2224c607b0c32307d07713f978c9cb0bcf5310328fcca8a76a1c1689a697.jpg)  
图6.24 赫夫曼树的构造过程

# 6.6.2 赫夫曼编码

目前，进行快速远距离通信的主要手段是电报，即将需传送的文字转换成由二进制的字符组成的字符串。例如，假设需传送的电文为'A B A C C D A'，它只有4种字符，只需两个字符的串便可分辨。假设A、B、C、D的编码分别为00、01、10和11，则上述7个字符的电文便为‘00010010101100'，总长14位，对方接收时，可按二位一分进行译码。

当然，在传送电文时，希望总长尽可能地短。

如果对每个字符设计长度不等的编码，且让电文中出现次数较多的字符采用尽可能短的编码，则传送电文的总长便可减少。如果设计A、B、C、D的编码分别为0、00、1和01，则上述7个字符的电文可转换成总长为9的字符串'000011010'。但是，这样的电文无法翻译，例如传送过去的字符串中前4个字符的子串'0000'就可有多种译法，或是'AAAA'，或是'ABA'，也可以是'BB'等。因此，若要设计长短不等的编码，则必须是任一个字符的编码都不是另一个字符的编码的前缀，这种编码称做前缀编码。

可以利用二叉树来设计二进制的前缀编码。假设有一棵如图6.25所示的二叉树，其4个叶子结点分别表示A、B、C、D这4个字符，且约定左分支表示字符  $0'$ ，右分支表示字符  $1'$ ，则可以从根结点到叶子结点的路径上分支字符组成的字符串作为该叶子结点字符的编码。读者可以证明，如此得到的必为二进制前缀编码。如由图6.25所得A、B、C、D的二进制前缀编码分别为0、10、110和111。

又如何得到使电文总长最短的二进制前缀编码呢？假设每种字符在电文中出现的次数为  $w_{i}$ ，其编码长度为  $l_{i}$ ，电文中只有  $n$  种字符，则电文总长为  $\sum_{i=1}^{n} w_{i} l_{i}$ 。对应到二叉树上，若置  $w_{i}$  为叶子结点的权， $l_{i}$  恰为从根到叶子的路径长度。则  $\sum_{i=1}^{n} w_{i} l_{i}$  恰为二叉树上带权路径长度。由此可见，设计电文总长最短的二进制前缀编码即为以  $n$  种字符出现的频率作权，设计一棵赫夫曼树的问题，由此得到的二进制前缀编码便称为赫夫曼编码。

![](images/f3755034db75fd57cc76c0239b4f96ca31ca6f34f2e0b4b9a73a8da800f4633a.jpg)  
图6.25 前缀编码示例

下面讨论具体做法。

由于赫夫曼树中没有度为1的结点(这类树又称严格的(strict)(或正则的)二叉树),

则一棵有  $n$  个叶子结点的赫夫曼树共有  $2n - 1$  个结点，可以存储在一个大小为  $2n - 1$  的一维数组中。如何选定结点结构？由于在构成赫夫曼树之后，为求编码需从叶子结点出发走一条从叶子到根的路径；而为译码需从根出发走一条从根到叶子的路径。则对每个结点而言，既需知双亲的信息，又需知孩子结点的信息。由此，设定下述存储结构：

```c
// -- -- -- 赫夫曼树和赫夫曼编码的存储表示 -- -- -- typedef struct {
    unsigned int weight;
    unsigned int parent, lchild, rchild;
} HTNode, *HuffmanTree; // 动态分配数组存储赫夫曼树 typedef char * * HuffmanCode; // 动态分配数组存储赫夫曼编码表
```

求赫夫曼编码的算法如算法6.12所示。

```javascript
void HuffmanCoding(HuffmanTree&HT,HuffmanCode&HC,int \*w,int n){//w存放n个字符的权值(均  $\geq 0$  )，构造赫夫曼树HT，并求出n个字符的赫夫曼编码HC。if  $(\mathrm{n} <   = 1)$  return;m  $= 2\ast \mathrm{n} - 1$  HT=(HuffmanTree)malloc((m+1）\*sizeof（HTNode)); //0号单元未用for  $(p = HT,i = 1;i <   = n; + + i, + + p, + + w)$ $\text{中}\mathfrak{p} = \{\text{水水},0,0,0\}$  for  $(i;i <   = m;i + + p)$ $\text{中}\mathfrak{p} = \{0,0,0,0\}$  for  $(i = n + 1;i <   = m;i + + i)$  { //建赫夫曼树//在HT[1..i-1]选择parent为0且weight最小的两个结点，其序号分别为sl和s2。Select(HT,i-1,s1,s2);HT[s1].parent  $=$  i；HT[s2].parent  $=$  i;HT[i].lchild  $=$  s1;HT[i].rchild  $=$  s2;HT[i].weight  $=$  HT[s1].weight  $^+$  HT[s2].weight;1//---从叶子到根逆向求每个字符的赫夫曼编码---HC  $=$  (HuffmanCode)malloc((n+1)*sizeof(char \*)）；//分配n个字符编码的头指针向量cd  $=$  (char \*)malloc(n\*sizeof(char)); //分配求编码的工作空间cd[n-1]  $\equiv$  "\0"; //编码结束符。for(i=1;i<=n;i){ //逐个字符求赫夫曼编码start  $= \mathrm{n - 1}$  //编码结束符位置for(c=i,f=HT[i].parent;f!  $= 0$  ;c=f,f=HT[f].parent）//从叶子到根逆向求编码if(HT[f].lchild  $= = c$  cd--start  $\equiv$  "0";elsecd--start  $\equiv$  "1";HC[i]  $=$  (char \*)malloc((n-start)\*sizeof(char));//为第i个字符编码分配空间strcpy(HC[i],&cd[ start]); //从cd复制编码(串)到HC}free(cd); //释放工作空间}//HuffmanCoding
```

# 算法 6.12

向量  $HT$  的前  $\pmb{n}$  个分量表示叶子结点，最后一个分量表示根结点。各字符的编码长度不

等, 所以按实际长度动态分配空间。在算法 6.12 中, 求每个字符的赫夫曼编码是从叶子到根逆向处理的。也可以从根出发, 遍历整棵赫夫曼树, 求得各个叶子结点所表示的字符的赫夫曼编码, 如算法 6.13 所示。

```c
// -- -- -- -- 无栈非递归遍历赫夫曼树，求赫夫曼编码  
HC = (HuffmanCode)malloc((n+1) * sizeof(char *));  
p = m; cdlen = 0;  
for (i=1; i<=m; ++i) HT[i].weight = 0; // 遍历赫夫曼树时用作结点状态标志  
while (p) {  
    if (HT[p].weight == 0) { // 向左  
        HT[p].weight = 1;  
    if (HT[p].lchild != 0) { p = HT[p].lchild; cd[cdlen++] = "0"; }  
    else if (HT[p].rchild == 0) { // 登记叶子结点的字符的编码  
        HC[p] = (char *)malloc((cdlen+1) * sizeof(char));  
        cd[cdlen] = "\0"; strcpy(HC[p], cd); // 复制编码(串)  
    }  
}  
else if (HT[p].weight == 1) { // 向右  
        HT[p].weight = 2;  
    if (HT[p].rchild != 0) { p = HT[p].rchild; cd[cdlen++] = "1"; }  
} else { // HT[p].weight == 2, 返回  
    HT[p].weight = 0; p = HT[p].parent; --cdlen; // 退到父结点，编码长度减1  
}; // else  
} // While
```

# 算法 6.13

译码的过程是分解电文中字符串, 从根出发, 按字符 '0' 或 '1' 确定找左孩子或右孩子, 直至叶子结点, 便求得该子串相应的字符。具体算法留给读者去完成。

例6-2 已知某系统在通信联络中只可能出现8种字符，其概率分别为0.05,0.29,0.07,0.08,0.14,0.23,0.03,0.11，试设计赫夫曼编码。

设权  $w = (5,29,7,8,14,23,3,11), n = 8$ ，则  $m = 15$ ，按上述算法可构造一棵赫夫曼树如图6.26所示。其存储结构HT的初始状态如图6.27(a)所示，其终结状态如图6.27(b)所示，所得赫夫曼编码如图6.27(c)所示。

![](images/9531545dbb1dc42376c99c9a44143d6e31ee62e767e0ef5b4cf7b50e99c32388.jpg)  
图6.26 例6-2的赫夫曼树

![](images/9cdcbac08a62572b32a5c6e21e4bd8accc52fddff5c5fa6833fdaf1fd8772df2.jpg)  
(a)

![](images/3b4fd394a1494a738bdc175909fa13cd8d7a603f1936d7a176783043864d55dd.jpg)  
(b)

![](images/ec9a0a30fa1fa993c1d19e10469579ca21a82cb8dcd64adc83c18dcbf9d93399.jpg)  
(c)  
图6.27 例6-2的存储结构

(a) HT 的初态；  
(b) HT 的终态；  
（c）赫夫曼编码HC

# 6.7 回溯法与树的遍历

在程序设计中, 有相当一类求一组解、或求全部解或求最优解的问题. 例如读者熟悉的八皇后问题等, 不是根据某种确定的计算法则, 而是利用试探和回溯(Backtracking)的搜索技术求解。回溯法也是设计递归过程的一种重要方法, 它的求解过程实质上是一个先序遍历一棵“状态树”的过程, 只是这棵树不是遍历前预先建立的, 而是隐含在遍历过程中, 但如果认识到这点, 很多问题的递归过程设计也就迎刃而解了。为了说明问题, 先看一个简单例子。

例6-3 求含  $n$  个元素的集合的幂集。

集合  $A$  的幂集是由集合  $A$  的所有子集所组成的集合。如： $A = \{1, 2, 3\}$ ，则  $A$  的幂集

$$
\rho (A) = \{\{1, 2, 3 \}, \{1, 2 \}, \{1, 3 \}, \{1 \}, \{2, 3 \}, \{2 \}, \{3 \}, \Phi \} \tag {6-6}
$$

当然，可以用5.7节介绍的分治法来设计这个求幂集的递归过程。在此，从另一角度分析问题。幂集的每个元素是一个集合，它或是空集，或含集合  $A$  中一个元素，或含集合  $A$  中两个元素，或等于集合  $A$  。反之，从集合  $A$  的每个元素来看，它只有两种状态：它或属幂集的元素集，或不属幂集元素集。则求幂集  $\rho(A)$  的元素的过程可看成是依次对集合

$A$  中元素进行“取”或“舍(弃)”的过程，并且可以用一棵如图6.28所示的二叉树，来表示

![](images/aecfee1e2aa5671e38097091d79af9f1dd9067ff3325f25e783d18b18ac4066c.jpg)  
图6.28 幂集元素在生成过程中的状态图

过程中幂集元素的状态变化状况，树中的根结点表示幂集元素的初始状态（为空集）；叶子结点表示它的终结状态（如图6.28中8个叶子结点表示式(6-6)中幂集  $\rho(A)$  的8个元素）；而第  $i (i = 2,3,\dots,n-1)$  层的分支结点，则表示已对集合  $A$  中前  $i-1$  个元素进行了取/舍处理的当前状态（左分支表示“取”，右分支表示“舍”）。因此求幂集元素的过程即为先序遍历这棵状态树的过程，如算法6.14所描述。

```javascript
voidPowerSet(inti,intn){//求含  $\mathbf{n}$  个元素的集合A的幂集P(A)。进入函数时已对A中前i-1个元素作了取舍处理，//现从第i个元素起进行取舍处理。若  $\mathrm{i} > \mathrm{n}$  ，则求得幂集的一个元素，并输出之。//初始调用：PowerSet(1，n);if（i>n）输出募集的一个元素；else{取第i个元素；PowerSet(i+1，n);舍第i个元素；PowerSet(i+1，n);1}//PowerSet
```

# 算法 6.14

对算法6.14求精需确定数据结构。假设以线性表表示集合，则求精后的算法如算法6.15所示。

```txt
void GetPowerSet(int i, List A, List &B) {
    // 线性表A表示集合A,线性表B表示幂集P(A)的一个元素。
    // 局部量k为进入函数时表B的当前长度。第一次调用本函数时,B为空表,i=1。
    if (i>ListLength(A)) Output(B); // 输出当前B值,即P(A)的一个元素
    else {GetElem(A, i, x); k = ListLength(B); 
        ListInsert(B, k+1, x); GetPowerSet(i+1, A, B); 
        ListDelete(B, k+1, x); GetPowerSet(i+1, A, B); }
```

# 算法 6.15

图6.28中的状态变化树是一棵满二叉树，树中每个叶子结点的状态都是求解过程中

可能出现的状态（即问题的解）。然而很多问题用回溯和试探求解时，描述求解过程的状态树不是一棵满的多叉树。当试探过程中出现的状态和问题所求解产生矛盾时，不再继续试探下去，这时出现的叶子结点不是问题的解的终结状态。这类问题的求解过程可看成是在约束条件下进行先序(根)遍历，并在遍历过程中剪去那些不满足条件的分支。

例6-4 求4皇后问题的所有合法布局（作为例子，我们将8皇后问题简化为4皇后问题）。

图6.29展示求解过程中棋盘状态的变化情况。这是一棵四叉树，树上每个结点表示

![](images/c90b7847eee18274aaa58c8f0241efd7ac9fecc5db3d337ab70e177ac09464a9.jpg)  
图6.29 四皇后问题的棋盘状态树

一个局部布局或一个完整的布局。根结点表示棋盘的初始状态：棋盘上无任何棋子。每个(皇后)棋子都有4个可选择的位置，但在任何时刻，棋盘的合法布局都必须满足3个约束条件，即任何两个棋子都不占据棋盘上的同一行、或者同一列、或者同一对角线。图6.29中除结点a之外的叶子结点都是不合法的布局。

求所有合法布局的过程即为在上述约束条件下先根遍历图6.29的状态树的过程。遍历中访问结点的操作为，判别棋盘上是否已得到一个完整的布局（即棋盘上是否已摆上4个棋子），若是，则输出该布局；否则依次先根遍历满足约束条件的各棵子树，即首先判断该子树根的布局是否合法，若合法，则先根遍历该子树，否则剪去该子树分支。算法6.16为求所有合法布局的伪码算法：

void Trial(int i, int n) {

// 进入本函数时，在  $n \times n$  棋盘前  $i - 1$  行已放置了互不攻击①的  $i - 1$  个棋子。  
// 现从第  $i$  行起继续为后续棋子选择合适①位置。  
//当  $\mathrm{i} > \mathrm{n}$  时，求得一个合法布局，输出之。

if  $(i > n)$  输出棋盘的当前布局； //  $n$  为4时，即为4皇后问题

else for  $(j = 1; j <= n; ++j)$  {

在第i行第j列放置一个棋子；

if（当前布局合法）Trial(i+1，n);

```txt
移走第i行第j列的棋子；}}//Trial
```

# 算法 6.16

算法6.16可进一步求精，在此从略。算法6.16可作为回溯法求解的一般模式，类似问题有骑士游历、迷宫问题、选最优解问题等等。

# 6.8 树的计数

本节将讨论的树的计数问题的提法是：具有  $n$  个结点的不同形态的树有多少棵？下面我们先讨论二叉树的情况，然后可将结果推广到树。

在讨论二叉树的计数之前应先明确两个不同的概念。

称二叉树  $T$  和  $T'$  相似是指：二者都为空树或者二者均不为空树，且它们的左右子树分别相似。

称二叉树  $T$  和  $T^{\prime}$  等价是指：二者不仅相似，而且所有对应结点上的数据元素均相同。

二叉树的计数问题就是讨论具有  $n$  个结点、互不相似的二叉树的数目  $b_{n}$  。

在  $n$  值很小的情况下，可直观地得到： $b_{0} = 1$  为空树； $b_{1} = 1$  是只有一个根结点的树； $b_{2} = 2$  和  $b_{3} = 5$ ，它们的形态分别如图6.30(a)和图6.30(b)所示。那么，在  $\eta > 3$  时又如何呢？

图6.30 二叉树的形态  
![](images/eee6fdf8c630d620bec0e31bb7c7471bd6ac864f08a86c9c011c561ce8d692fc.jpg)  
(a)  $n = 2$ ；(b)  $n = 3$ ；(c) 一般情形  $n > 1$

![](images/993937a9cc8084354ec26b660a39d2c5988c5e3ca658d777c6b821e387e520d0.jpg)

![](images/7356f1c1881b40ee4818748c487248941b56f3e30cbbc06e7fa04a3bf3dac22f.jpg)

一般情况下，一棵具有  $n(n > 1)$  个结点的二叉树可以看成是由一个根结点、一棵具有  $i$  个结点的左子树和一棵具有  $n - i - 1$  个结点的右子树组成（如图6.30(c)所示），其中  $0 \leqslant i \leqslant n - 1$ 。由此可得下列递推公式：

$$
\left\{ \begin{array}{l} b _ {0} = 1 \\ b _ {n} = \sum_ {i = 0} ^ {n - 1} b _ {i} b _ {n - i - 1}, \quad n \geqslant 1 \end{array} \right. \tag {6-7}
$$

可以利用生成函数来讨论这个递推公式。

对序列

$$
b _ {0}, b _ {1}, \dots , b _ {n} \dots
$$

定义生成函数

$$
\begin{array}{l} B (z) = b _ {0} + b _ {1} z + b _ {2} z ^ {2} + \dots + b _ {n} z ^ {n} + \dots \\ = \sum_ {k = 0} ^ {\infty} b _ {k} z ^ {k} \tag {6-8} \\ \end{array}
$$

因为

$$
\begin{array}{l} B ^ {2} (z) = b _ {0} b _ {0} + \left(b _ {0} b _ {1} + b _ {1} b _ {0}\right) z + \left(b _ {0} b _ {2} + b _ {1} b _ {1} + b _ {2} b _ {0}\right) z ^ {2} + \dots \\ = \sum_ {p = 0} ^ {\infty} \left(\sum_ {i = 0} ^ {p} b _ {i} b _ {p - i}\right) z ^ {p} \\ \end{array}
$$

根据（6-7）

$$
B ^ {2} (z) = \sum_ {p = 0} ^ {\infty} b _ {p + 1} z ^ {p} \tag {6-9}
$$

由此得

$$
z B ^ {2} (z) = B (z) - 1
$$

即

$$
z B ^ {2} (z) - B (z) + 1 = 0
$$

解此二次方程得

$$
B (z) = \frac {1 \pm \sqrt {1 - 4 z}}{2 z}
$$

由初值  $b_{0} = 1$  ，应有  $\lim_{z\to 0}B(z) = b_0 = 1$

所以

$$
B (z) = \frac {1 - \sqrt {1 - 4 z}}{2 z}
$$

利用二项式展开

$$
(1 - 4 z) ^ {\frac {1}{2}} = \sum_ {k = 0} ^ {\infty} \binom {\frac {1}{2}} {k} (- 4 z) ^ {k} \tag {6-10}
$$

当  $k = 0$  时，式(6-10)的第一项为1，故有

$$
\begin{array}{l} B (z) = \frac {1}{2} \sum_ {k = 1} ^ {\infty} \left( \begin{array}{c} \frac {1}{2} \\ k \end{array} \right) (- 1) ^ {k - 1} 2 ^ {2 k} z ^ {k - 1} \\ = \sum_ {m = 0} ^ {\infty} \left( \begin{array}{l} \frac {1}{2} \\ m + 1 \end{array} \right) (- 1) ^ {m} 2 ^ {2 m + 1} z ^ {m} \\ = 1 + z + 2 z ^ {2} + 5 z ^ {3} + 1 4 z ^ {4} + 4 2 z ^ {5} + \dots \tag {6-11} \\ \end{array}
$$

对照(6-8)和(6-11)而得

$$
\begin{array}{l} b _ {n} = \left( \begin{array}{c} \frac {1}{2} \\ n + 1 \end{array} \right) (- 1) ^ {n} 2 ^ {2 n + 1} \\ = \frac {\frac {1}{2} \left(\frac {1}{2} - 1\right) \left(\frac {1}{2} - 2\right) \cdots \left(\frac {1}{2} - n\right)}{(n + 1) !} (- 1) ^ {n} 2 ^ {2 n + 1} \\ \end{array}
$$

$$
b _ {n} = \frac {1}{n + 1} \cdot \frac {(2 n) !}{n ! n !} = \frac {1}{n + 1} C _ {2 n} ^ {n} \tag {6-12}
$$

因此，含有  $n$  个结点的不相似的二叉树有  $\frac{1}{n + 1} C_{2n}^{n}$  棵。

我们还可以从另一个角度来讨论这个问题。从二叉树的遍历已经知道，任意一棵二叉树结点的前序序列和中序序列是惟一的。反过来，给定结点的前序序列和中序序列，能否确定一棵二叉树呢？又是否惟一呢？

由定义, 二叉树的前序遍历是先访问根结点 D, 其次遍历左子树 L, 最后遍历右子树 R。即在结点的前序序列中, 第一个结点必是根 D; 而另一方面, 由于中序遍历是先遍历左子树 L, 然后访问根 D, 最后遍历右子树 R, 则根结点 D 将中序序列分割成两部分: 在 D 之前是左子树结点的中序序列, 在 D 之后是右子树结点的中序序列。反过来, 根据左子树的中序序列中结点个数, 又可将前序序列除根以外分成左子树的前序序列和右子树的前序序列两部分。依次类推, 便可递归得到整棵二叉树。

例6-5 已知结点的前序序列和中序序列分别为：

前序序列：ABCDEFG

中序序列：CBEDAFG

则可按上述分解求得整棵二叉树。其构造过程如图6.31所示。首先由前序序列得知二

![](images/1138acf652c7a4d1c0ffe743bb2250d629edbbd5a09ee1ef160a2da15c7246e4.jpg)  
(a)

![](images/f19afac4c5f0df3645bdab049c2c940233e96c6b7908f71187687db3b16db9eb.jpg)  
(b)

![](images/ba2ad64619951a7a921209f996716f6a8238ee6fcc93af91b40a16c3cb0e4f36.jpg)  
(c)

![](images/04375e4ab299c8222138e306fa527366e39d5ee0ad26ccee3ce09d2cfdad7893.jpg)  
(d)  
图6.31 由前序和中序序列构造一棵二叉树的过程

叉树的根为A，则其左子树的中序序列为(CBED)，右子树的中序序列为(FG)。反过来得

知其左子树的前序序列必为（BCDE），右子树的前序序列为(FG)。类似地，可由左子树的前序序列和中序序列构造得A的左子树，由右子树的前序序列和中序序列构造得A的右子树。

上述构造过程说明了给定结点的前序序列和中序序列，可确定一棵二叉树。至于它的惟一性，读者可试用归纳法证明之。

我们可由此结论来推论具有  $n$  个结点的不同形态的二叉树的数目。

![](images/bc1701251ed1023cb4177f9b2651d7e3c5a89d6f1d3dbd4a31af5cb9073febf7.jpg)  
图6.32 具有不同中序序列的二叉树

假设对二叉树的  $n$  个结点从1到  $n$  加以编号，且令其前序序列为  $1,2,\dots ,n$  ，则由前面的讨论可知，不同的二叉树所得中序序列不同。如图6.32所示两棵有8个结点的二叉树，它们的前序序列都是12345678，而(a)树的中序序列为32465178，(b)树的中序序列为

![](images/ade22c8d03d365427be142c3665fa103f904093531910e7407528ef856646c64.jpg)  
图6.33 中序遍历时进栈和出栈的过程

23147685。因此，不同形态的二叉树的数目恰好是前序序列均为  $12 \cdots n$  的二叉树所能得到的中序序列的数目。而中序遍历的过程实质上是一个结点进栈和出栈的过程。二叉树的形态确定了其结点进栈和出栈的顺序，也确定了其结点的中序序列。例如图6.33中所示为  $n = 3$  时不同形态的二叉树在中序遍历时栈的状态和访问结点次序的关系。由此，由前序序列  $12 \cdots n$  所能得到的中序序列的数目恰为数列  $12 \cdots n$  按不同顺序进栈和出栈所能

![](images/edebbc224c095fbfe1c400f263d9c0d4c354f830babe06e33e3c23371bebf8d5.jpg)  
图6.34 具有不同形态的树和二叉树

得到的排列的数目。这个数目为①

$$
C _ {2 n} ^ {n} - C _ {2 n} ^ {n - 1} = \frac {1}{n + 1} C _ {2 n} ^ {n} \tag {6-13}
$$

由二叉树的计数可推得树的计数。由“6.4.2森林与二叉树的转换”中可知一棵树可转换成惟一的一棵没有右子树的二叉树，反之亦然。则具有  $n$  个结点有不同形态的树的数目  $t_n$  和具有  $n - 1$  个结点互不相似的二叉树的数目相同。即  $t_n = b_{n - 1}$  。图6.34展示了具有4个

结点的树和具有3个结点的二叉树的关系。从图中可见，在此讨论树的计数是指有序树，因此(c)和(d)是两棵有不同形态的树(在无序树中，它们被认为是相同的)。

# 第7章图

图(Graph)是一种较线性表和树更为复杂的数据结构。在线性表中，数据元素之间仅有线性关系，每个数据元素只有一个直接前驱和一个直接后继；在树形结构中，数据元素之间有着明显的层次关系，并且每一层上的数据元素可能和下一层中多个元素（即其孩子结点）相关，但只能和上一层中一个元素（即其双亲结点）相关；而在图形结构中，结点之间的关系可以是任意的，图中任意两个数据元素之间都可能相关。由此，图的应用极为广泛，特别是近年来的迅速发展，已渗入到诸如语言学、逻辑学、物理、化学、电讯工程、计算机科学以及数学的其他分支中。

读者在“离散数学”课程中已学习了图的理论，在此仅应用图论的知识讨论如何在计算机上实现图的操作，因此主要学习图的存储结构以及若干图的操作的实现。

# 7.1 图的定义和术语

图是一种数据结构，加上一组基本操作，就构成了抽象数据类型。抽象数据类型图的定义如下：

```txt
ADT Graph {
```

数据对象  $\mathbf{V}:\mathbf{V}$  是具有相同特性的数据元素的集合，称为顶点集。

```txt
数据关系R：
```

```txt
$\mathbf{R} = \{\mathbf{V}\mathbf{R}\}$ $\mathrm{VR} = \{<  v,w > |v,w\in V$  且  $P(v,w), <   v,w>$  表示从  $\pmb{\nu}$  到  $\pmb{\omega}$  的弧，谓词  $\mathbb{P}(\mathbf{v},\mathbf{w})$  定义了弧  $<  v,w>$  的意义或信息
```

```txt
基本操作P：
```

```txt
CreateGraph(&G,V,VR);  
初始条件：V是图的顶点集，VR是图中弧的集合。  
操作结果：按V和VR的定义构造图G。  
DestroyGraph(&G);  
初始条件：图G存在。  
操作结果：销毁图G。  
LocateVex(G,u);  
初始条件：图G存在，u和G中顶点有相同特征。  
操作结果：若G中存在顶点u，则返回该顶点在图中位置；否则返回其他信息。  
GetVex(G,v);  
初始条件：图G存在，v是G中某个顶点。  
操作结果：返回v的值。  
PutVex(&G,v=value);  
初始条件：图G存在，v是G中某个顶点。  
操作结果：对v赋值value。
```

FirstAdjVex(G, v);

初始条件：图  $\mathbf{G}$  存在，  $\mathbf{v}$  是  $\mathbf{G}$  中某个顶点。

操作结果：返回  $\mathbf{v}$  的第一个邻接顶点。若顶点在G中没有邻接顶点，则返回“空”。

NextAdjVex(G, v, w);

初始条件：图G存在，  $\mathbf{v}$  是G中某个顶点，  $\mathbf{w}$  是  $\mathbf{v}$  的邻接顶点。

操作结果：返回  $\mathbf{v}$  的（相对于  $\mathbf{w}$  的）下一个邻接顶点。若  $\mathbf{w}$  是  $\mathbf{v}$  的最后一个邻接点，则返回“空”。

InsertVex(&G, v);

初始条件：图G存在，  $\mathbf{v}$  和图中顶点有相同特征。

操作结果：在图G中增添新顶点  $\mathbf{v}$ 。

DeleteVex(&G, v);

初始条件：图  $\mathbf{G}$  存在，  $\mathbf{v}$  是  $\mathbf{G}$  中某个顶点。

操作结果：删除G中顶点  $\mathbf{v}$  及其相关的弧。

InsertArc(&G, v, w);

初始条件：图G存在，  $\mathbf{v}$  和  $\mathbf{w}$  是G中两个顶点。

操作结果：在G中增添弧  $<  \nu ,\mathsf{w}>$  ，若G是无向的，则还增添对称弧  $<  w,v>$  。

DeleteArc(&G, v, w);

初始条件：图G存在，  $\mathbf{v}$  和  $\mathbf{w}$  是G中两个顶点。

操作结果：在G中删除弧  $<\mathbf{v}, \mathbf{w}>$ ，若G是无向的，则还删除对称弧  $<\mathbf{w}, \mathbf{v}>$ 。

DFStraverse(G,Visit());

初始条件：图G存在，Visit是顶点的应用函数。

操作结果：对图进行深度优先遍历。在遍历过程中对每个顶点调用函数 Visit 一次且仅一次。一旦 visit() 失败，则操作失败。

BFStraverse(G,Visit();

初始条件：图G存在，Visit是顶点的应用函数。

操作结果：对图进行广度优先遍历。在遍历过程中对每个顶点调用函数Visit一次且仅一次。一旦visit()失败，则操作失败。

ADT Graph

在图中的数据元素通常称做顶点（Vertex）， $V$  是顶点的有穷非空集合； $VR$  是两个顶点之间的关系的集合。若  $\langle v, w \rangle \in VR$ ，则  $\langle v, w \rangle$  表示从  $v$  到  $w$  的一条弧（Arc），且称  $v$  为弧尾（Tail）或初始点（Initial node），称  $w$  为弧头（Head）或终端点（Terminal node），此时的图称为有向图（Digraph）。若  $\langle v, w \rangle \in VR$  必有  $\langle w, v \rangle \in VR$ ，即  $VR$  是对称的，则以无序对  $(v, w)$  代替这两个有序

![](images/19c95dc46ab4fe05b38d7793929d126bcbb40ed227407a74f1160c14333a92b8.jpg)  
(a)  
图7.1 图的示例  
(a) 有向图  $G_{1}$ ; (b) 无向图  $G_{2}$

![](images/c9da9c5891b40c0c24d73154c4e3c6a64ec5f7462c86e5e79878cbacd8a178cd.jpg)  
(b)

对，表示  $v$  和  $w$  之间的一条边(Edge)，此时的图称为无向图(Undigraph)。例如图7.1(a)中  $G_{1}$  是有向图，定义此图的谓词  $P(v, w)$  则表示从  $v$  到  $w$  的一条单向通路。

$$
G _ {1} = \left(V _ {1}, \left\{A _ {1} \right\}\right)
$$

其中：  $V_{1} = \{v_{1},v_{2},v_{3},v_{4}\}$

$$
A _ {1} = \{\langle v _ {1}, v _ {2} \rangle , \langle v _ {1}, v _ {3} \rangle , \langle v _ {3}, v _ {4} \rangle , \langle v _ {4}, v _ {1} \rangle \}
$$

图7.1(b)中  $G_{2}$  为无向图。

$$
G _ {2} = \left(V _ {2} \left\{E _ {2} \right\}\right)
$$

其中  $V_{2} = \{v_{1},v_{2},v_{3},v_{4},v_{5}\}$

$$
E _ {2} = \left\{\left(v _ {1}, v _ {2}\right), \left(v _ {1}, v _ {4}\right) \left(v _ {2}, v _ {3}\right), \left(v _ {2}, v _ {5}\right), \left(v _ {3}, v _ {4}\right), \left(v _ {3}, v _ {5}\right) \right\}
$$

我们用  $n$  表示图中顶点数目，用  $\pmb{e}$  表示边或弧的数目。在下面的讨论中，我们不考虑顶点到其自身的弧或边，即若  $\langle v_i, v_j \rangle \in VR$  ，则  $v_i \neq v_j$  ，那么，对于无向图， $\pmb{e}$  的取值范围是0到  $\frac{1}{2} n(n-1)$  。有  $\frac{1}{2} n(n-1)$  条边的无向图称为完全图(Completed graph)。对于有向图， $\pmb{e}$  的取值范围是0到  $n(n-1)$  。具有  $n(n-1)$  条弧的有向图称为有向完全图。有很少条边或弧（如  $e < n \log n$ ）的图称为稀疏图(Sparse graph)，反之称为稠密图(Dense graph)。

有时图的边或弧具有与它相关的数，这种与图的边或弧相关的数叫做权（Weight）。这些权可以表示从一个顶点到另一个顶点的距离或耗费。这种带权的图通常称为网（Network）。

假设有两个图  $G = (V, \{E\})$  和  $G' = (V', \{E'\})$ ，如果  $V' \subseteq V$  且  $E' \subseteq E$ ，则称  $G'$  为  $G$  的子圈(Subgraph)。例如，图7.2是子图的一些例子。

图7.2 子图示例  
![](images/f080a3f5ab03f32eecf1db7923e49036fa84df97ce831a4afeb50cf403c2169f.jpg)  
(a)  $G_{1}$  的子图；(b)  $G_{2}$  的子图

对于无向图  $G = (V, \{E\})$ ，如果边  $(v, v') \in E$ ，则称顶点  $v$  和  $v'$  互为邻接点（Adjacent），即  $v$  和  $v'$  相邻接。边  $(v, v')$  依附(Incident)于顶点  $v$  和  $v'$ ，或者说  $(v, v')$  和顶点  $v$  和  $v'$  相关联。顶点  $v$  的度(Degree)是和  $v$  相关联的边的数目，记为  $TD(V)$ 。例如， $G_2$  中顶点  $v_3$  的度是3。对于有向图  $G = (V, \{A\})$ ，如果弧  $\langle v, v' \rangle \in A$ ，则称顶点  $v$  邻接到顶点  $v'$ ，顶点  $v'$  邻接自顶点  $v$ 。弧  $\langle v, v' \rangle$  和顶点  $v, v'$  相关联。以顶点  $v$  为头的弧的数目称为  $v$  的入度(InDegree)，记为  $ID(v)$ ；以  $v$  为尾的弧的数目称为  $v$  的出度(Outdegree)，记为  $OD(v)$ ；顶点  $v$  的度为  $TD(v) = ID(v) + OD(v)$ 。例如，图  $G_1$  中顶点  $v_1$  的入度  $ID(v_1) = 1$ ，出度  $OD(v_1) = 2$ ，度  $TD(v_1) = ID(v_1) + OD(v_1) = 3$ 。一般地，如果顶点  $v_i$  的度记为  $TD(v_i)$ ，那么一个有  $n$  个顶点， $e$  条边或弧的图，满足如下关系

$$
e = \frac {1}{2} \sum_ {i = 1} ^ {n} T D (v _ {i})
$$

无向图  $G = (V, \{E\})$  中从顶点  $v$  到顶点  $v'$  的路径（Path）是一个顶点序列  $(v = v_{i,0}, v_{i,1}, \dots, v_{i,m} = v')$ ，其中  $(v_{i,j-1}, v_{i,j}) \in E, 1 \leqslant j \leqslant m$ 。如果  $G$  是有向图，则路径也是有向的，顶点序列应满足  $\langle v_{i,j-1}, v_{i,j} \rangle \in E, 1 \leqslant j \leqslant m$ 。路径的长度是路径上的边或弧的数目。第一个顶点和最后一个顶点相同的路径称为回路或环（Cycle）。序列中顶点不重复出现的路径称为简单路径。除了第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路，称为简单回路或简单环。

在无向图  $G$  中，如果从顶点  $\pmb{v}$  到顶点  $\pmb{v}^{\prime}$  有路径，则称  $\pmb{v}$  和  $\pmb{v}^{\prime}$  是连通的。如果对于图中任意两个顶点  $v_{i}, v_{j} \in V, v_{i}$  和  $v_{j}$  都是连通的，则称  $G$  是连通图(Connected Graph)。图7.1(b)中的  $G_{2}$  就是一个连通图，而图7.3(a)中的  $G_{3}$  则是非连通图，但  $G_{3}$  有3个连通分量，如图7.3(b)所示。所谓连通分量(Connected Component)，指的是无向图中的极大连通子图。

图7.3 无向图及其连通分量  
![](images/87e63abc50148a451901c0cd0358569d5efdae1c420b92e8c49b936ef9e0ce48.jpg)  
(a) 无向图  $G_{3}$ ; (b)  $G_{3}$  的 3 个连通分量

在有向图  $G$  中，如果对于每一对  $v_{i}, v_{j} \in V, v_{i} \neq v_{j}$ ，从  $v_{i}$  到  $v_{j}$  和从  $v_{j}$  到  $v_{i}$  都存在路径，则称  $G$  是强连通图。有向图中的极大强连通子图称做有向图的强连通分量。例如图7.1(a)中的  $G_{1}$  不是强连通图，但它有两个强连通分量，如图7.4所示。

一个连通图的生成树是一个极小连通子图，它含有图中全部顶点，但只有足以构成一棵树的  $n - 1$  条边。图7.5是  $G_{3}$  中最大连通分量的一棵生成树。如果在一棵生成树上添加一条边，必定构成一个环，因为这条边使得它依附的那两个顶点之间有了第二条路径。

![](images/ecddf2a60f93e54be84b831fc1ac88dcc4c3731bd4864b06234c66fd58258dc8.jpg)  
图7.4  $G_{1}$  的两个强连通分量

![](images/11b8aedf36507327589731a690b06dd5a5636890326e883c1cfc347b7d9532ab.jpg)  
图7.5  $\mathbf{G}_3$  的最大连通分量的-棵生成树

一棵有  $n$  个顶点的生成树有且仅有  $n - 1$  条边。如果一个图有  $n$  个顶点和小于  $n - 1$  条边，则是非连通图。如果它多于  $n - 1$  条边，则一定有环。但是，有  $n - 1$  条边的图不一定是生成树。

如果一个有向图恰有一个顶点的入度为0，其余顶点的入度均为1，则是一棵有向树。一个有向图的生成森林由若干棵有向树组成，含有图中全部顶点，但只有足以构成若干棵不相交的有向树的弧。图7.6所示为其一例。

![](images/419a7adc3b6a69b4153343f64dff14453657d2af031a71e2029056d64a9cd631.jpg)  
图7.6 一个有向图及其生成森林

在前述图的基本操作的定义中，关于“顶点的位置”和“邻接点的位置”只是一个相对的概念。因为，从图的逻辑结构的定义来看，图中的顶点之间不存在全序的关系（即无法将图中顶点排列成一个线性序列），任何一个顶点都可被看成是第一个顶点；另一方面，任一顶点的邻接点之间也不存在次序关系。但为了操作方便，我们需要将图中顶点按任意的顺序排列起来（这个排列和关系  $\mathsf{VR}$  无关）。由此，所谓“顶点在图中的位置”指的是该顶点在这个人为的随意排列中的位置（或序号）。同理，可对某个顶点的所有邻接点进行排队，在这个排队中自然形成了第一个或第  $k$  个邻接点。若某个顶点的邻接点的个数大于  $k$ ，则称第  $k + 1$  个邻接点为第  $k$  个邻接点的下一个邻接点，而最后一个邻接点的下一个邻接点为“空”。

# 7.2 图的存储结构

在前面几章讨论的数据结构中，除了广义表和树以外，都可以有两类不同的存储结

构, 它们是由不同的映像方法 (顺序映像和链式映像) 得到的。由于图的结构比较复杂, 任意两个顶点之间都可能存在联系, 因此无法以数据元素在存储区中的物理位置来表示元素之间的关系, 即图没有顺序映像的存储结构, 但可以借助数组的数据类型表示元素之间的关系。另一方面, 用多重链表表示图是自然的事, 它是一种最简单的链式映像结构, 即以一个由一个数据域和多个指针域组成的结点表示图中一个顶点, 其中数据域存储该顶点的信息, 指针域存储指向其邻接点的指针, 如图 7.7 所示为图 7.1 中有向图  $G_{1}$  和无向图  $G_{2}$  的多重链表。但是, 由于图中各个结点的度数各不相同, 最大度数和最小度数可能相差很多, 因此, 若按度数最大的顶点设计结点结构, 则会浪费很多存储单元; 反之, 若按每个顶点自己的度数设计不同的结点结构, 又会给操作带

![](images/9f472206ea84ac2aba7e577361eb56415263eafc2a41293c5f522d8b81352212.jpg)

图7.7 图的多重链表  
![](images/da2eccfde3504ffb94baf256a0daec927b7b7fe27ccbd3930d9c925ce6880784.jpg)  
(a)  $G_{1}$  的多重链表；(b)  $G_{2}$  的多重链表

来不便。因此，和树类似，在实际应用中不宜采用这种结构，而应根据具体的图和需要进行的操作，设计恰当的结点结构和表结构。常用的有邻接表、邻接多重表和十字链表。下面分别讨论。

# 7.2.1 数组表示法

用两个数组分别存储数据元素（顶点）的信息和数据元素之间的关系（边或弧）的信息。其形式描述如下：

```c
//---- 图的数组(邻接矩阵)存储表示----  
#define INFINITY INT_MAX //最大值 $\mathbf{\text{号}}$    
#define MAX_VERTEX_NUM 20 //最大顶点个数  
typedef enum {DG,DN,UDG,UDN} GraphKind; //{有向图，有向网，无向图，无向网}  
typedef struct ArcCell{VRType adj; //VRType是顶点关系类型。对无权图，用1或0//表示相邻否；对带权图，则为权值类型。InfoType \*info; //该弧相关信息的指针  
}ArcCell，AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM];  
typedef struct{VertexType vexs[MAX_VERTEX_NUM]； //顶点向量AdjMatrix arcs; //邻接矩阵int vexnum,arcnum; //图的当前顶点数和弧数GraphKind kind; //图的种类标志  
}MGraph;
```

例如，图7.1中  $G_{1}$  和  $G_{2}$  的邻接矩阵如图7.8所示。以二维数组表示有  $\pmb{n}$  个顶点的图时，需存放  $\pmb{n}$  个顶点信息和  $n^2$  个弧信息的存储量。若考虑无向图的邻接矩阵的对称性，则可采用压缩存储的方式只存入矩阵的下三角(或上三角)元素。

$$
\mathrm {G 1 . a r c s} = \left[ \begin{array}{l l l l} 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 1 & 0 & 0 & 0 \end{array} \right], \quad \mathrm {G 2 . a r c s} = \left[ \begin{array}{l l l l l} 0 & 1 & 0 & 1 & 0 \\ 1 & 0 & 1 & 0 & 1 \\ 0 & 1 & 0 & 1 & 1 \\ 1 & 0 & 1 & 0 & 0 \\ 0 & 1 & 1 & 0 & 0 \end{array} \right]
$$

图7.8 图的邻接矩阵

借助于邻接矩阵容易判定任意两个顶点之间是否有边(或弧)相连，并容易求得各个顶点的度。对于无向图，顶点  $v_{i}$  的度是邻接矩阵中第  $i$  行(或第  $i$  列)的元素之和，即

$$
T D \left(v _ {i}\right) = \sum_ {j = 0} ^ {n - 1} A [ i ] [ j ] (n = M A X _ {-} V E R T E X _ {-} N U M)
$$

对于有向图，第  $i$  行的元素之和为顶点  $\pmb{v_{i}}$  的出度  $OD(v_{i})$  ，第  $_j$  列的元素之和为顶点  $\pmb{v_{j}}$  的入度  $ID(v_{j})$  。

网的邻接矩阵可定义为

$$
A [ i ] [ j ] = \left\{ \begin{array}{l l} w _ {i, j} & \text {若} \langle v _ {i}, v _ {j} \rangle \text {或} (v _ {i}, v _ {j}) \in V R \\ \infty & \text {反 之} \end{array} \right.
$$

例如，图7.9列出了一个有向网和它的邻接矩阵。

(a)  
图7.9 网及其邻接矩阵  
![](images/93dea76711d491b36fd557aee21ae919f037146bd378af670b365016867690c0.jpg)  
(a) 网  $\mathbf{N}$ ; (b) 邻接矩阵

![](images/a9034c4150501a05d78ab4f222016a8946d43299891e76440251879edc89bab1.jpg)  
(b)

算法7.1是在邻接矩阵存储结构MGraph上对图的构造操作的实现框架，它根据图  $G$  的种类调用具体构造算法。如果  $G$  是无向网，则调用算法7.2。构造一个具有  $n$  个顶点和  $\pmb{e}$  条边的无向网  $G$  的时间复杂度是  $O(n^{2} + e\cdot n)$ ，其中对邻接矩阵G.arcs的初始化耗费了  $O(n^{2})$  的时间。

```txt
Status CreateGraph(MGraph&G) {
// 采用数组(邻接矩阵)表示法,构造图G。
scanf(&G-kind);
switch(G-kind) {
    case DG: return CreateDG(G); // 构造有向图G
    case DN: return CreateDN(G); // 构造有向网G
    case UDG: return CreateUDG(G); // 构造无向图G
    case UDN: return CreateUDN(G); // 构造无向网G
    default: return ERROR;
}
```

# 算法 7.1

```javascript
Status CreateUDN(MGraph &G) {
// 采用数组(邻接矩阵)表示法,构造无向网 G。
scanf(&G.vexnum, &G.arcnum, &IncInfo); // IncInfo为0则各弧不含其他信息
for (i = 0; i < G.vexnum; ++i) scanf(&G.vexs[i]); // 构造顶点向量
for (i = 0; i < G.vexnum; ++i) // 初始化邻接矩阵
for (j = 0; j < G.vexnum; ++j) G.arcs[i][j] = {INFINITY, NULL}; // {adj, info}
for (k = 0; k < G.arcnum; ++k) // 构造邻接矩阵
scanf(&v1, &v2, &w); // 输入一条边依附的顶点及权值
i = LocateVex(G, v1); j = LocateVex(G, v2); // 确定v1和v2在G中位置
G.arcs[i][j].adj = w; // 弧<v1,v2>的权值
if (IncInfo) Input(*G.arcs[i][j].info); // 若弧含有相关信息,则输入
G.arcs[j][i] = G.arcs[i][j]; // 置<v1,v2>的对称弧<v2,v1>
}
return OK;
} // CreateUDN
```

# 算法 7.2

在这个存储结构上也易于实现7.2节所列的基本操作。如，FIRST_ADJ(G,v)找  $v$  的第一个邻接点。首先，由LOC_VERTEX(G,v)找到  $v$  在图  $G$  中的位置，即  $v$  在一维数组vexs中的序号  $i$ ，则二维数组arcs中第  $i$  行上第一个adj域的值为“1”的分量所在列号  $j$ ，便为  $v$  的第一个邻接点在图  $G$  中的位置。同理，下一个邻接点在图  $G$  中的位置便为  $j$  列之后第一个adj域的值为“1”的分量所在列号。

# 7.2.2 邻接表

邻接表(AdjacencyList）是图的一种链式存储结构。在邻接表中，对图中每个顶点建立一个单链表，第  $i$  个单链表中的结点表示依附于顶点  $\pmb{v_{i}}$  的边（对有向图是以顶点  $\pmb{v_{i}}$  为尾的弧）。每个结点由3个域组成，其中邻接点域(adjvex)指示与顶点  $\pmb{v_{i}}$  邻接的点在图中的位置，链域(nextarc)指示下一条边或弧的结点；数据域(info)存储和边或弧相关的信息，如权值等。每个链表上附设一个表头结点。在表头结点中，除了设有链域(firstarc)指向链表中第一个结点之外，还设有存储顶点  $\pmb{v_{i}}$  的名或其他有关信息的数据域(data)。如下图所示

<table><tr><td>adjvex</td><td>nextarc</td><td>info</td></tr></table>

<table><tr><td>data</td><td>firstarc</td></tr></table>

这些表头结点(可以链相接)通常以顺序结构的形式存储, 以便随机访问任一顶点的链表。例如图7.10(a)和(b)所示分别为图7.1中  $G_{1}$  和  $G_{2}$  的邻接表。一个图的邻接表存储结构可形式地说明如下:

```c
// -- -- -- 图的邻接表存储表示 -- -- --  
#define MAX_VERTEX_NUM 20  
typedef struct ArcNode{int adjvex; //该弧所指向的顶点的位置struct ArcNode \*nextarc; //指向下一条弧的指针InfoType \*info; //该弧相关信息的指针}ArcNode;  
typedef struct VNode{VertexType data; //顶点信息ArcNode \*firstarc; //指向第一条依附该顶点的弧的指针}VNode,AdjList[MAX_VERTEX_NUM];  
typedef struct{AdjList vertices;int vexnum, arcnum; //图的当前顶点数和弧数int kind; //图的种类标志}ALGraph;
```

若无向图中有  $n$  个顶点、 $e$  条边，则它的邻接表需  $n$  个头结点和  $2e$  个表结点。显然，在边稀疏  $\left(e \ll \frac{n(n-1)}{2}\right)$  的情况下，用邻接表表示图比邻接矩阵节省存储空间，当和边相关的信息较多时更是如此。

![](images/4354beae6a48b1ebdad17e7df099d0ec7799ee0a0c064e3eda3b683271c3a861.jpg)  
(a)

![](images/5791106e86040d5cf3f67a51b07c0549dd64a79d4a2370aff1e407c418285b5c.jpg)  
(b)

(c)  
图7.10 邻接表和逆邻接表  
![](images/6a11a1d38d271f0a0773d1965c78fdd207029af93625b264549ccdeda57fef08.jpg)  
(a)  $\mathbf{G}_1$  的邻接表；(b)  $\mathbf{G}_2$  的邻接表；(c)  $\mathbf{G}_1$  的逆邻接表

在无向图的邻接表中，顶点  $v_{i}$  的度恰为第  $i$  个链表中的结点数；而在有向图中，第  $i$  个链表中的结点个数只是顶点  $\pmb{v}_{i}$  的出度，为求入度，必须遍历整个邻接表。在所有链表中其邻接点域的值为  $i$  的结点的个数是顶点  $\pmb{v}_{i}$  的入度。有时，为了便于确定顶点的入度或以顶点 $\pmb{v}_{i}$  为头的弧，可以建立一个有向图的逆邻接表，即对每个顶点  $\pmb{v}_{i}$  建立一个链接以  $\pmb{v}_{i}$  为头的弧的表，例如图7.10(c)所示为有向图  $G_{1}$  的逆邻接表。

在建立邻接表或逆邻接表时，若输入的顶点信息即为顶点的编号，则建立邻接表的时间复杂度为  $O(n + e)$  ，否则，需要通过查找才能得到顶点在图中位置，则时间复杂度为  $O(n\bullet e)$  。

在邻接表上容易找到任一顶点的第一个邻接点和下一个邻接点，但要判定任意两个顶点  $(v_{i}$  和  $v_{j})$  之间是否有边或

弧相连, 则需搜索第  $i$  个或第  $j$  个链表, 因此, 不及邻接矩阵方便。

# 7.2.3 十字链表

十字链表(Orthogonal List)是有向图的另一种链式存储结构。可以看成是将有向图的邻接表和逆邻接表结合起来得到的一种链表。在十字链表中，对应于有向图中每一条弧有一个结点，对应于每个顶点也有一个结点。这些结点的结构如下所示：

弧结点  

<table><tr><td>tailvex</td><td>headvex</td><td>hlink</td><td>tlink</td><td>info</td></tr></table>

顶点结点  

<table><tr><td>data</td><td>firstin</td><td>firstout</td></tr></table>

在弧结点中有5个域：其中尾域(tailvex)和头域(headvex)分别指示弧尾和弧头这两个顶点在图中的位置，链域hlink指向弧头相同的下一条弧，而链域tlink指向弧尾相同的下一条弧，info域指向该弧的相关信息。弧头相同的弧在同一链表上，弧尾相同的弧也在同一链表上。它们的头结点即为顶点结点，它由3个域组成：其中data域存储和顶点相关的信息，如顶点的名称等；firstin和firstout为两个链域，分别指向以该顶点为弧头或弧尾的第一个弧结点。例如，图7.11(a)中所示图的十字链表如图7.11(b)所示。若将有向图的邻接矩阵看成是稀疏矩阵的话，则十字链表也可以看成是邻接矩阵的链表存储结构，在图的十字链表中，弧结点所在的链表非循环链表，结点之间相对位置自然形成，不一定按顶点序号有序，表头结点即顶点结点，它们之间不是链接，而是顺序存储。

![](images/e1957456bf7d479c6d18f71b53b1a0aed267fe607b914ae5428599d1ddb999c1.jpg)  
(a)

![](images/23c422a2dd27967f7aef03b0d7dc4758b0d76e873f7e3f9da79621914ed7894f.jpg)  
(b)  
图7.11 有向图的十字链表

有向图的十字链表存储表示的形式说明如下所示：

```c
// -- -- 有向图的十字链表存储表示 -- -- --  
#define MAX_VERTEX_NUM 20  
typedef struct ArcBox{int tailvex, headvex; //该弧的尾和头顶点的位置structArcBox \*hlink，\*tlink; //分别为弧头相同和弧尾相同的弧的链域InfoType \*info; //该弧相关信息的指针}ArcBox;  
typedef struct VexNode{VertexType data;ArcBox \*firstin,\*firstout; //分别指向该顶点第一条入弧和出弧}VexNode;  
typedef struct{VexNode xlist[MAX_VERTEX_NUM]; //表头向量int vexnum, arcnum; //有向图的当前顶点数和弧数}OLGraph;
```

只要输入  $n$  个顶点的信息和  $\pmb{e}$  条弧的信息，便可建立该有向图的十字链表，其算法如算法7.3所示。

```javascript
Status CreateDG(OLGraph &G) {
// 采用十字链表存储表示，构造有向图 G(G.kind = DG)。
scanf(&G.vexnum, &G.arcnum, &IncInfo); // IncInfo为0则各弧不含其他信息
for (i = 0; i < G.vexnum; ++i) { // 构造表头向量
    scanf(&G.xlist[i].data); // 输入顶点值
    G.xlist[i].firstin = NULL; G.xlist[i].firstout = NULL; // 初始化指针
}
for (k = 0; k < G.arcnum; ++k) { // 输入各弧并构造十字链表
    scanf(&v1, &v2); // 输入一条弧的始点和终点
    i = LocateVex(G, v1); j = LocateVex(G, v2); // 确定v1和v2在G中位置
    p = (ArcBox *) malloc(sizeof(ArcBox)); // 假定有足够空间
    *p = {i, j, G.xlist[j].firstin, G.xlist[i].firstout, NULL} // 对弧结点赋值
    // {tailvex, headvex, hlink, tlink, info}
    G.xlist[j].firstin = G.xlist[i].firstout = p; // 完成在入弧和出弧链头的插入
```

```txt
if (IncInfo) Input(\*p->info);   
}   
}// CreateDG
```

// 若弧含有相关信息，则输入

# 算法 7.3

在十字链表中既容易找到以  $v_{i}$  为尾的弧, 也容易找到以  $v_{i}$  为头的弧, 因而容易求得顶点的出度和入度 (或需要, 可在建立十字链表的同时求出)。同时, 由算法 7.3 可知, 建立十字链表的时间复杂度和建立邻接表是相同的。在某些有向图的应用中, 十字链表是很有用的工具。

# 7.2.4 邻接多重表

邻接多重表(Adjacency Multilist)是无向图的另一种链式存储结构。虽然邻接表是无向图的一种很有效的存储结构，在邻接表中容易求得顶点和边的各种信息。但是，在邻接表中每一条边  $(v_{i}, v_{j})$  有两个结点，分别在第  $i$  个和第  $j$  个链表中，这给某些图的操作带来不便。例如在某些图的应用问题中需要对边进行某种操作，如对已被搜索过的边作记号或删除一条边等，此时需要找到表示同一条边的两个结点。因此，在进行这一类操作的无向图的问题中采用邻接多重表作存储结构更为适宜。

邻接多重表的结构和十字链表类似。在邻接多重表中，每一条边用一个结点表示，它由如下所示的6个域组成：

<table><tr><td>mark</td><td>ivex</td><td>ilink</td><td>jvex</td><td>jlink</td><td>info</td></tr></table>

其中，mark 为标志域，可用以标记该条边是否被搜索过；ivex 和 jvex 为该边依附的两个顶点在图中的位置；ilink 指向下一条依附于顶点 ivex 的边；jlink 指向下一条依附于顶点 jvex 的边，info 为指向和边相关的各种信息的指针域。每一个顶点也用一个结点表示，它由如下所示的两个域组成：

<table><tr><td>data</td><td>firstedge</td></tr></table>

其中，data域存储和该顶点相关的信息，firstedge域指示第一条依附于该顶点的边。例如，图7.12所示为无向图  $G_{2}$  的邻接多重表。在邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，则每个边结点同时链接在两个链表中。可见，对无向图而言，其邻接多重表和邻接表的差别，仅仅在于同一条边在邻接表中用两个结点表示，而在邻接多重表中只有一个结点。因此，除了在边结点中增加一个标志域外，邻接多重表所需的存储量和邻接表相同。在邻接多重表上，各种基本操作的实现亦和邻接表相似。邻接多重表的类型说明如下：

```c
// -- -- -- 无向图的邻接多重表存储表示 -- -- -- #define MAX_VERTEX_NUM 20 typedef emnu{unvisited,visited} VisitIf; typedef struct EBox{ VisitIf mark; //访问标记
```

![](images/efaf7cc6d05b798c08a0fe559425b57149b7b4c3f1d18fc86417751b8f29dabb.jpg)  
图7.12 无向图  $G_{2}$  的邻接多重表

```c
int ivex, jvex; //该边依附的两个顶点的位置  
struct EBox *ilink, *jlink; //分别指向依附这两个顶点的下一条边  
InfoType *info; //该边信息指针  
}EBox;  
typedef struct VexBox{  
VertexType data;  
EBox *firstedge; //指向第一条依附该顶点的边  
}VexBox;  
typedef struct{  
VexBox adjmulant MAX_VERTEX_NUM;  
int vexnum, edgenum; //无向图的当前顶点数和边数  
}AMLGraph;
```

# 7.3 图的遍历

和树的遍历类似, 在此, 我们希望从图中某一顶点出发访遍图中其余顶点, 且使每一个顶点仅被访问一次。这一过程就叫做图的遍历(Traversing Graph)。图的遍历算法是求解图的连通性问题、拓扑排序和求关键路径等算法的基础。

然而，图的遍历要比树的遍历复杂得多。因为图的任一顶点都可能和其余的顶点相邻接。所以在访问了某个顶点之后，可能沿着某条路径搜索之后，又回到该顶点上。例如图7.1(b)中的  $G_{2}$ ，由于图中存在回路，因此在访问了  $v_{1}, v_{2}, v_{3}, v_{4}$  之后，沿着边  $\langle v_{4}, v_{1} \rangle$  又可访问到  $v_{1}$ 。为了避免同一顶点被访问多次，在遍历图的过程中，必须记下每个已访问过的顶点。为此，我们可以设一个辅助数组 visited[0..n-1]，它的初始值置为“假”或者零，一旦访问了顶点  $v_{i}$ ，便置 visited[i]为“真”或者为被访问时的次序号。

通常有两条遍历图的路径：深度优先搜索和广度优先搜索。它们对无向图和有向图都适用。

# 7.3.1 深度优先搜索

深度优先搜索(Depth_First Search)遍历类似于树的先根遍历, 是树的先根遍历的

推广。

假设初始状态是图中所有顶点未曾被访问，则深度优先搜索可从图中某个顶点  $v$  出发，访问此顶点，然后依次从  $v$  的未被访问的邻接点出发深度优先遍历图，直至图中所有和  $v$  有路径相通的顶点都被访问到；若此时图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。

以图7.13(a)中无向图  $G_{4}$  为例，深度优先搜索遍历图的过程如图7.13(b)所示①。假设从顶点  $\pmb{v}_{1}$  出发进行搜索，在访问了顶点  $\pmb{v}_{1}$  之后，选择邻接点  $\pmb{v}_{2}$  。因为  $\pmb{v}_{2}$  未曾访问，

图7.13 遍历图的过程  
![](images/649a6b4e7165956d96002f299f2fbc02c54c97af53cab5bd77dd6b033f7a6e92.jpg)  
(a) 无向图  $G_{4}$ ; (b) 深度优先搜索的过程; (c) 广度优先搜索的过程

则从  $v_{2}$  出发进行搜索。依次类推，接着从  $v_{4}, v_{8}, v_{5}$  出发进行搜索。在访问了  $v_{5}$  之后，由于  $v_{5}$  的邻接点都已被访问，则搜索回到  $v_{8}$  。由于同样的理由，搜索继续回到  $v_{4}, v_{2}$  直至  $v_{1}$ ，此时由于  $v_{1}$  的另一个邻接点未被访问，则搜索又从  $v_{1}$  到  $v_{3}$ ，再继续进行下去。由此，得到的顶点访问序列为：

$$
v _ {1} \rightarrow v _ {2} \rightarrow v _ {4} \rightarrow v _ {8} \rightarrow v _ {5} \rightarrow v _ {3} \rightarrow v _ {6} \rightarrow v _ {7}
$$

显然，这是一个递归的过程。为了在遍历过程中便于区分顶点是否已被访问，需附设访问标志数组 visited[0..n-1]，其初值为“false”，一旦某个顶点被访问，则其相应的分量置为“true”。整个图的遍历如算法7.4和7.5所示，其中  $w \geq 0$  表示存在邻接点。

```objectivec
// -- - 算法7.4和7.5使用的全局变量 -- --  
Boolean visited[MAX]; // 访问标志数组  
Status (*VisitFunc)(int v); // 函数变量  
void DFSTraverse(Graph G, Status (*Visit)(int v)) { // 对图G作深度优先遍历。 VisitFunc = Visit; // 使用全局变量VisitFunc，使DFS不必设函数指针参数 for  $(\mathbf{v} = 0;\mathbf{v} <   \mathbf{G}.$  vexnum; ++v)visited[v]  $=$  FALSE; // 访问标志数组初始化 for  $(\mathbf{v} = 0;\mathbf{v} <   \mathbf{G}.$  vexnum; ++v) if(!visited[v]) DFS(G,v); //对尚未访问的顶点调用DFS }
```

# 算法 7.4

```txt
void DFS(Graph G, int v) {
    // 从第  $\mathbf{v}$  个顶点出发递归地深度优先遍历图  $\mathbf{G}$ 。
    visited[v] = TRUE; VisitFunc(v); // 访问第  $\mathbf{v}$  个顶点
    for (w = FirstAdjVex(G, v); w >= 0; w = NextAdjVex(G, v, w)) 
        if (!visited[w]) DFS(G, w); // 对  $\mathbf{v}$  的尚未访问的邻接顶点  $\mathbf{w}$  递归调用 DFS
}
```

# 算法 7.5

分析上述算法, 在遍历图时, 对图中每个顶点至多调用一次 DFS 函数, 因为一旦某个顶点被标志成已被访问, 就不再从它出发进行搜索。因此, 遍历图的过程实质上是对每个顶点查找其邻接点的过程。其耗费的时间则取决于所采用的存储结构。当用二维数组表示邻接矩阵作图的存储结构时, 查找每个顶点的邻接点所需时间为  $O(n^{2})$ , 其中  $n$  为图中顶点数。而当以邻接表作图的存储结构时, 找邻接点所需时间为  $O(e)$ , 其中  $e$  为无向图中边的数或有向图中弧的数。由此, 当以邻接表作存储结构时, 深度优先搜索遍历图的时间复杂度为  $O(n + e)$  。

# 7.3.2 广度优先搜索

广度优先搜索(Breadth_First Search)遍历类似于树的按层次遍历的过程。

假设从图中某顶点  $v$  出发，在访问了  $v$  之后依次访问  $v$  的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使“先被访问的顶点的邻接点”先于“后被访问的顶点的邻接点”被访问，直至图中所有已被访问的顶点的邻接点都被访问到。若此时图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。换句话说，广度优先搜索遍历图的过程是以  $v$  为起始点，由近至远，依次访问和  $v$  有路径相通且路径长度为  $1,2,\dots$  的顶点。例如，对图  $G_{4}$  进行广度优先搜索遍历的过程如图7.13(c)所示，首先访问  $v_{1}$  和  $v_{1}$  的邻接点  $v_{2}$  和  $v_{3}$ ，然后依次访问  $v_{2}$  的邻接点  $v_{4}$  和  $v_{5}$  及  $v_{3}$  的邻接点  $v_{6}$  和  $v_{7}$ ，最后访问  $v_{4}$  的邻接点  $v_{8}$ 。由于这些顶点的邻接点均已被访问，并且图中所有顶点都被访问，由此完成了图的遍历。得到的顶点访问序列为

$$
v _ {1} \rightarrow v _ {2} \rightarrow v _ {3} \rightarrow v _ {4} \rightarrow v _ {5} \rightarrow v _ {6} \rightarrow v _ {7} \rightarrow v _ {8}
$$

和深度优先搜索类似，在遍历的过程中也需要一个访问标志数组。并且，为了顺次访问路径长度为2、3、…的顶点，需附设队列以存储已被访问的路径长度为1,2,…的顶点。广度优先遍历的算法如算法7.6所示。

```c
void BFSTraverse(Graph G, Status (*Visit)(int v)) {
// 按广度优先非递归遍历图 G。使用辅助队列 Q 和访问标志数组 visited。
for (v = 0; v < G.vexnum; ++v) visited[v] = FALSE;
InitQueue(Q);
for (v = 0; v < G.vexnum; ++v)
if (!visited[v]) {
visited[v] = TRUE; Visit(v);
EnQueue(Q, v);
while (!QueueEmpty(Q)) {
DeQueue(Q, u);
for (w = FirstAdjVex(G, u); w >= 0; w = NextAdjVex(G, u, w))
if (!Visited[w]) // 队头元素出队并置为 u
visited[w] = TRUE; Visit(w);
EnQueue(Q, w);
} // if
} // while
} // BFSTraverse
```

# 算法 7.6

分析上述算法, 每个顶点至多进一次队列。遍历图的过程实质上是通过边或弧找邻接点的过程, 因此广度优先搜索遍历图的时间复杂度和深度优先搜索遍历相同, 两者不同之处仅仅在于对顶点访问的顺序不同。

# 7.4 图的连通性问题

在这一节中，我们将利用遍历图的算法求解图的连通性问题，并讨论最小代价生成树以及重连通性与通信网络的经济性和可靠性的关系。

# 7.4.1 无向图的连通分量和生成树

在对无向图进行遍历时，对于连通图，仅需从图中任一顶点出发，进行深度优先搜索或广度优先搜索，便可访问到图中所有顶点。对非连通图，则需从多个顶点出发进行搜索，而每一次从一个新的起始点出发进行搜索过程中得到的顶点访问序列恰为其各个连通分量中的顶点集。例如，图7.3中的  $G_{3}$  是非连通图，按照图7.14所示  $G_{3}$  的邻接表进行深度优先搜索遍历，3次调用DFS过程(分别从顶点A、D和  $\mathbf{G}$  出发)得到的顶点访问序列为：

ALMJBFC DE GKHI

这3个顶点集分别加上所有依附于这些顶点的边，便构成了非连通图  $G_{3}$  的3个连通

![](images/a9c2219b6442dcf48eab030271879883c4394c8a7007edd440e209894a23c528.jpg)  
图7.14  $G_{3}$  的邻接表

$B(G)$  中的边。

对于非连通图，每个连通分量中的顶点集，和遍历时走过的边一起构成若干棵生成树，这些连通分量的生成树组成非连通图的生成森林。例如，图7.15(c)所示为  $G_{3}$  的深度优先生成森林，它由3棵深度优先生成树组成。

假设以孩子兄弟链表作生成森林的存储结构，则算法7.7生成非连通图的深度优先生成森林，其中DFSTree函数如算法7.8所示。显然，算法7.7的时间复杂度和遍历相同。

```txt
void DFSForest(Graph G, CSTree &T) {
    // 建立无向图G的深度优先生成森林的
    // (最左)孩子(右)兄弟链表T。
```

```c
T = NULL; 图7.15 生成树和生成森林  
for (v = 0; v < G.vexnum; ++v)  
    visited[v] = FALSE;  
for (v = 0; v < G.vexnum; ++v)  
    if (!visited[v]) { //第v顶点为新的生成树的根结点  
        p = (CSTree)malloc(sizeOf(CSNode)); //分配根结点  
        *p = {GetVex(G,v), NULL, NULL}; //给该结点赋值  
        if (!T) T = p; //是第一棵生成树的根(T的根)  
        else q->nextSiblinging = p; //是其他生成树的根(前一棵的根的“兄弟”)  
        q = p; //q指示当前生成树的根  
        DFSTree(G, v, p); //建立以p为根的生成树  
}
```

分量，如图7.3(b)所示。

设  $E(G)$  为连通图  $G$  中所有边的集合，则从图中任一顶点出发遍历图时，必定将 $E(G)$  分成两个集合  $T(G)$  和  $B(G)$  ，其中 $T(G)$  是遍历图过程中历经的边的集合； $B(G)$  是剩余的边的集合。显然，  $T(G)$  和图 $G$  中所有顶点一起构成连通图  $G$  的极小连通子图，按照7.1节的定义，它是连通图的一棵生成树，并且称由深度优先搜索得到的为深度优先生成树；由广度优先搜索得到的为广度优先生成树。例如，图7.15(a)和(b)所示分别为连通图  $G_{4}$  的深度优先生成树和广度优先生成树，图中虚线为集合

![](images/d9cddaa3f3d92563b2f41eb9ddcb41477adf757c3343fcbe4f7bbd4ba6a2aa66.jpg)

![](images/c35f75f927d9b4e1a96604b25dfe2002d1199dff09ae9d16269345e04210b500.jpg)

![](images/93a90a402a70ae99d17cdeddb069d3796090560eabe6768deae86d8d1749a6a6.jpg)  
图7.15 生成树和生成森林

![](images/ce9c7d0107e024bddebe4f786ee93fe295bda9fce7f7939de775af0fd7cf5363.jpg)

![](images/da7a6b51bd7d57a31970c63ef53277101a570e71aee7582cbf6b692a01322af4.jpg)

(a)  $G_{4}$  的深度优先生成树；  
（b）  $G_{4}$  的广度优先生成树；  
（c）  $G_{3}$  的深度优先生成森林

// 第  $\mathbf{v}$  顶点为新的生成树的根结点  
//分配根结点  
//给该结点赋值  
//是第一棵生成树的根（T的根）

//是其他生成树的根（前一棵的根的“兄弟”）

// q 指示当前生成树的根  
// 建立以  $\mathfrak{p}$  为根的生成树

```txt
} // DFSForest
```

# 算法 7.7

```txt
void DFSTree(Graph G, int v, CSTree &T) {
    // 从第  $\mathbf{v}$  个顶点出发深度优先遍历图 G. 建立以 T 为根的生成树。
    visited[v] = TRUE; first = TRUE;
    for (w = FisrtAdjVex(G, v); w >= 0; w = NextAdjVex(G, v, w))
        if (!visited[w]) {
            p = (CSTree) malloc (sizeof(CSNode)); // 分配孩子结点
            * p = {GetVex(G, w), NULL, NULL};
            if (first) {
                T->lchild = p; first = FALSE; // w 是 v 的第一个未被访问的邻接顶点
            }
            else {
                q->nextSibling = p; // 是根的左孩子结点
            }
        else
            q = p;
        DFSTree(G, w, q); // 从第 w 个顶点出发深度优先遍历图 G, 建立子生成树 q
        } // if
    } // DFSTree
```

# 算法 7.8

# 7.4.2 有向图的强连通分量

深度优先搜索是求有向图的强连通分量的一个新的有效方法。假设以十字链表作有向图的存储结构，则求强连通分量的步骤如下：

（1）在有向图  $G$  上，从某个顶点出发沿以该顶点为尾的弧进行深度优先搜索遍历，并按其所有邻接点的搜索都完成（即退出DFS函数)的顺序将顶点排列起来。此时需对7.3.1中的算法作如下两点修改：（a）在进入DFSTraverse函数时首先进行计数变量的初始化，即在入口处加上count=0的语句；（b）在退出DFS函数之前将完成搜索的顶点号记录在另一个辅助数组finished[vexnum]中，即在DFS函数结束之前加上finished[++count]=v的语句。  
（2）在有向图  $G$  上，从最后完成搜索的顶点（即finished[vexnum-1]中的顶点）出发，沿着以该顶点为头的弧作逆向的深度优先搜索遍历，若此次遍历不能访问到有向图中所有顶点，则从余下的顶点中最后完成搜索的那个顶点出发，继续作逆向的深度优先搜索遍历，依次类推，直至有向图中所有顶点都被访问到为止。此时调用DFSTraverse时需作如下修改：函数中第二个循环语句的边界条件应改为  $\pmb{v}$  从finished[vexnum-1]至finished[0]。

由此，每一次调用DFS作逆向深度优先遍历所访问到的顶点集便是有向图  $G$  中一个强连通分量的顶点集。

例如图7.11所示的有向图，假设从顶点  $v_{1}$  出发作深度优先搜索遍历，得到finished

数组中的顶点号为  $(1,3,2,0)$ ；则再从顶点  $v_{1}$  出发作逆向的深度优先搜索遍历，得到两个顶点集  $\{v_{1}, v_{3}, v_{4}\}$  和  $\{v_{2}\}$ ，这就是该有向图的两个强连通分量的顶点集。

上述求强连通分量的第二步，其实质为：(1)构造一个有向图  $G_{r}$ ，设  $G = (V, \{A\})$ ，则  $G_{r} = (V, \{A_{r}\})$ ，对于所有  $\langle v_{i}, v_{j} \rangle \in A$ ，必有  $\langle v_{j}, v_{i} \rangle \in A_{r}$ 。即  $G_{r}$  中拥有和  $G$  方向相反的弧；(2）在有向图  $G_{r}$  上，从顶点 finished[vexnum-1]出发作深度优先搜索遍历。可以证明，在  $G_{r}$  上所得深度优先生成森林中每一棵树的顶点集即为  $G$  的强连通分量的顶点集[8]。

显然，利用遍历求强连通分量的时间复杂度亦和遍历相同。

# 7.4.3 最小生成树

假设要在  $n$  个城市之间建立通信联络网, 则连通  $n$  个城市只需要  $n - 1$  条线路。这时, 自然会考虑这样一个问题, 如何在最节省经费的前提下建立这个通信网。

在每两个城市之间都可以设置一条线路，相应地都要付出一定的经济代价。 $n$  个城市之间，最多可能设置  $n(n - 1) / 2$  条线路，那么，如何在这些可能的线路中选择  $n - 1$  条，以使总的耗费最少呢？

可以用连通网来表示  $n$  个城市以及  $n$  个城市间可能设置的通信线路, 其中网的顶点表示城市, 边表示两城市之间的线路, 赋于边的权值表示相应的代价。对于  $n$  个顶点的连通网可以建立许多不同的生成树, 每一棵生成树都可以是一个通信网。现在, 我们要选择这样一棵生成树, 也就是使总的耗费最少。这个问题就是构造连通网的最小代价生成树 (Minimum Cost Spanning Tree) (简称为最小生成树) 的问题。一棵生成树的代价就是树上各边的代价之和。

构造最小生成树可以有多种算法。其中多数算法利用了最小生成树的下列一种简称为MST的性质：假设  $N = (V,\{E\})$  是一个连通网， $U$  是顶点集  $V$  的一个非空子集。若  $(u,v)$  是一条具有最小权值(代价)的边，其中  $u\in U,v\in V - U$  ，则必存在一棵包含边  $(u,v)$  的最小生成树。

可以用反证法证明之。假设网  $N$  的任何一棵最小生成树都不包含  $(u, v)$  。设  $T$  是连通网上的一棵最小生成树，当将边  $(u, v)$  加入到  $T$  中时，由生成树的定义， $T$  中必存在一条包含  $(u, v)$  的回路。另一方面，由于  $T$  是生成树，则在  $T$  上必存在另一条边  $(u', v')$  ，其中  $u' \in U, v' \in V - U$  ，且  $u$  和  $u'$  之间， $v$  和  $v'$  之间均有路径相通。删去边  $(u', v')$  ，便可消除上述回路，同时得到另一棵生成树  $T'$  。因为  $(u, v)$  的代价不高于  $(u', v')$  ，则  $T'$  的代价亦不高于  $T, T'$  是包含  $(u, v)$  的一棵最小生成树。由此和假设矛盾。

普里姆(Prim)算法和克鲁斯卡尔(Kruskal)算法是两个利用MST性质构造最小生成树的算法。

下面先介绍普里姆算法。

假设  $N = (V, \{E\})$  是连通网， $TE$  是  $N$  上最小生成树中边的集合。算法从  $U = \{u_0\} (u_0 \in V)$ ， $TE = \{\}$  开始，重复执行下述操作：在所有  $u \in U, v \in V - U$  的边  $(u, v) \in E$  中找一条代价最小的边  $(u_0, v_0)$  并入集合  $TE$ ，同时  $v_0$  并入  $U$ ，直至  $U = V$  为止。此时  $TE$  中必有  $n - 1$  条边，则  $T = (V, \{TE\})$  为  $N$  的最小生成树。

为实现这个算法需附设一个辅助数组 closedge, 以记录从  $U$  到  $V - U$  具有最小代价的边。对每个顶点  $v_i \in V - U$ , 在辅助数组中存在一个相应分量 closedge[i-1], 它包括两个域, 其中 lowcost 存储该边上的权。显然,

$$
\operatorname {c l o s e d g e} [ \mathrm {i} - 1 ]. \operatorname {l o w c o s t} = \operatorname {M i n} \left\{\operatorname {c o s t} (\mathrm {u}, \mathrm {v} _ {\mathrm {i}}) ^ {①} | \mathrm {u} \in \mathrm {U} \right\}
$$

![](images/5e38a1add1e89ac7ba7ad1a5ba46670197cfa065b9d87662693d3798d0362958.jpg)  
(a)

![](images/ad8ee03b80cd3d82b4cedb0478b5b8f0fd7a4b1485537677b68d52f99edde8ce.jpg)  
(b)

![](images/0d50d8ff026279eaac383219882696ff27f7d4fba8248876e203da41a3c42a3a.jpg)  
(c)

![](images/dd2973b3a0f89019620c09cdbd7bd006544eafc845dafc7794d151bc2bcdb8d2.jpg)  
(d)

![](images/77a6ea1f47ce950bc24f8ee90d07b3c53b99705c120bae90b40f97afcc397ee4.jpg)  
(e)

![](images/e368c40527ed59170ac522da220a2ffa48765ff14bab63f315327d486b525e02.jpg)  
(f)  
图7.16 普里姆算法构造最小生成树的过程  
图7.17 图7.16构造最小生成树过程中辅助数组中各分量的值

vex域存储该边依附的在  $U$  中的顶点。例如，图7.16所示为按普里姆算法构造网的一棵最小生成树的过程，在构造过程中辅助数组中各分量值的变化如图7.17所示。初始状态

<table><tr><td>i
closedge</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>U</td><td>V-U</td><td>k</td></tr><tr><td>adjvex</td><td>v1</td><td>v1</td><td>v1</td><td></td><td></td><td>{v1}</td><td>{v2, v3, v4, v5, v6}</td><td>2</td></tr><tr><td>lowcost</td><td>6</td><td>1</td><td>5</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>adjvex</td><td>v3</td><td></td><td>v1</td><td>v3</td><td>v3</td><td>{v1, v3}</td><td>{v2, v4, v5, v6}</td><td>5</td></tr><tr><td>lowcost</td><td>5</td><td>0</td><td>5</td><td>6</td><td>4</td><td></td><td></td><td></td></tr><tr><td>adjvex</td><td>v3</td><td></td><td>v6</td><td>v3</td><td></td><td>{v1, v3, v6}</td><td>{v2, v4, v5}</td><td>3</td></tr><tr><td>lowcost</td><td>5</td><td>0</td><td>2</td><td>6</td><td>0</td><td></td><td></td><td></td></tr><tr><td>adjvex</td><td>v3</td><td></td><td></td><td>v3</td><td></td><td>{v1, v3, v6, v4}</td><td>{v2, v5}</td><td>1</td></tr><tr><td>lowcost</td><td>5</td><td>0</td><td>0</td><td>6</td><td>0</td><td></td><td></td><td></td></tr><tr><td>adjvex</td><td></td><td></td><td></td><td>v2</td><td></td><td>{v1, v3, v6, v4, v2}</td><td>{v5}</td><td>4</td></tr><tr><td>lowcost</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td></td><td></td><td></td></tr><tr><td>adjvex</td><td></td><td></td><td></td><td></td><td></td><td>{v1, v3, v6, v4, v2, v5}</td><td>{}</td><td></td></tr><tr><td>lowcost</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td></td><td></td><td></td></tr></table>

时, 由于  $U = \{v_{1}\}$ , 则到  $V - U$  中各顶点的最小边, 即为从依附于顶点 1 的各条边中, 找到一条代价最小的边  $(u_{0}, v_{0}) = (1, 3)$  为生成树上的第一条边, 同时将  $v_{0} (= v_{3})$  并入集合  $U$ 。然后修改辅助数组中的值。首先将 closedge[2].lowcost 改为  $0'$ , 以示顶点  $v_{3}$  已并入  $U$ 。

然后，由于边  $(v_{3}, v_{2})$  上的权值小于 closedge[1]. lowcost，则需修改 closedge[1] 为边  $(v_{3}, v_{2})$  及其权值。同理修改 closedge[4] 和 closedge[5]。依次类推，直到  $U = V$  。假设以二维数组表示网的邻接矩阵，且令两个顶点之间不存在的边的权值为机内允许的最大值 (INT_MAX)，则普里姆算法如算法 7.9 所示。

```javascript
void MiniSpanTree.PRIM(MGraphG,VertexTypeu){ //用普里姆算法从第  $\mathbf{u}$  个顶点出发构造网G的最小生成树T，输出T的各条边。 //记录从顶点集U到V-U的代价最小的边的辅助数组定义： //struct{ // VertexTypeadjvex; //VRType lowcost; //}closedge[MAX_VERTEX_NUM]; k=LocateVex(G,u); for  $(j = 0;j <   G.$  vexnum；  $+ + j$  ）//辅助数组初始化 if  $(j! = k)$  closedge[j]  $\equiv$  {u,G.arcs[k][j].adj}; //{adjvex,lowcost} closedge[k].lowcost  $\equiv 0$  ： //初始，U={u} for  $(i = 1;i <   G.$  vexnum；  $+ + i$  }{//选择其余G.vexnum-1个顶点 k  $=$  minimum(closedge); //求出T的下一个结点：第k顶点 //此时closedge[k].lowcost  $=$  MIN{closedge[v].lowcost|closedge[v].lowcost>0，  $\mathbf{v}_i\in V - U$  ） printf(closedge[k].adjvex,G.vexs[k])； //输出生成树的边 closedge[k].lowcost  $\equiv 0$  ： //第k顶点并入U集 for  $(j = 0;j <   G.$  vexnum；  $+ + j$  ） if(G.arcs[k][j].adj  $<   <$  closedge[j].lowcost) //新顶点并入U后重新选择最 小边 closedge[j]  $\equiv$  {G.vexs[k],G.arcs[k][j].adj}；   
}//MiniSpanTree
```

# 算法 7.9

例如，对图7.16(a)中的网，利用算法7.9，将输出生成树上的5条边为：  $\{(v_{1},v_{3}),$ $(v_{3},v_{6}),(v_{6},v_{4}),(v_{3},v_{2}),(v_{2},v_{5})\}$  。

分析算法7.9, 假设网中有  $n$  个顶点, 则第一个进行初始化的循环语句的频度为  $n$ , 第二个循环语句的频度为  $n - 1$ . 其中有两个内循环: 其一是在  $\text{closedge}[\mathbf{v}]$ . lowcost中求最小值, 其频度为  $n - 1$ ; 其二是重新选择具有最小代价的边, 其频度为  $n$ . 由此, 普里姆算法的时间复杂度为  $O(n^{2})$ , 与网中的边数无关, 因此适用于求边稠密的网的最小生成树。

而克鲁斯卡尔算法恰恰相反，它的时间复杂度为  $O(elog_e)(e$  为网中边的数目），因此它相对于普里姆算法而言，适合于求边稀疏的网的最小生成树。

克鲁斯卡尔算法从另一途径求网的最小生成树。假设连通网  $N = (V, \{E\})$ ，则令最小生成树的初始状态为只有  $n$  个顶点而无边的非连通图  $T = (V, \{\})$ ，图中每个顶点自成一个连通分量。在  $E$  中选择代价最小的边，若该边依附的顶点落在  $T$  中不同的连通分量上，则将此边加入到  $T$  中，否则舍去此边而选择下一条代价最小的边。依次类推，直至  $T$

中所有顶点都在同一连通分量上为止。

例如，图7.18所示为依照克鲁斯卡尔算法构造一棵最小生成树的过程。代价分别为

![](images/3b0a49723fce71d5c75c2d1678b1fc92047b0b699ce394fb24e64a14ac28e328.jpg)

![](images/79ee05ebe5d17749530c7471df4ee7811363dadd28e37a17a4b2f7b32695eb57.jpg)

![](images/482e8e3dd92dfe9a6d8bee18d9630c6db2775e2c583f71bce815bdf038aff4eb.jpg)

![](images/197541ecd5f910b11bdf97978d39ffa98ff532d63c1cbb9d70ad072480c72f70.jpg)  
图7.18 克鲁斯卡尔算法构造最小生成树的过程

![](images/beb29dbbfb6f38bb8811b07606161bf68ecb217b5cb661d9e32da43ddbc74018.jpg)

1,2,3,4的4条边由于满足上述条件，则先后被加入到  $T$  中，代价为5的两条边  $(v_{1},v_{4})$  和  $(v_{3},v_{4})$  被舍去。因为它们依附的两顶点在同一连通分量上，它们若加入  $T$  中，则会使 $T$  中产生回路，而下一条代价  $(= 5)$  最小的边  $(v_{2},v_{3})$  联结两个连通分量，则可加入  $T$  。由此，构造成一棵最小生成树。

上述算法至多对  $e$  条边各扫描一次，假若以第 9 章将介绍的“堆”来存放网中的边，则每次选择最小代价的边仅需  $O(\log e)$  的时间（第一次需  $O(e)$ ）。又生成树  $T$  的每个连通分量可看成是一个等价类，则构造  $T$  加入新的边的过程类似于求等价类的过程，由此可以以 6.5 节中介绍的 MFSet 类型来描述  $T$ ，使构造  $T$  的过程仅需  $O(\log e)$  的时间，由此，克鲁斯卡尔算法的时间复杂度为  $O(\log e)$ 。

# 7.4.4 关节点和重连通分量

假若在删去顶点  $v$  以及和  $v$  相关联的各边之后, 将图的一个连通分量分割成两个或两个以上的连通分量, 则称顶点  $v$  为该图的一个关节点(articulation point)。一个没有关节点的连通图称为是重连通图(biconnected graph)。在重连通图上, 任意一对顶点之间至少存在两条路径, 则在删去某个顶点以及依附于该顶点的各边时也不破坏图的连通性。若在连通图上至少删去  $k$  个顶点才能破坏图的连通性, 则称此图的连通度为  $k$  。关节点和重连通在实际中有较多应用。显然, 一个表示通信网络的图的连通度越高, 其系统越可靠, 无论是哪一站点出现故障或遭到外界破坏, 都不影响系统的正常工作; 又如, 一个航空网若是重连通的, 则当某条航线因天气等某种原因关闭时, 旅客仍可从别的航线绕道而行; 再如, 若将大规模集成电路的关键线路设计成重连通的话, 则在某些元件失效的情况下, 整个片子的功能不受影响, 反之, 在战争中, 若要摧毁敌方的运输线, 仅需破坏其运输网中的关节点即可。

例如，图7.19中图  $G_{5}$  是连通图，但不是重连通图。图中有4个关节点  $A, B, D$  和  $G$ 。若删去顶点  $B$  以及所有依附顶点  $B$  的边， $G_{5}$  就被分割成3个连通分量  $\{A, C, F, L, M\}$ 。

$J\}$  、  $\{G,H,I,K\}$  和  $\{D,E\}$  。类似地，若删去顶点  $A$  或  $D$  或  $G$  以及所有依附于它们的边，则  $G_{5}$  被分割成两个连通分量，由此，关节点亦称割点。

利用深度优先搜索便可求得图的关节点，并由此可判别图是否是重连通的。

![](images/5024c06eefc3bda79a4eb44784f8ff617949753ca4829bf58f99cefdb37f9e77.jpg)  
图7.19 连通图  $G_{5}$

![](images/84b3247fb5bf79d0a51f0fdc0f021cd2238b79ccb0c3217520830b32dccbdecb.jpg)  
图7.20  $G_{5}$  的深度优先生成树

图7.20所示为从顶点  $A$  出发深度优先搜索遍历图  $G_{5}$  所得深度优先生成树，图中实线表示树边，虚线表示回边（即不在生成树上的边）。对树中任一顶点  $\pmb{v}$  而言，其孩子结点为在它之后搜索到的邻接点，而其双亲结点和由回边联结的祖先结点是在它之前搜索到的邻接点。由深度优先生成树可得出两类关节点的特性：

（1）若生成树的根有两棵或两棵以上的子树，则此根顶点必为关节点。因为图中不存在联结不同子树中顶点的边，因此，若删去根顶点，生成树便变成生成森林。如图7.20中的顶点  $A$  。  
（2）若生成树中某个非叶子顶点  $v$ ，其某棵子树的根和子树中的其他结点均没有指向  $v$  的祖先的回边，则  $v$  为关节点。因为，若删去  $v$ ，则其子树和图的其他部分被分割开来。如图7.20中的顶点  $B, D$  和  $G$ 。

若对图  $\mathrm{Graph} = (\mathrm{V},\{\mathrm{Edge}\})$  重新定义遍历时的访问函数visited，并引入一个新的函数low，则由一次深度优先搜索遍历便可求得连通图中存在的所有关键节点。

定义visited[v]为深度优先搜索遍历连通图时访问顶点  $\pmb{v}$  的次序号；定义

$$
\begin{array}{r} {\mathrm {l o w} (\mathbf {v}) = \mathrm {M i n} \left\{ \begin{array}{l l} & {\mathbf {w} \text {是 顶 点} \mathbf {v} \text {在 深 度 优 先 生 成 树 上 的 孩 子 结 点};} \\ {\mathrm {v i s i t e d} [ \mathbf {v} ], \mathrm {l o w} [ \mathbf {w} ], \mathrm {v i s i t e d} [ \mathbf {k} ]} & {\mathbf {k} \text {是 顶 点} \mathbf {v} \text {在 深 度 优 先 生 成 树 上 由 回 边 联 结 的}} \\ & {\mathbf {\text {祖 先 结 点}};} \\ & {(\mathbf {v}, \mathbf {w}) \in \mathrm {E d g e},} \\ & {(\mathbf {v}, \mathbf {k}) \in \mathrm {E d g e},} \end{array} \right\}} \end{array}
$$

若对于某个顶点  $v$ , 存在孩子结点  $w$  且  $\mathrm{low}[\mathbf{w}] \geqslant \mathrm{visited}[\mathbf{v}]$ , 则该顶点  $v$  必为关节点。因为当  $w$  是  $v$  的孩子结点时,  $\mathrm{low}[\mathbf{w}] \geqslant \mathrm{visited}[\mathbf{v}]$ , 表明  $w$  及其子孙均无指向  $v$  的祖先的回边。

由定义可知，visited[v]值即为  $v$  在深度优先生成树的前序序列中的序号，只需将

DFS函数中头两个语句改为visited[v0] = ++count（在DFSTraverse中设初值count=1)即可；low[v]可由后序遍历深度优先生成树求得，而  $\pmb{v}$  在后序序列中的次序和遍历时退出DFS函数的次序相同，由此修改深度优先搜索遍历的算法便可得到求关节点的算法(见算法7.10和算法7.11)。

```txt
void FindArticul(ALGraph G) { // 连通图G以邻接表作存储结构,查找并输出G上全部关节点。全局量count 对访问计数。 count = 1; visited[0] = 1; // 设定邻接表上0号顶点为生成树的根 for (i = 1; i < G.vexnum; ++i) visited[i] = 0; // 其余顶点尚未访问 p = G.vectrics[0].firstarc; v = p->adjvex; DFSArticul(G, v); // 从第  $\mathbf{V}$  顶点出发深度优先查找关节点。 if (count < G.vexnum) { // 生成树的根有至少两棵子树 printf(0, G.vectrics[0].data); // 根是关节点,输出 while (p->nextarc) { p = p->nextarc; v = p->adjvex; if (visited[v] == 0) DFSArticul(g, v); } // while } // if } // FindArticul
```

# 算法 7.10

```txt
void DFSArticul(ALGraph G, int v0) {
    // 从第 v0 个顶点出发深度优先遍历图 G, 查找并输出关节点。
    visited[v0] = min = ++count; // v0 是第 count 个访问的顶点
    for (p = G.vertices[v0].firstarc; p; p = p->nextarc) { // 对 v0 的每个邻接顶点检查 w = p->adjvex; // w 为 v0 的邻接顶点
        if (visited[w] == 0) { // w 未曾访问, 是 v0 的孩子
            DFSArticul(G, w); // 返回前求得 low[w]
            if (low[w] < min) min = low[w];
            if (low[w] >= visited[v0]) printf(v0, G.vertices[v0].data); // 关节点 }
        else if (visited[w] < min) min = visited[w]; // w 已访问, w 是 v0 在生成树上的祖先
    } // for
    low[v0] = min;
} // DFSArticul
```

# 算法 7.11

例如，图  $G_{5}$  中各顶点计算所得visited和low的函数值如下所列：

<table><tr><td>i</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>G. vertices[i]. data</td><td>A</td><td>B</td><td>C</td><td>D</td><td>E</td><td>F</td><td>G</td><td>H</td><td>I</td><td>J</td><td>K</td><td>L</td><td>M</td></tr><tr><td>visited[i]</td><td>1</td><td>5</td><td>12</td><td>10</td><td>11</td><td>13</td><td>8</td><td>6</td><td>9</td><td>4</td><td>7</td><td>2</td><td>3</td></tr><tr><td>low[i]</td><td>1</td><td>1</td><td>1</td><td>5</td><td>10</td><td>1</td><td>5</td><td>5</td><td>8</td><td>2</td><td>5</td><td>1</td><td>1</td></tr><tr><td>求得 low 值的顺序</td><td>13</td><td>9</td><td>8</td><td>7</td><td>6</td><td>12</td><td>3</td><td>5</td><td>2</td><td>1</td><td>4</td><td>11</td><td>10</td></tr></table>

其中J是第一个求得low值的顶点，由于存在回边  $(J,L)$  ，则  $\mathrm{low}[\mathrm{J}] = \mathrm{Min}\{\mathrm{visited}[\mathrm{J}]$  visited[L]  $\} = 2$  。顺便提一句，上述算法中将指向双亲的树边也看成是回边，由于不影响关节点的判别，因此，为使算法简明起见，在算法中没有区别之。

由于上述算法的过程就是一个遍历的过程，因此，求关节点的时间复杂度仍为  $O(n + e)$  。若尚需输出双连通分量，仅需在算法中增加一些语句即可，在此不再详述，留给读者自己完成。

# 7.5 有向无环图及其应用

一个无环的有向图称做有向无环图（directedacyclinegraph），简称DAG图。DAG

图是一类较有向树更一般的特殊有向图，如图7.21列示了有向树、DAG图和有向图的例子。

有向无环图是描述含有公共子式的表达式的有效工具。例如下述表达式

$$
\begin{array}{l} ((a + b) * (b * (c + d)) + (c + d) * \\ e) * ((c + d) * e) \\ \end{array}
$$

![](images/e1fb818713d93a1a9e3427fa426ffb2b9e5b76ca7ad5ad4458a282172da6d0cb.jpg)  
图7.21 有向树、DAG图和有向图一例

可以用第6章讨论的二叉树来表示，如图7.22所示。仔细观察该表达式，可发现有一些相同的子表达式，如  $(c + d)$  和  $(c + d)*e$  等，在二叉树中，它们也重复出现。若利用有向

![](images/7eb0729592102fde75e765c81cd8ecf453ffb36ee899ef93e7e6f1198cde7483.jpg)  
图7.22 用二叉树描述表达式

![](images/dcf364faccddd79aed5efa8d82e2c8eecf0faf18d12e0996c8821487fc29a00b.jpg)  
图7.23 描述表达式的有向无环图

无环图, 则可实现对相同子式的共享, 从而节省存储空间。例如图7.23所示为表示同一表达式的有向无环图。

检查一个有向图是否存在环要比无向图复杂。对于无向图来说，若深度优先遍历过程中遇到回边（即指向已访问过的顶点的边），则必定存在环；而对于有向图来说，这条回边有可能是指向深度优先生成森林中另一棵生成树上顶点的弧。但是，如果从有向图上某个顶点  $v$  出发的遍历，在  $\mathrm{dfs}(v)$  结束之前出现一条从顶点  $u$  到顶点  $v$  的回边（如图7.24所示），由于  $u$  在生成树上是  $v$  的子孙，则有向图中必定存在包含顶点  $v$  和  $u$  的环。

有向无环图也是描述一项工程或系统的进行过程的有效工具。除最简单的情况之

外, 几乎所有的工程 (project) 都可分为若干个称做活动 (activity) 的子工程, 而这些子工

程之间，通常受着一定条件的约束，如其中某些子工程的开始必须在另一些子工程完成之后。对整个工程和系统，人们关心的是两个方面的问题：一是工程能否顺利进行；二是估算整个工程完成所必须的最短时间，对应于有向图，即为进行拓扑排序和求关键路径的操作。下面分别就这两个问题讨论之。

# 7.5.1 拓扑排序

什么是拓扑排序 (Topological Sort)? 简单地说, 由某个集合上的一个偏序得到该集合上的一个全序, 这个操作称之为拓扑排序。回顾离散数学中关于偏序和全序的定义:

![](images/f1740573866009ae1792938c1170b3133bf7fd9b24cb6a28536cfc07230c2b77.jpg)  
图7.24 含有环的有向图的深度优先生成树

若集合  $X$  上的关系  $R$  是自反的、反对称的和传递的，则称  $R$  是集合  $X$  上的偏序关系。

设  $R$  是集合  $X$  上的偏序(Partial Order)，如果对每个  $x, y \in X$  必有  $xRy$  或  $yRx$ ，则称  $R$  是集合  $X$  上的全序关系。

直观地看，偏序指集合中仅有部分成员之间可比较，而全序指集合中全体成员之间均可比较。例如，图7.25所示的两个有向图，图中弧  $\langle x, y \rangle$  表示  $x \leqslant y$  ，则(a)表示偏序，

(a)  
图7.25 表示偏序和全序的有向图  
![](images/4c09924eb13f8465b723b6d4d1674b25a9ddf57bad79b1d3345d4feb0cfcedab.jpg)  
(a) 表示偏序；(b) 表示全序

![](images/e47d9e95bb5b610b71fc02fa8cd9bd518fb03fcb222ef0d3a6da38a5817e3fd6.jpg)  
(b)

(b)表示全序。若在(a)的有向图上人为地加一个表示  $v_{2} \leqslant v_{3}$  的弧（符号“≤”表示  $v_{2}$  领先于  $v_{3}$ ），则(a)表示的亦为全序，且这个全序称为拓扑有序（Topological Order），而由偏序定义得到拓扑有序的操作便是拓扑排序。

一个表示偏序的有向图可用来表示一个流程图。它或者是一个施工流程图，或者是一个产品生产的流程图，再或是一个数据流图（每个顶点表示一个过程）。图中每一条有向边表示两个子工程之间的次序关系（领先关系）。

例如，一个软件专业的学生必须学习一系列基本课程（如图7.26所示），其中有些课程是基础课，它独立于其他课程，如《高等数学》；而另一些课程必须在学完作为它的基础的先修课程才能开始。如，在《程序设计基础》和《离散数学》学完之前就不能开始学习《数据结构》。这些先决条件定义了课程之间的领先(优先)关系。这个关系可以用有向图更清楚地表示，如图7.27所示。图中顶点表示课程，有向边(弧)表示先决条件。若课程i

是课程  $j$  的先决条件，则图中有弧  $\langle i,j\rangle$

这种用顶点表示活动，用弧表示活动间的优先关系的有向图称为顶点表示活动的网（Activity On Vertex Network），简称AOV-网。在网中，若从顶点  $i$  到顶点  $j$  有一条有向路径，则  $i$  是  $j$  的前驱； $j$  是  $i$  的后继。若  $\langle i, j \rangle$  是网中一条弧，则  $i$  是  $j$  的直接前驱； $j$  是  $i$  的直接后继。

<table><tr><td>课程编号</td><td>课程名称</td><td>先决条件</td></tr><tr><td>C1</td><td>程序设计基础</td><td>无</td></tr><tr><td>C2</td><td>离散数学</td><td>C1</td></tr><tr><td>C3</td><td>数据结构</td><td>C1,C2</td></tr><tr><td>C4</td><td>汇编语言</td><td>C1</td></tr><tr><td>C5</td><td>语言的设计和分析</td><td>C3,C4</td></tr><tr><td>C6</td><td>计算机原理</td><td>C11</td></tr><tr><td>C7</td><td>编译原理</td><td>C5,C3</td></tr><tr><td>C8</td><td>操作系统</td><td>C3,C6</td></tr><tr><td>C9</td><td>高等数学</td><td>无</td></tr><tr><td>C10</td><td>线性代数</td><td>C9</td></tr><tr><td>C11</td><td>普通物理</td><td>C9</td></tr><tr><td>C12</td><td>数值分析</td><td>C9,C10,C1</td></tr></table>

图7.26 软件专业的学生必须学习的课程

在  $AOV$  网中，不应该出现有向环，因为存在环意味着某项活动应以自己为先决条件。显然，这是荒谬的。若设计出这样的流程图，工程便无法进行。而对程序的数据流图来说，则表明存在一个死循环。因此，对给定的  $AOV$  网应首先判定网中是否存在环。检测的办法是对有向图构造其顶点的拓扑有序序列，若网中所有顶点都在它的拓扑有序序列中，则该  $AOV$  网中必定不存在环。例如，图7.27的有向图有如下两个拓扑有序序列：

![](images/54b609b5c6b586edb0f88d2a337dd5463430c419ccc0605baff308ac48753366.jpg)  
图7.27 表示课程之间优先关系的有向图

$$
\left(C _ {1}, C _ {2}, C _ {3}, C _ {4}, C _ {5}, C _ {7}, C _ {9}, C _ {1 0}, C _ {1 1}, C _ {6}, C _ {1 2}, C _ {8}\right)
$$

和

$$
\left(C _ {9}, C _ {1 0}, C _ {1 1}, C _ {6}, C _ {1}, C _ {1 2}, C _ {4}, C _ {2}, C _ {3}, C _ {5}, C _ {7}, C _ {8}\right)
$$

(当然, 对此图也可构造得其他的拓扑有序序列)。若某个学生每学期只学一门课程的话, 则他必须按拓扑有序的顺序来安排学习计划。

如何进行拓扑排序？解决的方法很简单：

（1）在有向图中选一个没有前驱的顶点且输出之。  
（2）从图中删除该顶点和所有以它为尾的弧。

重复上述两步，直至全部顶点均已输出，或者当前图中不存在无前驱的顶点为止。后一种情况则说明有向图中存在环。

以图7.28(a)中的有向图为例，图中，  $v_{1}$  和  $v_{6}$  没有前驱，则可任选一个。假设先输出 $v_{6}$ ，在删除  $v_{6}$  及弧  $\langle v_6,v_1\rangle ,\langle v_6,v_5\rangle$  之后，只有顶点  $v_{1}$  没有前驱，则输出  $v_{1}$  且删去  $v_{1}$  及弧 $\langle v_1,v_2\rangle ,\langle v_1,v_3\rangle$  和  $\langle v_1,v_4\rangle$  ，之后  $v_{3}$  和  $v_{4}$  都没有前驱。依次类推，可从中任选一个继续进行。整个拓扑排序的过程如图7.28所示。最后得到该有向图的拓扑有序序列为：

$$
v _ {6} - v _ {1} - v _ {4} - v _ {3} - v _ {2} - v _ {3}.
$$

(a)  
![](images/39c242ff7a596b492cf1912f2ee4b23536436d44680c0a8b5c75a28889b200e9.jpg)  
(a) AOV-网；(b) 输出  $v_{6}$  之后；(c) 输出  $v_{1}$  之后；

(b)  
![](images/48b7107ffcdd2cadbdad61fe5fb694e60549bd397bb47f2b343d10c38b92c69f.jpg)  
(d) 输出  $v_{4}$  之后；(e) 输出  $v_{3}$  之后；(f) 输出  $v_{2}$  之后

![](images/e9b4eb269a8a6bb71a1d22b594822bba012fb23cc6aaa0f91ff1631bf4b59897.jpg)  
(c)  
图7.28  $\Lambda (0)\mathbf{V}$  -网及其拓扑有序序列产生的过程

![](images/1d22c0d3775183c6a5c1b15377be37ae21e52a4bf8841b22086081b512868cce.jpg)  
(d)

![](images/d209174846f75b71d088bd1c606f7562c323c14fc3fc1d821eb580c72f71b09b.jpg)  
(e)

![](images/7220509cffcde8559b18086f09b56d9ea8879d33e8b0e6fdb9cae9e07a7f4687.jpg)  
(f)

如何在计算机中实现？针对上述两步操作，我们可采用邻接表作有向图的存储结构，且在头结点中增加一个存放顶点入度的数组(indegree)。入度为零的顶点即为没有前驱的顶点，删除顶点及以它为尾的弧的操作，则可换以弧头顶点的入度减1来实现。

为了避免重复检测入度为零的顶点，可另设一栈暂存所有人度为零的顶点，由此可得拓扑排序的算法如算法7.12所示。

```txt
Status TopologicalSort(ALGraph G) { //有向图G采用邻接表存储结构。 //若G无回路，则输出G的顶点的一个拓扑序列并返回OK，否则ERROR。 FindInDegree(G, indegree); //对各顶点求入度 indegree[0..vernum-1] InitStack(S); for  $(\mathrm{i} = 0$  ：  $\mathrm{i} <   \mathrm{G}$  .vexnum;  $+ + \mathrm{i})$  //建零入度顶点栈S if(!indegree[i])Push(S,i); //入度为0者进栈 count  $= 0$  ; //对输出顶点计数 while(!StackEmpty(S)) { Pop(S.i):printf(i.G.vectrics[i].data); ++count; //输出i号顶点并计数 for(p-G. vertices.i|.firstarc:p; p=p->nextarc）{ k-p-adjvex; //对i号顶点的每个邻接点的人度减1 if(!（-indegree[k]）)Push(S,k);//若入度减为0.则入栈 }//for }//while if(count<G.vexnum) return ERROR; //该有向图有回路 else return OK; } //TopologicalSort
```

# 算法 7.12

分析算法7.12，对有  $n$  个顶点和  $\pmb{e}$  条弧的有向图而言，建立求各顶点的入度的时间复杂度为  $O(e)$ ；建零入度顶点栈的时间复杂度为  $O(n)$ ；在拓扑排序过程中，若有向图无环，则每个顶点进一次栈，出一次栈，入度减1的操作在WHILE语句中总共执行  $\pmb{e}$  次，所以，总的时间复杂度为  $O(n + e)$ 。上述拓扑排序的算法亦是下节讨论的求关键路径的基础。

当有向图中无环时，也可利用深度优先遍历进行拓扑排序，因为图中无环，则由图中某点出发进行深度优先搜索遍历时，最先退出DFS函数的顶点即出度为零的顶点，是拓扑有序序列中最后一个顶点。由此，按退出DFS函数的先后记录下来的顶点序列（如同求强连通分量时finished数组中的顶点序列)即为逆向的拓扑有序序列。

# 7.5.2 关键路径

与AOV-网相对应的是AOE-网(ActivityOnEdge)即边表示活动的网。AOE-网是一个带权的有向无环图，其中，顶点表示事件(Event)，弧表示活动，权表示活动持续的时间。通常，AOE-网可用来估算工程的完成时间。

例如，图7.29是一个假想的有11项活动的AOE-网。其中有9个事件  $v_{1}, v_{2}, v_{3}, \cdots, v_{9}$ ，每个事件表示在它之前的活动已经完成，在它之后的活动可以开始。如  $v_{1}$  表示整个工程开始， $v_{9}$  表示整个工程结束， $v_{5}$  表示  $a_{4}$  和  $a_{5}$  已经完成， $a_{7}$  和  $a_{8}$  可以开始。与每个活动相联系的数是执行该活动所需的时间。比如，活动  $a_{1}$  需要6天， $a_{2}$  需要4天等。

![](images/18f17a9dc63ad2a3c879ede9d5057f1f1596dbca1b96df4bdc829b6916cd5f8c.jpg)  
图7.29 一个AOE-网

由于整个工程只有一个开始点和一个完成点，

故在正常的情况(无环)下，网中只有一个人度为零的点（称做源点）和一个出度为零的点（叫做汇点）。

和AOV-网不同，对AOE-网有待研究的问题是：（1)完成整项工程至少需要多少时间？(2)哪些活动是影响工程进度的关键？

由于在AOE-网中有些活动可以并行地进行，所以完成工程的最短时间是从开始点到完成点的最长路径的长度(这里所说的路径长度是指路径上各活动持续时间之和，不是路径上弧的数目)。路径长度最长的路径叫做关键路径(Critical Path)。假设开始点是  $v_{1}$ ，从  $v_{1}$  到  $v_{i}$  的最长路径长度叫做事件  $v_{i}$  的最早发生时间。这个时间决定了所有以  $v_{i}$  为尾的弧所表示的活动的最早开始时间。我们用  $e(i)$  表示活动  $a_{i}$  的最早开始时间。还可以定义一个活动的最迟开始时间  $l(i)$ ，这是在不推迟整个工程完成的前提下，活动  $a_{i}$  最迟必须开始进行的时间。两者之差  $l(i) - e(i)$  意味着完成活动  $a_{i}$  的时间余量。我们把  $l(i) = e(i)$  的活动叫做关键活动。显然，关键路径上的所有活动都是关键活动，因此提前完成非关键活动并不能加快工程的进度。例如图7.29中的网，从  $v_{1}$  到  $v_{9}$  的最长路径是  $(v_{1}, v_{2}, v_{5}, v_{8}, v_{9})$ ，路径长度是18，即  $v_{9}$  的最早发生时间是18。而活动  $a_{6}$  的最早开始时间是5，最迟开始时间是8，这意味着：如果  $a_{6}$  推迟3天开始或者延迟3天完成，都不会影响整个工程的完成。因此，分析关键路径的目的是辨别哪些是关键活动，以便争取提高关

键活动的工效，缩短整个工期。

由上分析可知，辨别关键活动就是要找  $e(i) = l(i)$  的活动。为了求得AOE-网中活动的  $e(i)$  和  $l(i)$ ，首先应求得事件的最早发生时间  $\boldsymbol{v}\boldsymbol{e}(\boldsymbol{j})$  和最迟发生时间  $\boldsymbol{vl}(\boldsymbol{j})$ 。如果活动  $a_{i}$  由弧  $\langle j,k\rangle$  表示，其持续时间记为  $dut(\langle j,k\rangle)$ ，则有如下关系

$$
\begin{array}{l} e (i) = v e (j) \\ l (i) = v l (k) - d u t (\langle j, k \rangle) \tag {7-1} \\ \end{array}
$$

求  $ve(j)$  和  $vl(j)$  需分两步进行：

（1）从  $ve(0) = 0$  开始向前递推

$$
\begin{array}{l} v e (j) = \underset {i} {\operatorname {M a x}} \left\{v e (i) + d u t (\langle i, j \rangle) \right\} \tag {7-2} \\ \langle i, j \rangle \in T, \quad j = 1, 2, \dots , n - 1 \\ \end{array}
$$

其中，  $T$  是所有以第  $j$  个顶点为头的弧的集合。

（2）从  $vl(n - 1) = ve(n - 1)$  起向后递推

$$
\begin{array}{l} v l (i) = \underset {j} {\operatorname {M i n}} \left\{v l (j) - d u t (\langle i, j \rangle) \right\} \tag {7-3} \\ \langle i, j \rangle \in S, \quad i = n - 2, \dots , 0 \\ \end{array}
$$

其中， $S$  是所有以第  $i$  个顶点为尾的弧的集合。

这两个递推公式的计算必须分别在拓扑有序和逆拓扑有序的前提下进行。也就是说， $ve(j - 1)$  必须在  $v_{j}$  的所有前驱的最早发生时间求得之后才能确定，而  $vl(j - 1)$  则必须在  $v_{j}$  的所有后继的最迟发生时间求得之后才能确定。因此，可以在拓扑排序的基础上计算  $ve(j - 1)$  和  $vl(j - 1)$ 。

由此得到如下所述求关键路径的算法：

（1）输入  $e$  条弧  $\langle j,k\rangle$  ，建立AOE-网的存储结构；  
(2) 从源点  $v_{0}$  出发, 令  $ve[0] = 0$ , 按拓扑有序求其余各顶点的最早发生时间  $ve[i]$ $(1 \leqslant i \leqslant n - 1)$  。如果得到的拓扑有序序列中顶点个数小于网中顶点数  $n$ , 则说明网中存在环, 不能求关键路径, 算法终止; 否则执行步骤 (3)。  
（3）从汇点  $v_{n}$  出发，令  $vl[n - 1] = ve[n - 1]$ ，按逆拓扑有序求其余各顶点的最迟发生时间  $vl[i](n - 2 \geqslant i \geqslant 2)$ ；  
（4）根据各顶点的  $ve$  和  $vl$  值，求每条弧  $s$  的最早开始时间  $e(s)$  和最迟开始时间l(s)。若某条弧满足条件  $e(s) = l(s)$ ，则为关键活动。

如上所述，计算各顶点的  $ve$  值是在拓扑排序的过程中进行的，需对拓扑排序的算法作如下修改：(a)在拓扑排序之前设初值，令  $ve[i] = 0 (0 \leqslant i \leqslant n - 1)$ ；(b)在算法中增加一个计算  $v_{j}$  的直接后继  $v_{k}$  的最早发生时间的操作：若  $ve[j] + du t(\langle j, k \rangle) > ve[k]$ ，则  $ve[k] = ve[j] + du t(\langle j, k \rangle)$ ；(c)为了能按逆拓扑有序序列的顺序计算各顶点的  $vl$  值，需记下在拓扑排序的过程中求得的拓扑有序序列，这需要在拓扑排序算法中，增设一个栈以记录拓扑有序序列，则在计算求得各顶点的  $ve$  值之后，从栈顶至栈底便为逆拓扑有序序列。

先将算法7.12改写成算法7.13，则算法7.14便为求关键路径的算法。

```c
Status TopologicalOrder(ALGraph G, Stack &T) {
// 有向网G采用邻接表存储结构，求各顶点事件的最早发生时间ve(全局变量)。
// T为拓扑序列顶点栈，S为零入度顶点栈。
// 若G无回路，则用栈T返回G的一个拓扑序列，且函数值为OK，否则为ERROR。
FindInDegree(G, indegree); // 对各顶点求入度 indegree[0..vernum-1]
建零入度顶点栈S;
InitStack(T); count = 0; ve[0..G.vexnum-1] = 0; // 初始化
while (!StackEmpty(S)) {
Pop(S, j); Push(T, j); ++count; // j号顶点入T栈并计数
for (p = G.vertices[j].firstarc; p; p->nextarc) {
k = p->adjvex; // 对j号顶点的每个邻接点的入度减1
if (-- indegree[k] == 0) Push(S, k); // 若入度减为0，则入栈
if (ve[j] + *(p->info) > ve[k]) ve[k] = ve[j] + *(p->info);
} // for * (p->info) = dut(<j,k>)
```

# 算法 7.13

```txt
Status CriticalPath((ALGraph G) {
// G为有向网，输出G的各项关键活动。
if (!TopologicalOrder(G, T)) return ERROR;
vl[0..G.vexnum-1] = ve[G.vexnum-1]; //初始化顶点事件的最迟发生时间
while (!StackEmpty(T)) //按拓扑逆序求各顶点的vl值
for (Pop(T, j), p = G.vertices[j].firstarc; p; p = p->nextarc) {
k = p->adjvex; dut = *(p->info); // dut < j, k>
if (vl[k]-dut < vl[j]) vl[j] = vl[k]-dut;
} // for
for (j = 0; j < G.vexnum; ++j) //求ee, el和关键活动
for (p = G.vertices[j].firstarc; p; p = p->nextarc) {
k = p->adjvex; dut = *(p->info);
ee = ve[j]; el = vl[k]-dut;
tag = (ee == el)? ':*': '';
printf(j, k, dut, ee, el, tag); //输出关键活动
}
```

# 算法 7.14

由于逆拓扑排序必定在网中无环的前提下进行, 则亦可利用DFS函数, 在退出DFS函数之前按式(7-3)计算顶点  $v$  的  $vl$  值(因为此时  $v$  的所有直接后继的  $vl$  值都已求出)。

这两种算法的时间复杂度均为  $O(n + e)$ ，显然，前一种算法的常数因子要小些。由于计算弧的活动最早开始时间和最迟开始时间的复杂度为  $O(e)$ ，所以总的求关键路径的时间复杂度为  $O(n + e)$ 。

例如，对图7.30(a)所示网的计算结果如图7.31所示，可见  $a_2, a_5$  和  $a_7$  为关键活动，组成一条从源点到汇点的关键路径，如图7.30(b)所示。

图7.30 AOE-网及其关键路径  
![](images/bea8d3876ce80c5a6f20c63d0beb05ccd71477267fa8bbc05132103e6fc4109e.jpg)  
(a)AOE-网； (b）关键路径

![](images/f1c675223b0210af30d94b49804be2cc2da3cc7e19e54112a55655a67880ae32.jpg)  
图7.31 图7.30(a)所示AOE-网中顶点的发生时间和活动的开始时间

<table><tr><td>顶点</td><td>ve</td><td>vl</td><td>活动</td><td>e</td><td>l</td><td>l-e</td></tr><tr><td>v1</td><td>0</td><td>0</td><td>a1</td><td>0</td><td>1</td><td>1</td></tr><tr><td>v2</td><td>3</td><td>4</td><td>a2</td><td>0</td><td>0</td><td>0</td></tr><tr><td>v3</td><td>2</td><td>2</td><td>a3</td><td>3</td><td>4</td><td>1</td></tr><tr><td>v4</td><td>6</td><td>6</td><td>a4</td><td>3</td><td>4</td><td>1</td></tr><tr><td>v5</td><td>6</td><td>7</td><td>a5</td><td>2</td><td>2</td><td>0</td></tr><tr><td>v6</td><td>8</td><td>8</td><td>a6</td><td>2</td><td>5</td><td>3</td></tr><tr><td></td><td></td><td></td><td>a7</td><td>6</td><td>6</td><td>0</td></tr><tr><td></td><td></td><td></td><td>a8</td><td>6</td><td>7</td><td>1</td></tr></table>

对于图7.29所示的网，可计算求得关键活动为  $a_1, a_4, a_7, a_8, a_{10}$  和  $a_{11}$  。如图7.32所示，它们构成两条关键路径： $(v_1, v_2, v_5, v_7, v_9)$  和  $(v_1, v_2, v_5, v_8, v_9)$  。

实践已经证明：用AOE-网来估算某些工程完成的时间是非常有用的。实际上，求关键路径的方法本身最初就是与维修和建造工程一起发展的。但是，由于网中各项活动是

![](images/da458d94f99f1c65b4b72253f7296e88bc930473847b1b4e56ba7da8d1289fff.jpg)  
图7.32 图7.29所示网的关键路径

互相牵涉的，因此，影响关键活动的因素亦是多方面的，任何一项活动持续时间的改变都会影响关键路径的改变。例如，对于图7.30(a)所示的网来说，若  $a_5$  的持续时间改为3，则可发现，关键活动数量增加，关键路径也增加。若同时将  $a_4$  的时间改成4，则  $(v_{1}, v_{3}, v_{4}, v_{6})$  不再是关键路径。由此可见，关键活动的速度

提高是有限度的。只有在不改变网的关键路径的情况下，提高关键活动的速度才有效。

另一方面，若网中有几条关键路径，那么，单是提高一条关键路径上的关键活动的速度，还不能导致整个工程缩短工期，而必须提高同时在几条关键路径上的活动的速度。

# 7.6 最短路径

假若要在计算机上建立一个交通咨询系统则可以采用图的结构来表示实际的交通网络。如图7.33所示，图中顶点表示城市，边表示城市间的交通联系。这个咨询系统可以回答。旅客提出的各种问题。例如，一位旅客要从A城到B城，他希望选择一条途中中转次数最少的路线。假设图中每一站都需要换车，则这个问题反映到图上就是要找一条

![](images/40c53178ab5e7e4f99d253005fae3f186041ee304967da5607f2778b8ad34a39.jpg)  
图7.33 一个表示交通网的例图

从顶点  $A$  到  $B$  所含边的数目最少的路径。我们只需从顶点  $A$  出发对图作广度优先搜索，一旦遇到顶点  $B$  就终止。由此所得广度优先生成树上，从根顶点  $A$  到顶点  $B$  的路径就是中转次数最少的路径，路径上  $A$  与  $B$  之间的顶点就是途径的中转站数，但是，这只是一类最简单的图的最短路径问题。有时，对于旅客来说，可能更关心的是节省交通费用；而对于司机来说，里程和速度则是他们感兴趣的信息。为了在图上表示有关信息，可对边赋以权，权的值表示两城市间的距离，或途中所需时间，或交通费用等等。此时路径长度的度量就不再是路径上边的数目，而是路径上边的权值之和。考虑到交通图的有向性（如航运，逆水和顺水时的船速就不一样），本节将讨论带权有向图，并称路径上的第一个顶点为源点(Sourse)，最后一个顶点为终点(Destination)。下面讨论两种最常见的最短路径问题。

# 7.6.1 从某个源点到其余各顶点的最短路径

我们先来讨论单源点的最短路径问题：给定带权有向图  $G$  和源点  $\pmb{v}$ ，求从  $\pmb{v}$  到  $G$  中其余各顶点的最短路径。

例如，图7.34所示带权有向图  $G_{6}$  中从  $\pmb{v}_{0}$  到其余各顶点之间的最短路径，如图7.35所示。从图中可见，从  $\pmb{v}_{0}$  到  $\pmb{v}_{3}$  有两条不同的路径： $(v_{0}, v_{2}, v_{3})$  和  $(v_{0}, v_{4}, v_{3})$  ，前者长度为60，而后者的长度为50。因此，后者是从  $\pmb{v}_{0}$  到  $\pmb{v}_{3}$  的最短路径；而从  $\pmb{v}_{0}$  到  $\pmb{v}_{1}$  没有路径。

如何求得这些路径？迪杰斯特拉(Dijkstra)提出了一个按路径长度递增的次序产生最短路径的算法。

首先，引进一个辅助向量  $D$  ，它的每个分量  $D[i]$  表示当前所找到的从始点  $\pmb{v}$  到每个

![](images/c3a6aa154b1a4ec58f29602238906d27286e003122c0a25fb369f26fe2d6a75e.jpg)  
图7.34 带权有向图  $G_{5}$

<table><tr><td>始点</td><td>终点</td><td>最短路径</td><td>路径长度</td></tr><tr><td>v0</td><td>v1</td><td>无</td><td></td></tr><tr><td></td><td>v2</td><td>(v0, v2)</td><td>10</td></tr><tr><td></td><td>v3</td><td>(v1, v1, v4)</td><td>50</td></tr><tr><td></td><td>v4</td><td>(v0, v4)</td><td>30</td></tr><tr><td></td><td>v5</td><td>(v0, v4, v3, v5)</td><td>60</td></tr></table>

图7.35 有向图  $G_{6}$  中从  $\pmb{v}_{0}$  到其余各点的最短路径

终点  $v_{i}$  的最短路径的长度。它的初态为：若从  $\pmb{v}$  到  $\pmb{v}_{i}$  有弧，则  $D[i]$  为弧上的权值；否则置  $D[i]$  为  $\infty$  。显然，长度为

$$
D [ j ] = \underset {i} {\operatorname {M i n}} \{D [ i ] \mid v _ {i} \in V \}
$$

的路径就是从  $v$  出发的长度最短的一条最短路径。此路径为  $(v, v_j)$ 。

那么，下一条长度次短的最短路径是哪一条呢？假设该次短路径的终点是  $v_{k}$ ，则可想而知，这条路径或者是  $(v, v_{k})$ ，或者是  $(v, v_{j}, v_{k})$ 。它的长度或者是从  $v$  到  $v_{k}$  的弧上的权值，或者是  $D[j]$  和从  $v_{j}$  到  $v_{k}$  的弧上的权值之和。

一般情况下，假设  $S$  为已求得最短路径的终点的集合，则可证明：下一条最短路径（设其终点为  $x$ ）或者是弧  $(v, x)$ ，或者是中间只经过  $S$  中的顶点而最后到达顶点  $x$  的路径。这可用反证法来证明。假设此路径上有一个顶点不在  $S$  中，则说明存在一条终点不在  $S$  而长度比此路径短的路径。但是，这是不可能的。因为我们是按路径长度递增的次序来产生各最短路径的，故长度比此路径短的所有路径均已产生，它们的终点必定在  $S$  中，即假设不成立。

因此，在一般情况下，下一条长度次短的最短路径的长度必是

$$
D [ j ] = \underset {i} {\operatorname {M i n}} \{D [ i ] \mid v _ {i} \in V - S \}
$$

其中，  $D[i]$  或者是弧  $(v,v_{i})$  上的权值，或者是  $D[k](v_{k}\in S)$  和弧  $(v_{k},v_{i})$  上的权值之和。

根据以上分析，可以得到如下描述的算法：

（1）假设用带权的邻接矩阵  $\mathbf{arcs}$  来表示带权有向图， $\mathbf{arcs}[i][j]$  表示弧  $\langle v_i, v_j \rangle$  上的权值。若  $\langle v_i, v_j \rangle$  不存在，则置  $\mathbf{arcs}[i][j]$  为  $\infty$  （在计算机上可用允许的最大值代替）。S 为已找到从  $v$  出发的最短路径的终点的集合，它的初始状态为空集。那么，从  $v$  出发到图上其余各顶点(终点)  $v_i$  可能达到的最短路径长度的初值为：

$$
D [ i ] = \operatorname {a r c s} [ \text {L o c a t e V e x} (G, v) [ i ] \quad v _ {i} \in V
$$

（2）选择  $v_{j}$  ，使得

$$
D [ j ] = \operatorname {M i n} \left\{D [ i ] \mid v _ {i} \in V - S \right\}
$$

$v_{j}$  就是当前求得的一条从  $\pmb{v}$  出发的最短路径的终点。令

$$
S = S \cup \{j \}
$$

（3）修改从  $\pmb{v}$  出发到集合  $V - S$  上任一顶点  $\pmb{v}_{k}$  可达的最短路径长度。如果

$$
D [ j ] + \operatorname {a r c s} [ j ] [ k ] <   D [ k ]
$$

则修改  $D[k]$  为

$$
D [ k ] = D [ j ] + \operatorname {a r c s} [ j ] [ k ]
$$

(4) 重复操作 (2)、(3) 共  $n - 1$  次。由此求得从  $\pmb{v}$  到图上其余各顶点的最短路径是依路径长度递增的序列。

算法7.15为用C语言描述的迪杰斯特拉算法。

```txt
void ShortestPath.DIJ(MGraph G, int v0, PathMatrix &P, ShortPathTable &D) {
// 用 Dijkstra 算法求有向网 G 的 v0 顶点到其余顶点 v 的最短路径 P[v] 及其带权长度 D[v]。
// 若 P[v][w] 为 TRUE，则 w 是从 v0 到 v 当前求得最短路径上的顶点。
// final[v] 为 TRUE 当且仅当 v ∈ S，即已经求得从 v0 到 v 的最短路径。
for (v = 0; v < G.vexnum; ++v) {
    final[v] = FALSE; D[v] = G.arcs[v0][v];
    for (w = 0; w < G.vexnum; ++w) P[v][w] = FALSE; // 设空路径
        if (D[v] < INFINITY) { P[v][v0] = TRUE; P[v][v] = TRUE;} // for
    D[v0] = 0; final[v0] = TRUE; // 初始化，v0 顶点属于 S 集
// 开始主循环，每次求得 v0 到某个 v 顶点的最短路径，并加 v 到 S 集
for (i = 1; i < G.vexnum; ++i) {
    min = INFINITY; // 当前所知离 v0 顶点的最近距离
    for (w = 0; w < G.vexnum; ++w)
        if (!final[w]) // w 顶点在 V-S 中
            if (D[w] < min) { v = w; min = D[w]; } // w 顶点离 v0 顶点更近
    final[v] = TRUE; // 离 v0 顶点最近的 v 加入 S 集
    for (w = 0; w < G.vexnum; ++w) // 更新当前最短路径及距离
        if (!final[w] && (min + G.arcs[v][w] < D[w])) { // 修改 D[w] 和 P[w], w ∈ V-S
            D[w] = min + G.arcs[v][w];
            P[w] = P[v]; P[w][w] = TRUE; // P[w] = P[v] + [w]
        } // if
    } // for
} // ShortestPath.DIJ
```

# 算法 7.15

例如，图7.34所示有向网  $G_{6}$  的带权邻接矩阵为

$$
\left[ \begin{array}{c c c c c c} \infty & \infty & 1 0 & \infty & 3 0 & 1 0 0 \\ \infty & \infty & 5 & \infty & \infty & \infty \\ \infty & \infty & \infty & 5 0 & \infty & \infty \\ \infty & \infty & \infty & \infty & \infty & 1 0 \\ \infty & \infty & \infty & 2 0 & \infty & 6 0 \\ \infty & \infty & \infty & \infty & \infty & \infty \end{array} \right]
$$

若对  $G_{6}$  施行迪杰斯特拉算法, 则所得从  $\pmb{v}_{0}$  到其余各顶点的最短路径, 以及运算过程中  $D$  向量的变化状况, 如下所示:

<table><tr><td rowspan="2">终点</td><td colspan="5">从 \( v_0 \) 到各终点的 \( D \) 值和最短路径的求解过程</td></tr><tr><td>i=1</td><td>i=2</td><td>i=3</td><td>i=4</td><td>i=5</td></tr><tr><td rowspan="2">\( v_1 \)</td><td>∞</td><td>∞</td><td>∞</td><td>∞</td><td>∞</td></tr><tr><td></td><td></td><td></td><td></td><td>无</td></tr><tr><td>\( v_2 \)</td><td>10\( (v_0, v_2) \)</td><td></td><td></td><td></td><td></td></tr><tr><td>\( v_3 \)</td><td>∞</td><td>60\( (v_0, v_2, v_3) \)</td><td>50\( (v_0, v_4, v_3) \)</td><td></td><td></td></tr><tr><td>\( v_4 \)</td><td>30\( (v_0, v_4) \)</td><td>30\( (v_0, v_4) \)</td><td></td><td></td><td></td></tr><tr><td>\( v_5 \)</td><td>100\( (v_0, v_5) \)</td><td>100\( (v_0, v_5) \)</td><td>90\( (v_0, v_4, v_5) \)</td><td>60\( (v_0, v_4, v_3, v_5) \)</td><td></td></tr><tr><td>\( v_j \)</td><td>\( v_2 \)</td><td>\( v_4 \)</td><td>\( v_3 \)</td><td>\( v_5 \)</td><td></td></tr><tr><td>S</td><td>\( \{v_0, v_2\} \)</td><td>\( \{v_0, v_2, v_4\} \)</td><td>\( \{v_0, v_2, v_3, v_4\} \)</td><td>\( \{v_0, v_2, v_3, v_4, v_5\} \)</td><td></td></tr></table>

我们分析这个算法的运行时间。第一个FOR循环的时间复杂度是  $O(n)$ ，第二个FOR循环共进行  $n - 1$  次，每次执行的时间是  $O(n)$  。所以总的时间复杂度是  $O(n^{2})$  。如果用带权的邻接表作为有向图的存储结构，则虽然修改  $D$  的时间可以减少，但由于在  $D$  向量中选择最小分量的时间不变，所以总的时间仍为  $O(n^{2})$  。

人们可能只希望找到从源点到某一个特定的终点的最短路径, 但是, 这个问题和求源点到其他所有顶点的最短路径一样复杂, 其时间复杂度也是  $O(n^{2})$  的。

# 7.6.2 每一对顶点之间的最短路径

解决这个问题的一个办法是：每次以一个顶点为源点，重复执行迪杰斯特拉算法  $n$  次。这样，便可求得每一对顶点之间的最短路径。总的执行时间为  $O(n^{3})$  。

这里要介绍由弗洛伊德(Floyd)提出的另一个算法。这个算法的时间复杂度也是  $O(n^{3})$ ，但形式上简单些。

弗洛伊德算法仍从图的带权邻接矩阵cost出发，其基本思想是：

假设求从顶点  $v_{i}$  到  $v_{j}$  的最短路径。如果从  $v_{i}$  到  $v_{j}$  有弧，则从  $v_{i}$  到  $v_{j}$  存在一条长度为  $\arcs [i][j]$  的路径，该路径不一定是最短路径，尚需进行  $\pmb{n}$  次试探。首先考虑路径  $(\dot{v}_i,v_0,v_j)$  是否存在（即判别弧  $(v_{i},v_{0})$  和  $(v_0,v_j)$  是否存在）。如果存在，则比较  $(v_{i},v_{j})$  和  $(v_{i},v_{0},v_{j})$  的路径长度取长度较短者为从  $v_{i}$  到  $v_{j}$  的中间顶点的序号不大于0的最短路径。假如在路径上再增加一个顶点  $v_{1}$ ，也就是说，如果  $(v_{i},\dots ,v_{1})$  和  $(v_{1},\dots ,v_{j})$  分别是当前找到的中间顶点的序号不大于0的最短路径，那么  $(v_{i},\dots ,v_{1},\dots ,v_{j})$  就有可能是从  $v_{i}$  到  $v_{j}$  的中间顶点的序号不大于1的最短路径。将它和已经得到的从  $v_{i}$  到  $v_{j}$  中间顶点序号不大于0的最短路径相比较，从中选出中间顶点的序号不大于1的最短路径之后，再增加一个顶点  $v_{2}$ ，继续进行试探。依次类推。在一般情况下，若  $(v_{i},\dots ,v_{k})$  和  $(v_{k},\dots ,v_{j})$  分别是从  $v_{i}$  到  $v_{k}$  和从  $v_{k}$  到  $v_{j}$  的中间顶点的序号不大于  $k - 1$  的最短路径，则将  $(v_{i},\dots , v_{k},\dots , v_{j})$  和已经得到的从  $v_{i}$  到  $v_{j}$  且中间顶点序号不大于  $k - 1$  的最短路径相比较，其长

度较短者便是从  $v_{i}$  到  $v_{j}$  的中间顶点的序号不大于  $\pmb{k}$  的最短路径。这样，在经过  $\pmb{n}$  次比较后，最后求得的必是从  $v_{i}$  到  $v_{j}$  的最短路径。按此方法，可以同时求得各对顶点间的最短路径。

现定义一个  $n$  阶方阵序列

$$
\mathrm {D} ^ {(n - 1)}, \mathrm {D} ^ {(0)}, \mathrm {D} ^ {(1)}, \dots , \mathrm {D} ^ {(k)}, \dots , \mathrm {D} ^ {(n - 1)}
$$

其中

$$
\mathrm {D} ^ {(- 1)} [ \mathrm {i} ] [ \mathrm {j} ] = \mathrm {G . a r c s} [ \mathrm {i} ] [ \mathrm {j} ]
$$

$$
\mathrm {D} ^ {(k)} [ \mathrm {i} ] [ \mathrm {j} ] = \operatorname {M i n} \left\{\mathrm {D} ^ {(k - 1)} [ \mathrm {i} ] [ \mathrm {j} ], \mathrm {D} ^ {(k - 1)} [ \mathrm {i} ] [ \mathrm {k} ] + \mathrm {D} ^ {(k - 1)} [ \mathrm {k} ] [ \mathrm {j} ] \right\} \quad 0 \leqslant \mathrm {k} \leqslant \mathrm {n} - 1
$$

从上述计算公式可见， $\mathbf{D}^{(1)}[i][j]$  是从  $\mathbf{v}_i$  到  $\mathbf{v}_j$  的中间顶点的序号不大于 1 的最短路径的长度； $\mathbf{D}^{(k)}[i][j]$  是从  $\mathbf{v}_i$  到  $\mathbf{v}_j$  的中间顶点的序号不大于 k 的最短路径的长度； $\mathbf{D}^{(n-1)}[i][j]$  就是从  $\mathbf{v}_i$  到  $\mathbf{v}_j$  的最短路径的长度。

由此可得算法7.16。

```c
void ShortestPath.FLOYD(MGraph G, PathMatrix &P[], DistancMatrix &D) {
// 用Floyd算法求有向网G中各对顶点v和w之间的最短路径P[v][w]及其
// 带权长度D[v][w]。若P[v][w][u]为TRUE,则u是从v到w当前求得最
// 短路径上的顶点。
for (v = 0; v < G.vexnum; ++v) // 各对结点之间初始已知路径及距离
for (w = 0; w < G.vexnum; ++w) {
    D[v][w] = G.arcs[v][w];
    for (u = 0; u < G.vexnum; ++u) P[v][w][u] = FALSE;
    if (D[v][w] < INFINITY) // 从v到w有直接路径
        P[v][w][v] = TRUE; P[v][w][w] = TRUE;
} // if
} // for
for (u = 0; u < G.vexnum; ++u)
for (v = 0; v < G.vexnum; ++v)
for (w = 0; w < G.vexnum; ++w)
if (D[v][u] + D[u][w] < D[v][w]) { // 从v经u到w的一条路径更短
    D[v][w] = D[v][u] + D[u][w];
    for (i = 0; i < G.vexnum; ++i)
        P[v][w][i] = P[v][u][i] || P[u][w][i];
} // if
} // ShortestPath.FLOYD
```

算法 7.16  
(a)  
图7.36 带权有向图  
![](images/a2ca41e8f9170c569d4164641aed4af9d8221d0c7913a0da812e00b578869e4d.jpg)  
(a) 有向网  $G_{7}$ ; (b) 邻接矩阵

![](images/5ca822fbd59ca8d341ba8a64abafe48fc99532411af5d641addd66d73be5e5d1.jpg)  
(b)

例如，利用上述算法，可求得图7.36所示带权有向图  $G_{7}$  的每一对顶点之间的最短路径及其路径长度如图7.37所示。

![](images/0126d043db39a0da8bda91b1972e1fd8f74ab66f45cd4ddee26e071117d0fb43.jpg)  
图7.37 图7.36中有向图的各对顶点间的最短路径及其路径长度

![](images/ecc99c94d51bcc9a86da6064e6433dc9ceff4bb427bf2a2f9dfd41ac860e3f94.jpg)  
扫描上方二维码：获取更多免费资料

# 第8章 动态存储管理

# 8.1 概述

在前面各章的讨论中，对每一种数据结构虽都介绍了它们在内存储器中的映像，但只是借助高级语言中的变量说明加以描述，并没涉及具体的存储分配。而实际上，结构中的每个数据元素都占有一定的内存位置，在程序执行的过程中，数据元素的存取是通过对应的存储单元来进行的。在早期的计算机上，这个存储管理的工作是由程序员自己来完成的。在程序执行之前，首先需将用机器语言或汇编语言编写的程序输送到内存的某个固定区域上，并预先给变量和数据分配好对应的内存地址（绝对地址或相对地址）。在有了高级语言之后，程序员不需要直接和内存地址打交道，程序中使用的存储单元都由逻辑变量(标识符)来表示，它们对应的内存地址都是由编译程序在编译或执行时进行分配。

另一方面，当计算机是被单个用户使用时，那么整个内存除操作系统占用一部分之外，都归这个用户的程序使用（如PDP-11/03的内存为32KB，系统占用4KB，用户程序可用28KB）。但在多用户分时并发系统中，多个用户程序共享一个内存区域，此时每个用户程序使用的内存就由操作系统来进行分配了。并且，在总的内存不够使用时，还可采用自动覆盖技术。

对操作系统和编译程序来说，存储管理都是一个复杂而又重要的问题。不同语言的编译程序和不同的操作系统可以采用不同的存储管理方法。它们采用的具体做法，读者将在后续课程——编译原理和操作系统中学习。本课程仅就动态存储管理中涉及的一些基本技术进行讨论。

动态存储管理的基本问题是系统如何应用提出的“请求”分配内存？又如何回收那些用户不再使用而“释放”的内存，以备新的“请求”产生时重新进行分配？提出请求的用户可能是进入系统的一个作业，也可能是程序执行过程中的一个动态变量。因此，在不同的动态存储管理系统中，请求分配的内存量大小不同。通常在编译程序中是一个或几个字，而在系统中则是几千、几万，甚至是几十万。然而，系统每次分配给用户（不论大小）都是一个地址连续的内存区。为了叙述方便起见，在下面的讨论中，将统称已分配给用户使用的地址连续的内存区为“占用块”，称未曾分配的地址连续的内存区为“可利用空间块”或“空闲块”。

显然，不管什么样的动态存储管理系统，在刚开工时，整个内存区是一个“空闲块”（在编译程序中称之为“堆”）。随着用户进入系统，先后提出存储请求，系统则依次进行分配。因此，在系统运行的初期，整个内存区基本上分隔成两大部分：低地址区包含若干占用块；高地址区（即分配后的剩余部分）是一个“空闲块”。例如图8.1(a)所示为依次给8个用户进行分配后的系统的内存状态。经过一段时间以后，有的用户运行结束，它所占用的内存区变成空闲块，这就使整个内存区呈现出占用块和空闲块犬牙交错的状态。如图8.1(b)

所示。

(a)  
![](images/3db635e70b1cffc30f544a17c329d5c5854cd630671f882a0d11723f7f2d6bdd.jpg)  
（a）系统运行初期；（b）系统运行若干时间之后

![](images/be51a0a1a072064884650235dcb8207f2c8ed2ed31112ff7a9b70c9db0686eae.jpg)  
(b)  
图8.1 动态存储分配过程中的内存状态

假如此时又有新的用户进入系统请求分配内存，那么，系统将如何做呢？

通常有两种做法：一种策略是系统继续从高地址的空闲块中进行分配，而不理会已分配给用户的内存区是否已空闲，直到分配无法进行（即剩余的空闲块不能满足分配的请求）时，系统才去回收所有用户不再使用的空闲块，并且重新组织内存，将所有空闲的内存区连接在一起成为一个大的空闲块。另一种策略是用户一旦运行结束，便将它所占内存区释放成为空闲块，同时，每当新的用户请求分配内存时，系统需要巡视整个内存区中所有空闲块，并从中找出一个“合适”的空闲块分配之。由此，系统需建立一张记录所有空闲块的“可利用空间表”，此表的结构可以是“目录表”，也可以是“链表”。如图8.2所示为某

![](images/550e076c33668fca591537c7fc52a5aab5453f572eb46c90095bfaeb1d4651e3.jpg)  
(a)

起始地址  
内存块大小  
使用情况  

<table><tr><td>10 000</td><td>15 000</td><td>空闲</td></tr><tr><td>31 000</td><td>8 000</td><td>空闲</td></tr><tr><td>59 000</td><td>41 000</td><td>空闲</td></tr></table>

(b)

(c)  
图8.2 动态存储管理过程中的内存状态和可利用空间表  
![](images/605c35bce92555901e75e3471a3f71a57284a490386fe792e0e72b31623f2882.jpg)  
(a) 内存状态；  
（b）目录表；  
(c)链表

系统运行过程中的内存状态及其两种结构的可利用空间表。其中图8.2(b)是目录表，表中每个表目包括3项信息：初始地址、空闲块大小和使用情况。图8.2(c)是链表，表中一个结点表示一个空闲块，系统每次进行分配或回收即为在可利用空间表中删除或插入一个结点。

下面将分别讨论利用不同策略进行动态存储管理的方法。

# 8.2 可利用空间表及分配方法

这一节主要讨论利用可利用空间表进行动态存储分配的方法。目录表的情况比较简单，这类系统将在操作系统课程中作详细介绍，在此仅就链表的情况进行讨论。

如上所述，可利用空间表中包含所有可分配的空闲块，每一块是链表中的一个结点。当用户请求分配时，系统从可利用空间表中删除一个结点分配之；当用户释放其所占内存时，系统即回收并将它插入到可利用空间表中。因此，可利用空间表亦称做“存储池”。根据系统运行的不同情况，可利用空间表可以有下列3种不同的结构形式：

第一种情况是系统运行期间所有用户请求分配的存储量大小相同。对此类系统，通常的做法是，在系统开始运行时将归它使用的内存区按所需大小分割成若干大小相同的块，然后用指针链接成一个可利用空间表。由于表中结点大小相同，则分配时无需查找，只要将第一个结点分配给用户即可；同样，当用户释放内存时，系统只要将用户释放的空闲块插入在表头即可。可见，这种情况下的可利用空间表实质上是一个链栈。这是一种最简单的动态存储管理的方式，如第2章的“2.3.1线性链表”中的静态链表就是一例。

第二种情况，系统运行期间用户请求分配的存储量有若干种大小的规格。对此类系统，一般情况下是建立若干个可利用空间表，同一链表中的结点大小相同。例如，某动态存储管理系统中的用户将请求分配2个字、4个字或8个字的内存块，则系统建立3个结点大小分别为3个字、5个字和9个字的链表，它们的表头指针分别为av2、av4和av8。如图8.3所示，每个结点中的第一个字设有链域(link)、标志域（tag）和结点类型域(type)。其中：类型域为区别3种大小不同的结点而设，type的值为“0”、“1”或“2”，分别表示结点大小为2个字、4个字或8个字；标志域tag为“0”或“1”分别表示结点为空闲块或占用块；链域中存储指向同一链表中下一结点的指针，而结点中的值域是其大小分别为2、4和8个字的连续空间。此时的分配和回收的方法在很大程度上和第一种情况类似，只是当结点大小和请求分配的量相同的链表为空时，需查询结点较大的链表，并从中取出一个结点，将其中一部分内存分配给用户，而将剩余部分插入到相应大小的链表中。回收时，也只要将释放的空闲块插入到相应大小的链表的表头中去即可。然而，这种情况的系统还有一个特殊的问题要处理：即当结点与请求相符的链表和结点更大的链表均为空时，分配不能进行，而实际上内存空间并不一定不存在所需大小的连续空间，只是由于在系统运行过程中，频繁出现小块的分配和回收，使得大结点链表中的空闲块被分隔成小块后插入在小结点的链表中，此时若要使系统能继续运行，就必须重新组织内存，即执行“存储紧缩”的操作。除此之外，上述这个系统本身的分配和回收的算法都比较简单，读者可自行写出。

第3种情况，系统在运行期间分配给用户的内存块的大小不固定，可以随请求而变。因此，可利用空间表中的结点即空闲块的大小也是随意的。通常，操作系统中的可利用空间表属这种类型。

系统刚开始工作时，整个内存空间是一个空闲块，即可利用空间表中只有一个大小为

整个内存区的结点，随着分配和回收的进行，可利用空间表中的结点大小和个数也随之而变，上述图8.2(c)中的链表即为这种情况的可利用空间表。

![](images/d03e5bbddc2cdbc2c3666b7d23a9ace7c4e1a6f4da46b098227ddf952629400f.jpg)  
(a) 结点结构；(b) 可利用空间表

$$
\mathrm {t a g} = \left\{ \begin{array}{l l} 0 & \text {空 闲 块} \\ 1 & \text {占 用 块} \end{array} \right.
$$

$$
\text {t y p e} = \left\{ \begin{array}{l l} 0 & \text {结 点 大 小 为} 2 \text {个 字} \\ 1 & \text {结 点 大 小 为} 4 \text {个 字} \\ 2 & \text {结 点 大 小 为} 8 \text {个 字} \end{array} \right.
$$

(a)

![](images/2dacd8503c80d38c90417460e1bffb151b358c8a3ce62442875b26baadf1108f.jpg)  
(b)

由于链表中结点大小不同，则结点的结构与前两种情况也有所不同，结点中除标志域和链域之外，尚需有一个结点大小域(size)，以指示空闲块的存储量，如图8.4所示。结点中的space域是一个地址连续的内存空间。

![](images/d01137ac65b20701eb11fe4fe93572da9c56d76c6439972d60dfcfac61d50e48.jpg)  
图8.3 有3种大小结点的可利用空间表  
图8.4 空闲块的大小随意的结点结构

$$
\mathrm {t a g} = \left\{ \begin{array}{l l} 0 & \text {空 闲 块} \\ 1 & \text {占 用 块} \end{array} \right.
$$

由于可利用空间表中的结点大小不同, 则在分配时就有一个如何分配的问题。假设某用户需大小为  $n$  的内存, 而可利用空间表中仅有一块大小为  $m \geqslant n$  的空闲块, 则只需将其中大小为  $n$  的一部分分配给申请分配的用户, 同时将剩余大小为  $m - n$  的部分作为一个结点留在链表中即可。然而, 若可利用空间表中有若干个不小于  $n$  的空闲块时, 该分配哪一块呢? 通常, 可有 3 种不同的分配策略:

（1）首次拟合法。从表头指针开始查找可利用空间表，将找到的第一个大小不小于  $n$  的空闲块的一部分分配给用户。可利用空间表本身既不按结点的初始地址有序，也不按结点的大小有序。则在回收时，只要将释放的空闲块插入在链表的表头即可。例如，在图 8.2(c)的状态时有用户  $\mathrm{U}_{9}$  进入系统并申请 7KB 的内存，系统在可利用空间表中进行查询，发现第一个空闲块即满足要求，则将此块中大小为 7KB 的一部分分配之，剩余 8KB 的空闲块仍在链表中，如图 8.5(a) 所示。图 8.5(d) 为分配给用户的占用块。

（2）最佳拟合法。将可利用空间表中一个不小于  $n$  且最接近  $n$  的空闲块的一部分分配给用户。则系统在分配前首先要对可利用空间表从头到尾扫视一遍，然后从中找出一块不小于  $n$  且最接近  $n$  的空闲块进行分配。显然，在图8.2(c)的状态时，系统就应该将第二个空闲块的一部分分配给用户  $\mathrm{U}_{9}$ ，分配后的可利用空间表如图8.5(b)所示。在用最佳拟合法进行分配时，为了避免每次分配都要扫视整个链表。通常，预先设定可利用空间表的结构按空间块的大小自小至大有序，由此，只需找到第一块大于  $n$  的空闲块即可进行分配，但在回收时，必须将释放的空闲块插入到合适的位置上去。

（3）最差拟合法。将可利用空间表中不小于  $n$  且是链表中最大的空闲块的一部分分配给用户。例如在图8.2(c)的状态时，就应将大小为41KB的空闲块中的一部分分配给

图8.5 结点大小随意的可利用空间表  
![](images/0e73e7d30417a18dcef6379f74c39230bfd5d0501b90dad7fbbd823be78eb6f3.jpg)  
（a）按首次拟合原则进行分配；（b）按最佳拟合原则进行分配；  
（c）按最差拟合原则进行分配；（d）分配给用户的占用块

用户,分配后的可利用空间表如图8.5(c)所示。显然,为了节省时间,此时的可利用空间表的结构应按空闲块的大小自大至小有序。这样,每次分配无需查找,只需从链表中删除第一个结点,并将其中一部分分配给用户,而剩余部分作为一个新的结点插入到可利用空间表的适当位置上去。当然,在回收时亦需将释放的空闲块插入到链表的适当位置上去。

上述3种分配策略各有所长。一般来说，最佳拟合法适用于请求分配的内存大小范围较广的系统。因为按最佳拟合的原则进行分配时，总是找大小最接近请求的空闲块，由

此系统中可能产生一些存储量甚小而无法利用的小片内存，同时也保留那些很大的内存块以备响应后面将发生的内存量特大的请求，从而使整个链表趋向于结点大小差别甚远的状态。反之，由于最拟合每次都从内存量最大的结点中进行分配，从而使链表中的结点大小趋于均匀，因此它适用于请求分配的内存大小范围较窄的系统。而首次拟合法的分配是随机的，因此它介于两者之间，通常适用于系统事先不掌握运行期间可能出现的请求分配和释放的信息的情况。从时间上来比较，首次拟合在分配时需查询可利用空间表，而回收时仅需插入在表头即可；最差拟合恰相反，分配时无需查询链表，而回收时为将新的“空闲块”插入在链表中适当的位置上，需先进行查找；最佳拟合无论分配和回收，均需查找链表，因此最费时间。

因此，不同的情景需采用不同的方法，通常在选择时需考虑下列因素：用户的逻辑要求；请求分配量的大小分布；分配和释放的频率以及效率对系统的重要性等等。

在实际使用的系统中回收空闲块时还需考虑一个“结点合并”的问题。这是因为系统在不断进行分配和回收的过程中，大的空闲块逐渐被分割成小的占用块，在它们重又成为空闲块回收之后，即使是地址相邻的两个空闲块也只是作为两个结点插入到可利用空间表中，以致使得后来出现的大容量的请求分配无法进行，为了更有效地利用内存，就要求系统在回收时应考虑将地址相邻的空闲块合并成尽可能大的结点。换句话说，在回收空闲块时，首先应检查地址与它相邻的内存是否是空闲块。具体实现的方法将在下面两节中讨论的动态存储管理系统中加以详细说明。

# 8.3 边界标识法

边界标识法（boundary tag method）是操作系统中用以进行动态分区分配的一种存储管理方法，它属于上一节讨论中的第三种情况。系统将所有的空闲块链接在一个双重循环链表结构的可利用空间表中；分配可按首次拟合进行，也可按最佳拟合进行。系统的特点在于：在每个内存区的头部和底部两个边界上分别设有标识，以标识该区域为占用块或空闲块，使得在回收用户释放的空闲块时易于判别在物理位置上与其相邻的内存区域是否为空闲块，以便将所有地址连续的空闲存储区组合成一个尽可能大的空闲块。下面分别就系统的可利用空间表的结构及其分配和回收的算法进行讨论。

# 8.3.1 可利用空间表的结构

可利用空间表中的结点结构如下所示：

![](images/00fc26c8914b44435676c0d1d69b1a1f33d323662240e1069c6d980dc965da97.jpg)

它表示一个空闲块。整个结点由3部分组成。其中space为一组地址连续的存储单元，是可以分配给用户使用的内存区域，它的大小由head中的size域指示，并以头部head和底部foot作为它的两个边界；在head和foot中分别设有标志域tag，且设定空闲块中tag的值为“0”，占用块中tag的值为“1”；foot位于结点底部，因此它的地址是随结点中space空间的大小而变的。为讨论简便起见，我们假定内存块的大小以“字”为单位来计，地址也以“字”为单位来计，结点头部中的size域的值为整个结点的大小，包括头部head和底部foot所占空间，并假设head和foot各占一个字的空间，但在分配时忽略不计。

借助C语言，在此将可利用空间表的结点结构定义为如下说明的数据类型：

```c
typedef struct WORD { //WORD:内存字类型  
union { //head和foot分别是结点的第一个字和最后的字  
WORD * llink; //头部域,指向前驱结点  
WORD * uplink; //底部域,指向本结点点头部  
};  
int tag; //块标志，0：空闲，1：占用，头部和尾部均有。  
int size; //头部域，块大小  
WORD * rlink; //头部域，指向后继结点  
OtherType other; //字的其他部分  
}WORD, head, foot, *Space; //*Space:可利用空间指针类型
```

define FootLoc(p)  $p + p \rightarrow \text{size} - 1$  // 指向  $p$  所指结点的底部

可利用空间表设为双重循环链表。head 中的 llink 和 rlink 分别指向前驱结点和后继结点。表中不设表头结点，表头指针 pav 可以指向表中任一结点，即任何一个结点都可看成是链表中的第一个结点；表头指针为空，则表明可利用空间表为空。foot 中的 up-link 域也为指针，它指向本结点，它的值即为该空闲块的首地址。例如图 8.6(a) 是一个占有 100KB 内存空间的系统在运行开始时的可利用空间表。

# 8.3.2 分配算法

分配的算法比较简单，假设我们采用首次拟合法进行分配，则只要从表头指针 pav 所指结点起，在可利用空间表中进行查找，找到第一个容量不小于请求分配的存储量  $(n)$  的空闲块时，即可进行分配。为了使整个系统更有效地运行，在边界标识法中还作了如下两条约定：

（1）假设找到的此块待分配的空闲块的容量为  $m$  个字(包括头部和底部)，若每次分配只是从中分配  $n$  个字给用户，剩余  $m - n$  个字大小的结点仍留在链表中，则在若干次分配之后，链表中会出现一些容量极小总也分配不出去的空闲块，这就大大减慢了分配(查找)的速度。弥补的办法是：选定一个适当的常量  $e$  ，当  $m - n \leqslant e$  时，就将容量为  $m$  的空闲块整块分配给用户；反之，只分配其中  $n$  个字的内存块。同时，为了避免修改指针，约定将该结点中的高地址部分分配给用户。  
（2）如果每次分配都从同一个结点开始查找的话，势必造成存储量小的结点密集在头指针 pav 所指结点附近，这同样会增加查询较大空闲块的时间。反之，如果每次分配从

图8.6 某系统的可利用空间表  
![](images/26601054a5e441536daf6ab1c6c35a646756c4cd8121226ecd278dc2c7eb8260.jpg)  
(a) 初始状态；(b) 运行若干时间后的状态；(c) 进行再分配后的状态

不同的结点开始进行查找，使分配后剩余的小块均匀地分布在链表中，则可避免上述弊病。实现的方法是，在每次分配之后，令指针 pav 指向刚进行过分配的结点的后继结点。

例如，图8.6(b)所示可利用空间表在进行分配之后的状态如图8.6(c)所示。

算法8.1是上述分配策略的算法描述。

```txt
SpaceAllocBoundTag(Space&pav,intn）{//若有不小于  $\mathbf{n}$  的空闲块，则分配相应的存储块，并返回其首地址；否则返回//NULL。若分配后可利用空间表不空，则pav指向表中刚分配过的结点的后继//结点for  $(\mathtt{p} = \mathtt{pav};\mathtt{p}\& \& \mathtt{p} - >$  size<n&&p->rlink！  $=$  pav; $p = p - > rlink)$  //查找不小于  $\mathbf{n}$  的空闲块if（!p  $\parallel$  p->size<n）return NULL; //找不到，返回空指针else{ //p指向找到的空闲块f  $=$  FootLoc(p); //指向底部pav  $=$  p->rlink; //pav指向  $\ast_{\mathbb{P}}$  结点的后继结点。if（p->size-n<=e）{//整块分配，不保留  $<   = e$  的剩余量if(pav  $= =$  p）pav  $=$  NULL; //可利用空间表变为空表else{ //在表中删除分配的结点pav->llink  $=$  p->llink; p->llink->rlink  $=$  pav;}//ifp->tag  $=$  f->tag  $= 1$  //修改分配结点的头部和底部标志}//ifelse{ //分配该块的后n个字
```

```c
$\mathrm{f - > tag = 1}$  //修改分配块的底部标志  
p->size  $= \texttt{n};$  //置剩余块大小  
f  $=$  FootLoc(p); //指向剩余块底部  
f->tag  $= 0$  ：f->uplink  $=$  p; //设置剩余块底部  
p  $= \mathrm{f} + 1$  //指向分配块头部  
p->tag  $= 1$  ：p->size  $=$  n; //设置分配块头部  
}  
return p; //返回分配块首地址  
} // else  
} // AllocBoundTag
```

# 算法 8.1

# 8.3.3 回收算法

一旦用户释放占用块，系统需立即回收以备新的请求产生时进行再分配。为了使物理地址毗邻的空闲块结合成一个尽可能大的结点，则首先需要检查刚释放的占用块的左、右紧邻是否为空闲块。由于本系统在每个内存区（无论是占用块或空闲块）的边界上都设有标志值，则很容易辨明这一点。

假设用户释放的内存区的头部地址为p，则与其低地址紧邻的内存区的底部地址为p-1；与其高地址紧邻的内存区的头部地址为  $\mathsf{p} + \mathsf{p}\longrightarrow \mathsf{size}$  ，它们中的标志域就表明了这两个邻区的使用状况：若  $(\mathfrak{p} - 1)\rightarrow >\mathrm{tag} = 0$  ；则表明其左邻为空闲块，若  $(\mathsf{p} + \mathsf{p}\longrightarrow \mathsf{size})\longrightarrow$ $\mathrm{tag} = 0$  ；则表明其右邻为空闲块。

若释放块的左、右邻区均为占用块，则处理最为简单，只要将此新的空闲块作为一个结点插入到可利用空闲表中即可；若只有左邻区是空闲块，则应与左邻区合并成一个结点；若只有右邻区是空闲块，则应与右邻区合并成一个结点；若左、右邻区都是空闲块，则应将3块合起来成为一个结点留在可利用空间表中，下面我们就这4种情况分别描述它们的算法：

（1）释放块的左、右邻区均为占用块。此时只要作简单插入即可。由于边界标识法在按首次拟合进行分配时对可利用空间表的结构没有任何要求，则新的空闲块插入在表中任何位置均可。简单的做法就是插入在 pav 指针所指结点之前（或之后），可描述如下：

```txt
$\mathsf{p} - > \mathsf{tag} = 0$  ：FootLoc(p)  $\rightharpoondown$  uplink  $=$  p;FootLoc(p)  $\rightharpoonup$  tag  $= 0$  ·  
if(!pav）pav  $=$  p->llink  $=$  p->rlink  $=$  p;  
else{q=pav->llink;p->rlink  $=$  pav;  $\mathsf{p}\rightarrow \mathsf{>l}\mathsf{l}\mathsf{k}\mathsf{n} = \mathsf{q};$  q->rlink  $=$  pav->llink  $=$  p;pav  $=$  p; //令刚释放的结点为下次分配时的最先查询的结点
```

（2）释放块的左邻区为空闲块，而右邻区为占用块。由于释放块的头部和左邻空闲块的底部毗邻，因此只要改变左邻空闲块的结点：增加结点的size域的值且重新设置结点的底部即可。描述如下：

```txt
$\mathbf{n} = \mathbf{p}$  ->size;  
 $s = (p - 1) - >$  uptoLink;
```

```txt
//释放块的大小  
//左邻空闲块的头部地址
```

（3）释放块的右邻区为空闲块，而左邻区为占用块。由于释放块的底部和右邻空闲块的头部毗邻，因此，当表中结点由原来的右邻空闲块变成合并后的大空闲块时，结点的底部位置不变，但头部要变，由此，链表中的指针也要变。描述如下：

```txt
$\mathbf{t} = \mathbf{p} + \mathbf{p} - > \mathbf{size};$  //右邻空闲块的头部地址  
 $\mathbf{p} - > \mathbf{tag} = 0;$  //  $\mathbb{P}$  为合并后的结点头部地址  
 $\mathrm{q} = \mathrm{t} - > \mathrm{l}\mathrm{l}\mathrm{n}\mathrm{k};$  //  $\mathbf{q}$  为  $^*\mathbf{t}$  结点在可利用空间表中的前驱结点的头部地址  
 $\mathbf{p} - > \mathbf{l}\mathbf{l}\mathbf{n}\mathbf{k} = \mathbf{q};$  q->rlink=p; //q指向  $\ast \mathbb{P}$  的前驱  
ql  $= \texttt{t} - > \texttt{r}\texttt{l}\texttt{n}\texttt{k};$  //ql为  $^*\mathbf{t}$  结点在可利用空间表中的后继结点的头部地址  
 $\mathbf{p} - > \mathbf{r}\mathbf{l}\mathbf{n}\mathbf{k} = \mathbf{q}\mathbf{l};$  ql->llink=p; //ql指向  $^{\star}\mathbb{P}$  的后继  
 $\mathbf{p} - > \mathbf{size} + = \mathbf{t} - > \mathbf{size};$  //新的空闲块的大小  
FootLoc(t)->uplink=p; //底部指针指向新结点的头部
```

![](images/1e339c9f8470c3f4f251bf2df9609145afe6b91b9fea2abb9f293ec1a828d4fc.jpg)

![](images/89a70b7b894b9568aa4d4b1be4dc5e6eab39a5f0705f882999c9f8945c6b7841.jpg)

![](images/5aacaf68d7e1824dd8faefb515e762751a03081e89fb57ba6587b29277f56370.jpg)  
图8.7 回收存储块后的可利用空间表

(a) 释放的存储块； (b) 左邻区是空闲块的情况；  
（c）右邻区是空闲块的情况；（d）左、右邻区均是空闲块的情况

（4）释放块的左、右邻区均为空闲块。为使3个空闲块连接在一起成为一个大结点留在可利用空间表中，只要增加左邻空闲块的space容量，同时在链表中删去右邻空闲块结点即可。所作改变可描述如下：

```txt
$\mathbf{n} = \mathbf{p} - > \mathbf{size};$  //释放块的大小  
 $\mathbf{s} = (\mathbf{p} - 1) - > \mathbf{uplink};$  //指向左邻块
```

```txt
$\mathbf{t} = \mathbf{p} + \mathbf{p} - > \mathbf{size};$  //指向右邻块  
s->size += n+t->size; //设置新结点的大小  
q = t->llink; q1 = t->rlink; //q! = ql  
q->rlink = ql; q1->llink = q; //删去右邻空闲块结点  
FootLoc(t) ->uplink = s; //新结点底部指针指向其头部
```

总之，边界标识法由于在每个结点的头部和底部设立了标识域，使得在回收用户释放的内存块时，很容易判别与它毗邻的内存区是否是空闲块，且不需要查询整个可利用空间表便能找到毗邻的空闲块与其合并之；再者，由于可利用空间表上结点既不需依结点大小有序，也不需依结点地址有序，则释放块插入时也不需查找链表。由此，不管是哪一种情况，回收空闲块的时间都是个常量，和可利用空间表的大小无关。惟一的缺点是增加了结点底部所占的存储量。

在上述后3种情况下，可利用空间表的变化如图8.7所示。

# 8.4 伙伴关系

伙伴系统(buddy system)是操作系统中用到的另一种动态存储管理方法。它和边界标识法类似，在用户提出申请时，分配一块大小“恰当”的内存区给用户；反之，在用户释放内存区时即回收。所不同的是：在伙伴系统中，无论是占用块或空闲块，其大小均为2的  $k$  次幂（ $k$  为某个正整数）。例如；当用户申请  $n$  个字的内存区时，分配的占用块大小为  $2^k$  个字  $(2^{k-1} < n \leqslant 2^k)$  。由此，在可利用空间表中的空闲块大小也只能是2的  $k$  次幂。若总的可利用内存容量为  $2^m$  个字，则空闲块的大小只可能为  $2^0, 2^1, \dots, 2^m$  。下面我们仍和上节一样，分3个问题来介绍这个系统。

# 8.4.1 可利用空间表的结构

假设系统的可利用内存空间容量为  $2^{m}$  个字（地址从0到  $2^{m} - 1$ ），则在开始运行时，整个内存区是一个大小为  $2^{m}$  的空闲块，在运行了一段时间之后，被分隔成若干占用块和空闲块。为了再分配时查找方便起见，我们将所有大小相同的空闲块建于一张子表中。每个子表是一个双重链表，这样的链表可能有  $m + 1$  个，将这  $m + 1$  个表头指针用向量结构组织成一个表，这就是伙伴系统中的可利用空间表。

双重链表中的结点结构如图8.8(a)所示，其中head为结点头部，是一个由4个域组成的记录，其中的llink域和rlink域分别指向同一链表中的前驱和后继结点；tag域为值取“0”“1”的标志域，kval域的值为2的幂次  $k$  ；space是一个大小为  $2^k - 1$  个字的连续内存空间（和前面类似，仍假设head占一个字的空间）。

可利用空间表的初始状态如图8.8(b)所示，其中  $m$  个子表都为空表，只有大小为  $2^{m}$  的链表中有一个结点，即整个存储空间。表头向量的每个分量由两个域组成，除指针域外另设nodesize域表示该链表中空闲块的大小，以便分配时查找方便。此可利用空间表的数据类型，示意描述如下：

```txt
define m 16 //可利用空间总容量64K字的2的幂次，子表的个数为  $\mathfrak{m} + 1$  typedef struct WORD.b{
```

<table><tr><td>WORD_b * llink;</td><td>// 指向前驱结点</td></tr><tr><td>int tag;</td><td>// 块标志,0:空闲,1:占用。</td></tr><tr><td>int kval;</td><td>// 块大小,值为2的幂次k</td></tr><tr><td>WORD_b * rlink;</td><td>// 头部域,指向后继结点</td></tr><tr><td>OtherType other;</td><td>// 字的其他部分</td></tr><tr><td>}WORD_b, head;</td><td>// WORD:内存字类型,结点的第一个字也称为head</td></tr><tr><td>typedef struct HeadNode {</td><td></td></tr><tr><td>int nodesize;</td><td>// 该链表的空闲块的大小</td></tr><tr><td>WORD_b * first;</td><td>// 该链表的表头指针</td></tr><tr><td>}FreeList[m+1];</td><td>// 表头向量类型</td></tr></table>

![](images/68bf2651cb99430534a0be4bc61f1c41c33ec047bf4d996cb7aa08a70a1d9b67.jpg)  
(a)

![](images/05a4aae634ebb3bb7eb580a3fcb6e57666163ef19b2597d28d11f27018871ce8.jpg)  
(b)

(c)  
图8.8 伙伴系统中的可利用空间表  
![](images/4292323837cdc8be0c3201c5996aeea9279b834d0cfb1b17f229cecd0363065d.jpg)  
(a) 空闲块的结点结构；(b) 表的初始状态；(c) 分配前的表；(d) 分配后的表

![](images/777676a2b7a5a56b8b131735e55d7cfb5ce447a65c282e5a284fd68c15f380da.jpg)  
(d)

# 8.4.2 分配算法

当用户提出大小为  $n$  的内存请求时，首先在可利用表上寻找结点大小与  $n$  相匹配的子表，若此子表非空，则将子表中任意一个结点分配之即可；若此子表为空，则需从结点更大的非空子表中去查找，直至找到一个空闲块，则将其中一部分分配给用户，而将剩余部分插入相应的子表中。

假设分配前的可利用空间表的状态如图8.8(c)所示。若  $2^{k-1} < n \leqslant 2^k - 1$ ，又第  $k + 1$  个子表不空，则只要删除此链表中第一个结点并分配给用户即可；若  $2^{k-2} < n \leqslant 2^{k-1} - 1$ ，此时由于结点大小为  $2^{k-1}$  的子表为空，则需从结点大小为  $2^k$  的子表中取出一块，将其中一半分配给用户，剩余的一半作为一个新结点插入在结点大小为  $2^{k-1}$  的子表中，如图8.8(d)所示。若  $2^{k-i-1} < n \leqslant 2^{k-i} - 1$ （ $i$  为小于  $k$  的整数），并且所有结点小于  $2^k$  的子表均为空，

则同样需从结点大小为  $2^{k}$  的子表中取出一块，将其中  $2^{k - i}$  的一小部分分配给用户，剩余部分分割成若干个结点分别插入在结点大小为  $2^{k - i}, 2^{k - i + 1}, \dots, 2^{k - 1}$  的子表中。假设从第  $k + 1$  个子表中删除的结点的起始地址为  $p$  ，且假设分配给用户的占用块的初始地址为  $p$  （占用块为该空闲块的低地址区），则插入上述子表的新结点的起始地址分别为  $p + 2^{k - i}, p + 2^{k - i + 1}, \dots, p + 2^{k - 1}$ ，如右图所示（图中  $i = 3$ ）。

![](images/e96baa912e7a020a6237b3e3a1ca364ecc92a4665af7a5545324af7ac66d0791.jpg)

下面用算法语言描述之：

```txt
WORD_b* AllocBuddy (FreeList &avail, int n) {
// avail[0..m]为可利用空间表，n为申请分配量，若有不小于n的空闲块，
// 则分配相应的存储块，并返回其首地址；否则返回NULL
for (k = 0; k <= m && (avail[k].nodesize < n + 1 || !avail[k].first);
++ k); // 查找满足分配要求的子表
if (k > m) return NULL; // 分配失败，返回 NULL
else {
pa = avail[k].first; // 指向可分配子表的第一个结点
pre = pa->llink; suc = pa->rlink; // 分别指向前驱和后继
if (pa = suc) avail[k].first = NULL; // 分配后该子表变成空表
else {
pre->rlink = suc; suc->llink = pre; avail[k].first = suc;
}
for (i = 1; avail[k - i].nodesize >= n + 1; ++ i) {
pi = pa + 2^{k - i}; pi->rlink = pi; pi->llink = pi;
pi->tag = 0; pi->kval = k - i; avail[k - i].first = pi;
} // 将剩余块插入相应子表
pa->tag = 1; pa->kval = k - (-i);
}
return pa;
} // AllocBuddy
```

# 算法 8.2

# 8.4.3 回收算法

在用户释放不再使用的占用块时，系统需将这新的空闲块插入到可利用空间表中去。这里，同样有一个地址相邻的空闲块归并成大块的问题。但是在伙伴关系中仅考虑互为“伙伴”的两个空闲块的归并。

何谓“伙伴”？如前所述，在分配时经常需要将一个大的空闲块分裂成两个大小相等的存储区，这两个由同一大块分裂出来的小块就称之“互为伙伴”。例如：假设  $p$  为大小为  $2^k$  的空闲块的初始地址，且  $p \bmod 2^{k+1} = 0$ ，则初始地址为  $p$  和  $p + 2^k$  的两个空闲块互为伙伴。在伙伴系统中回收空闲块时，只当其伙伴为空闲块时才归并成大块。也就是说，若有两个空闲块，即使大小相同且地址相邻，但不是由同一大块分裂出来的，也不归并在一起。例如图中的 A、B 两个空闲块不是伙伴。

由此，在回收空闲块时，应首先判别其伙伴是否为空闲块，若否，则只要将释放的空闲

![](images/4b251a9fa07bfc972615f8b46a33a7bd1f92b1fda4a77990163ac3bd01b2ec35.jpg)

块简单插入在相应子表中即可；若是，则需在相应子表中找到其伙伴并删除之，然后再判别合并后的空闲块的伙伴是否是空闲块。依此重复，直到归并所得空闲块的伙伴不是空闲块时，再插入到相应的子表中去。

起始地址为  $p$  ，大小为  $2^{k}$  的内存块，其伙伴块的起始地址为：

$$
\mathrm {b u d d y} (p, k) = \left\{ \begin{array}{l l} p + 2 ^ {k} & (\text {若} p \mathrm {M O D} 2 ^ {k + 1} = 0) \\ p - 2 ^ {k} & (\text {若} p \mathrm {M O D} 2 ^ {k + 1} = 2 ^ {k}) \end{array} \right.
$$

例如，假设整个可利用内存区大小为  $2^{10} = 1024$ （地址从0到1023），则大小为  $2^{8}$ ，起始地址为512的伙伴块的起始地址为768；大小为  $2^{7}$ ，起始地址为384的伙伴块的起始地址为256。

整个释放算法在此不再详细列出，请读者自行补充。

总之，伙伴系统的优点是算法简单、速度快；缺点是由于只归并伙伴而容易产生碎片。

# 8.5 无用单元收集

以上3节讨论的问题都是如何利用可利用空间表来进行动态存储管理。它的特点是：在用户请求存储时进行分配；在用户释放存储时进行回收，即系统是应用人的需求来进行存储分配和回收的。因此，在这类存储管理系统中，用户必须明确给出“请求”和“释放”的信息。如在多用户分时并发的操作系统中，当用户程序进入系统时即请求分配存储区；反之，当用户程序执行完毕退出系统时即释放所占存储。又如，在使用C语言编写程序时，用户是通过malloc和free两个函数来表示请求分配和释放存储的。但有时会因为用户的疏漏或结构本身的原因致使系统在不恰当的时候或没有进行回收而产生“无用单元”或“悬挂访问”的问题。

“无用单元”是指那些用户不再使用而系统没有回收的结构和变量。例如下列C程序段

```latex
$\mathbf{p} =$  malloc(size);  $\vdots$ $\mathbf{p} = \mathbf{N}\mathbf{U}\mathbf{L}\mathbf{L}$
```

执行的结果，是使执行  $\mathfrak{p} = \mathrm{malloc(size)}$  为用户分配的结点成为无用单元，无法得到利用；而下列程序段

```txt
$\mathbf{p} =$  malloc(size);  $\vdots$    
q=p;   
free(p);
```

执行的结果使指针变量q悬空，如果所释放的结点被再分配而继续访问指针q所指结点，则称这种访问为“悬挂访问”，并且由此引起的恶劣后果是可想而知的。

另一方面，由于结构本身的某些特性，也会产生同上类似问题。

例如在某用户程序中有3个广义表结构，如图8.9所示， $\mathbf{L}_1$ 、 $\mathbf{L}_2$ 和 $\mathbf{L}_3$ 分别为它们的表头指针， $\mathbf{L}_4$ 是 $\mathbf{L}_1$ 和 $\mathbf{L}_2$ 共享的子表， $\mathbf{L}_3$ 本身又为 $\mathbf{L}_2$ 共享，则 $\mathbf{L}_5$ 为3个广义表所共享。

![](images/9267b69ea6224b73436ee2363140d26dad1815c49fce9f2bbeb3491c4191a9bc.jpg)  
图8.9 含有共享子表的广义表

在这种情况下，表结点的释放就成为一个问题。假设表  $\mathbf{L}_1$  不再使用，而表  $\mathbf{L}_2$  和  $\mathbf{L}_3$  尚在使用，若释放表  $\mathbf{L}_1$  ，即自  $\mathbf{L}_1$  指针起，顺链将所有结点回收到可利用空间表中（包括子表  $\mathbf{L}_4$  和  $\mathbf{L}_5$  上所有结点），这就破坏了表  $\mathbf{L}_2$  和  $\mathbf{L}_3$  ，从而产生“悬挂访问”；反之，若不将表  $\mathbf{L}_1$  中结点释放，则当  $\mathbf{L}_2$  和  $\mathbf{L}_3$  两个表也不被使用时，这些结点由于未曾“释放”无法被再分配而成为“无用单元”。

如何解决这个问题？有两条途径：

（1）使用访问计数器：在所有子表或广义表上增加一个表头结点，并设立一个“计数域”，它的值为指向该子表或广义表的指针数目。只有当该计数域的值为零时，此子表或广义表中结点才被释放。  
（2）收集无用单元：在程序运行的过程中，对所有的链表结点，不管它是否还有用，都不回收，直到整个可利用空间表为空。此时才暂时中断执行程序，将所有当前不被使用的结点链接在一起，成为一个新的可利用空间表，而后程序再继续执行。显然，在一般情况下，是无法辨别哪些结点是当前未被使用的。然而，对于一个正在运行的程序，哪些结点正在使用是容易查明的，这只要从所有当前正在工作的指针变量出发，顺链遍历，那么，所有链结在这些链上的结点都是占用的。反之，可利用存储空间中的其余结点就都是无用的了。

由此，收集无用单元应分两步进行：第一步是对所有占用结点加上标志。回顾第5章的广义表的存储结构可在每个结点上再加设一个标志（mark）域，假设在无用单元收集之前所有结点的标志域均置为“0”，则加上标志就是将结点的标志域置为“1”；第二步是对整个可利用存储空间顺序扫描一遍，将所有标志域为“0”的结点链接成一个新的可利用空间表。值得注意的是：上述第二步是容易进行的，而第一步是在极其困难的条件（即可利用存储几乎耗用殆尽）下进行的，因此，人们的精力主要集中在研究标志算法上。下面我们介绍3种标志算法。

（1）递归算法 从上面所述可知，加标志的操作实质上是遍历广义表，将广义表中所有结点的标志域赋值“1”。我们可写出遍历(加标志)算法的递归定义如下：

若列表为空, 则无需遍历; 若是一个数据元素, 则标志元素结点; 反之, 则列表非空, 首先标志表结点; 然后分别遍历表头和表尾。

这个算法很简单，易于用允许递归的高级语言描述之。但是，它需要一个较大的实现递归用的栈的辅助内存，这部分内存不能用于动态分配。并且，由于列表的层次不定，使得栈的容量不易确定，除非是在内存区中开辟一个相当大的区域留作栈，否则就有可能由于在标志过程中因栈的溢出而使系统瘫痪。

（2）非递归算法 程序中附设栈(或队列)实现广义表的遍历。从广义表的存储结构来看，表中有两种结点：一种是元素结点，结点中没有指针域；另一种是表结点，结点中包含两个指针域：表头指针和表尾指针，则它很类似于二叉树的二叉链表。列表中的元素结点相当于二叉树中的叶子结点，可以类似于遍历二叉树写出遍历表的非递归算法，只是在算法中应尽量减少栈的容量。

例如, 类似于二叉树的前序遍历, 对广义表则为: 当表非空时, 在对表结点加标志后, 先顺表头指针逐层向下对表头加标志, 同时将同层非空且未加标志的表尾指针依次入栈, 直到表头为空表或为元素结点时停止, 然后退栈取出上一层的表尾指针。反复上述进行过程, 直到栈空为止。这个过程也可以称做深度优先搜索遍历。因为它和图的深度优先搜索遍历很相似。

显然，还可以类似于图的广度优先搜索遍历，对列表进行广度优先搜索遍历，或者说是对列表按层次遍历。同样，为实现这个遍历需附设一个队列（这两个算法和二叉树或图的遍历极为相似，故在此不作详细描述，读者完全可以自己写出）。在这两种非递归算法中，虽然附设的栈或队列的容量比递归算法中的栈的容量小，但和递归算法有同样的问题仍需要一个不确定量的附加存储，因此也不是理想的方法。

（3）利用表结点本身的指针域标记遍历路径的算法无论是在递归算法中还是在深度优先搜索的非递归算法中，不难看出，设栈的目的都是为了记下遍历时指针所走的路径，以便在遍历表头之后可以沿原路退回，继而对表尾进行遍历。如果我们能用别的方法记下指针所走路径，则可以免除附设栈。在下面介绍的算法中就是利用已经标志过的表结点中的tag、hp和tp域来代替栈记录遍历过程中的路径。例如：对图8.10中的广义表

![](images/37eff398c01047302cd1ae89b0eabd9e06fe7e5ba732e4618c0ec9232237e9f4.jpg)  
图8.10 待遍历的广义表

加标志。假设在递归算法中指针p指向刚加上标志的b结点，则：①当指针p由b移向表头c之前需将b入栈(此时a已在栈中)；②在表头标志之后需退栈，然后指针p在由b移向表尾f时需再次将b入栈；③在b的表尾标志完之后应连续两次退栈，使p重又指向a。与此对应，在本算法中不设栈。而是当指针p由b移向c之前，先将b结点中的hp域的值改为指向a，并将b结点中的tag域的值改为“0”；而当指针p由b移向f之前，则先将b结点中的tp域的值改为指向a,tag域的值改为“1”。

下面详细叙述算法的基本思想(注：假设图8.10中的广义表  $\mathbf{L}^{\prime}$  已加上标志)。

算法中设定了3个互相关联的指针：当p指向某个表结点时；t指向p的母表结点；q指向p的表头或表尾。如图8.11中(a)和(b)所示。

当  $q$  指向  $p$  的表头结点时，可能有3种情况出现：①设  $p$  的表头只是一个元素结点，则遍历表头仅需对该表头结点打上标志后即令  $q$  指向  $p$  的表尾；②设  $p$  的表头为空表或是已加上标志的子表，则无需遍历表头只要令  $q$  指向  $p$  的表尾即可；③设  $p$  的表头为未加标志的子表，则需先遍历表头子表，即  $p$  应赋  $q$  的值， $t$  相应往下移动改赋  $p$  的值。为了记下  $t$  指针移动的路径，以便在  $p$  退回原结点时同时能找到  $p$  的母表结点（即使  $t$  退回到原来的值），则在修改这个指针的值之前，应先记下  $t$  移动的路径，即令  $p$  所指结点的hp域的值为  $t$ ，且tag域的值为“0”。

另一方面，当  $q$  指向  $p$  的表尾时，也可能有两种情况出现：①  $p$  的表尾为未加标志的子表，则需遍历表尾的子表，同样  $p, t$  指针要作相应的移动。为了记下当前表结点的母表结点，同样要在改动  $p, t$  指针的值之前先记下路径；即令  $p$  所指结点的  $tp$  域的值改为  $t$ ，然后令  $t$  赋值  $p, p$  赋值  $q$ ；②  $p$  的表尾为“空”或是已加上标志的子表，此时表明  $p$  所指的表已加上标志，则  $p$  应退回到其母表结点即  $t$  所指结点，相应地  $t$  也应后退一步，即退到  $t$  结点的母表结点。综上所述可知， $t$  的移动路径已记录在  $t$  结点的  $hp$  域或  $tp$  域中，究竟是哪一个？则要由辨别 tag 域的值来定。它不仅指示  $t$  应按哪个指针所指路径退回，而且指示了下一步应做什么。若  $t$  结点是其母表表头，则应继续遍历其母表的表尾。若  $t$  结点是其母表的表尾，则应继续找更高一层的母表结点。整个算法大致描述如下：（GL为广义表的头指针）

```javascript
$\mathbf{t} = \mathbf{N}\mathbf{U}\mathbf{L}\mathbf{L};\quad \mathbf{p} = \mathbf{G}\mathbf{L};\quad \mathbf{f i n i s h e d} = \mathbf{F}\mathbf{A}\mathbf{L}\mathbf{S}\mathbf{E};$    
while(!finished){while  $(\mathrm{p - > }$  mark  $= = 0)$  {p->mark  $= 1$  MarkHead(p); //若表头是未经遍历的非空子表，则修改指针记录路径，} //且p指向表头；否则p不变q=p->p.tp;if(q&&q->mark  $= = 0$  )MarkTail(p); //修改指针记录路径，且p指向表尾elseBackTrack(finished);//若从表尾回溯到第一个结点，则finished为TRUE
```

求精后的广义表遍历算法如算法8.3所示。

```txt
voidMarkList(GListGL）{//遍历非空广义表GL！  $\equiv$  NULL且GL->mark  $\equiv = 0$  ，对表中所有未加标志的结点加标志。t  $=$  NULL;  $\mathbf{p} = \mathbf{G}\mathbf{L};$  finished  $\equiv$  FALSE; //t指示p的母表
```

![](images/ba7432548e117936d7d6e226c3a1169972fc76fcb5191ff5ed22122896c72cfc.jpg)  
图8.11 遍历广义表

(a) 指针初始化, q指向表头;  
(b)和(c）指针向表头方向推进一步；  
(d) 对元素结点加标志后指针后退, q 指向表尾;  
(e) 指针向表尾方向推进一步, q指向表头;  
(f) 指针后退一步；  
(g) 指针继续后退, q 指向表尾;  
（h）指针向表尾方向推进一步，q指向表尾(表头为空表)；  
(i) 指针继续向表尾方向推进一步,  $q$  指向表头

```txt
while(!finished) {  
    while(p->mark==0) {  
        p->mark=1;  
        //MarkHead(p)的细化：  
        q=p->p.hp; //q指向\*p的表头  
        if(q&&q->mark==0) {  
            if(q->tag==0) q->mrank=1; //ATOM,表头为原子结点  
            else{p->p.hp=t; p->tag=0; t=p; p=q;} //继续遍历子表}
```

完成对表头的标志

q = p->p.tp; // q指向 *p的表尾

```txt
if  $(\mathbf{q}\& \& \mathbf{q} - > \mathbf{mark} = = 0)$  {p->p.tp  $= t$  ；t=p; p=q;} //继续遍历表尾 else{//BackTrack(finished)的细化： while(t&&t->tag  $= = 1$  ）{//LIST,表结点，从表尾回溯 q=t；t=q->p.tp; q->p.tp=p; p=q; } if(!t)finished  $=$  TRUE; //结束 else{//从表头回溯 q=t；t=q->p.mp; q->p.mp=p; p=q; p->tag=1; } //继续遍历表尾 } } }}//MarkList
```

# 算法 8.3

图8.11展示对图8.10中的广义表进行遍历加标志时各指针的变化状况。（a)为算法8.3开始执行时的状态。（b)和(c)为指针向表头方向移动并改变结点的hp域指针的情形。（d)表示当表头遍历完成将对表尾进行标志时的指针变化情况。从(e)和(f)读者可看到指针回溯的情形。在此省略了继续遍历时的指针变化状况，有兴趣的读者可试之补充。

比较上述3种算法各有利弊。第3种算法在标志时不需要附加存储，使动态分配的可利用空间得到充分利用，但是由于在算法中，几乎是每个表结点的指针域的值都要作两次改变，因此时间上的开销相当大，而且，一旦发生中断，整个系统瘫痪，无法重新启动运行。而非递归算法操作简单，时间上要比第3种算法省得多，然而它需要占有一定空间，使动态分配所用的存储量减少。总之，无用单元收集是很费时间的，不能在实时处理的情况下应用。

通常, 无用单元的收集工作是由编译程序中的专用系统来完成的, 它也可以作为一个标准函数由用户自行调用 (类似于 free 函数的使用)。不论哪一种情况, 系统都要求用户建立一个初始变量表登录用户程序中所有链表的表头指针, 以便从这些指针出发进行标志。

下面我们可以对无用单元收集算法作某种定量估计。如上所述，整个算法分两步进行：第一步对占用结点加标志，不管用哪一种算法，其所用时间都和结点数成正比。假设总的占用结点数为  $N$  ，则标志过程所需时间为  $c_{1}N$  （其中  $c_{1}$  为某个常数）；第二步是从可用空间的第一个结点起，顺序扫描，将所有未加标志的结点链结在一起。假设可用空间总共含有  $M$  个结点，则所需时间为  $c_{2}M$  （其中  $c_{2}$  为某个常数）。由此，收集算法总的时间为 $c_{1}N + c_{2}M$  ，同时收集到的无用结点个数为  $M - N$  。

显然，无用单元收集这项工作的效率和最后能收集到的可以重新分配的无用结点数有关。我们用收集一个无用结点所需的平均时间  $(c_{1}N + c_{2}M) / (M - N)$  来度量这个效率。假设以  $\rho = N / M$  表示内存使用的密度，则上述平均时间为  $(c_{1}\rho +c_{2}) / (1 - \rho)$  。当内存中  $3 / 4$  的结点为无用结点，即  $\rho = 1 / 4$  时，收集一个结点所需平均时间为  $1 / 3c_{1} + 4 / 3c_{2}$  。反之，当内存中  $1 / 4$  的结点为无用结点，即  $\rho = 3 / 4$  时，收集一个结点所需平均时间为 $3c_{1} + 4c_{2}$  。由此可见，可利用内存区中只有少量的结点为无用结点时，收集无用单元的操

作的效率很低。不仅如此，而且当系统重又恢复运行时，这些结点又很快被消耗掉，导致另一次无用单元的收集。如此下去有可能造成恶性循环，以至最后整个系统瘫痪。解决的办法可以由系统事先确定一个常数  $k$  ，当收集到的无用单元数为  $k$  或更少时系统就不再运行下去。

# 8.6 存储紧缩

前面几节中讨论的动态存储管理方法都有一个共同的特点，即建立一个“空闲块”或“无用结点”组成的可利用空间表，这个可利用空间表采用链表结构，其结点大小可以相同，也可以不同。

这一节将要介绍另一种结构的动态存储管理方法。在整个动态存储管理过程中，不

![](images/5742724c723f53fc2c4972256fc3fd606f7220c9409c665baaa193c0ea596090.jpg)

![](images/a513b1e48f28d650bcd41e10b3e345de645f13f0652074d4b9131fc79c41419e.jpg)

图8.12 堆存储管理示意图  
![](images/95295ddf31093e79b521ef0de7057e56f3420fe063a749c9762b3040a3c5e7ed.jpg)  
(a) 堆空间；(b) 串的存储映像；(c) 紧缩后的堆；(d) 修改后的存储映像

![](images/a4caea7094d2d4280383986c51e95d91ad74d5c34f51720885b701814b6cd3da.jpg)

管哪个时刻，可利用空间都是一个地址连续的存储区，在编译程序中称之为“堆”，每次分配都是从这个可利用空间中划出一块。其实现办法是：设立一个指针，称之为堆指针，始终指向堆的最低(或最高)地址。当用户申请  $N$  个单位的存储块时，堆指针向高地址（或低地址）移动  $N$  个存储单位，而移动之前的堆指针的值就是分配给用户的占用块的初始地址。回顾第4章中提及的串值存储空间的动态分配就是用的这种堆的存储管理。例如，某个串处理系统中有A、B、C、D这4个串，其串值长度分别为12、6、10和8。假设堆指针free的初值为零，则分配给这4个串值的存储空间的初始地址分别为0、12、18和28，如图8.12(a)和(b)所示，分配后的堆指针的值为36。因此，这种堆结构的存储管理的

分配算法非常简单。反之，回收用户释放的空闲块就比较麻烦。由于系统的可利用空间始终是一个地址连续的存储块，因此回收时必须将所释放的空闲块合并到整个堆上去才能重新使用，这就是“存储紧缩”的任务。通常，有两种做法：一种是一旦有用户释放存储块即进行回收紧缩，例如，图8.12(a)的堆，在c串释放存储块时即回收紧缩成为图8.12(c)的堆，同时修改串的存储映像成图8.12(d)的状态；另一种是在程序执行过程中不回收用户随时释放的存储块，直到可利用空间不够分配或堆指针指向最高地址时才进行存储紧缩。此时紧缩的目的是将堆中所有的空闲块连成一片，即将所有的占用块都集中到可利用空间的低地址区，而剩余的高地址区成为一整个地址连续的空闲块，如图8.13所示，其中(a)为紧缩前的状态，(b)为紧缩后的状态。

图8.13 紧缩前后的堆（存储空间）  
![](images/a3ef9a67839efdb3da0f5f38e660d1834e2802594c943cc565f9eafd98a841c1.jpg)  
(a) 紧缩前；(b) 紧缩后

![](images/fe4a605d6f2a98300ad3cb95971ae30ac8692ff578f8ae0e8cb6e208a48e29ac.jpg)

和上节讨论的无用单元收集类似，为实现存储紧缩，首先要对占用块进行“标志”，标志算法和上节类同(存储块的结构可能不同)；其次需进行下列4步操作：

（1）计算占用块的新地址。从最低地址始巡查整个存储空间，对每一个占用块找到它在紧缩后的新地址。为此，需设立两个指针随巡查向前移动，这两个指针分别指示占用块在紧缩之前和之后的原地址和新地址。因此，在每个占用块的第一个存储单位中，除了设立长度域(存储该占用块的大小)和标志域(存储区别该存储块是占用块或空闲块的标志)之外，还需设立一个新地址域，以存储占用块在紧缩后应有的新地址，即建立一张新、旧地址的对照表。

（2）修改用户的初始变量表，以便在存储紧缩后用户程序能继续正常运行。  
（3）检查每个占用块中存储的数据。若有指向其他存储块的指针，则需作相应修改。  
（4）将所有占用块迁移到新地址去。这实质上是作传送数据的工作。

至此，完成了存储紧缩的操作。最后，将堆指针赋以新值（即紧缩后的空闲存储区的最低地址）。

可见，存储紧缩法比无用单元收集法更为复杂，前者不仅要传送数据（进行占用块迁移），而且要修改所有占用块中的指针值。因此，存储紧缩也是一个系统操作，且非不得已就不用。

# 第9章 查找

本书在第2章至第7章中已经介绍了各种线性或非线性的数据结构，在这一章将讨论另一种在实际应用中大量使用的数据结构——查找表。

查找表(Search Table)是由同一类型的数据元素(或记录)构成的集合。由于“集合”中的数据元素之间存在着完全松散的关系，因此查找表是一种非常灵便的数据结构。

对查找表经常进行的操作有：(1)查询某个“特定的”数据元素是否在查找表中；(2)检索某个“特定的”数据元素的各种属性；(3)在查找表中插入一个数据元素；(4)从查找表中删去某个数据元素。若对查找表只作前两种统称为“查找”的操作，则称此类查找表为静态查找表(Static Search Table)。若在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已存在的某个数据元素，则称此类表为动态查找表(Dynamic Search Table)。

在日常生活中，人们几乎每天都要进行“查找”工作。例如，在电话号码簿中查阅“某单位”或“某人”的电话号码；在字典中查阅“某个词”的读音和含义等等。其中“电话号码簿”和“字典”都可视作是一张查找表。

在各种系统软件或应用软件中，查找表也是最常见的结构之一。如编译程序中符号表、信息处理系统中信息表等等。

由上述可见，所谓“查找”即为在一个含有众多的数据元素(或记录)的查找表中找出某个“特定的”数据元素(或记录）。

为了便于讨论，必须给出这个“特定的”词的确切含义。首先需引入一个“关键字”的概念。

关键字(Key)是数据元素(或记录)中某个数据项的值, 用它可以标识(识别)一个数据元素(或记录)。若此关键字可以惟一地标识一个记录, 则称此关键字为主关键字 (Primary Key)(对不同的记录, 其主关键字均不同)。反之, 称用以识别若干记录的关键字为次关键字(Secondary Key)。当数据元素只有一个数据项时, 其关键字即为该数据元素的值。

查找（Searching）根据给定的某个值，在查找表中确定一个其关键字等于给定值的记录或数据元素。若表中存在这样的一个记录，则称查找是成功的，此时查找的结果为给出整个记录的信息，或指示该记录在查找表中的位置；若表中不存在关键字等于给定值的记录，则称查找不成功，此时查找的结果可给出一个“空”记录或“空”指针。

例如，当用计算机处理大学入学考试成绩时，全部考生的成绩可以用图9.1所示表的结构储存在计算机中，表中每一行为一个记录，考生的准考证号为记录的关键字。假设给定值为179326，则通过查找可得考生陆华的各科成绩和总分，此时查找为成功的。若给定值为179238，则由于表中没有关键字为179238的记录，则查找不成功。

如何进行查找？显然，在一个结构中查找某个数据元素的过程依赖于这个数据元素在结构中所处的地位。因此，对表进行查找的方法取决于表中数据元素依何种关系（这个

关系是人为地加上的)组织在一起的。例如查电话号码时，由于电话号码簿是按用户(集体或个人)的名称(或姓名)分类且依笔划顺序编排，则查找的方法就是先顺序查找待查用户的所属类别，然后在此类中顺序查找，直到找到该用户的电话号码为止。又如，查阅英文单词时，由于字典是按单词的字母在字母表中的次序编排的，因此查找时不需要从字典中第一个单词比较起，而只要根据待查单词中每个字母在字母表中的位置查到该单词。

<table><tr><td rowspan="2">准考证号</td><td rowspan="2">姓名</td><td colspan="7">各 科 成 绩</td><td rowspan="2">总分</td></tr><tr><td>政治</td><td>语文</td><td>外语</td><td>数学</td><td>物理</td><td>化学</td><td>生物</td></tr><tr><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td></tr><tr><td>179325</td><td>陈红</td><td>85</td><td>86</td><td>88</td><td>100</td><td>92</td><td>90</td><td>45</td><td>586</td></tr><tr><td>179326</td><td>陆华</td><td>78</td><td>75</td><td>90</td><td>80</td><td>95</td><td>88</td><td>37</td><td>543</td></tr><tr><td>179327</td><td>张平</td><td>82</td><td>80</td><td>78</td><td>98</td><td>84</td><td>96</td><td>40</td><td>558</td></tr><tr><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td></tr></table>

图9.1 高考成绩表示例

同样，在计算机中进行查找的方法也随数据结构不同而不同。正如前所述，本章讨论的查找表是一种非常灵便的数据结构。但也正是由于表中数据元素之间仅存在着“同属一个集合”的松散关系，给查找带来不便。为此，需在数据元素之间人为地加上一些关系，以便按某种规则进行查找，即以另一种数据结构来表示查找表。本章将分别就静态查找表和动态查找表两种抽象数据类型讨论其表示和操作实现的方法。

在本章以后各节的讨论中，涉及的关键字类型和数据元素类型统一说明如下：

典型的关键字类型说明可以是

```txt
typedef floatKeyType; //实型 typedef intKeyType; //整型 typedef char *KeyType; //字符串型
```

数据元素类型定义为：

```txt
typedef struct {
   KeyType key; //关键字域
    ...
}SElemType;
```

对两个关键字的比较约定为如下的宏定义：

// - - 对数值型关键字  
```c
define EQ(a,b) ((a) ==(b))   
#define LT(a,b) ((a)< (b))   
#define LQ(a,b) ((a)<= (b))   
//--对字符串型关键字   
#define EQ(a,b) (!strcmp((a)，(b)))   
#define LT(a,b) (strcmp((a)，(b))<0)   
#define LQ(a,b) (strcmp((a)，(b))<=0)   
…
```

# 9.1 静态查找表

抽象数据类型静态查找表的定义为：

ADTStaticSearchTable{数据对象D：D是具有相同特性的数据元素的集合。各个数据元素均含有类型相同，可惟一标识数据元素的关键字。  
数据关系R：数据元素同属一个集合。  
基本操作P：Create(&ST，n);操作结果：构造一个含  $\mathbf{n}$  个数据元素的静态查找表ST。Destroy(&ST);初始条件：静态查找表ST存在。操作结果：销毁表ST。Search(ST,key);初始条件：静态查找表ST存在，key为和关键字类型相同的给定值。操作结果：若ST中存在其关键字等于key的数据元素，则函数值为该元素的值或在表中的位置，否则为“空”。Traverse(ST,Visit();初始条件：静态查找表ST存在，Visit是对元素操作的应用函数。操作结果：按某种次序对ST的每个元素调用函数visit()一次且仅一次。一旦visit()失败，则操作失败。}ADTStaticSearchTable

静态查找表可以有不同的表示方法，在不同的表示方法中，实现查找操作的方法也不同。

# 9.1.1 顺序表的查找

以顺序表或线性链表表示静态查找表, 则 Search 函数可用顺序查找来实现。本节中只讨论它在顺序存储结构模块中的实现, 在线性链表模块中实现的情况留给读者去完成。

// -- -- -- 静态查找表的顺序存储结构 -- -- -- typedef struct {
ElemType * elem; // 数据元素存储空间基址,建表时按实际长度分配,0号单元留空
int length; // 表长度
} SSTable;

下面讨论顺序查找的实现。

顺序查找(Sequential Search)的查找过程为: 从表中最后一个记录开始, 逐个进行记录的关键字和给定值的比较, 若某个记录的关键字和给定值比较相等, 则查找成功, 找到所查记录; 反之, 若直至第一个记录, 其关键字和给定值比较都不等, 则表明表中没有所查记录, 查找不成功。此查找过程可用算法9.1描述之。

int Search_Seq(SSTable ST, KeyType key) {
    // 在顺序表ST中顺序查找其关键字等于key的数据元素。若找到，则函数值为
    // 该元素在表中的位置，否则为0。

ST.elem[0].key = key; //“哨兵”  
for (i = ST.length; !EQ(ST.elem[i].key, key); --i); //从后往前找  
return i; //找不到时，i为0  
} //SearchSeq

# 算法 9.1

这个算法的思想和第2章中的函数LocateElbm_Sq一致。只是在Search_Seq中，查找之前先对ST.elem[0]的关键字赋值key，目的在于免去查找过程中每一步都要检测整个表是否查找完毕。在此，ST.elem[0]起到了监视哨的作用。这仅是一个程序设计技巧上的改进，然而实践证明，这个改进能使顺序查找在ST.length≥1000时，进行一次查找所需的平均时间几乎减少一半(参阅参考书目[1]中342页表7.1)。当然，监视哨也可设在高下标处。

# 查找操作的性能分析

在第1章中曾提及，衡量一个算法好坏的量度有3条：时间复杂度（衡量算法执行的时间量级）、空间复杂度（衡量算法的数据结构所占存储以及大量的附加存储）和算法的其他性能。对于查找算法来说，通常只需要一个或几个辅助空间。又，查找算法中的基本操作是“将记录的关键字和给定值进行比较”，因此，通常以“其关键字和给定值进行过比较的记录个数的平均值”作为衡量查找算法好坏的依据。

定义：为确定记录在查找表中的位置，需和给定值进行比较的关键字个数的期望值称为查找算法在查找成功时的平均查找长度(Average Search Length)。

对于含有  $n$  个记录的表，查找成功时的平均查找长度为

$$
A S L = \sum_ {i = 1} ^ {n} P _ {i} C _ {i} \tag {9-1}
$$

其中：  $P_{i}$  为查找表中第  $\pmb{i}$  个记录的概率，且  $\sum_{i = 1}^{n}P_{i} = 1$

$C_i$  为找到表中其关键字与给定值相等的第  $i$  个记录时，和给定值已进行过比较的关键字个数。显然， $C_i$  随查找过程不同而不同。

从顺序查找的过程可见， $C_i$  取决于所查记录在表中的位置。如：查找表中最后一个记录时，仅需比较一次；而查找表中第一个记录时，则需比较  $n$  次。一般情况下  $C_i$  等于  $n - i + 1$ 。

假设  $n = \mathrm{ST}$  .length,则顺序查找的平均查找长度为

$$
A S L = n P _ {1} + (n - 1) P _ {2} + \dots + 2 P _ {n - 1} + P _ {n} \tag {9-2}
$$

假设每个记录的查找概率相等，即

$$
P _ {i} = 1 / n
$$

则在等概率情况下顺序查找的平均查找长度为

$$
\begin{array}{l} A S L _ {\mathrm {S S}} = \sum_ {i = 1} ^ {n} P _ {i} C _ {i} \\ = \frac {1}{n} \sum_ {i = 1} ^ {n} (n - i + 1) \\ \end{array}
$$

$$
A S L _ {s s} = \frac {n + 1}{2} \tag {9-3}
$$

有时, 表中各个记录的查找概率并不相等。例如: 将全校学生的病历档案建立一张表存放在计算机中, 则体弱多病同学的病历记录的查找概率必定高于健康同学的病历记录。由于式(9-2)中的  $ASL$  在  $P_{n} \geqslant P_{n-1} \geqslant \cdots \geqslant P_{2} \geqslant P_{1}$  时达到极小值。因此, 对记录的查找概率不等的查找表若能预先得知每个记录的查找概率, 则应先对记录的查找概率进行排序, 使表中记录按查找概率由小至大重新排列, 以便提高查找效率。

然而，在一般情况下，记录的查找概率预先无法测定。为了提高查找效率，我们可以在每个记录中附设一个访问频度域，并使顺序表中的记录始终保持按访问频度非递减有序的次序排列，使得查找概率大的记录在查找过程中不断往后移，以便在以后的逐次查找中减少比较次数。或者在每次查找之后都将刚查找到的记录直接移至表尾。

顺序查找和我们后面将要讨论到的其他查找算法相比，其缺点是平均查找长度较大，特别是当  $n$  很大时，查找效率较低。然而，它有很大的优点是：算法简单且适应面广。它对表的结构无任何要求，无论记录是否按关键字有序①均可应用，而且，上述所有讨论对线性链表也同样适用。

容易看出, 上述对平均查找长度的讨论是在  $\sum_{i=1}^{n} P_i = 1$  的前提下进行的, 换句话说, 我们认为每次查找都是“成功”的。在本章开始时曾提到, 查找可能产生“成功”与“不成功”两种结果, 但在实际应用的大多数情况下, 查找成功的可能性比不成功的可能性大得多, 特别是在表中记录数  $n$  很大时, 查找不成功的概率可以忽略不计。当查找不成功的情形不能忽视时, 查找算法的平均查找长度应是查找成功时的平均查找长度与查找不成功时的平均查找长度之和。

对于顺序查找，不论给定值key为何值，查找不成功时和给定值进行比较的关键字个数均为  $n + 1$  。假设查找成功与不成功的可能性相同，对每个记录的查找概率也相等，则 $P_{i} = 1 / (2n)$  ，此时顺序查找的平均查找长度为

$$
\begin{array}{l} A S L _ {s} ^ {\prime} = \frac {1}{2 n} \sum_ {i = 1} ^ {n} (n - i + 1) + \frac {1}{2} (n + 1) \\ = \frac {3}{4} (n + 1) \tag {9-4} \\ \end{array}
$$

在本章的以后各节中，仅讨论查找成功时的平均查找长度和查找不成功时的比较次数，但哈希表例外。

# 9.1.2 有序表的查找

以有序表表示静态查找表时, Search 函数可用折半查找来实现。

折半查找(Binary Search)的查找过程是：先确定待查记录所在的范围(区间)，然后逐

步缩小范围直到找到或找不到该记录为止。

例如：已知如下11个数据元素的有序表(关键字即为数据元素的值)：

(05,13,19,21,37,56,64,75,80,88,92)

现要查找关键字为21和85的数据元素。

假设指针 low 和 high 分别指示待查元素所在范围的下界和上界, 指针 mid 指示区间的中间位置, 即  $\text{mid} = \left\lfloor (\text{low} + \text{high}) / 2 \right\rfloor$  。在此例中, low 和 high 的初值分别为 1 和 11, 即 [1,11] 为待查范围。

下面先看给定值  $\mathrm{key} = 21$  的查找过程：

![](images/9db53d33b4d1cc7ce3ab680760e83fad137ab3dff2b5bf5bc4cd1ab45e71a9d1.jpg)

首先令查找范围中间位置的数据元素的关键字ST.elem[mid].key与给定值key相比较，因为ST.elem[mid].key  $>$  key，说明待查元素若存在，必在区间  $[low, mid - 1]$  的范围内，则令指针high指向第mid-1个元素，重新求得  $mid = \lfloor (1 + 5) / 2\rfloor = 3$

![](images/3554b47d9e8e176d59078fcbb3a492168f661da3e76ac0b1ae090f1657b6c5fc.jpg)

仍以ST.elem[mid].key和key相比，因为ST.elem[mid].key  $<$  key，说明待查元素若存在，必在  $[mid + 1,high]$  范围内，则令指针low指向第  $mid + 1$  个元素，求得mid的新值为4，比较ST.elem[mid].key和key，因为相等，则查找成功；所查元素在表中序号等于指针mid的值。

![](images/b9114a84193f77adcce74649f405276b2880052bceca8b2ff70f268796cff639.jpg)

再看key  $= 85$  的查找过程：

![](images/05e6e06eaf763f10019213167dc5d7a041ef5f0b2daa68f21072a8d70869a06f.jpg)

ST.elem[mid].key  $<  _{\mathrm{key}}$  令low  $\equiv$  mid+1

![](images/f80a55f964234c743a8872de2b851cac8acac478ebe1bc9afecc571906128536.jpg)

此时因为下界  $low >$  上界 high，则说明表中没有关键字等于 key 的元素，查找不成功。

从上述例子可见，折半查找过程是以处于区间中间位置记录的关键字和给定值比较，若相等，则查找成功，若不等，则缩小范围，直至新的区间中间位置记录的关键字等于给定值或者查找区间的大小小于零时(表明查找不成功)为止。

上述折半查找过程如算法9.2描述所示。

```javascript
int Search_Bin（SSTable ST, KeyType key）{//在有序表ST中折半查找其关键字等于key的数据元素。若找到，则函数值为//该元素在表中的位置，否则为0。low  $= 1$  ；high  $=$  ST.length; //置区间初值while  $(\text{low} <   = \text{high})$  {mid  $=$  （low  $^+$  high)/2;if（EQ(key，ST.elem[mid].key)) return mid; //找到待查元素else if (LT(key，ST.elem[mid].key)) high  $=$  mid-1; //继续在前半区间进行查找else low  $=$  mid+1; //继续在后半区间进行查找}return 0; //顺序表中不存在待查元素}//Search_Bin
```

# 算法 9.2

折半查找的性能分析

先看上述11个元素的表的具体例子。从上述查找过程可知：

找到第⑥个元素仅需比较1次；找到第③和第⑨个元素需比较2次；找到第①、④、⑦和⑩个元素需比较3次；找到第②、⑤、⑧和⑪个元素需比较4次。

这个查找过程可用图9.2所示的二叉树来描述。树中每个结点表示表中一个记录，结点中的值为该记录在表中的位置，通常称这个描述查找过程的二叉树为判定树，从判定树上可见，查找21的过程恰好是走了一条从根到结点④的路径，和给定值进行比较的关键字个数为该路径上的结点数或结点④在判定树上的层次数。类似地，找到有序表中任一记录的过程就是走了一条从根结点到与该记录相应的结点的路径，和给定值进行比较的关键字个数恰为该结点在判定树上的层次数。因此，折半查找法在查找成功时进行比较的关键字个数最多不超过树的深度，而具有  $n$  个结点的判定树的深度为  $\lfloor \log_2n\rfloor +1^{\mathfrak{Q}}$ ，所以，折半查找法在查找成功时和给定值进行比较的关键字个数至多为  $\lfloor \log_2n\rfloor +1$  。

![](images/9ebcfb10f14f010689cd6c5e23f17f529d8895cfb30c2f605c1f3aed7cc09a7d.jpg)  
图9.2 描述折半查找过程的判定树及查找21的过程

如果在图9.2所示判定树中所有结点的空指针域上加一个指向一个方形结点的指针，如图9.3所示。并且，称这些方形结点为判定树的外部结点（与之相对，称那些圆形结点为内部结点），那么折半查找时查找不成功的过程就是走了一条从根结点到外部结点的路径，和给定值进行比较的关键字个数等于该路径上内部结点个数，例如：查找85的过程即为走了一条从

根到结点  $\boxed{9-10}$  的路径。因此，折半查找在查找不成功时和给定值进行比较的关键字个数最多也不超过  $\lfloor \log_2 n \rfloor + 1$ 。

那么，折半查找的平均查找长度是多少呢？

![](images/a64ffe8753944f639fc816e2cd63fadbdedf52824ccd88b3f6afbe4ad60cb532.jpg)  
图9.3 加上外部结点的判定树和查找85的过程

为讨论方便起见, 假定有序表的长度  $n = 2^h - 1$  (反之,  $h = \log_2(n + 1)$ ), 则描述折半查找的判定树是深度为  $h$  的满二叉树。树中层次为 1 的结点有 1 个, 层次为 2 的结点有 2 个, ……, 层次为  $h$  的结点有  $2^{h - 1}$  个。假设表中每个记录的查找概率相等  $\left(P_i = \frac{1}{n}\right)$ , 则查找成功时折半查找的平均查找长度

$$
\begin{array}{l} A S L _ {b s} = \sum_ {i = 1} ^ {n} P _ {i} C _ {i} \\ = \frac {1}{n} \sum_ {j = 1} ^ {h} j \cdot 2 ^ {j - 1} \\ = \frac {n + 1}{n} \log_ {2} (n + 1) - 1 ^ {\Phi} \tag {9-5} \\ \end{array}
$$

对任意的  $n$  ，当  $\pmb{n}$  较大  $(n > 50)$  时，可有下列近似结果

$$
A S L _ {b s} = \log_ {2} (n + 1) - 1 \tag {9-6}
$$

可见，折半查找的效率比顺序查找高，但折半查找只适用于有序表，且限于顺序存储结构（对线性链表无法有效地进行折半查找）。

以有序表表示静态查找表时，进行查找的方法除折半查找之外，还有斐波那契查找和插值查找。

斐波那契查找是根据斐波那契序列②的特点对表进行分割的。假设开始时表中记录个数比某个斐波那契数小1，即  $n = F_{u} - 1$ ，然后将给定值key和ST.elem[Fu-1].key进行比较，若相等，则查找成功；若key<ST.elem[Fu-1].key，则继续在自ST.elem[1]至ST.elem[Fu-1-1]的子表中进行查找，否则继续在自ST.elem[Fu-1+1]至ST.elem[Fu-1]的子表中进行查找，后一子表的长度为  $F_{u-2} - 1$  。斐波那契查找的平均性能比折半查找好，但最坏情况下的性能(虽然仍是  $O(\log n)$ )却比折半查找差。它还有一个优点就是分割时只需进行加、减运算。

①  $ASL_{n} = \sum_{i=1}^{n} P_{i} C_{i} = \frac{1}{n} \sum_{i=1}^{n} C_{i} = \frac{1}{n} \sum_{j=1}^{h} j \cdot 2^{j-1} = \frac{1}{n} \left( \sum_{i=0}^{h-1} 2^{i} + 2 \sum_{i=0}^{h-2} 2^{i} + \cdots + 2^{h-1} \sum_{i=0}^{0} 2^{i} \right)$

$$
\begin{array}{l} = \frac {1}{n} [ h \cdot 2 ^ {h} - (2 ^ {0} + 2 ^ {1} + \dots + 2 ^ {h - 1}) ] = \frac {1}{n} [ (h - 1) 2 ^ {h} + 1 ] \\ = \frac {1}{n} [ (n + 1) (\log_ {2} (n + 1) - 1) + 1 ] = \frac {n + 1}{n} \log_ {2} (n + 1) - 1 \\ \end{array}
$$

② 这种序列可定义为：  $F_{0} = 0$  ，  $F_{1} = 1$  ，  $F_{i} = F_{i - 1} + F_{i - 2}$  ，  $i\geqslant 2$

插值查找是根据给定值 key 来确定进行比较的关键字 ST.elem[i].key 的查找方法。令  $i = \frac{\text{key} - \text{ST.elem}[1].\text{key}}{\text{ST.elem}[h].\text{key} - \text{ST.elem}[l].\text{key}} (h - 1 + 1)$ ，其中 ST.elem[1] 和 ST.elem[h] 分别为有序表中具有最小关键字和最大关键字的记录。显然，这种插值查找只适于关键字均匀分布的表，在这种情况下，对表长较大的顺序表，其平均性能比折半查找好。

# 9.1.3 静态树表的查找

上一小节对有序表的查找性能的讨论是在“等概率”的前提下进行的，即当有序表中各记录的查找概率相等时，按图9.2所示判定树描述的查找过程来进行折半查找，其性能最优。如果有序表中各记录的查找概率不等，情况又如何呢？

先看一个具体例子。假设有序表中含5个记录，并且已知各记录的查找概率不等，分别为  $p_1 = 0.1, p_2 = 0.2, p_3 = 0.1, p_4 = 0.4$  和  $p_5 = 0.2$  。则按式(9-1)的定义，对此有序表进行折半查找，查找成功时的平均查找长度为

$$
\sum_ {i = 1} ^ {5} P _ {i} C _ {i} = 0. 1 \times 2 + 0. 2 \times 3 + 0. 1 \times 1 + 0. 4 \times 2 + 0. 2 \times 3 = 2. 3
$$

但是，如果在查找时令给定值先和第4个记录的关键字进行比较，比较不相等时再继续在左子序列或右子序列中进行折半查找，则查找成功时的平均查找长度为

$$
\sum_ {i = 1} ^ {5} P _ {i} C _ {i} = 0. 1 \times 3 + 0. 2 \times 2 + 0. 1 \times 3 + 0. 4 \times 1 + 0. 2 \times 2 = 1. 8
$$

这就说明，当有序表中各记录的查找概率不等时，按图9.2所示判定树进行折半查找，其性能未必是最优的。那么此时应如何进行查找呢？换句话说，描述查找过程的判定树为何类二叉树时，其查找性能最佳？

如果只考虑查找成功的情况，则使查找性能达最佳的判定树是其带权内路径长度之和  $PH$  值①

$$
P H = \sum_ {i = 1} ^ {n} w _ {i} h _ {i} \tag {9-7}
$$

取最小值的二叉树。其中：  $n$  为二叉树上结点的个数（即有序表的长度）；  $h_i$  为第  $i$  个结点在二叉树上的层次数；结点的权  $w_i = c p_i (i = 1,2,\dots,n)$ ，其中  $p_i$  为结点的查找概率， $c$  为某个常量。称  $PH$  值取最小的二叉树为静态最优查找树(Static Optimal Search Tree)。由于构造静态最优查找树花费的时间代价较高，因此在本书中不作详细讨论，有兴趣的读者可查阅参考书目[1]。在此向读者介绍一种构造近似最优查找树的有效算法。

已知一个按关键字有序的记录序列

$$
\left(r _ {l}, r _ {l + 1}, \dots , r _ {h}\right) \tag {9-8}
$$

其中  $\mathbf{r}_1.$  key  $<  \mathrm{r}_{\mathrm{h} + 1}.$  key  $<  \dots <  \mathrm{r_h}$  .key

与每个记录相应的权值为

$$
w _ {l}, w _ {l + 1}, \dots , w _ {h} \tag {9-9}
$$

现构造一棵二叉树, 使这棵二叉树的带权内路径长度  $PH$  值在所有具有同样权值的二叉

树中近似为最小，称这类二叉树为次优查找树(Nearly Optimal Search Tree)。

构造次优查找树的方法是：首先在式(9-8)所示的记录序列中取第  $i(l \leqslant i \leqslant h)$  个记录构造根结点  $\widehat{r_i}$ ，使得

$$
\Delta P _ {i} = \left| \sum_ {j = i + 1} ^ {h} w _ {j} - \sum_ {j = l} ^ {i - 1} w _ {j} \right| \tag {9-10}
$$

取最小值  $(\Delta P_{i} = \min_{l\leqslant j\leqslant h}\{\Delta P_{j}\})$  ，然后分别对子序列  $\{r_l,r_{l + 1},\dots ,r_{i - 1}\}$  和  $\{r_{i + 1},\dots ,r_h\}$  构造两棵次优查找树，并分别设为根结点的左子树和右子树。

为便于计算  $\Delta P$  ，引入累计权值和

$$
s w _ {i} = \sum_ {j = l} ^ {i} w _ {j} \tag {9-11}
$$

并设  $w_{l - 1} = 0$  和  $sw_{l - 1} = 0$  ，则

$$
\left\{ \begin{array}{l} s w _ {i - 1} - s w _ {l - 1} = \sum_ {j = l} ^ {i - 1} w _ {j} \\ s w _ {h} - s w _ {i} = \sum_ {j = i + 1} ^ {h} w _ {j} \end{array} \right. \tag {9-12}
$$

$$
\begin{array}{l} \Delta P _ {i} = \left| \left(s w _ {h} - s w _ {i}\right) - \left(s w _ {i - 1} - s w _ {t - 1}\right) \right| \\ = \left| \left(s w _ {h} + s w _ {l - 1}\right) - s w _ {i} - s w _ {i - 1} \right| \tag {9-13} \\ \end{array}
$$

由此可得构造次优查找树的递归算法如算法9.3所示。

```c
void SecondOptimal(BiTree &T, ElemType R[], float sw[], int low, int high) {
// 由有序表 R[low..high]及其累计权值表 sw(其中 sw[0] == 0)递归构造次优查找树 T。
i = low; min = abs(sw[high] - sw[low]); dw = sw[high] + sw[low-1];
for (j = low+1; j<=high; ++j) // 选择最小的  $\Delta P_{i}$  值
if (abs(dw - sw[j] - sw[j-1]) < min) {
i = j; min = abs(dw - sw[j] - sw[j-1]);
}
T = (BiTree)malloc(sizeof(BiTNode));
T->data = R[i]; // 生成结点
if (i == low) T->lchild = NULL; // 左子树空
else SecondOptimal(T->lchild, R, sw, low, i-1); // 构造左子树
if (i == high) T->rchild = NULL; // 右子树空
else SecondOptimal(T->rchild, R, sw, i+1, high); // 构造右子树
} // SecondOptimal
```

# 算法 9.3

例9-1 已知含9个关键字的有序表及其相应权值为：

<table><tr><td>关键字</td><td>A</td><td>B</td><td>C</td><td>D</td><td>E</td><td>F</td><td>G</td><td>H</td><td>I</td></tr><tr><td>权值</td><td>1</td><td>1</td><td>2</td><td>5</td><td>3</td><td>4</td><td>4</td><td>3</td><td>5</td></tr></table>

则按算法9.3构造次优查找树的过程中累计权值SW和  $\Delta P$  的值如图9.4(a)所示，构造所得次优二叉查找树如图9.4(b)所示。

<table><tr><td>j</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td>keyi</td><td></td><td>A</td><td>B</td><td>C</td><td>D</td><td>E</td><td>F</td><td>G</td><td>H</td><td>I</td></tr><tr><td>Wj</td><td>0</td><td>1</td><td>1</td><td>2</td><td>5</td><td>3</td><td>4</td><td>4</td><td>3</td><td>5</td></tr><tr><td>SWj</td><td>0</td><td>1</td><td>2</td><td>4</td><td>9</td><td>12</td><td>16</td><td>20</td><td>23</td><td>28</td></tr><tr><td>ΔPj</td><td></td><td>27</td><td>25</td><td>22</td><td>15</td><td>7</td><td>0</td><td>8</td><td>15</td><td>23</td></tr><tr><td>(根)</td><td></td><td></td><td></td><td></td><td></td><td></td><td>^i</td><td></td><td></td><td></td></tr><tr><td>ΔPj</td><td></td><td>11</td><td>9</td><td>6</td><td>1</td><td>9</td><td></td><td>8</td><td>1</td><td>7</td></tr><tr><td>(根)</td><td></td><td></td><td></td><td></td><td>^i</td><td></td><td></td><td></td><td>^i</td><td></td></tr><tr><td>ΔPj</td><td></td><td>3</td><td>1</td><td>2</td><td></td><td>0</td><td></td><td>0</td><td></td><td>0</td></tr><tr><td>(根)</td><td></td><td></td><td>^i</td><td></td><td></td><td>^i</td><td></td><td>^i</td><td></td><td>^i</td></tr><tr><td>ΔPj</td><td></td><td>0</td><td></td><td>0</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>(根)</td><td></td><td>^i</td><td></td><td>^i</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

(a)  
(b)  
图9.4 构造次优二叉查找树示例  
![](images/753aad3755cabb2522ebdd9c3960cddc6c71aa7bafb86cfeef7b016a1f46fd62.jpg)  
(a) 累计权值和  $\Delta P$  值；(b) 次优查找树

由于在构造次优查找树的过程中，没有考察单个关键字的相应权值，则有可能出现被选为根的关键字的权值比与它相邻的关键字的权值小。此时应作适当调整：选取邻近的权值较大的关键字作次优查找树的根结点。

例9-2 已知含5个关键字的有序表及其相应权值为

<table><tr><td>关键字</td><td>A</td><td>B</td><td>C</td><td>D</td><td>E</td></tr><tr><td>权值</td><td>1</td><td>30</td><td>2</td><td>29</td><td>3</td></tr></table>

则按算法9.3构造所得次优查找树如图9.5(a)所示，调整处理后的次优查找树如图9.5(b)所示。容易算得，前者的  $PH$  值为132，后者的  $PH$  值为105。

大量的实验研究表明，次优查找树和最优查找树的查找性能之差仅为  $1\% \sim 2\%$  ，很少超过  $3\%$  ，而且构造次优查找树的算法的时间复杂度为  $O(n \log n)$  ，因此算法9.3是构造近似最优二叉查找树的有效算法。

图9.5 根的权小于子树根权的情况  
![](images/401942a685c1f00740f4566aa397317dbf77855a969fd1c444c61c8e396e4011.jpg)  
(a) 调整之前的次优查找树；  
（b）调整之后的次优查找树

从次优查找树的结构特点可见，其查找过程类似于折半查找。若次优查找树为空，则查找不成功，否则，首先将给定值 key 和其根结点的关键字相比，若相等，则查找成功，该根结点的记录即为所求；否则将根据给定值 key 小于或大于根结点的关键字而分别在左子树或右子树中继续查找直至查找成功或不成功为止（算法描述和下节讨论的二叉排序

树的查找算法类似, 在此省略)。由于查找过程恰是走了一条从根到待查记录所在结点 (或叶子结点)的一条路径, 进行过比较的关键字个数不超过树的深度, 因此, 次优查找树的平均查找长度和  $\log n$  成正比。可见, 在记录的查找概率不等时, 可用次优查找树表示静态查找树, 故又称静态树表, 按有序表构造次优查找树的算法如算法 9.4 所示。

```txt
typedef BiTreeSOSTree; //次优查找树采用二叉链表的存储结构  
Status CreateSOSTree(SOSTree&T, SSTableST) { //由有序表ST构造一棵次优查找树T。ST的数据元素含有权域weight。 if(ST.length == 0) T = NULL; else { FindSW(sw, ST); //按照由有序表ST中各数据元素的weight域求累计权值表sw。 SecondOpomial(T, ST.elem, sw, 1, ST.length); } return OK; } //CreateSOSTree
```

# 算法 9.4

# 9.1.4 索引顺序表的查找

若以索引顺序表表示静态查找表，则Search函数可用分块查找来实现。

分块查找又称索引顺序查找，这是顺序查找的一种改进方法。在此查找法中，除表本身以外，尚需建立一个“索引表”。例如，图9.6所示为一个表及其索引表，表中含有18个记录，可分成3个子表  $(R_{1}, R_{2}, \dots, R_{6}), (R_{7}, R_{8}, \dots, R_{12}), (R_{13}, R_{14}, \dots, R_{18})$  ，对每个子表(或称块)建立一个索引项，其中包括两项内容：关键字项（其值为该子表内的最大关键字）和指针项(指示该子表的第一个记录在表中位置)。索引表按关键字有序，则表或者有序或者分块有序。所谓“分块有序”指的是第二个子表中所有记录的关键字均大于第一个子表中的最大关键字，第三个子表中的所有关键字均大于第二个子表中的最大关键字，……，依次类推。

![](images/401dbc5cb6884351aa5389411b89d93020b868cd73f6f5b945a7807466fcdaf9.jpg)  
图9.6 表及其索引表

因此，分块查找过程需分两步进行。先确定待查记录所在的块(子表)，然后在块中顺序查找。假设给定值  $key = 38$  ，则先将  $key$  依次和索引表中各最大关键字进行比较，因为  $22 < key < 48$  ，则关键字为38的记录若存在，必定在第二个子表中，由于同一索引项中的指针指示第二个子表中的第一个记录是表中第7个记录，则自第7个记录起进行顺序查找，直到ST.elem[10].key  $\equiv$  key为止。假如此子表中没有关键字等于  $key$  的记录（例如：  $key = 29$  时自第7个记录起至第12个记录的关键字和key比较都不等），则查找不成功。

由于由索引项组成的索引表按关键字有序, 则确定块的查找可以用顺序查找, 亦可用

折半查找，而块中记录是任意排列的，则在块中只能是顺序查找。

由此，分块查找的算法即为这两种查找算法的简单合成。

分块查找的平均查找长度为

$$
A S L _ {b s} = L _ {b} + L _ {w} \tag {9-14}
$$

其中：  $L_{b}$  为查找索引表确定所在块的平均查找长度，  $L_{w}$  为在块中查找元素的平均查找长度。

一般情况下，为进行分块查找，可以将长度为  $n$  的表均匀地分成  $b$  块，每块含有  $s$  个记录，即  $b = \lceil n / s \rceil$ ；又假定表中每个记录的查找概率相等，则每块查找的概率为  $1 / b$ ，块中每个记录的查找概率为  $1 / s$ 。

若用顺序查找确定所在块，则分块查找的平均查找长度为

$$
\begin{array}{l} A S L _ {b s} = L _ {b} + L _ {w} = \frac {1}{b} \sum_ {j = 1} ^ {b} j + \frac {1}{s} \sum_ {i = 1} ^ {s} i = \frac {b + 1}{2} + \frac {s + 1}{2} \\ = \frac {1}{2} \left(\frac {n}{s} + s\right) + 1 \tag {9-15} \\ \end{array}
$$

可见, 此时的平均查找长度不仅和表长  $n$  有关, 而且和每一块中的记录个数  $s$  有关。在给定  $n$  的前提下,  $s$  是可以选择的。容易证明, 当  $s$  取  $\sqrt{n}$  时,  $ASL_{bs}$  取最小值  $\sqrt{n} + 1$  。这个值比顺序查找有了很大改进, 但远不及折半查找。

若用折半查找确定所在块，则分块查找的平均查找长度为

$$
A S L _ {b s} ^ {\prime} \approx \log_ {2} \left(\frac {n}{s} + 1\right) + \frac {s}{2} \tag {9-16}
$$

# 9.2 动态查找表

在这一节和下一节中，我们将讨论动态查找表的表示和实现。动态查找表的特点是，表结构本身是在查找过程中动态生成的，即对于给定值key，若表中存在其关键字等于key的记录，则查找成功返回，否则插入关键字等于key的记录。以下是动态查找表的定义：

抽象数据类型动态查找表的定义如下：

ADT DynamicSearchTable {

数据对象D：D是具有相同特性的数据元素的集合。各个数据元素均含有类型相同，可惟一标识数据元素的关键字。

数据关系R：数据元素同属一个集合。

基本操作P：

InitDTable(&DT);

操作结果：构造一个空的动态查找表DT。

DestroyDSTable(&DT);

初始条件：动态查找表DT存在。

操作结果：销毁动态查找表DT。

SearchDSTable(DT, key);

初始条件：动态查找表DT存在，key为和关键字类型相同的给定值。

操作结果：若DT中存在其关键字等于key的数据元素，则函数值为该元素的值或在表中的位置，否则为“空”。

InsertDSTable(&DT, e);

初始条件：动态查找表DT存在，e为待插入的数据元素。

操作结果：若DT中不存在其关键字等于e.key的数据元素，则插入e到DT。

DeleteDSTable(&DT, key);

初始条件：动态查找表DT存在，key为和关键字类型相同的给定值。

操作结果：若DT中存在其关键字等于key的数据元素，则删除之。

TraverseDSTable(DT,Visit());

初始条件：动态查找表DT存在，Visit是对结点操作的应用函数。

操作结果：按某种次序对DT的每个结点调用函数Visit()一次且至多一次。一旦Visit()失败，则操作失败。

ADT DynamicSearchTable

动态查找表亦可有不同的表示方法。在本节中将讨论以各种树结构表示时的实现方法。

# 9.2.1 二叉排序树和平衡二叉树

# 1. 二叉排序树及其查找过程

什么是二叉排序树？

二叉排序树（Binary Sort Tree）或者是一棵空树；或者是具有下列性质的二叉树：(1)若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；(2)若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；(3)它的左、右子树也分别为二叉排序树。

例如图9.7所示为两棵二叉排序树。

![](images/70c50c767f3a7013ec88ec2b1d4317f77f44c795b37f2cdaf49192ec8f69e587.jpg)  
(a)

![](images/035a8f78906518d588c88b4cc678efd8433cfc0435eb124bbd7a139899db3664.jpg)  
(b)  
图9.7 二叉排序树示例

二叉排序树又称二叉查找树，根据上述定义的结构特点可见，它的查找过程和次优二叉树类似。即当二叉排序树不空时，首先将给定值和根结点的关键字比较，若相等，则查找成功，否则将依据给定值和根结点的关键字之间的大小关系，分别在左子树或右子树上继续进行查找。通常，可取二叉链表作为二叉排序树的存储结构，则上述查找过程如算法9.5(a)所描述。

```txt
BiTree SearchBST(BiT,KeyType key) { // 在根指针T所指二叉排序树中递归地查找某关键字等于key的数据元素， // 若查找成功，则返回指向该数据元素结点的指针，否则返回空指针 if(!T) || EQ(key,T->data.key)) return(T); // 查找结束 else if LT(key,T->data.key) return(SearchBST(T->lchild,key)); // 在左子树中继续查找 else return(SearchBST(T->rchild,key)); // 在右子树中继续查找 } // SearchBST
```

# 算法 9.5(a)

例如：在图9.7(a)所示的二叉排序树中查找关键字等于100的记录（树中结点内的数均为记录的关键字）。首先以  $key = 100$  和根结点的关键字作比较，因为  $key > 45$  ，则查找以⑤为根的右子树，此时右子树不空，且  $key > 53$  ，则继续查找以结点③为根的右子树，由于  $key$  和③的右子树根的关键字100相等，则查找成功，返回指向结点⑩的指针值。又如在图9.7(a)中查找关键字等于40的记录，和上述过程类似，在给定值  $key$  与关键字45、12及37相继比较之后，继续查找以结点⑦为根的右子树，此时右子树为空，则说明该树中没有待查记录，故查找不成功，返回指针值为“NULL”。

# 2. 二叉排序树的插入和删除

和次优二叉树相对，二叉排序树是一种动态树表。其特点是，树的结构通常不是一次生成的，而是在查找过程中，当树中不存在关键字等于给定值的结点时再进行插入。新插入的结点一定是一个新添加的叶子结点，并且是查找不成功时查找路径上访问的最后一个结点的左孩子或右孩子结点。为此，需将上一小节的二叉排序树的查找算法改写成算法9.5(b)，以便能在查找不成功时返回插入位置。插入算法如算法9.6所示。

```c
Status SearchBST(BiTree T,KeyType key, BiTree f, BiTree &p) {
// 在根指针 T 所指二叉排序树中递归地查找其关键字等于 key 的数据元素，若查找成功，
// 则指针 p 指向该数据元素结点，并返回 TRUE，否则指针 p 指向查找路径上访问的
// 最后一个结点并返回 FALSE，指针 f 指向 T 的双亲，其初始调用值为 NULL
if (!T) {p = f; return FALSE;} // 查找不成功
else if EQ(key, T->data.key) {p = T; return TRUE;} // 查找成功
else if LT(key, T->data.key) return SearchBST(T->lchild, key, T, p); // 在左子树中继续查找
else return SearchBST(T->rchild, key, T, p); // 在右子树中继续查找
} // SearchBST
```

# 算法 9.5(b)

```javascript
Status InsertBST(BiTree &T,ElemType e) { //当二叉排序树T中不存在关键字等于e.key的数据元素时，插入e并返回TRUE，//否则返回FALSE if(!SearchBST(T,e.key,NULL,p){ //查找不成功s=(BiTree)malloc(sizeof(BitNode)); s->data=e; s->lchild=s-rchild=NULL; if（!p）T=s; //被插结点  $\ast \mathbf{s}$  为新的根结点elseifLT(e.key,p->data.key)p->lchild=s; //被插结点  $\ast \mathbf{s}$  为左孩子elsep->rchild=s; //被插结点  $\ast \mathbf{s}$  为右孩子returnTRUE;
```

```txt
} else return FALSE; } // Insert BST
```

// 树中已有关键字相同的结点，不再插入

# 算法 9.6

若从空树出发, 经过一系列的查找插入操作之后, 可生成一棵二叉树。设查找的关键字序列为  $\{45, 24, 53, 45, 12, 24, 90\}$ , 则生成的二叉排序树如图 9.8 所示。

图9.8 二叉排序树的构造过程  
![](images/427cb1903c852a3c3b2f11f245dff423f80c87caded1757ff346f9613e7d4cf5.jpg)  
(a) 空树；(b) 插入 45；(c) 插入 24；(d) 插入 53；(e) 插入 12；(f) 插入 90

容易看出, 中序遍历二叉排序树可得到一个关键字的有序序列 (这个性质是由二叉排序树的定义决定的, 读者可以自己证明之)。这就是说, 一个无序序列可以通过构造一棵二叉排序树而变成一个有序序列, 构造树的过程即为对无序序列进行排序的过程。不仅如此, 从上面的插入过程还可以看到, 每次插入的新结点都是二叉排序树上新的叶子结点, 则在进行插入操作时, 不必移动其他结点, 仅需改动某个结点的指针, 由空变为非空即可。这就相当于在一个有序序列上插入一个记录而不需要移动其他记录。它表明, 二叉排序树既拥有类似于折半查找的特性, 又采用了链表作存储结构, 因此是动态查找表的一种适宜表示。

同样，在二叉排序树上删去一个结点也很方便。对于一般的二叉树来说，删去树中一个结点是没有意义的。因为它将使以被删结点为根的子树成为森林，破坏了整棵树的结构。然而，对于二叉排序树，删去树上一个结点相当于删去有序序列中的一个记录，只要在删除某个结点之后依旧保持二叉排序树的特性即可。

那么，如何在二叉排序树上删去一个结点呢？假设在二叉排序树上被删结点为  $*\mathfrak{p}^{\text{①}}$ （指向结点的指针为  $\mathfrak{p}$ ），其双亲结点为  $*\mathbf{f}$ （结点指针为  $\mathbf{f}$ ），且不失一般性，可设  $*\mathfrak{p}$  是  $*\mathbf{f}$  的左孩子（图9.9(a)所示）。

下面分3种情况进行讨论：

(1) 若  $* \mathfrak{p}$  结点为叶子结点, 即  $\mathrm{P_L}$  和  $\mathrm{P_R}$  均为空树。由于删去叶子结点不破坏整棵树的结构, 则只需修改其双亲结点的指针即可。  
(2) 若  $* \mathrm{p}$  结点只有左子树  $\mathbf{P}_{\mathrm{L}}$  或者只有右子树  $\mathbf{P}_{\mathrm{R}}$ ，此时只要令  $\mathbf{P}_{\mathrm{L}}$  或  $\mathbf{P}_{\mathrm{R}}$  直接成为其

双亲结点  $* \mathrm{f}$  的左子树即可。显然，作此修改也不破坏二叉排序树的特性。

（3）若  $*\mathfrak{p}$  结点的左子树和右子树均不空。显然，此时不能如上简单处理。从图9.9(b)可知，在删去  $*\mathfrak{p}$  结点之前，中序遍历该二叉树得到的序列为  $\{\cdots C_{L}C\cdots Q_{L}Q S_{L}S P P_{R}F\cdots\}$ ，在删去  $*\mathfrak{p}$  之后，为保持其他元素之间的相对位置不变，可以有两种做法：其一是令  $*\mathfrak{p}$  的左子树为  $*\mathfrak{f}$  的左子树，而  $*\mathfrak{p}$  的右子树为  $*\mathbf{s}$  的右子树，如图9.9(c)所示；其二是令  $*\mathfrak{p}$  的直接前驱(或直接后继)替代  $*\mathfrak{p}$ ，然后再从二叉排序树中删去它的直接前驱(或直接后继)。如图9.9(d)所示，当以直接前驱  $*\mathbf{s}$  替代  $*\mathfrak{p}$  时，由于  $*\mathbf{s}$  只有左子树  $S_{L}$ ，则在删去  $*\mathbf{s}$  之后，只要令  $S_{L}$  为  $*\mathbf{s}$  的双亲  $*\mathbf{q}$  的右子树即可。

(a)  
![](images/aa9baea0b781643f6c7d220fa65152aa7184a9d7cbdffbe20204fc5e62586861.jpg)  
(a) 以  $* \mathbf{f}$  为根的子树；(b) 删除  $* \mathbf{p}$  之前；

(b)  
图9.9 在二叉排序树中删除  $\star p$  
![](images/5499d633e66c3ba060cb7b7178cf2a43db901d735791e027d7521f8a344c0033.jpg)  
（c）删除  $\ast \mathbb{P}$  之后，以  $\mathrm{P_R}$  作为  $\ast \mathbf{s}$  的右子树的情形；

(c)  
![](images/faef8a99b2fab0550ee1876d458bf855b90baa630ff4d45ad2167ab50f816977.jpg)  
(d) 删除  $* \mathrm{p}$  之后，以  $* \mathrm{s}$  替代  $* \mathrm{p}$  的情形

![](images/f286fa574ff3641f4e5ad7a227c7c4eb5ab6421e1dc84851d0baa4370b606686.jpg)  
(d)

在二叉排序树上删除一个结点的算法如算法9.7所示，其中由前述3种情况综合所得的删除操作如算法9.8所示。

```c
Status DeleteBST (BiTree &T, KeyType key) {
// 若二叉排序树 T 中存在关键字等于 key 的数据元素时，则删除该数据元素结点，
// 并返回 TRUE; 否则返回 FALSE
if (!T) return FALSE; // 不存在关键字等于 key 的数据元素
else {
if (EQ(key, T->data.key)) {return Delete(T);} // 找到关键字等于 key 的数据元素
else if (LT(key, T->data.key)) return DeleteBST(T->lchild, key);
else return DeleteBST(T->rchild, key);
}
} // DeleteBST
```

# 算法 9.7

其中删除操作过程如算法9.8所描述：

```txt
Status Delete (BiTree &p) {
// 从二叉排序树中删除结点 p, 并重接它的左或右子树
if (!p->rchild) { // 右子树空则只需重接它的左子树
q = p; p = p->lchild; free(q);
```

```c
}  
else if (!p->lchild) { // 只需重接它的右子树  
q = p; p = p->rchild; free(q);  
}  
else { // 左右子树均不空  
q = p; s = p->lchild;  
while (s->rchild) { q = s; s = s->rchild} // 转左,然后向右到尽头  
p->data = s->data; // s指向被删结点的“前驱”  
if (q != p) q->rchild = s->lchild; // 重接 *q 的右子树  
else q->lchild = s->lchild; // 重接 *q 的左子树  
delete s;  
}  
return TRUE;  
}// Delete
```

# 算法 9.8

# 3. 二叉排序树的查找分析

从前述的两个查找例子  $(key = 100$  和  $key = 40)$  可见，在二叉排序树上查找其关键字等于给定值的结点的过程，恰是走了一条从根结点到该结点的路径的过程，和给定值比较的关键字个数等于路径长度加1（或结点所在层次数），因此，和折半查找类似，与给定值比较的关键字个数不超过树的深度。然而，折半查找长度为  $n$  的表的判定树是惟一的，而含有  $n$  个结点的二叉排序树却不惟一。图9.10中(a)和(b)的两棵二叉排序树中结点的值都相同，但前者由关键字序列(45,24,53,12,37,93)构成，而后者由关键字序列(12,24,37,45,53,93)构成。(a)树的深度为3，而(b)树的深度为6。再从平均查找长度来看，假设6个记录的查找概率相等，为  $1 / 6$  ，则(a)树的平均查找长度为

$$
A S L _ {\mathrm {(a)}} = \frac {1}{6} [ 1 + 2 + 2 + 3 + 3 + 3 ] = 1 4 / 6
$$

而(b)树的平均查找长度为

图9.10 不同形态的二叉查找树  
![](images/40579f036c5b04558bd445e3113ed48fdfc78e9baf608dc4032e0dd6df8eefbc.jpg)  
(a) 关键字序列为(45,24,53,12,37,93)的二叉排序树；  
（b）关键字序列为（12，24，37，45，53，93)的单支树

因此，含有  $n$  个结点的二叉排序树的平均查找长度和树的形态有关。当先后插入的关键字有序时，构成的二叉排序树蜕变为单支树。树的深度为  $n$  ，其平均查找长度为  $\frac{n + 1}{2}$  （和顺序查找相同），这是最差的情况。显然，最好的情况是二叉排序树的形态和折半查找的判定树相同，其平均查找长度和  $\log_2 n$  成正比。那么，它的平均性能如何呢？

假设在含有  $n(n\geqslant 1)$  个关键字的序列中， $i$  个关键字小于第一个关键字， $n - i - 1$  个关键字大于第一个关键字，则由此构造而得的二叉排序树在  $n$  个记录的查找概率相等的情况下，其平均查找长度为

$$
P (n, i) = \frac {1}{n} [ 1 + i * (P (i) + 1) + (n - i - 1) (P (n - i - 1) + 1) ] \tag {9-17}
$$

其中  $P(i)$  为含有  $i$  个结点的二叉排序树的平均查找长度，则  $P(i) + 1$  为查找左子树中每个关键字时所用比较次数的平均值， $P(n - i - 1) + 1$  为查找右子树中每个关键字时所用比较次数的平均值。又假设表中  $n$  个关键字的排列是“随机”的，即任一个关键字在序列中将是第1个，或第2个，…，或第  $n$  个的概率相同，则可对(9-17)式从  $i$  等于0至 $n - 1$  取平均值

$$
\begin{array}{l} P (n) = \frac {1}{n} \sum_ {i = 0} ^ {n - 1} P (n, i) \\ = 1 + \frac {1}{n ^ {2}} \sum_ {i = 0} ^ {n - 1} [ i P (i) + (n - i - 1) P (n - i - 1) ] \\ \end{array}
$$

容易看出上式括弧中的第一项和第二项对称。又， $i = 0$  时  $iP(i) = 0$ ，则上式可改写为

$$
P (n) = 1 + \frac {2}{n ^ {2}} \sum_ {i = 1} ^ {n - 1} i P (i) \quad n \geqslant 2 \tag {9-18}
$$

显然，  $P(0) = 0,P(1) = 1$

由式(9-18)可推得

$$
\sum_ {j = 0} ^ {n - 1} j P (j) = \frac {n ^ {2}}{2} [ P (n) - 1 ]
$$

又  $\sum_{j=0}^{n-1} jP(j) = (n-1)P(n-1) + \sum_{j=0}^{n-2} jP(j)$

由此可得  $\frac{n^2}{2} [P(n) - 1] = (n - 1)P(n - 1) + \frac{(n - 1)^2}{2} [P(n - 1) - 1]$

即  $P(n) = \left(1 - \frac{1}{n^2}\right)P(n - 1) + \frac{2}{n} -\frac{1}{n^2}$  (9-19)

由递推公式(9-19)和初始条件  $P(1) = 1$  可推得：

$$
\begin{array}{l} P (n) = 2 \frac {n + 1}{n} \left(\frac {1}{2} + \frac {1}{3} + \dots + \frac {1}{n + 1}\right) - 1 \\ = 2 \left(1 + \frac {1}{n}\right) \left(\frac {1}{2} + \frac {1}{3} + \dots + \frac {1}{n}\right) + \frac {2}{n} - 1 \\ \end{array}
$$

则当  $n \geqslant 2$  时

$$
P (n) \leqslant 2 \left(1 + \frac {1}{n}\right) \ln n \tag {9-20}
$$

由此可见，在随机的情况下，二叉排序树的平均查找长度和  $\log n$  是等数量级的。然而，在某些情况下（有人研究证明，这种情况出现的概率约为  $46.5\%$ ）[1]，尚需在构成二叉排序树的过程中进行“平衡化”处理，成为二叉平衡树。

# 4. 平衡二叉树

平衡二叉树（Balanced Binary Tree 或 Height-Balanced Tree）又称 AVL 树。它或者是一棵空树，或者是具有下列性质的二叉树：它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过 1。若将二叉树上结点的平衡因子 BF（Balance Factor）定义为该结点的左子树的深度减去它的右子树的深度，则平衡二叉树上所有结点的平衡因子只可能是一 1、0 和 1。只要二叉树上有一个结点的平衡因子的绝对值大于 1，则该二叉树就是不平衡的。如图 9.11(a) 所示为两棵平衡二叉树，而图 9.11(b) 所示为两棵不平衡的二叉树，结点中的值为该结点的平衡因子。

图9.11 平衡与不平衡的二叉树及结点的平衡因子  
![](images/d2fdcbd71f2b6b626394abea563b3c37856471abef226f338cb4ceecb9c07189.jpg)  
(a) 平衡二叉树；(b) 不平衡的二叉树

我们希望由任何初始序列构成的二叉排序树都是AVL树。因为AVL树上任何结点的左右子树的深度之差都不超过1，则可以证明它的深度和  $\log n$  是同数量级的（其中 $n$  为结点个数)。由此，它的平均查找长度也和  $\log n$  同数量级。

如何使构成的二叉排序树成为平衡树呢？先看一个具体例子(参见图9.12)。假设表中关键字序列为(13,24,37,90,53)。空树和1个结点⑬的树显然都是平衡的二叉树。在插入24之后仍是平衡的，只是根结点的平衡因子BF由0变为-1；在继续插入37之后，由于结点⑬的BF值由-1变成-2，由此出现了不平衡的现象。此时好比一根扁担出现一头重一头轻的现象，若能将扁担的支撑点由⑬改至④，扁担的两头就平衡了。由此，可以对树作一个向左逆时针“旋转”的操作，令结点②为根，而结点③为它的左子树，此时，结点③和④的平衡因子都为0，而且仍保持二叉排序树的特性。在继续插入90和53之后，由于结点⑦的BF值由-1变成-2，排序树中出现了新的不平衡的现象，需进行调整。但此时由于结点③插在结点⑩的左子树上，因此不能如上作简单调整。对于以结点⑦为根的子树来说，既要保持二叉排序树的特性，又要平衡，则必须以⑤作为根结点，而使⑦成

图9.12 平衡树的生成过程  
![](images/c5755fa918b0c3f7efff754c9447f0f1a1ed70f34303b65a44f378b5682afd9e.jpg)  
(a) 空树；(b) 插入 13；(c) 插入 24；(d) 插入 37；(e) 向左逆时针右旋转平衡；  
(f) 相继插入 90 和 53；(g) 第一次向右顺时针旋转；(h) 第二次向左逆时针旋转平衡之

为它的左子树的根，⑩成为它的右子树的根。这好比对树作了两次“旋转”操作——先向右顺时针，后向左逆时针（见图9.12(f)-(h)），使二叉排序树由不平衡转化为平衡。

一般情况下，假设由于在二叉排序树上插入结点而失去平衡的最小子树根结点的指针为a（即a是离插入结点最近，且平衡因子绝对值超过1的祖先结点），则失去平衡后进行调整的规律可归纳为下列4种情况：

（1）单向右旋平衡处理：由于在  $*a$  的左子树根结点的左子树上插入结点， $*a$  的平衡因子由1增至2，致使以  $^{\ast}a$  为根的子树失去平衡，则需进行一次向右的顺时针旋转操作，如图9.13(a)所示。  
（2）单向左旋平衡处理：由于在  $*a$  的右子树根结点的右子树上插入结点， $*a$  的平衡因子由-1变为-2，致使以  $^{\ast}a$  为根结点的子树失去平衡，则需进行一次向左的逆时针旋转操作。如图9.13(c)所示。  
（3）双向旋转(先左后右)平衡处理：由于在  $*a$  的左子树根结点的右子树上插入结点， $*a$  的平衡因子由1增至2，致使以 $*a$ 为根结点的子树失去平衡，则需进行两次旋转（先左旋后右旋)操作。如图9.13(b)所示。  
（4）双向旋转(先右后左)平衡处理：由于在  $*a$  的右子树根结点的左子树上插入结点， $*a$  的平衡因子由-1变为-2，致使以  $^{\ast}a$  为根结点的子树失去平衡，则需进行两次旋转(先右旋后左旋)操作。如图9.13(d)所示。

上述4种情况中，(1)和(2)对称，(3)和(4)对称。旋转操作的正确性容易由“保持二叉排序树的特性：中序遍历所得关键字序列自小至大有序”证明之。同时，从图9.13可见，无论哪一种情况，在经过平衡旋转处理之后，以  $*\mathbf{b}$  或  $*\mathbf{c}$  为根的新子树为平衡二叉

图9.13 二叉排序树的平衡旋转图例  
![](images/13c010f24087050c6fa079879669545bd9aacd6a45066d11092e9234b5bcd9e7.jpg)  
(a) L.L 型；(b) LR 型；(c) RR 型；(d) RL 型

树, 而且它的深度和插入之前以  $*a$  为根的子树相同。因此, 当平衡的二叉排序树因插入结点而失去平衡时, 仅需对最小不平衡子树进行平衡旋转处理即可。因为经过旋转处理之后的子树深度和插入之前相同, 因而不影响插入路径上所有祖先结点的平衡度。

在平衡的二叉排序树BBST上插入一个新的数据元素e的递归算法可描述如下：

（1）若BBST为空树，则插入一个数据元素为  $\mathbf{e}$  的新结点作为BBST的根结点，树的深度增1；  
（2）若e的关键字和BBST的根结点的关键字相等，则不进行插入；  
（3）若  $\mathbf{e}$  的关键字小于BBST的根结点的关键字，而且在BBST的左子树中不存在和  $\mathbf{e}$  有相同关键字的结点，则将  $\mathbf{e}$  插入在BBST的左子树上，并且当插入之后的左子树深度增加  $(+1)$  时，分别就下列不同情况处理之：  
① BBST 的根结点的平衡因子为 -1（右子树的深度大于左子树的深度）：则将根结

点的平衡因子更改为0，BBST的深度不变；

② BBST 的根结点的平衡因子为 0（左、右子树的深度相等）；则将根结点的平衡因子更改为 1，BBST 的深度增 1；  
③ BBST 的根结点的平衡因子为 1（左子树的深度大于右子树的深度）：若 BBST 的左子树根结点的平衡因子为 1，则需进行单向右旋平衡处理，并且在右旋处理之后，将根结点和其右子树根结点的平衡因子更改为 0，树的深度不变；

若BBST的左子树根结点的平衡因子为一1,则需进行先向左、后向右的双向旋转平衡处理,并且在旋转处理之后,修改根结点和其左、右子树根结点的平衡因子,树的深度不变;

（4）若  $\mathbf{e}$  的关键字大于BBST的根结点的关键字，而且在BBST的右子树中不存在和  $\mathbf{e}$  有相同关键字的结点，则将  $\mathbf{e}$  插入在BBST的右子树上，并且当插入之后的右子树深度增加  $(+1)$  时，分别就不同情况处理之。其处理操作和(三)中所述相对称，读者可自行补充。

假设在“6.2.3二叉树的存储结构”中定义的二叉链表的结点中增加一个存储结点平衡因子的域bf,则上述在平衡的二叉排序树BBST上插入一个新的数据元素e的递归算法如算法9.11所示,其中,左平衡处理的算法如算法9.12所示。算法9.9和算法9.10分别描述了在平衡处理中进行右旋操作和左旋操作时修改指针的情况。右平衡处理的算法和左平衡处理的算法类似,读者可自己补充。

# 二叉排序树的类型定义为：

```c
typedef struct BSTNode{ElemType data;int bf; //结点的平衡因子struct BSTNode \*lchild，\*rchild；//左、右孩子指针}BSTNode，\*BSTree;  
void RRotate(BSTree&p){//对以  $\ast \mathbb{P}$  为根的二叉排序树作右旋处理，处理之后p指向新的树根结点，即旋转//处理之前的左子树的根结点lc  $= \mathrm{p - > lchild};$  //1c指向的  $\ast \mathbb{P}$  的左子树根结点p->lchild  $= \mathrm{lc - > rchild};$  //1c的右子树挂接为  $\ast \mathbb{P}$  的左子树lc->rchild  $= \mathrm{p};\mathrm{p} = \mathrm{l}\mathrm{c};$  //p指向新的根结点  
} //RRotate
```

# 算法 9.9

```javascript
void LRotate(BBSTree&p){ //对以  $\ast \mathbb{P}$  为根的二叉排序树作左旋处理，处理之后  $\mathbb{P}$  指向新的树根结点，即旋转 //处理之前的右子树的根结点 rc  $= \mathrm{p - > rchild};$  //rc指向的  $\ast \mathbb{P}$  的右子树根结点 p->rchild  $= \mathrm{rc - > lchild};$  //rc的左子树挂接为  $\ast \mathbb{P}$  的右子树 rc->lchild  $= \mathrm{p};\mathrm{p} = \mathrm{rc};$  //p指向新的根结点 }//LRotate
```

# 算法 9.10

```c
define LH +1 //左高
#define EH 0 //等高
#define RH -1 //右高
Status InsertAVL (BSTree &T, ElemType e, Boolean &taller) {
//若在平衡的二叉排序树T中不存在和e有相同关键字的结点，则插入一个数据元素
//为e的新结点，并返回1，否则返回0。若因插入而使二叉排序树失去平衡，则作平衡
//旋转处理，布尔变量taller反映T长高与否
if (!T) { //插入新结点，树“长高”，置taller为TRUE
    T = (BSTree) malloc(sizeof(BSTNode)); T->data = e;
    T->lchild = T->rchild = NULL; T->bf = EH; taller = TRUE;
}
else {
if (EQ(e.key, T->data.key)) //树中已存在和e有相同关键字的结点
{ taller = FALSE; return 0; } //则不再插入
if (LT(e.key, T->data.key)) { //应继续在*T的左子树中进行搜索
if (!InsertAVL(T->lchild, e, taller)) return 0; //未插入
if (taller) //已插入到*T的左子树中且左子树“长高”
switch (T->bf) { //检查*T的平衡度
case LH: //原本左子树比右子树高，需要作左平衡处理
LeftBalance(T); taller = FALSE; break;
case EH: //原本左、右子树等高，现因左子树增高而使树增高
T->bf = LH; taller = TRUE; break;
case RH: //原本右子树比左子树高，现左、右子树等高
T->bf = EH; taller = FALSE; break;
} // switch (T->bf)
} // if
else {
if (!InsertAVL(T->rchild, e, taller)) return 0; //未插入
if (taller) //已插入到*T的右子树且右子树长高
switch (T->bf) { //检查*T的平衡度
case LH: //原本左子树比右子树高，现左、右子树等高
T->bf = EH; taller = FALSE; break;
case EH: //原本左、右子树等高，现因右子树增高而使树增高
T->bf = RH; taller = TRUE; break;
case RH: //原本右子树比左子树高，需要作右平衡处理
RightBalance(T); taller = FALSE; break;
} // switch (T->bf)
} // else
} // else
return 1;
} // InsertAVL
```

# 算法 9.11

```c
void LeftBalance(BBSTree&T){  
//对以指针T所指结点为根的二叉树作左平衡旋转处理，本算法结束时，指针T指向  
//新的根结点  
lc=T->lchild; //lc指向  $\ast \mathrm{T}$  的左子树根结点  
switch(lc->bf){ //检查  $\ast \mathrm{T}$  的左子树的平衡度，并作相应平衡处理  
case LH; //新结点插入在  $\ast \mathrm{T}$  的左孩子的左子树上，要作单右旋处理 $\mathrm{T - > bf = lc - > bf = EH};$  R_Rotate(T); break;  
case RH; //新结点插入在  $\ast \mathrm{T}$  的左孩子的右子树上，要作双旋处理rd=lc->rchild; //rd指向  $\ast \mathrm{T}$  的左孩子的右子树根
```

```c
switch (rd->bf) { // 修改  $*\mathrm{T}$  及其左孩子的平衡因子  
    case LH: T->bf = RH; lc->bf = EH; break;  
    case EH: T->bf = lc->bf = EH; break;  
    case RH: T->bf = EH; lc->bf = LH; break;  
} // switch (rd->bf)  
rd->bf = EH;  
LRotate(T->lchild); // 对  $*\mathrm{T}$  的左子树作左旋平衡处理  
RRotate(T); // 对  $*\mathrm{T}$  作右旋平衡处理  
} // switch (lc->bf)  
} // LeftBalance
```

# 算法 9.12

# 5. 平衡树查找的分析

在平衡树上进行查找的过程和排序树相同, 因此, 在查找过程中和给定值进行比较的关键字个数不超过树的深度。那么, 含有  $n$  个关键字的平衡树的最大深度是多少呢? 为解答这个问题, 我们先分析深度为  $h$  的平衡树所具有最少结点数。

假设以  $N_{h}$  表示深度为  $h$  的平衡树中含有的最少结点数。显然， $N_{0} = 0, N_{1} = 1, N_{2} = 2$ ，并且  $N_{h} = N_{h-1} + N_{h-2} + 1$ 。这个关系和斐波那契序列极为相似。利用归纳法容易证明：当  $h \geqslant 0$  时  $N_{h} = F_{h+2} - 1$ ，而  $F_{h}$  约等于  $\varphi^{h} / \sqrt{5}$ （其中  $\varphi = \frac{1 + \sqrt{5}}{2}$ ），则  $N_{h}$  约等于  $\varphi^{h+2} / \sqrt{5} - 1$ 。反之，含有  $n$  个结点的平衡树的最大深度为  $\log_{\varphi}(\sqrt{5}(n+1)) - 2$ 。因此，在平衡树上进行查找的时间复杂度为  $O(\log n)$ 。

上述对二叉排序树和二叉平衡树的查找性能的讨论都是在等概率的前提下进行的，若查找概率不等，则类似于“9.1.3静态树表的查找”中的讨论。为了提高查找效率，需要对待查记录序列先进行排序，使其按关键字递增(或递减)有序，然后再按算法9.4构造一棵次优查找树。显然，次优查找树也是一棵二叉排序树，但次优查找树不能在查找过程中插入结点生成。二叉排序树(或称二叉查找树)是动态树表，最优或次优查找树是静态树表。

# 9.2.2 B-树和  $\mathbf{B}^{+}$  树

# 1. B-树及其查找

B-树是一种平衡的多路查找树, 它在文件系统中很有用。在此先介绍这种树的结构及其查找算法。

一棵  $m$  阶的B-树，或为空树，或为满足下列特性的  $m$  叉树：

（1）树中每个结点至多有  $m$  棵子树；  
（2）若根结点不是叶子结点，则至少有两棵子树；  
（3）除根之外的所有非终端结点至少有  $\lceil m / 2\rceil$  棵子树；  
（4）所有的非终端结点中包含下列信息数据

$$
\left(n, A _ {0}, K _ {1}, A _ {1}, K _ {2}, A _ {2}, \dots , K _ {n}, A _ {n}\right) ^ {\text {①}}
$$

其中： $K_{i}(i = 1,\dots ,n)$  为关键字，且  $K_{i} < K_{i + 1}(i = 1,\dots ,n - 1);A_{i}(i = 0,\dots ,n)$  为指向子树根结点的指针，且指针  $A_{i - 1}$  所指子树中所有结点的关键字均小于  $K_{i}(i = 1,\dots ,n),A_{n}$  所指子树中所有结点的关键字均大于  $K_{n},n(\lceil m / 2\rceil -1\leqslant n\leqslant m - 1)$  为关键字的个数（或 $n + 1$  为子树个数）。

（5）所有的叶子结点都出现在同一层次上，并且不带信息（可以看作是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空）。

例如图9.14所示为一棵4阶的B-树，其深度为4。

![](images/1797d0ae49d3cfe8dfbd2ba1c7592a498ff04dfe5dc6b7b980fff0714123ce6e.jpg)  
图9.14 一棵4阶的B-树

由B-树的定义可知，在B-树上进行查找的过程和二叉排序树的查找类似。例如，在图9.14的B-树上查找关键字47的过程如下：首先从根开始，根据根结点指针t找到*a结点，因*a结点中只有一个关键字，且给定值47>关键字35，则若存在必在指针A所指的子树内，顺指针找到*c结点，该结点有两个关键字(43和78)，而43<47<78，则若存在必在指针A所指的子树中。同样，顺指针找到*g结点，在该结点中顺序查找找到关键字47，由此，查找成功。查找不成功的过程也类似，例如在同一棵树中查找23。从根开始，因为23<35，则顺该结点中指针A0找到*b结点，又因为*b结点中只有一个关键字18，且23>18，所以顺结点中第二个指针A1找到*e结点。同理因为23<27，则顺指针往下找，此时因指针所指为叶子结点，说明此棵B-树中不存在关键字23，查找因失败而告终。

由此可见，在B-树上进行查找的过程是一个顺指针查找结点和在结点的关键字中进行查找交叉进行的过程。

由于B-树主要用作文件的索引，因此它的查找涉及外存的存取，在此略去外存的读写，只作示意性的描述。假设结点类型如下说明：

```txt
define m 3 //B-树的阶，暂设为3 typedef struct BTNode{ int keynum; //结点中关键字个数，即结点的大小 struct BTNode \* parent; //指向双亲结点 KeyType key[m+1]; //关键字向量，0号单元未用 struct BTNode \*ptr[m+1]; //子树指针向量
```

```javascript
Record \*recptr[m+1]; //记录指针向量，0号单元未用}BTNode，\*BTree; //B-树结点和B-树的类型typedef struct{BTNode \*pt; //指向找到的结点int i; //1..m，在结点中的关键字序号int tag; //1:查找成功，0：查找失败}Result; //B-树的查找结果类型
```

则算法9.13简要地描述了B-树的查找操作的实现。

```c
Result SearchBTree(BTree T, KeyType K) {
// 在  $m$  阶  $B$ -树  $T$  上查找关键字  $K$ , 返回结果  $(pt, i, tag)$  。若查找成功, 则特征值  $tag = 1$ , 指针  $pt$ 
// 所指结点中第  $i$  个关键字等于  $K$ ; 否则特征值  $tag = 0$ , 等于  $K$  的关键字应插入在指针  $pt$  所指
// 结点中第  $i$  和第  $i + 1$  个关键字之间
 $p = T$ ;  $q = NULL$ ; found = FALSE;  $i = 0$ ; // 初始化,  $p$  指向待查结点,  $q$  指向  $p$  的双亲
while (p && !found) {
i = Search(p, K); // 在  $p->key[1..keynum]$  中查找,
// i使得:  $p->key[i] <= K < p->key[i + 1]$ 
if (i > 0 && p->key[i] == K) found = TRUE; // 找到待查关键字
else {q = p; p = p->ptr[i]; }
if (found) return (p, i, 1); // 查找成功
else return (q, i, 0); // 查找不成功, 返回  $K$  的插入位置信息
} // SearchBTree
```

# 算法 9.13

# 2. B-树查找分析

从算法9.11可见，在B-树上进行查找包含两种基本操作：(1)在B-树中找结点；(2)在结点中找关键字。由于B-树通常存储在磁盘上，则前一查找操作是在磁盘上进行的（在算法9.11中没有体现），而后一查找操作是在内存中进行的，即在磁盘上找到指针p所指结点后，先将结点中的信息读入内存，然后再利用顺序查找或折半查找查询等于K的关键字。显然，在磁盘上进行一次查找比在内存中进行一次查找耗费时间多得多，因此，在磁盘上进行查找的次数、即待查关键字所在结点在B-树上的层次数，是决定B-树查找效率的首要因素。

现考虑最坏的情况，即待查结点在B-树上的最大层次数。也就是，含  $N$  个关键字的 $m$  阶B-树的最大深度是多少？

先看一棵3阶的B-树。按B-树的定义，3阶的B-树上所有非终端结点至多可有两个关键字，至少有一个关键字(即子树个数为2或3,故又称2-3树)。因此，若关键字个数  $\leqslant$  2时，树的深度为2（即叶子结点层次为2）；若关键字个数  $\leqslant 6$  时，树的深度不超过3。反之，若B-树的深度为4，则关键字的个数必须  $\geqslant 7$  （参见图9.15(g))，此时，每个结点都含有可能的关键字的最小数目。

一般情况的分析可类似二叉平衡树进行，先讨论深度为  $l + 1$  的  $m$  阶B-树所具有的最少结点数。

根据B-树的定义，第一层至少有1个结点；第二层至少有2个结点；由于除根之外的

图9.15 不同关键字数目的B-树  
![](images/43eb902103c3e1c605e5012a8f8558f68d5420a719c83661d9798db41211c1ed.jpg)  
(a) 空树；(b)  $N = 1$ ；(c)  $N = 2$ ；(d)  $N = 3$ ；(e)  $N = 4$ ；(f)  $N = 5$ ；(g)  $N = 7$

每个非终端结点至少有  $\lceil m / 2\rceil$  棵子树，则第三层至少有  $2(\lceil m / 2\rceil)$  个结点；……；依次类推，第  $l + 1$  层至少有  $2(\lceil m / 2\rceil)^{l - 1}$  个结点。而  $l + 1$  层的结点为叶子结点。若  $m$  阶B-树中具有  $N$  个关键字，则叶子结点即查找不成功的结点为  $N + 1$  ，由此有：

$$
N + 1 \geqslant 2 * (\lceil m / 2 \rceil) ^ {l - 1}
$$

反之

$$
l \leqslant \log_ {\lceil m / 2 \rceil} \left(\frac {N + 1}{2}\right) + 1 \tag {9-21}
$$

这就是说，在含有  $N$  个关键字的B-树上进行查找时，从根结点到关键字所在结点的路径上涉及的结点数不超过  $\log_{\lceil m / 2\rceil}\left(\frac{N + 1}{2}\right) + 1$ 。

# 3. B-树的插入和删除

B-树的生成也是从空树起，逐个插入关键字而得。但由于B-树结点中的关键字个数必须  $\geqslant \lceil m / 2\rceil -1$  ，因此，每次插入一个关键字不是在树中添加一个叶子结点，而是首先在最低层的某个非终端结点中添加一个关键字，若该结点的关键字个数不超过  $m - 1$  ，则插入完成，否则要产生结点的“分裂”，如图9.16所示。

例如，图9.16(a)所示为3阶的B-树(图中略去F结点(即叶子结点))，假设需依次插入关键字30,26,85和7。首先通过查找确定应插入的位置。由根\*a起进行查找，确定30应插入在\*d结点中，由于\*d中关键字数目不超过2(即m-1)，故第一个关键字插入完成。插入30后的B-树如图9.16(b)所示。同样，通过查找确定关键字26亦应插入在\*d结点中。由于\*d中关键字的数目超过2，此时需将\*d分裂成两个结点，关键字26及其前、后两个指针仍保留在\*d结点中，而关键字37及其前、后两个指针存储到新产生的结点\*d'中。同时，将关键字30和指示结点\*d'的指针插入到其双亲结点中。由于\*b结点中的关键字数目没有超过2，则插入完成。插入后的B-树如图9.16(d)所示。类似

地，在  $\star \mathbf{g}$  中插入85之后需分裂成两个结点，而当70继而插入到双亲结点时，由于  $\star \mathbf{e}$  中关键字数目超过2，则再次分裂为结点  $\star \mathbf{e}$  和  $\star \mathrm{e}^{\prime}$ ，如图9.16(g)所示。最后在插入关键字7时， $\star \mathrm{c}, \star \mathrm{b}$  和  $\star \mathrm{a}$  相继分裂，并生成一个新的根结点  $\star \mathrm{m}$ ，如图9.16(h)～(j)所示。

![](images/94f2266291f22a681504276ffa36ba2ebf54ace8bf7d5b88d4b5af440c559fcb.jpg)

![](images/4066805a15f71b1718ba058753069882b35322dfa56c2c487c36c179c49bd7d3.jpg)  
(a)  
(b)

![](images/27e4270ebd2a2435206a3bf2150fbb912971c0772c2563f6a96f73c7f34eaaef.jpg)  
(c)

![](images/00d5535201785c6f1e642d2c78130a7e72a7035723e21c7a720a67f0f3321cc0.jpg)  
(d)

(e)  
图9.16 在B-树中进行插入（省略叶子结点）  
![](images/e003183103d50b69a054674362c51659b8ac0c9fdba47cdc60da47bc5d5928b1.jpg)  
(a)一棵2-3树；(b)插入30之后；(c)、(d)插入26之后；  
$(e)\sim (g)$  插入85之后；  $(h)\sim (j)$  插入7之后

![](images/91113567335c2b9a899e0c74a24c142ef975f77492b2f8c81d512cd13bf9fd1f.jpg)

![](images/1c3a48dea27cfdd877e894a9d85207272e6b241a0b90250014cf632e8692856e.jpg)

![](images/088b767f6faf957076a21bfae0f5a1b1a4e0b9ed9971ec81eaa6cf76ea0dc70c.jpg)

![](images/a1b0caf801ad5cc01f92a2353eba0ee2e720cb5c09e581b22baddc2481283dd9.jpg)  
图9.16 (续)

一般情况下，结点可如下实现“分裂”。

假设  $*\mathfrak{p}$  结点中已有  $m - 1$  个关键字，当插入一个关键字之后，结点中含有信息为：

$$
m, A _ {0}, \left(K _ {1}, A _ {1}\right), \dots , \left(K _ {m}, A _ {m}\right)
$$

且其中  $K_{i} < K_{i + 1}$ $1\leqslant i < m$

此时可将  $\mathbf{\nabla}^{*}\mathbf{p}$  结点分裂为  $\mathbf{\nabla}^{*}\mathbf{p}$  和  $\mathbf{\nabla}^{*}\mathbf{p}^{\prime}$  两个结点，其中  $\mathbf{\nabla}^{*}\mathbf{p}$  结点中含有信息为

$$
\lceil m / 2 \rceil - 1, A _ {0}, \left(K _ {1}, A _ {1}\right), \dots , \left(K _ {\lceil m / 2 \rceil - 1}, A _ {\lceil m / 2 \rceil - 1}\right) \tag {9-22}
$$

$\ast \mathfrak{p}^{\prime}$  结点中含有信息

$$
m - \lceil m / 2 \rceil , A _ {\lceil m / 2 \rceil}, (K _ {\lceil m / 2 + 1 \rceil}, A _ {\lceil m / 2 + 1 \rceil}), \dots , (K _ {m}, A _ {m}) \tag {9-23}
$$

而关键字  $K_{\lceil m / 2\rceil}$  和指针  $\mathbf{\nabla}^{*}\mathbf{p}^{\prime}$  一起插入到  $\ast \mathbf{p}$  的双亲结点中。

在B-树上插入关键字的过程如算法9.14所示，其中  $\mathbf{q}$  和  $\mathbf{i}$  是由查找函数SearchB-Tree返回的信息而得。

```txt
Status InsertBTree(BTree&T, KeyTypeK, BTreeq,inti）{//在  $\mathfrak{m}$  阶B-树T上结点  $\ast q$  的key[i]与key[i+1]之间插入关键字K。//若引起结点过大，则沿双亲链进行必要的结点分裂调整，使T仍是  $\mathfrak{m}$  阶B-树。 $\textbf{x} = \textbf{K};\quad \texttt{ap} = \texttt{NULL};\quad \texttt{finished} = \texttt{FALSE};$  while(q&&!finished){Insert(q,i,x,ap); //将  $\mathbf{x}$  和ap分别插入到  $\mathrm{q - > key[i + 1]}$  和  $\mathrm{q - > ptr[i + 1]}$  if  $(q - >$  keynum  $<  m)$  finished  $\equiv$  TRUE; //插入完成else{ //分裂结点  $\ast q$  （20 $s = \lceil m / 2\rceil ;\quad \mathrm{split}(q,s,\mathrm{ap});\quad x = q - > key[s];$  //将  $\mathrm{q - > key[s + 1..m]}$  ，  $\mathrm{q - > ptr[s..m]}$  和  $\mathrm{q - > recptr[s + 1..m]}$  移入新结点  $\ast a p$ $q = q - >$  parent;if(q)i  $=$  Search(q,x); //在双亲结点  $\ast q$  中查找  $\mathbf{x}$  的插入位置}//else}//whileif(!finished) //T是空树(参数q初值为NULL)或者根结点已分裂为结点  $\ast q$  和  $\ast a p$  NewRoot(T,q,x,ap); //生成含信息(T,x,ap)的新的根结点  $\ast T$  ，原T和ap为子树指针return OK;}//InsertBTree
```

# 算法 9.14

反之，若在B-树上删除一个关键字，则首先应找到该关键字所在结点，并从中删除之，若该结点为最下层的非终端结点，且其中的关键字数目不少于  $\lceil m / 2\rceil$  ，则删除完成，否则要进行“合并”结点的操作。假若所删关键字为非终端结点中的  $\mathbf{K}_{\mathrm{i}}$  ，则可以指针  $\mathbf{A}_{\mathrm{i}}$  所指子树中的最小关键字Y替代  $\mathbf{K}_{\mathrm{i}}$  ，然后在相应的结点中删去Y。例如，在图9.16(a)的B-树上删去45，可以  $*\mathbf{f}$  结点中的50替代45，然后在  $*\mathbf{f}$  结点中删去50。因此，下面我们可以只需讨论删除最下层非终端结点中的关键字的情形。有下列3种可能：

（1）被删关键字所在结点中的关键字数目不小于  $\lceil m / 2\rceil$  则只需从该结点中删去该关键字  $\mathbf{K}_{\mathrm{i}}$  和相应指针  $\mathbf{A}_{\mathrm{i}}$  ，树的其他部分不变，例如，从图9.16(a)所示B-树中删去关键字12，删除后的B-树如图9.17(a)所示。  
（2）被删关键字所在结点中的关键字数目等于  $\lceil m / 2\rceil -1$  ，而与该结点相邻的右兄弟（或左兄弟)结点中的关键字数目大于  $\lceil m / 2\rceil -1$  ，则需将其兄弟结点中的最小(或最

![](images/00c34a0f1d5b537dad32fc575c8454fe7b90d8c5fa228aeb0b6ce878ebf58b8a.jpg)

![](images/98e7b349364a9315bc429387233306da30eb21352c7bdcd9139268435c0cadad.jpg)

![](images/d7eb749f2835655443a32694ad6686a6e7a4887517544aa58c5a75d93369ff38.jpg)

![](images/4c9526a2f542a36240725440357ddd3e27cbe2cc621015d2d33af53ef8f772a9.jpg)  
图9.17 在B-树中删除关键字的情形

大)的关键字上移至双亲结点中, 而将双亲结点中小于(或大于)且紧靠该上移关键字的关键字下移至被删关键字所在结点中。例如, 从图9.17(a)中删去50, 需将其右兄弟结点中的61上移至*e结点中, 而将*e结点中的53移至*f, 从而使*f和*g中关键字数目均不小于  $\lceil m / 2\rceil -1$ , 而双亲结点中的关键字数目不变, 如图9.17(b)所示。

（3）被删关键字所在结点和其相邻的兄弟结点中的关键字数目均等于  $\lceil m / 2\rceil -1$  。假设该结点有右兄弟，且其右兄弟结点地址由双亲结点中的指针  $\mathbf{A}_{\mathrm{i}}$  所指，则在删去关键字之后，它所在结点中剩余的关键字和指针，加上双亲结点中的关键字  $\mathbf{K}_{\mathrm{i}}$  一起，合并到  $\mathbf{A}_{\mathrm{i}}$  所指兄弟结点中（若没有右兄弟，则合并至左兄弟结点中）。例如，从图9.17(b)所示B-树中删去53，则应删去  $*\mathrm{f}$  结点，并将  $*\mathrm{f}$  中的剩余信息(指针“空”)和双亲  $*\mathrm{e}$  结点中的61一起合并到右兄弟结点  $*\mathrm{g}$  中。删除后的树如图9.17(c)所示。如果因此使双亲结点中的关键字数目小于  $\lceil m / 2\rceil -1$  ，则依次类推作相应处理。例如，在图9.17(c)的B-树中

删去关键字37之后，双亲b结点中剩余信息("指针c")应和其双亲*a结点中关键字45一起合并至右兄弟结点*e中，删除后的B-树如图9.17(d)所示。

在B-树中删除结点的算法在此不再详述，请读者参阅参考书目[1]后自己写出。

# 4.  $\mathbf{B}^{+}$  树

$\mathbf{B}^{+}$  树是应文件系统所需而出的一种B-树的变型树①。一棵  $m$  阶的  $\mathbf{B}^{+}$  树和  $m$  阶的B-树的差异在于：

（1）有  $n$  棵子树的结点中含有  $n$  个关键字。  
（2）所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。  
（3）所有的非终端结点可以看成是索引部分，结点中仅含有其子树(根结点)中的最大(或最小)关键字。

例如图9.18所示为一棵3阶的  $\mathbf{B}^{+}$  树，通常在  $\mathbf{B}^{+}$  树上有两个头指针，一个指向根结点，另一个指向关键字最小的叶子结点。因此，可以对  $\mathbf{B}^{+}$  树进行两种查找运算：一种是从最小关键字起顺序查找，另一种是从根结点开始，进行随机查找。

![](images/073fee7fbd104d079dceeac9ebdf34a8015fee27fa2bd87932d2b8d15a75f423.jpg)  
图9.18 一棵3阶的  $\mathbf{B}^{+}$  树

在  $\mathbf{B}^{+}$  树上进行随机查找、插入和删除的过程基本上与B-树类似。只是在查找时，若非终端结点上的关键字等于给定值，并不终止，而是继续向下直到叶子结点。因此，在  $\mathbf{B}^{+}$  树，不管查找成功与否，每次查找都是走了一条从根到叶子结点的路径。 $\mathbf{B}^{+}$  树查找的分析类似于B-树。 $\mathbf{B}^{+}$  树的插入仅在叶子结点上进行，当结点中的关键字个数大于  $m$  时要分裂成两个结点，它们所含关键字的个数分别为  $\left\lceil \frac{m + 1}{2} \right\rceil$  和  $\left\lceil \frac{m + 1}{2} \right\rceil$  。并且，它们的双亲结点中应同时包含这两个结点中的最大关键字。 $\mathbf{B}^{+}$  树的删除也仅在叶子结点进行，当叶子结点中的最大关键字被删除时，其在非终端结点中的值可以作为一个“分界关键字”存在。若因删除而使结点中关键字的个数少于  $\left\lceil \frac{m}{2} \right\rceil$  时，其和兄弟结点的合并过程亦和B-树类似。

# 9.2.3 键树

键树又称数字查找树(Digital Search Trees)。它是一棵度  $\geqslant 2$  的树，树中的每个结点中不是包含一个或几个关键字，而是只含有组成关键字的符号。例如，若关键字是数值，则结点中只包含一个数位；若关键字是单词，则结点中只包含一个字母字符。这种树会给某种类型关键字的表的查找带来方便。

假设有如下16个关键字的集合

{CAI、CAO、LI、LAN、CHA、CHANG、WEN、CHAO、YUN、YANG、LONG、WANG、ZHAO、LIU、WU、CHEN} (9-24)

可对此集合作如下的逐层分割。

首先按其首字符不同将它们分成5个子集：

{CAI、CAO、CHA、CHANG、CHAO、CHEN}, {WEN、WANG、WU}, {ZHAO}, {LI、LAN、LONG、LIU}, {YUN、YANG},

然后对其中4个关键字个数大于1的子集再按其第二个字符不同进行分割。若所得子集的关键字多于1个，则还需按其第三个字符不同进行再分割。依此类推，直至每个小子集中只包含一个关键字为止。例如对首字符为C的集合可进行如下的分割：

{((CAI)、(CAO))、{((CHA)、(CHANG)、(CHAO)、(CHEN))}

显然，如此集合、子集和元素之间的层次关系可以用一棵树来表示，这棵树便为键树。例如，上述集合及其分割可用图9.19所示的键树来表示。树中根结点的五棵子树分别表示

![](images/ff8f3f73856ce42546ed64734ae0dfa53c3f3ade3dd00e63e3a658cfd3cca949.jpg)  
图9.19 表示式(9-24)关键字集的一棵键树

首字符为C、L、W、Y和Z的5个关键字子集。从根到叶子结点路径中结点的字符组成的字符串表示一个关键字,叶子结点中的特殊符号$表示字符串的结束。在叶子结点还含有指向该关键字记录的指针。

为了查找和插入方便,我们约定键树是有序树,即同一层中兄弟结点之间依所含符号自左至右有序,并约定结束符$小于任何字符。

通常，键树可有两种存储结构。

（1）以树的孩子兄弟链表来表示键树，则每个分支结点包括3个域：symbol域：存储关键字的一个字符；first域：存储指向第一棵子树根的指针；next域：存储指向右兄弟的指针。同时，叶子结点的infoptr域存储指向该关键字记录的指针。此时的键树又称双链树。例如，图9.19所示键树的双链树如图9.20所示（图中只画出第一棵子树，其余部分省略）。

双链树的查找可如下进行:假设给定值为K.ch(0..num-1),其中K.ch[0]至K.ch[num-2]表示待查关键字中num-1个字符,K.ch[num-1]为结束符$,从双链树的

![](images/24a8f37b0090b254a35f34e29834454e2ae22fab4e85635b599523e94534081c.jpg)  
图9.20 双链树示例

根指针出发, 顺 first 指针找到第一棵子树的根结点, 以 K.ch[0] 和此结点的 symbol 域比较, 若相等, 则顺 first 域再比较下一字符, 否则沿 next 域顺序查找。若直至“空”仍比较不等, 则查找不成功。

如果对双链树采用以下存储表示

```c
define MAXKEYLEN 16 //关键字的最大长度  
typedef struct{  
    char ch[MAXKEYLEN]; //关键字  
    int num; //关键字长度  
} KeysType; //关键字类型  
typedef enum {LEAF, BRANCH} NodeKind; //结点种类：{叶子，分支}  
typedef struct DLTNode{  
    char symbol;  
    struct DLTNode * next; //指向兄弟结点的指针  
    NodeKind kind;  
    union{  
        Record * infoptr; //叶子结点的记录指针  
        struct DLTNode * first; //分支结点的孩子链指针  
    }  
} DLTNode, * DLTTree; //双链树的类型
```

则在双链树中查找记录的操作由算法9.15实现。

```javascript
Record  $\ast$  SearchDLTree (DLTree T, KeysType K) { //在非空双链树T中查找关键字等于K的记录，若存在，则返回指向该记录的指针，否则返回空 //指针  $p = T->first;\quad i = 0;\quad //$  初始化 while  $(p\& \& i <   K.\text{num})$  { while  $(p\& \& p->symbol! = K.ch[i])p = p->next; //$  查找关键字的第i位 if  $(p\& \& i <   K.\text{num} -1)$ $p = p->first;$  //准备查找下一位 ++i;
```

} //查找结束if(!p)then return NULL; //查找不成功else return  $\mathfrak{p}\rightarrow$  infoptr; //查找成功}//SearchDLTree

# 算法 9.15

键树中每个结点的最大度  $d$  和关键字的“基”有关, 若关键字是单词, 则  $d = 27$ , 若关键字是数值, 则  $d = 11$  。键树的深度  $h$  则取决于关键字中字符或数位的个数。假设关键字为随机的(即关键字中每一位取基内任何值的概率相同), 则在双链树中查找每一位的平均查找长度为  $\frac{1}{2} (1 + d)$  。又假设关键字中字符(或数位)的个数都相等, 则在双链树中进行查找的平均查找长度为  $\frac{h}{2} (1 + d)$  。

在双链树中插入或删除一个关键字，相当于在树中某个结点上插入或删除一棵子树，在此不再详述。

(2) 若以树的多重链表表示键树,则树的每个结点中应含有d个指针域,此时的键树又称Trie树①。若从键树中某个结点到叶子结点的路径上每个结点都只有一个孩子,则可将该路径上所有结点压缩成一个“叶子结点”,且在该叶子结点中存储关键字及指向记录的指针等信息。例如,图9.19所示键树中,从结点Z到结点$为单支树,则在图9.21相应的Trie树中只有一个含有关键字ZHAO及相关信息的叶子结点。由此,在Trie树中有两种结点:分支结点(含有d个指针域和一个指示该结点中非空指针域的个数的整数域)和叶子结点(含有关键字域和指向记录的指针域)。在分支结点中不设数据域,每个分支结点所表示的字符均由其双亲结点中(指向该结点)的指针所在位置决定。

![](images/7007d0325ae6ad4cd662cb356f90f222cc96f3a93b434e9b06e03bf65de684d8.jpg)  
图9.21 表示(9-24)关键字集的Trie树（深度  $= 5$ ）

在Trie树上进行查找的过程为：从根结点出发，沿和给定值相应的指针逐层向下，直至叶子结点，若叶子结点中的关键字和给定值相等，则查找成功，若分支结点中和给定值

相应的指针为空，或叶结点中的关键字和给定值不相等，则查找不成功。若设

```c
typedef struct TrieNode{ NodeKind kind; union { struct {KeysType K; Record \* infoptr;}lf; //叶子结点 struct{TrieNode \*ptr[27]；int num;}bh; //分支结点 }TrieNode，\*TrieTree; //键树类型
```

则键树查找操作可如算法9.16实现之。

```javascript
Record \*SearchTrie (TrieTree T, KeysType K) {//在键树T中查找关键字等于K的记录。for（p=T，i=0; //对K的每个字符逐个查找p&&p->kind  $=$  BRANCH &&i<K num; //\*p为分支结点p=p->bh.ptr[ord(K.ch[i])]，++i）； //ord①求字符在字母表中序号if(p&&p->kind  $=$  LEAF&&p->lf.K  $=$  K）return p->lf.infopptr; //查找成功else return NULL; //查找不成功} //SearchTrie
```

# 算法 9.16

从上述查找过程可见，在查找成功时走了一条从根到叶子结点的路径。例如，在图9.21上，查找关键字CHEN的过程为：从根结点  $\alpha$  出发，经  $\beta, \gamma$  结点，最后到达叶子结点δ。而查找CHAI的过程为从根结点  $\alpha$  出发，经  $\beta, \gamma$  结点后到ε结点。由于该结点中和字符‘I'相应的指针为空，则查找不成功。由此，其查找的时间依赖于树的深度。我们可以对关键字集选择一种合适的分割，以缩减Trie树的深度。例如，根据(9-24)中关键字集的特点，可作如下分割。先按首字符不同分成多个子集之后，然后按最后一个字符不同分割每个子集，再按第二个字符……，前后交叉分割。由此得到如图9.22所示的Trie树，在该树上，除两个叶子结点在第四层上外，其余叶子结点均在第三层上。还可限制Trie

![](images/01a371231892f64a0a82a8f78c57fb52910a9fe5063372873b0641f5f38920aa.jpg)  
图9.22 对(9-24)关键字集采用另一种分割法得到的Trie树（深度  $= 4$ ）

树的深度, 假设允许Trie树的最大深度为  $l$ , 则所有直至  $l-1$  层皆为同义词的关键字都进入同一叶子结点。若分割得合适, 则可使每个叶子结点中只含有少数几个同义词。当然也可增加分支的个数以减少树的深度。

在Trie树上易于进行插入和删除，只是需要相应地增加和删除一些分支结点。当分支结点中num域的值减为1时，便可被删除。

双链树和Trie树是键树的两种不同的表示方法，它们有各自的特点。从其不同的存储结构特性可见，若键树中结点的度较大，则采用Trie树结构较双链树更为合适。

综上对树表的讨论可见，它们的查找过程都是从根结点出发，走了一条从根到叶子（或非终端结点）的路径，其查找时间依赖于树的深度。由于树表主要用作文件索引，因此结点的存取还涉及外部存储设备的特性，故在此没有对它们作平均查找长度的分析。

# 9.3 哈希表

# 9.3.1 什么是哈希表

在前面讨论的各种结构(线性表、树等)中, 记录在结构中的相对位置是随机的, 和记录的关键字之间不存在确定的关系, 因此, 在结构中查找记录时需进行一系列和关键字的比较。这一类查找方法建立在“比较”的基础上。在顺序查找时, 比较的结果为“=”与“≠”两种可能; 在折半查找、二叉排序树查找和B-树查找时, 比较的结果为“<”、“=”和“>”3种可能。查找的效率依赖于查找过程中所进行的比较次数。

理想的情况是希望不经过任何比较，一次存取便能得到所查记录，那就必须在记录的存储位置和它的关键字之间建立一个确定的对应关系  $f$ ，使每个关键字和结构中一个唯一的存储位置相对应。因而在查找时，只要根据这个对应关系  $f$  找到给定值  $K$  的像  $f(K)$ 。若结构中存在关键字和  $K$  相等的记录，则必定在  $f(K)$  的存储位置上，由此，不需要进行比较便可直接取得所查记录。在此，我们称这个对应关系  $f$  为哈希(Hash)函数，按这个思想建立的表为哈希表。

我们可以举一个哈希表的最简单的例子。假设要建立一张全国34个地区的各民族人口统计表，每个地区为一个记录，记录的各数据项为：

<table><tr><td>编号</td><td>地区名</td><td>总人口</td><td>汉族</td><td>回族</td><td>…</td></tr></table>

显然，可以用一个一维数组C(1..30)来存放这张表，其中C[i]是编号为  $i$  的地区的人口情况。编号  $i$  便为记录的关键字，由它惟一确定记录的存储位置C[i]。例如：假设北京市的编号为1，则若要查看北京市的各民族人口，只要取出C[1]的记录即可。假如把这个数组看成是哈希表，则哈希函数  $f(key) = key$  。然而，很多情况下的哈希函数并不如此简单。可仍以此为例，为了查看方便应以地区名作为关键字。假设地区名以汉语拼音的字符表示，则不能简单地取哈希函数  $f(key) = key$  ，而是首先要将它们转化为数字，有时还要作些简单的处理。例如我们可以有这样的哈希函数：(1)取关键字中第一个字母在字母表中的序号作为哈希函数。例如：BEIJING的哈希函数值为字母“B”在字母表中的序号，

等于02；或(2)先求关键字的第一个和最后一个字母在字母表中的序号之和，然后判别这个和值，若比30(表长)大，则减去30。例如：TIANJIN的首尾两个字母“T”和“N”的序号之和为34，故取04为它的哈希函数值；或(3)先求每个汉字的第一个拼音字母的ASCII码(和英文字母相同)之和的八进制形式，然后将这个八进制数看成是十进制数再除以30取余数，若余数为零则加上30而为哈希函数值。例如：HENAN的头两个拼音字母为“H”和“N”，它们的ASCII码之和为  $(226)_{8}$ ，以  $(226)_{10}$  除以  $(30)_{10}$  得余数为16，则16为HENAN的哈希函数值，即记录在数组中的下标值。上述人口统计表中部分关键字在这3种不同的哈希函数情况下的哈希函数值如表9.1所列：

表 9.1 简单的哈希函数示例  

<table><tr><td>key</td><td>BEIJING (北京)</td><td>TIANJIN (天津)</td><td>HEBEI (河北)</td><td>SHANXI (山西)</td><td>SHANGHAI (上海)</td><td>SHANDONG (山东)</td><td>HENAN (河南)</td><td>SICHUAN (四川)</td></tr><tr><td>f1(key)</td><td>02</td><td>20</td><td>08</td><td>19</td><td>19</td><td>19</td><td>08</td><td>19</td></tr><tr><td>f2(key)</td><td>09</td><td>04</td><td>17</td><td>28</td><td>28</td><td>26</td><td>22</td><td>03</td></tr><tr><td>f3(key)</td><td>04</td><td>26</td><td>02</td><td>13</td><td>23</td><td>17</td><td>16</td><td>16</td></tr></table>

从这个例子可见：

（1）哈希函数是一个映像，因此哈希函数的设定很灵活①，只要使得任何关键字由此所得的哈希函数值都落在表长允许范围之内即可；  
（2）对不同的关键字可能得到同一哈希地址，即  $key1 \neq key2$ ，而  $f(key1) = f(key2)$ ，这种现象称冲突（collision）。具有相同函数值的关键字对该哈希函数来说称做同义词（synonym）。例如：关键字HEBEI和HENAN不等，但  $f_{1}(\text{HEBEI}) = f_{1}(\text{HENAN})$ ，又如： $f_{2}(\text{SHANXI}) = f_{2}(\text{SHANGHAI})$ ； $f_{3}(\text{HENAN}) = f_{3}(\text{SICHUAN})$ 。这种现象给建表造成困难，如在第一种哈希函数的情况下，因为山西、上海、山东和四川这4个记录的哈希地址均为19，而C[19]只能存放一个记录，那么其他3个记录存放在表中什么位置呢？并且，从上表3个不同的哈希函数的情况可以看出，哈希函数选得合适可以减少这种冲突现象。特别是在这个例子中。只可能有30个记录，可以仔细分析这30个关键字的特性，选择一个恰当的哈希函数来避免冲突的发生。

然而，在一般情况下，冲突只能尽可能地少，而不能完全避免。因为，哈希函数是从关键字集合到地址集合的映像。通常，关键字集合比较大，它的元素包括所有可能的关键字，而地址集合的元素仅为哈希表中的地址值。假设表长为  $n$ ，则地址为 0 到  $n - 1$  。例如，在 C 语言的编译程序中可对源程序中的标识符建立一张哈希表。在设定哈希函数时考虑的关键字集合应包含所有可能产生的关键字；假设标识符定义为以字母为首的 8 位字母或数字，则关键字(标识符)的集合大小为  $C_{52}^{1} * C_{62}^{7} * 7! = 1.288899 \times 10^{14}$ ，而在一个源程序中出现的标识符是有限的，设表长为 1000 足矣。地址集合中的元素为 0 到 999。因此，在一般情况下，哈希函数是一个压缩映像，这就不可避免产生冲突。因此，在建造哈

希表时不仅要设定一个“好”的哈希函数，而且要设定一种处理冲突的方法。

综上所述，可如下描述哈希表：根据设定的哈希函数  $H(key)$  和处理冲突的方法将一组关键字映像到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为哈希表，这一映像过程称为哈希造表或散列，所得存储位置称哈希地址或散列地址。

下面分别就哈希函数和处理冲突的方法进行讨论。

# 9.3.2 哈希函数的构造方法

构造哈希函数的方法很多。在介绍各种方法之前，首先需要明确什么是“好”的哈希函数。

若对于关键字集合中的任一个关键字，经哈希函数映像到地址集合中任何一个地址的概率是相等的，则称此类哈希函数为均匀的(Uniform)哈希函数。换句话说，就是使关键字经过哈希函数得到一个“随机的地址”，以便使一组关键字的哈希地址均匀分布在整个地址区间中，从而减少冲突。

常用的构造哈希函数的方法有：

# 1. 直接定址法

取关键字或关键字的某个线性函数值为哈希地址。即：

$$
H (k e y) = k e y \text {或} H (k e y) = a \cdot k e y + b
$$

其中  $a$  和  $b$  为常数（这种哈希函数叫做自身函数）。

例如：有一个从1岁到100岁的人口数字统计表，其中，年龄作为关键字，哈希函数取关键字自身。如表9.2所示：

表 9.2 直接定址哈希函数例之一  

<table><tr><td>地址</td><td>01</td><td>02</td><td>03</td><td>...</td><td>25</td><td>26</td><td>27</td><td>...</td><td>100</td></tr><tr><td>年龄</td><td>1</td><td>2</td><td>3</td><td>...</td><td>25</td><td>26</td><td>27</td><td>...</td><td>...</td></tr><tr><td>人数</td><td>3000</td><td>2000</td><td>5000</td><td>...</td><td>1050</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>:</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

这样，若要询问25岁的人有多少，则只要查表的第25项即可。

又如：有一个解放后出生的人口调查表，关键字是年份，哈希函数取关键字加一常数： $H(key) = key + (-1948)$ ，如表9.3所示。

表 9.3 直接定址哈希函数例之二  

<table><tr><td>地址</td><td>01</td><td>02</td><td>03</td><td>...</td><td>22</td><td>...</td></tr><tr><td>年份</td><td>1949</td><td>1950</td><td>1951</td><td>...</td><td>1970</td><td>...</td></tr><tr><td>人数</td><td>...</td><td>...</td><td>...</td><td>...</td><td>15000</td><td>...</td></tr><tr><td>:</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

这样，若要查1970年出生的人数，则只要查第  $(1970 - 1948) = 22$  项即可。

由于直接定址所得地址集合和关键字集合的大小相同。因此，对于不同的关键字不会发生冲突。但实际中能使用这种哈希函数的情况很少。

# 2. 数字分析法

假设关键字是以  $r$  为基的数（如：以10为基的十进制数），并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。

例如有80个记录，其关键字为8位十进制数。假设哈希表的表长为  $100_{10}$ ，则可取两位十进制数组成哈希地址。取哪两位？原则是使得到的哈希地址尽量避免产生冲突，则需从分析这80个关键字着手。假设这80个关键字中的一部分如下所列：

<table><tr><td>8</td><td>1</td><td>3</td><td>4</td><td>6</td><td>5</td><td>3</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td><td>7</td><td>2</td><td>2</td><td>4</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td><td>8</td><td>7</td><td>4</td><td>2</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>6</td><td>7</td></tr><tr><td>8</td><td>1</td><td>3</td><td>2</td><td>2</td><td>8</td><td>1</td><td>7</td></tr><tr><td>8</td><td>1</td><td>3</td><td>3</td><td>8</td><td>9</td><td>6</td><td>7</td></tr><tr><td>8</td><td>1</td><td>3</td><td>5</td><td>4</td><td>1</td><td>5</td><td>7</td></tr><tr><td>8</td><td>1</td><td>3</td><td>6</td><td>8</td><td>5</td><td>3</td><td>7</td></tr><tr><td>8</td><td>1</td><td>4</td><td>1</td><td>9</td><td>3</td><td>5</td><td>5</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>①</td><td>②</td><td>③</td><td>④</td><td>⑤</td><td>⑥</td><td>⑦</td><td>⑧</td></tr></table>

对关键字全体的分析中我们发现：第①②位都是“81”，第③位只可能取1、2、3或4，第⑧位只可能取2、5或7，因此这4位都不可取。由于中间的4位可看成是近乎随机的，因此可取其中任意两位，或取其中两位与另外两位的叠加求和后舍去进位作为哈希地址。

# 3. 平方取中法

取关键字平方后的中间几位为哈希地址。这是一种较常用的构造哈希函数的方法。通常在选定哈希函数时不一定能知道关键字的全部情况，取其中哪几位也不一定合适，而一个数平方后的中间几位数和数的每一位都相关，由此使随机分布的关键字得到的哈希地址也是随机的。取的位数由表长决定。

例如：为BASIC源程序中的标识符建立一个哈希表。假设BASIC语言中允许的标识符为一个字母，或一个字母和一个数字。在计算机内可用两位八进制数表示字母和数字，如图9.23(a)所示。取标识符在计算机中的八进制数为它的关键字。假设表长为 $512 = 2^{9}$ ，则可取关键字平方后的中间9位二进制数为哈希地址。例如，图9.23(b)列出了一些标识符及它们的哈希地址。

# 4. 折叠法

将关键字分割成位数相同的几部分(最后一部分的位数可以不同), 然后取这几部分的叠加和(舍去进位)作为哈希地址, 这方法称为折叠法(folding)。关键字位数很多, 而且关键字中每一位上数字分布大致均匀时, 可以采用折叠法得到哈希地址。

<table><tr><td>A</td><td>B</td><td>C</td><td>...</td><td>Z</td><td>0</td><td>1</td><td>2</td><td>...</td><td>9</td></tr><tr><td>01</td><td>02</td><td>03</td><td></td><td>32</td><td>60</td><td>61</td><td>62</td><td></td><td>71</td></tr></table>

(a)  

<table><tr><td>记 录</td><td>关键字</td><td>(关键字)2</td><td>哈希地址 (217~29)</td></tr><tr><td>A</td><td>0100</td><td>0 010000</td><td>010</td></tr><tr><td>I</td><td>1100</td><td>1 210000</td><td>210</td></tr><tr><td>J</td><td>1200</td><td>1 440000</td><td>440</td></tr><tr><td>I0</td><td>1160</td><td>1 370400</td><td>370</td></tr><tr><td>P1</td><td>2061</td><td>4 310541</td><td>310</td></tr><tr><td>P2</td><td>2062</td><td>4 314704</td><td>314</td></tr><tr><td>Q1</td><td>2161</td><td>4 734741</td><td>734</td></tr><tr><td>Q2</td><td>2162</td><td>4 741304</td><td>741</td></tr><tr><td>Q3</td><td>2163</td><td>4 745651</td><td>745</td></tr></table>

(b)

例如：每一种西文图书都有一个国际标准图书编号(ISBN)，它是一个10位的十进制数字，若要以它作关键字建立一个哈希表，当馆藏书种类不到10000时，可采用折叠法构造一个四位数的哈希函数。在折叠法中数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端沿分割界来回折叠，然后对齐相加。如国际标准图书编号0-442-20586-4的哈希地址分别如图9.24(a)和(b)所示。

![](images/65f19ec1d080959ae3e9ef1eb80264f66c2ed81f9ce86c94ca35603bf9ee7577.jpg)  
图9.23  
（a）字符的八进制表示对照表；（b）标识符及其哈希地址  
图9.24 由折叠法求得哈希地址  
（a）移位叠加；（b）间界叠加

# 5. 除留余数法

取关键字被某个不大于哈希表表长  $m$  的数  $\pmb{p}$  除后所得余数为哈希地址。即

$$
H (k e y) = k e y \quad \mathrm {M O D} \quad p, p \leqslant m
$$

这是一种最简单，也最常用的构造哈希函数的方法。它不仅可以对关键字直接取模（MOD），也可在折叠、平方取中等运算之后取模。

值得注意的是，在使用除留余数法时，对  $p$  的选择很重要。若  $p$  选的不好，容易产生同义词。请看下面3个例子。

假设取标识符在计算机中的二进制表示为它的关键字（标识符中每个字母均用两位

八进制数表示), 然后对  $p = 2^6$  取模。这个运算在计算机中只要移位便可实现, 将关键字左移直至只留下最低的 6 位二进制数。这等于将关键字的所有高位值都忽略不计。因而使得所有最后一个字符相同的标识符, 如 a1, i1, templ, cp1 等均成为同义词。

若  $p$  含有质因子  $pf$ , 则所有含有  $pf$  因子的关键字的哈希地址均为  $pf$  的倍数。例如, 当  $p = 21 (= 3 \times 7)$  时, 下列含因子 7 的关键字对 21 取模的哈希地址均为 7 的倍数。

<table><tr><td>关键字</td><td>28</td><td>35</td><td>63</td><td>77</td><td>105</td></tr><tr><td>哈希地址</td><td>7</td><td>14</td><td>0</td><td>14</td><td>0</td></tr></table>

假设有两个标识符  $xy$  和  $yx$ , 其中  $x, y$  均为字符, 又假设它们的机器代码 (6 位二进制数) 分别为  $c(x)$  和  $c(y)$ , 则上述两个标识符的关键字分别为

$$
k e y 1 = 2 ^ {6} c (x) + c (y) \text {和} k e y 2 = 2 ^ {6} c (y) + c (x)
$$

假设用除留余数法求哈希地址，且  $p = tq, t$  是某个常数， $q$  是某个质数。则当  $q = 3$  时，这两个关键字将被散列在差为3的地址上。因为

$$
\begin{array}{l} \left[ H (k e y 1) - H (k e y 2) \right] \mathrm {M O D} q \\ = \left\{\left[ 2 ^ {6} c (x) + c (y) \right] \mathrm {M O D} p - \left[ 2 ^ {6} c (y) + c (x) \right] \mathrm {M O D} p \right\} \mathrm {M O D} q \\ = \{2 ^ {6} c (x) \mathrm {M O D} p + c (y) \mathrm {M O D} p - 2 ^ {6} c (y) \mathrm {M O D} p - c (x) \mathrm {M O D} p \} \mathrm {M O D} q \\ = \{2 ^ {6} c (x) \mathrm {M O D} q + c (y) \mathrm {M O D} q - 2 ^ {6} c (y) \mathrm {M O D} q - c (x) \mathrm {M O D} q \} \mathrm {M O D} q \\ \end{array}
$$

（因对任一  $x$  有  $(x \mod (t * q)) \mod q = (x \mod q) \mod q$ ）

当  $q = 3$  时，上式为

$$
\begin{array}{l} \begin{array}{l} = \{(2 ^ {6} \mathrm {M O D} 3) c (x) \mathrm {M O D} 3 + c (y) \mathrm {M O D} 3 - (2 ^ {6} \mathrm {M O D} 3) c (y) \mathrm {M O D} 3 - c (x) \mathrm {M O D} \\ 3 \} \mathrm {M O D} 3 \end{array} \\ = 0 \quad \text {M O D} \quad 3 \\ \end{array}
$$

由众人的经验得知：一般情况下，可以选  $p$  为质数或不包含小于20的质因数的合数。

# 6. 随机数法

选择一个随机函数，取关键字的随机函数值为它的哈希地址，即  $\mathrm{H}(\mathrm{key}) = \mathrm{random}(\mathrm{key})$  ，其中random为随机函数。通常，当关键字长度不等时采用此法构造哈希函数较恰当。

实际工作中需视不同的情况采用不同的哈希函数。通常，考虑的因素有：

（1）计算哈希函数所需时间（包括硬件指令的因素）；  
（2）关键字的长度；  
（3）哈希表的大小；  
（4）关键字的分布情况；  
（5）记录的查找频率。

# 9.3.3 处理冲突的方法

在“9.3.1 什么是哈希表”中曾提及均匀的哈希函数可以减少冲突, 但不能避免, 因

此，如何处理冲突是哈希造表不可缺少的另一方面。

假设哈希表的地址集为  $0 \sim (n - 1)$ , 冲突是指由关键字得到的哈希地址为  $j(0 \leqslant j \leqslant n - 1)$  的位置上已存有记录, 则“处理冲突”就是为该关键字的记录找到另一个“空”的哈希地址。在处理冲突的过程中可能得到一个地址序列  $H_{i} \quad i = 1, 2, \dots, k$ ,  $(H_{i} \in [0, n - 1])$  。即在处理哈希地址的冲突时, 若得到的另一个哈希地址  $H_{1}$  仍然发生冲突, 则再求下一个地址  $H_{2}$ , 若  $H_{2}$  仍然冲突, 再求得  $H_{3}$  。依次类推, 直至  $H_{k}$  不发生冲突为止, 则  $H_{k}$  为记录在表中的地址。

通常用的处理冲突的方法有下列几种：

# 1. 开放定址法

$$
H _ {i} = \left(H (k e y) + d _ {i}\right) \mathrm {M O D} m i = 1, 2, \dots , k (k \leqslant m - 1) \tag {9-25}
$$

其中：  $H(key)$  为哈希函数；  $m$  为哈希表表长；  $d_{i}$  为增量序列，可有下列3种取法：

(1)  $d_{i} = 1,2,3,\dots ,m - 1$  ，称线性探测再散列；(2）  $d_{i} = 1^{2}, - 1^{2},2^{2}, - 2^{2},3^{2},\dots ,\pm k^{2},(k\leqslant$ $m / 2)$  称二次探测再散列；(3）  $d_{i} =$  伪随机数序列，称伪随机探测再散列。

例如，在长度为11的哈希表中已填有关键字分别为17，60，29的记录（哈希函数 $H(key) = key \mod 11$ ），现有第四个记录，其关键字为38，由哈希函数得到哈希地址为5，产生冲突。若用线性探测再散列的方法处理时，得到下一个地址6，仍冲突；再求下一个地址7，仍冲突；直到哈希地址为8的位置为“空”时止，处理冲突的过程结束，记录填入哈希表中序号为8的位置。若用二次探测再散列，则应该填入序号为4的位置。类似地可得到伪随机再散列的地址(参见图9.25)。

图9.25 用开放定址处理冲突时，关键字为38的记录插入前后的哈希表  
![](images/c92c84a71ff6e5c76828c2caf54429d4185a843d16048a77962c863709a73087.jpg)  
(a) 插入前；(b) 线性探测再散列；(c) 二次探测再散列；(d) 伪随机探测再散列，伪随机数列 9，…

从上述线性探测再散列的过程中可以看到一个现象：当表中  $i, i + 1, i + 2$  位置上已填有记录时，下一个哈希地址为  $i, i + 1, i + 2$  和  $i + 3$  的记录都将填入  $i + 3$  的位置，这种在处理冲突过程中发生的两个第一个哈希地址不同的记录争夺同一个后继哈希地址的现象称做“二次聚集”，即在处理同义词的冲突过程中又添加了非同义词的冲突，显然，这种现象对查找不利。但另一方面，用线性探测再散列处理冲突可以保证做到：只要哈希表未填满，总能找到一个不发生冲突的地址  $H_{k}$ ，而二次探测再散列只有在哈希表长  $m$  为形如

$4j + 3(j$  为整数)的素数时才可能[1]，随机探测再散列，则取决于伪随机数列。

# 2. 再哈希法

$$
H _ {i} = R H _ {i} (k e y) \quad i = 1, 2, \dots , k \tag {9-26}
$$

$RH_{i}$  均是不同的哈希函数，即在同义词产生地址冲突时计算另一个哈希函数地址，直到冲突不再发生。这种方法不易产生“聚集”，但增加了计算的时间。

# 3.链地址法

将所有关键字为同义词的记录存储在同一线性链表中。假设某哈希函数产生的哈希地址在区间  $[0, m-1]$  上，则设立一个指针型向量

$$
\text {C h a i n C h a i n H a s h} [ m ];
$$

其每个分量的初始状态都是空指针。凡哈希地址为  $\mathbf{i}$  的记录都插入到头指针为ChainHash[i]的链表中。在链表中的插入位置可以在表头或表尾；也可以在中间，以保持同义词在同一线性链表中按关键字有序。

例9-3 已知一组关键字为（19，14，23，01，68，20，84，27，55，11，10，79）

则按哈希函数  $H(key) = key \mod 13$  和链地址法处理冲突构造所得的哈希表如图9.26所示。

![](images/b14e81e7d9cfbda2445e543faa28676de13dcb67d3794afcb0c1d2b416b63831.jpg)  
图9.26 链地址法处理冲突时的哈希表（同一链表中关键字自小至大有序）

# 4. 建立一个公共溢出区

这也是处理冲突的一种方法。假设哈希函数的值域为  $[0, m - 1]$ ，则设向量[ \text{HashTable}[0..m - 1] ]为基本表，每个分量存放一个记录，另设立向量[ \text{OverTable}[0..v] ]为溢出表。所有关键字和基本表中关键字为同义词的记录，不管它们由哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。

# 9.3.4 哈希表的查找及其分析

在哈希表上进行查找的过程和哈希造表的过程基本一致。给定  $K$  值，根据造表时设定的哈希函数求得哈希地址，若表中此位置上没有记录，则查找不成功；否则比较关键字，若和给定值相等，则查找成功；否则根据造表时设定的处理冲突的方法找“下一地址”，直至哈希表中某个位置为“空”或者表中所填记录的关键字等于给定值时为止。

算法9.17为以开放定址等方法(除链地址法外)处理冲突的哈希表的查找过程。

```c
// -- -- 开放定址哈希表的存储结构 -- --  
int hashsize[] = {997, ...}; // 哈希表容量递增表，一个合适的素数序列  
typedef struct{ElemType *elem; // 数据元素存储基址，动态分配数组  
int count; // 当前数据元素个数  
int sizeindex; // hashsize[sizeindex]为当前容量  
}HashTable;  
#define SUCCESS 1  
#define UNSUCCEED 0  
#define DUPLICATE -1
```

```c
Status SearchHash (HashTable H, KeyType K, int &p, int &c) {
// 在开放定址哈希表 H 中查找关键码为 K 的元素，若查找成功，以 p 指示待查数据
// 元素在表中位置，并返回 SUCCESS；否则，以 p 指示插入位置，并返回 UNSUCCEED,
// c 用以计冲突次数，其初值置零，修建表插入时参考
p = Hash(K); // 求得哈希地址
while (H.elem[p].key != NULLKEY && // 该位置中填有记录
!EQ(K, H.elem[p].key)) // 并且关键字不相等
collision(p, ++c); // 求得下一探查地址 p
if EQ(K, H.elem[p].key)
return SUCCESS; // 查找成功，p 返回待查数据元素位置
else return UNSUCCEED; // 查找不成功 (H.elem[p].key == NULLKEY),
// p 返回的是插入位置
} // SearchHash
```

# 算法 9.17

算法9.18通过调用查找算法(算法9.17)实现了开放定址哈希表的插入操作。

```txt
Status InsertHash (HashTable &H, Elemtype e) {
// 查找不成功时插入数据元素 e 到开放定址哈希表 H 中，并返回 OK；若冲突次数
// 过大，则重建哈希表
c = 0;
if (SearchHash (H, e.key, p, c)) return DUPPLICATE; // 表中已有与 e 有相同关键字的元素
else if (c < hashsize[H.sizeindex]/2) { // 冲突次数 c 未达到上限，(c 的阀值可调)
    H.elem[p] = e; ++H.count; return OK; // 插入 e
} else {RecreateHashTable(H); return UNSUCCEED;} // 重建哈希表
} // InsertHash
```

# 算法 9.18

例9-4 已知例9-3中所示的一组关键字按哈希函数  $H(key) = key \mod 13$  和线性探测处理冲突构造所得哈希表a.elem[0..15]如图9.27所示。

<table><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td></tr><tr><td></td><td>14</td><td>01</td><td>68</td><td>27</td><td>55</td><td>19</td><td>20</td><td>84</td><td>79</td><td>23</td><td>11</td><td>10</td><td></td><td></td><td></td></tr></table>

图9.27 哈希表a.elem[0：15]

（其哈希函数为  $H(key) = key \mod 13$  ，处理冲突为线性探测再散列）

给定值  $K = 84$  的查找过程为：首先求得哈希地址  $H(84) = 6$ ，因 a.elem[6]不空且 a.elem[6].key≠84，则找第一次冲突处理后的地址  $H_{1} = (6 + 1) \mod 16 = 7$ ，而 a.elem[7]不空且 a.elem[7].key≠84，则找第二次冲突处理后的地址  $H_{2} = (6 + 2) \mod 16 = 8$ ，a.elem[8]不空且 a.elem[8].key=84，则查找成功，返回记录在表中序号8。

给定值  $K = 38$  的查找过程为：先求哈希地址  $H(38) = 12$ ，a.elem[12]不空且 a.elem[12].key  $\neq 38$ ，则找下一地址  $H_{1} = (12 + 1)$  MOD  $16 = 13$ ，由于 a.elem[13]是空记录，则表明表中不存在关键字等于38的记录。

从哈希表的查找过程可见：

（1）虽然哈希表在关键字与记录的存储位置之间建立了直接映像，但由于“冲突”的产生，使得哈希表的查找过程仍然是一个给定值和关键字进行比较的过程。因此，仍需以平均查找长度作为衡量哈希表的查找效率的量度。  
（2）查找过程中需和给定值进行比较的关键字的个数取决于下列三个因素：哈希函数，处理冲突的方法和哈希表的装填因子。

哈希函数的“好坏”首先影响出现冲突的频繁程度。但是，对于“均匀的”哈希函数可以假定：不同的哈希函数对同一组随机的关键字，产生冲突的可能性相同，因为一般情况下设定的哈希函数是均匀的，则可不考虑它对平均查找长度的影响。

对同样一组关键字, 设定相同的哈希函数, 则不同的处理冲突的方法得到的哈希表不同, 它们的平均查找长度也不同。如例 9-3 和例 9-4 中的两个哈希表, 在记录的查找概率相等的前提下, 前者(链地址法)的平均查找长度为

$$
A S L (1 2) = \frac {1}{1 2} (1 \cdot 6 + 2 \cdot 4 + 3 + 4) = 1. 7 5
$$

后者(线性探测再散列)的平均查找长度为

$$
A S L (1 2) = \frac {1}{1 2} (1 \cdot 6 + 2 + 3 \cdot 3 + 4 + 9) = 2. 5
$$

容易看出，线性探测再散列在处理冲突的过程中易产生记录的二次聚集，如既使得哈希地址不相同的记录又产生新的冲突；而链地址法处理冲突不会发生类似情况，因为哈希地址不同的记录在不同的链表中。

在一般情况下，处理冲突方法相同的哈希表，其平均查找长度依赖于哈希表的装填因子。

哈希表的装填因子定义为

$$
\alpha = \frac {\text {表 中 填 入 的 记 录 数}}{\text {哈 希 表 的 长 度}}
$$

$\alpha$  标志哈希表的装满程度。直观地看， $\alpha$  越小，发生冲突的可能性就越小；反之， $\alpha$  越大，表中已填入的记录越多，再填记录时，发生冲突的可能性就越大，则查找时，给定值需与之进行比较的关键字的个数也就越多。

可以证明：[1][2]

线性探测再散列的哈希表查找成功时的平均查找长度为

$$
S _ {\mathrm {n l}} \approx \frac {1}{2} \left(1 + \frac {1}{1 - \alpha}\right) \tag {9-27}
$$

随机探测再散列、二次探测再散列和再哈希的哈希表查找成功时的平均查找长度为

$$
S _ {\mathrm {n r}} \approx - \frac {1}{\alpha} \ln (1 - \alpha) \tag {9-28}
$$

链地址法处理冲突的哈希表查找成功时的平均查找长度为

$$
S _ {\mathrm {n c}} \approx 1 + \frac {\alpha}{2} \tag {9-29}
$$

由于哈希表在查找不成功时所用比较次数也和给定值有关, 则可类似地定义哈希表在查找不成功时的平均查找长度为: 查找不成功时需和给定值进行比较的关键字个数的期望值。同样可证明, 不同的处理冲突方法构成的哈希表查找不成功时的平均查找长度分别为

$$
U _ {\mathrm {n l}} \approx \frac {1}{2} \left(1 + \frac {1}{(1 - \alpha) ^ {2}}\right) \tag {9-30}
$$

——线性探测再散列

$$
U _ {\mathrm {n r}} \approx \frac {1}{1 - \alpha} \tag {9-31}
$$

——伪随机探测再散列等

$$
U _ {\mathrm {n c}} \approx \alpha + e ^ {- \alpha} \tag {9-32}
$$

链地址

下面仅以随机探测的一组公式为例进行分析推导。

先分析长度为  $m$  的哈希表中装填有  $n$  个记录时查找不成功的平均查找长度。这个问题相当于要求在这张表中填入第  $n + 1$  个记录时所需作的比较次数的期望值。

假定：(1)哈希函数是均匀的。即产生表中各个地址的概率相等；(2)处理冲突后产生的地址也是随机的。

若设  $p_i$  表示前  $i$  个哈希地址均发生冲突的概率；  $q_i$  表示需进行  $i$  次比较才找到一个“空位”的哈希地址（即前  $i - 1$  次发生冲突，第  $i$  次不冲突）的概率。则有：

$$
p _ {1} = \frac {n}{m}
$$

$$
q _ {1} = 1 - \frac {n}{m}
$$

$$
p _ {2} = \frac {n}{m} \cdot \frac {n - 1}{m - 1}
$$

$$
q _ {2} = \frac {n}{m} \cdot \left(1 - \frac {n - 1}{m - 1}\right)
$$

$$
\begin{array}{c} \bullet \\ \vdots \\ \bullet \end{array}
$$

中

$$
p _ {i} = \frac {n}{m} \cdot \frac {n - 1}{m - 1} \dots \frac {n - i + 1}{m - i + 1}
$$

$$
q _ {i} = \frac {n}{m} \cdot \frac {n - 1}{m - 1} \dots \frac {n - i + 2}{m - i + 2} \left(1 - \frac {n - i + 1}{m - i + 1}\right)
$$

$$
\begin{array}{c} \vdots \\ p _ {n} = \frac {n}{m} \cdot \frac {n - 1}{m - 1} \dots \frac {1}{m - n + 1} \end{array}
$$

$$
\begin{array}{c} \vdots \\ q _ {n} = \frac {n}{m} \dots \frac {2}{m - n + 2} \left(1 - \frac {1}{m - n + 1}\right) \end{array}
$$

$$
p _ {n + 1} = 0
$$

$$
q _ {n + 1} = \frac {n}{m} \dots \frac {1}{m - n + 1}
$$

可见，在  $p_i$  和  $q_i$  之间，存在关系式

$$
q _ {i} = p _ {i - 1} - p _ {i} \tag {9-33}
$$

由此，当长度为  $m$  的哈希表中已填有  $n$  个记录时，查找不成功的平均查找长度为

$$
\begin{array}{l} U _ {n} = \sum_ {i = 1} ^ {n + 1} q _ {i} C _ {i} = \sum_ {i = 1} ^ {n + 1} \left(p _ {i - 1} - p _ {i}\right) i \\ = 1 + p _ {1} + p _ {2} + \dots + p _ {n} - (n + 1) p _ {n + 1} \\ = \frac {1}{1 - \frac {n}{m + 1}} \quad (\text {用 归 纳 法 证 明}) \\ \approx \frac {1}{1 - a} \\ \end{array}
$$

由于哈希表中  $n$  个记录是先后填入的，查找每一个记录所需比较次数的期望值，恰为填入此记录时找到此哈希地址时所进行的比较次数的期望值。因此，对表长为  $m$  、记录数为  $n$  的哈希表，查找成功时的平均查找长度为

$$
S _ {n} = \sum_ {i = 1} ^ {n - 1} p _ {i} C _ {i} = \sum_ {i = 0} ^ {n - 1} p _ {i} U _ {i}
$$

设对  $n$  个记录的查找概率相等。即  $p_i = \frac{1}{n}$  则

$$
\begin{array}{l} S _ {n} = \frac {1}{n} \sum_ {i = 0} ^ {n - 1} U _ {i} = \frac {1}{n} \sum_ {i = 0} ^ {n - 1} \frac {1}{1 - \frac {i}{m}} \\ \approx \frac {m}{n} \int_ {0} ^ {a} \frac {\mathrm {d} x}{1 - x} \approx - \frac {1}{\alpha} \ln (1 - \alpha) \\ \end{array}
$$

从以上分析可见，哈希表的平均查找长度是  $\alpha$  的函数，而不是  $n$  的函数。由此，不管  $n$  多大，我们总可以选择一个合适的装填因子以便将平均查找长度限定在一个范围内。

值得提醒的是，若要在非链地址处理冲突的哈希表中删除一个记录，则需在该记录的位置上填入一个特殊的符号，以免找不到在它之后填入的“同义词”的记录。

最后要说明的是，对于预先知道且规模不大的关键字集，有时也可以找到不发生冲突的哈希函数，因此，对频繁进行查找的关键字集，还是应尽力设计一个完美的(perfect)的哈希函数。例如，对PASCAL语言中的26个保留字可设定下述无冲突的哈希函数

$$
\mathrm {H} (\text {k e y}) = \mathrm {L} + \mathrm {g} (\text {k e y} [ 1 ]) + \mathrm {g} (\text {k e y} [ \mathrm {L} ]) \tag {9-34}
$$

其中  $\mathbf{L}$  为保留字长度，key[1]为第一个字符，key[L]为最后一个字符， $\mathbf{g}(\mathbf{x})$  为从字符到数字的转换函数，例如  $\mathbf{g}(\mathbf{F}) = 15, \mathbf{g}(\mathbf{N}) = 13, \mathbf{H}(\mathbf{FUNCTION}) = 8 + 15 + 13 = 36$ 。所得哈希表长度为37（请参见参考书目[14]327页～328页）。

# 第10章 内部排序

# 10.1 概述

排序(Sorting)是计算机程序设计中的一种重要操作，它的功能是将一个数据元素（或记录）的任意序列，重新排列成一个按关键字有序的序列。

从第9章的讨论中容易看出，为了查找方便，通常希望计算机中的表是按关键字有序的。因为有序的顺序表可以采用查找效率较高的折半查找法，其平均查找长度为  $\log_2(n + 1) - 1$  ，而无序的顺序表只能进行顺序查找，其平均查找长度为  $(n + 1) / 2$  。又如建造树表(无论是二叉排序树或B-树)的过程本身就是一个排序的过程。因此，学习和研究各种排序方法是计算机工作者的重要课题之一。

为了便于讨论，在此首先要对排序下一个确切的定义：

假设含  $n$  个记录的序列为

$$
\left\{R _ {1}, R _ {2}, \dots , R _ {n} \right\} \tag {10-1}
$$

其相应的关键字序列为

$$
\left\{K _ {1}, K _ {2}, \dots , K _ {n} \right\}
$$

需确定  $1,2,\dots ,n$  的一种排列  $p_1,p_2,\dots ,p_n$  ，使其相应的关键字满足如下的非递减（或非递增  $\mathfrak{Q}$  )关系

$$
K _ {p _ {1}} \leqslant K _ {p _ {2}} \leqslant \dots \leqslant K _ {p _ {n}} \tag {10-2}
$$

即使式(10-1)的序列成为一个按关键字有序的序列

$$
\left\{R _ {p _ {1}}, R _ {p _ {2}}, \dots , R _ {p _ {n}} \right\} \tag {10-3}
$$

这样一种操作称为排序。

上述排序定义中的关键字  $K_{i}$  可以是记录  $R_{i}(i = 1,2,\dots ,n)$  的主关键字，也可以是记录  $R_{i}$  的次关键字，甚至是若干数据项的组合。若  $K_{i}$  是主关键字，则任何一个记录的无序序列经排序后得到的结果是惟一的；若  $K_{i}$  是次关键字，则排序的结果不惟一，因为待排序的记录序列中可能存在两个或两个以上关键字相等的记录。假设  $K_{i} = K_{j}$  （  $1\leqslant i\leqslant n$ $1\leqslant j\leqslant n,i\neq j)$  ，且在排序前的序列中  $R_{i}$  领先于  $R_{j}$  （即  $i <   j$  )。若在排序后的序列中  $R_{i}$  仍领先于  $R_{j}$  ，则称所用的排序方法是稳定的；反之，若可能使排序后的序列中  $R_{j}$  领先于  $R_{i}$  则称所用的排序方法是不稳定的。②

由于待排序的记录数量不同，使得排序过程中涉及的存储器不同，可将排序方法分为两大类：一类是内部排序，指的是待排序记录存放在计算机随机存储器中进行的排序过程；另一类是外部排序，指的是待排序记录的数量很大，以致内存一次不能容纳全部记录，

在排序过程中尚需对外存进行访问的排序过程。本章先集中讨论内部排序，将在下一章中讨论外部排序。

内部排序的方法很多，但就其全面性能而言，很难提出一种被认为是最好的方法，每一种方法都有各自的优缺点，适合在不同的环境（如记录的初始排列状态等）下使用。如果按排序过程中依据的不同原则对内部排序方法进行分类，则大致可分为插入排序、交换排序、选择排序、归并排序和计数排序等五类；如果按内部排序过程中所需的工作量来区分，则可分为3类：(1)简单的排序方法，其时间复杂度为  $O(n^{2})$  ；(2)先进的排序方法，其时间复杂度为  $O(n\log n)$  ；(3)基数排序，其时间复杂度为  $O(d \cdot n)$  。本章仅就每一类介绍一两个典型算法，有兴趣了解更多算法的读者可阅读D.E.克努特著《计算机程序设计技巧》[2]（第三卷，排序和查找）。读者在学习本章内容时应注意，除了掌握算法本身以外，更重要的是了解该算法在进行排序时所依据的原则，以利于学习和创造更加新的算法。

通常，在排序的过程中需进行下列两种基本操作：（1)比较两个关键字的大小；(2)将记录从一个位置移动至另一个位置。前一个操作对大多数排序方法来说都是必要的，而后一个操作可以通过改变记录的存储方式来予以避免。待排序的记录序列可有下列3种存储方式：(1)待排序的一组记录存放在地址连续的一组存储单元上。它类似于线性表的顺序存储结构，在序列中相邻的两个记录  $R_{j}$  和  $R_{j + 1}(j = 1,2,\dots ,n - 1)$  ，它们的存储位置也相邻。在这种存储方式中，记录之间的次序关系由其存储位置决定，则实现排序必须借助移动记录；(2)一组待排序记录存放在静态链表①中，记录之间的次序关系由指针指示，则实现排序不需要移动记录，仅需修改指针即可；(3)待排序记录本身存储在一组地址连续的存储单元内，同时另设一个指示各个记录存储位置的地址向量，在排序过程中不移动记录本身，而移动地址向量中这些记录的“地址”，在排序结束之后再按照地址向量中的值调整记录的存储位置。在第二种存储方式下实现的排序又称(链)表排序，在第三种存储方式下实现的排序又称地址排序。在本章的讨论中，设待排序的一组记录以上述第一种方式存储，且为了讨论方便起见，设记录的关键字均为整数。即在以后讨论的大部分算法中，待排记录的数据类型设为：

```c
define MAXSIZE 20 //一个用作示例的小顺序表的最大长度  
typedef intKeyType; //定义关键字类型为整数类型  
typedef struct{  
   KeyType key; //关键字项  
    InfoType otherinfo; //其他数据项  
}RedType; //记录类型  
typedef struct{  
    RedType r[MAXSIZE + 1]; //r[0]闲置或用作哨兵单元  
    int length; //顺序表长度  
}SqList; //顺序表类型
```

# 10.2 插入排序

# 10.2.1 直接插入排序

直接插入排序（Straight Insertion Sort）是一种最简单的排序方法，它的基本操作是将一个记录插入到已排好序的有序表中，从而得到一个新的、记录数增1的有序表。

例如，已知待排序的一组记录的初始排列如下所示：①

$$
R (4 9), R (3 8), R (6 5), R (9 7), R (7 6), R (1 3), R (2 7), R (\overline {{4 9}}), \dots \tag {10-4}
$$

假设在排序过程中，前4个记录已按关键字递增的次序重新排列，构成一个含4个记录的有序序列

$$
\{R (3 8), R (4 9), R (6 5), R (9 7) \} \tag {10-5}
$$

现要将式(10-4)中第5个(即关键字为76的)记录插入上述序列，以得到一个新的含5个记录的有序序列，则首先要在式(10-5)的序列中进行查找以确定  $R(76)$  所应插入的位置，然后进行插入。假设从  $R(97)$  起向左进行顺序查找，由于  $65 < 76 < 97$  ，则  $R(76)$  应插人在 $R(65)$  和  $R(97)$  之间，从而得到下列新的有序序列

$$
\{R (3 8), R (4 9), R (6 5), R (7 6), R (9 7) \} \tag {10-6}
$$

称从式(10-5)到式(10-6)的过程为一趟直接插入排序。一般情况下，第  $i$  趟直接插入排序的操作为：在含有  $i - 1$  个记录的有序子序列  $\mathbf{r}[1..i - 1]^{2}$  中插入一个记录  $\mathbf{r}[i]$  后，变成含有  $i$  个记录的有序子序列  $\mathbf{r}[1..i]$ ；并且，和顺序查找类似，为了在查找插入位置的过程中避免数组下标出界，在  $\mathbf{r}[0]$  处设置监视哨。在自  $i - 1$  起往前搜索的过程中，可以同时后移记录。整个排序过程为进行  $n - 1$  趟插入，即：先将序列中的第1个记录看成是一个有序的子序列，然后从第2个记录起逐个进行插入，直至整个序列变成按关键字非递减有序序列为止。其算法如算法10.1所示：

```javascript
void InsertSort (SqList &L) {
// 对顺序表 L 作直接插入排序。
for (i = 2; i <= L.length; ++i)
if (LT(L.r[i].key, L.r[i-1].key)) { // “(”, 需将 L.r[i]插入有序子表
L.r[0] = L.r[i];
L.r[i] = L.r[i-1];
for (j = i-2; LT(L.r[0].key, L.r[j].key); --j)
L.r[j+1] = L.r[j];
L.r[j+1] = L.r[0];
} // InsertSort
```

# 算法 10.1

以式(10-4)中关键字为例，按照算法10.1进行直接插入排序的过程如图10.1所示。③

![](images/99181ff41daa8bb960b9bdd6d2cd3ca1405e30fe4ba46cb432459317ec7175ea.jpg)  
图10.1 直接插入排序示例

从上面的叙述可见，直接插入排序的算法简洁，容易实现，那么它的效率如何呢？

从空间来看, 它只需要一个记录的辅助空间, 从时间来看, 排序的基本操作为: 比较两个关键字的大小和移动记录。先分析一趟插入排序的情况。算法 10.1 中里层的 for 循环的次数取决于待插记录的关键字与前  $i - 1$  个记录的关键字之间的关系。若 L.r[i].key  $< \mathrm{L.r}[1]$ .key, 则内循环中, 待插记录的关键字需与有序子序列 L.r[1..i-1]中  $i - 1$  个记录的关键字和监视哨中的关键字进行比较, 并将 L.r[1..i-1]中  $i - 1$  个记录后移。则在整个排序过程 (进行  $n - 1$  趟插入排序) 中, 当待排序列中记录按关键字非递减有序排列 (以下称之为“正序”) 时, 所需进行关键字间比较的次数达最小值  $n - 1$  (即  $\sum_{i = 2}^{n}1$ ), 记录不需移动; 反之, 当待排序列中记录按关键字非递增有序排列 (以下称之为“逆序”) 时, 总的比较次数达最大值  $(n + 2)(n - 1)/2$  (即  $\sum_{i = 2}^{n}i$ ), 记录移动的次数也达最大值  $(n + 4)(n - 1)/2$  (即  $\sum_{i = 2}^{n}(i + 1)$ ). 若待排序记录是随机的, 即待排序列中的记录可能出现的各种排列的概率相同, 则我们可取上述最小值和最大值的平均值, 作为直接插入排序时所需进行关键字间的比较次数和移动记录的次数, 约为  $n^2/4$  。由此, 直接插入排序的时间复杂度为  $O(n^2)$  。

# 10.2.2 其他插入排序

从上一节的讨论中可见，直接插入排序算法简便，且容易实现。当待排序记录的数量  $n$  很小时，这是一种很好的排序方法。但是，通常待排序序列中的记录数量  $n$  很大，则不宜采用直接插入排序。由此需要讨论改进的办法。在直接插入排序的基础上，从减少“比较”和“移动”这两种操作的次数着眼，可得下列各种插入排序的方法。

# 1. 折半插入排序

由于插入排序的基本操作是在一个有序表中进行查找和插入, 则从 9.1 节的讨论中可知, 这个“查找”操作可利用“折半查找”来实现, 由此进行的插入排序称之为折半插入排

序 (Binary Insertion Sort), 其算法如算法 10.2 所示。

```txt
void BInsertSort (SqList &L) {
// 对顺序表 L 作折半插入排序。
for (i = 2; i <= L.length; ++i) {
L.r[0] = L.r[i]; // 将 L.r[i] 暂存到 L.r[0]
low = 1; high = i - 1;
while (low <= high) // 在 r[low..high] 中折半查找有序插入的位置
m = (low + high)/2; // 折半
if (LT(L.r[0].key, L.r[m].key)) high = m - 1; // 插入点在低半区
else low = m + 1; // 插入点在高半区
} // while
for (j = i - 1; j >= high + 1; --j) L.r[j + 1] = L.r[j]; // 记录后移
L.r[high + 1] = L.r[0]; // 插入
} // for
} // BInsertSort
```

# 算法 10.2

从算法10.2容易看出，折半插入排序所需附加存储空间和直接插入排序相同，从时间上比较，折半插入排序仅减少了关键字间的比较次数，而记录的移动次数不变。因此，折半插入排序的时间复杂度仍为  $O(n^{2})$  。

# 2. 2-路插入排序

2-路插入排序是在折半插入排序的基础上再改进之，其目的是减少排序过程中移动记录的次数，但为此需要  $n$  个记录的辅助空间。具体做法是：另设一个和 L.r 同类型的数组 d，首先将 L.r[1] 赋值给 d[1]，并将 d[1] 看成是在排好序的序列中处于中间位置的记录，然后从 L.r 中第 2 个记录起依次插入到 d[1] 之前或之后的有序序列中。先将待插记录的关键字和 d[1] 的关键字进行比较，若 L.r[i].key < d[1].key，则将 L.r[i] 插入到 d[1] 之前的有序表中。反之，则将 L.r[i] 插入到 d[1] 之后的有序表中。在实现算法时，可将 d 看成是一个循环向量，并设两个指针 first 和 final 分别指示排序过程中得到的有序序列中的第一个记录和最后一个记录在 d 中的位置。具体算法留作习题由读者自己写出。

仍以式(10-4)中的关键字为例，进行2-路插入排序的过程如图10.2所示。

在2-路插入排序中，移动记录的次数约为  $n^2 / 8$  。因此，2-路插入排序只能减少移动记录的次数，而不能绝对避免移动记录。并且，当L.r[1]是待排序记录中关键字最小或最大的记录时，2-路插入排序就完全失去它的优越性。因此，若希望在排序过程中不移动记录，只有改变存储结构，进行表插入排序。

# 3. 表插入排序

```txt
define SIZE 100 //静态链表容量 typedef struct{ RcdType rc; //记录项 int next; //指针项 }SLNode; //表结点类型 typedef struct{
```

![](images/9d4553b567e2183959da4307c21b989d749d3a378f67b4b67986aecb7b33325c.jpg)  
图10.2 2-路插入排序示例

假设以上述说明的静态链表类型作为待排记录序列的存储结构，并且，为了插入方便起见，设数组中下标为“0”的分量为表头结点，并令表头结点记录的关键字取最大整数MAXINT。则表插入排序的过程描述如下：首先将静态链表中数组下标为“1”的分量（结点）和表头结点构成一个循环链表，然后依次将下标为“2”至“n”的分量（结点）按记录关键字非递减有序插入到循环链表中。仍以式(10-4)中的关键字为例，表插入排序的过程如图10.3所示（图中省略记录的其他数据项）。

从表插入排序的过程可见，表插入排序的基本操作仍是将一个记录插入到已排好序的有序表中。和直接插入排序相比，不同之处仅是以修改  $2n$  次指针值代替移动记录，排序过程中所需进行的关键字间的比较次数相同。因此，表插入排序的时间复杂度仍是  $O(n^{2})$  。

另一方面，表插入排序的结果只是求得一个有序链表，则只能对它进行顺序查找，不能进行随机查找，为了能实现有序表的折半查找，尚需对记录进行重新排列。

重排记录的做法是：顺序扫描有序链表，将链表中第  $i$  个结点移动至数组的第  $i$  个分量中。例如，图10.4(a)是经表插入排序后得到的有序链表SL。根据头结点中指针域的指示，链表的第一个结点，即关键字最小的结点是数组中下标为6的分量，其中记录应移至数组的第一个分量中，则将SL.r[1]和SL.r[6]互换，并且为了不中断静态链表中的“链”，即在继续顺链扫描时仍能找到互换之前在SL.r[1]中的结点，令互换之后的SL.r[1]中指针域的值改为“6”（见图10.4(b)）。推广至一般情况，若第  $i$  个最小关键

![](images/4ac2873663b8220c0698916353d24a041d0c6f0d0f59398ac9e8803ae054f69f.jpg)  
图10.3 表插入排序示例

字的结点是数组中下标为  $p$  且  $p > i$  的分量, 则互换 SL. r[i] 和 SL. r[p], 且令 SL. r[i] 中指针域的值改为  $p$ ; 由于此时数组中所有小于  $i$  的分量中已是“到位”的记录, 则当  $p < i$  时, 应顺链继续查找直到  $p \geqslant i$  为止。图 10.4 所示为重排记录的全部过程。

算法10.3描述了上述重排记录的过程。容易看出，在重排记录的过程中，最坏情况是每个记录到位都必须进行一次记录的交换，即3次移动记录，所以重排记录至多需进行  $3(n - 1)$  次记录的移动，它并不增加表插入排序的时间复杂度。

```javascript
void Arrange（SLinkListType&SL）{//根据静态链表SL中各结点的指针值调整记录位置，使得SL中记录按关键字非递减//减有序顺序排列 $\mathfrak{p} = \mathfrak{SL}\cdot \mathfrak{r}[0].\mathfrak{next};$  //p指示第一个记录的当前位置
```

```javascript
for（i=1；i<SL.length;++i）{//SL.r[1..i-1]中记录已按关键字有序排列，//第i个记录在SL中的当前位置应不小于iwhile  $(\mathfrak{p} <   \mathfrak{i})$  p  $=$  SL.r[p].next; //找到第i个记录，并用p指示其在SL中当前位置q  $=$  SL.r[p].next; //q指示尚未调整的表尾if（p!=i）{//交换记录，使第i个记录到位SL.r[p]  $\longleftrightarrow$  SL.r[i]; //指向被移走的记录，使得以后可由while循环找回 $\textbf{\textit{p}} = \textbf{\textit{q}};$  //p指示尚未调整的表尾，为找第  $\mathrm{i + 1}$  个记录作准备}}//Arrange
```

算法 10.3  

<table><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td></tr><tr><td>maxint</td><td>49</td><td>38</td><td>65</td><td>97</td><td>76</td><td>13</td><td>27</td><td>52</td></tr><tr><td>6</td><td>8</td><td>1</td><td>5</td><td>0</td><td>4</td><td>7</td><td>2</td><td>3</td></tr><tr><td>i=1</td><td>maxint</td><td>13</td><td>38</td><td>65</td><td>97</td><td>76</td><td>49</td><td>27</td></tr><tr><td>p=6</td><td>6</td><td>(6)</td><td>1</td><td>5</td><td>0</td><td>4</td><td>8</td><td>2</td></tr><tr><td>i=2</td><td>maxint</td><td>13</td><td>27</td><td>65</td><td>97</td><td>76</td><td>49</td><td>38</td></tr><tr><td>p=7</td><td>6</td><td>(6)</td><td>(7)</td><td>5</td><td>0</td><td>4</td><td>8</td><td>1</td></tr><tr><td>i=3</td><td>maxint</td><td>13</td><td>27</td><td>38</td><td>97</td><td>76</td><td>49</td><td>65</td></tr><tr><td>p=(2), 7</td><td>6</td><td>(6)</td><td>(7)</td><td>(7)</td><td>0</td><td>4</td><td>8</td><td>5</td></tr><tr><td>i=4</td><td>maxint</td><td>13</td><td>27</td><td>38</td><td>49</td><td>76</td><td>97</td><td>65</td></tr><tr><td>p=(1), 6</td><td>6</td><td>(6)</td><td>(7)</td><td>(7)</td><td>(6)</td><td>4</td><td>0</td><td>5</td></tr><tr><td>i=5</td><td>maxint</td><td>13</td><td>27</td><td>38</td><td>49</td><td>52</td><td>97</td><td>65</td></tr><tr><td>p=8</td><td>6</td><td>(6)</td><td>(7)</td><td>(7)</td><td>(6)</td><td>(8)</td><td>0</td><td>5</td></tr><tr><td>i=6</td><td>maxint</td><td>13</td><td>27</td><td>38</td><td>49</td><td>52</td><td>65</td><td>97</td></tr><tr><td>p=(3), 7</td><td>6</td><td>(6)</td><td>(7)</td><td>(7)</td><td>(6)</td><td>(8)</td><td>(7)</td><td>0</td></tr><tr><td>i=7</td><td>maxint</td><td>13</td><td>27</td><td>38</td><td>49</td><td>52</td><td>65</td><td>97</td></tr><tr><td>p=(5), 8</td><td>6</td><td>(6)</td><td>(7)</td><td>(7)</td><td>(6)</td><td>(8)</td><td>(7)</td><td>(8)</td></tr></table>

图10.4 重排静态链表数组中记录的过程

# 10.2.3 希尔排序

希尔排序(Shell's Sort)又称“缩小增量排序”(Diminishing Increment Sort), 它也是一种属插入排序类的方法, 但在时间效率上较前述几种排序方法有较大的改进。

从对直接插入排序的分析得知，其算法时间复杂度为  $O(n^{2})$  ，但是，若待排记录序列为“正序”时，其时间复杂度可提高至  $O(n)$  。由此可设想，若待排记录序列按关键字“基本有序”，即序列中具有下列特性

$$
L. r [ i ]. k e y <   \max  _ {1 \leqslant j <   i} \{L. r [ j ]. k e y \} \tag {10-7}
$$

的记录较少时, 直接插入排序的效率就可大大提高, 从另一方面来看, 由于直接插入排序算法简单, 则在  $n$  值很小时效率也比较高。希尔排序正是从这两点分析出发对直接插入排序进行改进得到的一种插入排序方法。

它的基本思想是：先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。

仍以式(10-4)中的关键字为例，先看一下希尔排序的过程。初始关键字序列如图10.5的第1行所示。首先将该序列分成5个子序列  $\{R_1,R_6\} ,\{R_2,R_7\} ,\dots ,\{R_5,R_{10}\}$  ，如图10.5的第2行至第6行所示，分别对每个子序列进行直接插入排序，排序结果如图10.5的第7行所示，从第1行的初始序列得到第7行的序列的过程称为一趟希尔排序。然后进行第二趟希尔排序，即分别对下列3个子序列：  $\{R_1,R_4,R_7,R_{10}\} ,\{R_2,R_5,R_8\}$  和 $\{R_3,R_6,R_9\}$  进行直接插入排序，其结果如图10.5的第11行所示，最后对整个序列进行一趟直接插入排序。至此，希尔排序结束，整个序列的记录已按关键字非递减有序排列。

![](images/bd74e329bad10673718ff84560e4b6ab0fdcd4d5d0120d46cd7d9290557af0aa.jpg)  
图10.5 希尔排序示例

从上述排序过程可见，希尔排序的一个特点是：子序列的构成不是简单地“逐段分割”，而是将相隔某个“增量”的记录组成一个子序列。如上例中，第一趟排序时的增量为

5, 第二趟排序时的增量为 3, 由于在前两趟的插入排序中记录的关键字是和同一子序列中的前一个记录的关键字进行比较, 因此关键字较小的记录就不是一步一步地往前挪动, 而是跳跃式地往前移, 从而使得在进行最后一趟增量为 1 的插入排序时, 序列已基本有序, 只要作记录的少量比较和移动即可完成排序, 因此希尔排序的时间复杂度较直接插入排序低。下面用算法语言描述上述希尔排序的过程, 为此先将算法 10.1 改写成如算法 10.4 所示的一般形式。希尔排序算法如算法 10.5 所示。

```txt
void ShellInsert (SqList &L, int dk) {
// 对顺序表 L 作一趟希尔插入排序。本算法是和一趟直接插入排序相比，作了以下修改：
// 1. 前后记录位置的增量是 dk，而不是 1；
// 2. r[0] 只是暂存单元，不是哨兵。当 j <= 0 时，插入位置已找到。
for (i = dk + 1; i <= L.length; ++ i)
if (LT(L.r[i].key, L.r[i - dk].key)) { // 需将 L.r[i] 插入有序增量子表
L.r[0] = L.r[i];
for (j = i - dk; j > 0 && LT(L.r[0].key, L.r[j].key); j -= dk)
L.r[j + dk] = L.r[j];
L.r[j + dk] = L.r[0];
}
```

# 算法 10.4

```txt
void ShellSort (SqList &L, int dhta[], int t) {
// 按增量序列 dhta[0..t-1]对顺序表 L 作希尔排序。
for (k = 0; k < t; ++k)
    ShellInsert(L, dhta[k]); // 一趟增量为 dhta[k]的插入排序
} // ShellSort
```

# 算法 10.5

希尔排序的分析是一个复杂的问题，因为它的时间是所取“增量”序列的函数，这涉及一些数学上尚未解决的难题。因此，到目前为止尚未有人求得一种最好的增量序列，但大量的研究已得出一些局部的结论。如有人指出，当增量序列为  $\mathrm{dlta}[k] = 2^{t - k + 1} - 1$  时，希尔排序的时间复杂度为  $O(n^{3 / 2})$  ，其中  $t$  为排序趟数，  $1\leqslant k\leqslant t\leqslant \lfloor \log_2(n + 1)\rfloor$  。还有人在大量的实验基础上推出：当  $\pmb{n}$  在某个特定范围内，希尔排序所需的比较和移动次数约为 $n^{1.3}$  ，当  $n\to \infty$  时，可减少到  $n(\log_2n)^{2^{[2]}}$  。增量序列可以有各种取法①，但需注意：应使增量序列中的值没有除1之外的公因子，并且最后一个增量值必须等于1。

# 10.3 快速排序

这一节讨论一类藉助“交换”进行排序的方法，其中最简单的一种就是人们所熟知的起泡排序（Bubble Sort）。

① 其他增量序列如：

```txt
…9,5,3,2,1  $\mathrm{dlta}[k] = 2^{t - k} + 1\quad 0\leqslant k\leqslant t\leqslant \lfloor \log_2(n - 1)\rfloor$  …40,13,4,1  $\mathrm{dlta}[k] = \frac{1}{2} (3^{t - k} - 1)\quad 0\leqslant k\leqslant t\leqslant \lfloor \log_3(2n + 1)\rfloor$
```

起泡排序的过程很简单。首先将第一个记录的关键字和第二个记录的关键字进行比较，若为逆序（即L.r[1].key  $\rightharpoondown$  L.r[2].key)，则将两个记录交换之，然后比较第二个记录和第三个记录的关键字。依次类推，直至第  $n - 1$  个记录和第  $_n$  个记录的关键字进行过比较为止。上述过程称做第一趟起泡排序，其结果使得关键字最大的记录被安置到最后一个记录的位置上。然后进行第二趟起泡排序，对前  $n - 1$  个记录进行同样操作，其结果是使关键字次大的记录被安置到第  $n - 1$  个记录的位置上。一般地，第  $_i$  趟起泡排序是从L.r[1]到L.r[n-i+1]依次比较相邻两个记录的关键字，并在“逆序”时交换相邻记录，其结果是这  $n - i + 1$  个记录中关键字最大的记录被交换到第  $n - i + 1$  的位置上。整个排序过程需进行  $k(1\leqslant k <   n)$  趟起泡排序，显然，判别起泡排序结束的条件应该是“在一趟排序过程中没有进行过交换记录的操作”。图10.6展示了起泡排序的一个实例。从图中可见，在起泡排序的过程中，关键字较小的记录好比水中气泡逐趋向上飘浮，而关键字较大的记录好比石块往下沉，每一趟有一块“最大”的石头沉到水底(请参见“1.4.3节算法效率的度量”中起泡排序的算法）。

<table><tr><td>49</td><td>38</td><td>38</td><td>38</td><td>38</td><td>13</td><td>13</td></tr><tr><td>38</td><td>49</td><td>49</td><td>49</td><td>13</td><td>27</td><td>27</td></tr><tr><td>65</td><td>65</td><td>65</td><td>13</td><td>27</td><td>38</td><td>38</td></tr><tr><td>97</td><td>76</td><td>13</td><td>27</td><td>49</td><td>49</td><td></td></tr><tr><td>76</td><td>13</td><td>27</td><td>49</td><td>49</td><td></td><td></td></tr><tr><td>13</td><td>27</td><td>49</td><td>65</td><td></td><td></td><td></td></tr><tr><td>27</td><td>49</td><td>76</td><td></td><td></td><td></td><td></td></tr><tr><td>49</td><td>97</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>初始关键字</td><td>第一趟排序后</td><td>第二趟排序后</td><td>第三趟排序后</td><td>第四趟排序后</td><td>第五趟排序后</td><td>第六趟排序后</td></tr></table>

图10.6 起泡排序示例

分析起泡排序的效率, 容易看出, 若初始序列为“正序”序列, 则只需进行一趟排序, 在排序过程中进行  $n - 1$  次关键字间的比较, 且不移动记录; 反之, 若初始序列为“逆序”序列, 则需进行  $n - 1$  趟排序, 需进行  $\sum_{i=n}^{2} (i - 1) = n(n - 1)/2$  次比较, 并作等数量级的记录移动。因此, 总的时间复杂度为  $O(n^2)$  。

快速排序(Quick Sort)是对起泡排序的一种改进。它的基本思想是，通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。

假设待排序的序列为  $\{\mathrm{L.r[s]},\mathrm{L.r[s + 1]},\dots ,\mathrm{L.r[t]}\}$  ，首先任意选取一个记录(通常可选第一个记录L.r[s])作为枢轴(或支点)(pivot)，然后按下述原则重新排列其余记录：将所有关键字较它小的记录都安置在它的位置之前，将所有关键字较它大的记录都安置在它的位置之后。由此可以该“枢轴”记录最后所落的位置i作分界线，将序列

$\{\mathrm{L.r[s],\cdots,L.r[t]}\}$  分割成两个子序列  $\{\mathrm{L.r[s],L.r[s + 1],\cdots,L.r[i - 1]}\}$  和 $\{\mathrm{L.r[i + 1],L.r[i + 2],\cdots,L.r[t]}\}$  。这个过程称做一趟快速排序(或一次划分)。

一趟快速排序的具体做法是：附设两个指针 low 和 high，它们的初值分别为 low 和 high，设枢轴记录的关键字为 pivotkey，则首先从 high 所指位置起向前搜索找到第一个关键字小于 pivotkey 的记录和枢轴记录互相交换，然后从 low 所指位置起向后搜索，找到第一个关键字大于 pivotkey 的记录和枢轴记录互相交换，重复这两步直至 low = high 为止。其算法如算法 10.6(a) 所示。

```txt
int Partition (SqList &L, int low, int high) {
// 交换顺序表 L 中子表 L.r[low..high]的记录，使枢轴记录到位，并返回其所在位置，此时
// 在它之前(后)的记录均不大(小)于它。
pivotkey = L.r[low].key; // 用子表的第一个记录作枢轴记录
while (low<high) {
while (low<high && L.r[high].key>=pivotkey) -- high;
L.r[low]←→L.r[high];
while (low<high && L.r[low].key<=pivotkey) ++ low;
L.r[low]←→L.r[high];
}
return low; // 返回枢轴所在位置
} // Partition
```

# 算法10.6(a)

具体实现上述算法时，每交换一对记录需进行3次记录移动(赋值)的操作。而实际上，在排序过程中对枢轴记录的赋值是多余的，因为只有在一趟排序结束时，即low=high的位置才是枢轴记录的最后位置。由此可改写上述算法，先将枢轴记录暂存在r[0]的位置上，排序过程中只作r[low]或r[high]的单向移动，直至一趟排序结束后再将枢轴记录移至正确位置上。如算法10.6(b)所示。

```txt
int Partition (SqlList &L, int low, int high) {
// 交换顺序表 L 中子表 r[low..high] 的记录，枢轴记录到位，并返回其所在位置，此时
// 在它之前(后)的记录均不大(小)于它。
L.r[0] = L.r[low];
pivotkey = L.r[low].key;
while (low<high) {
while (low<high && L.r[high].key >= pivotkey) -- high;
L.r[low] = L.r[high];
while (low<high && L.r[low].key <= pivotkey) ++ low;
L.r[high] = L.r[low];
}
L.r[low] = L.r[0];
return low;
} // Partition
```

# 算法 10.6(b)

以式(10-4)中的关键字为例，一趟快排的过程如图10.7(a)所示。整个快速排序的过程可递归进行。若待排序列中只有一个记录，显然已有序，否则进行一趟快速排序后再分

别对分割所得的两个子序列进行快速排序，如图10.7(b)所示。

图10.7 快速排序示例  
![](images/aca8d486f9bd7515085609780d4e27ad8e7d0661d54f83dac8f3152344e7aef4.jpg)  
(a) 一趟快排过程；(b) 排序的全过程

递归形式的快速排序算法如算法10.7和算法10.8所示。

```txt
void QSort (SqList &L, int low, int high) {
    // 对顺序表 L 中的子序列 L.r[low..high]作快速排序
    if (low < high) {
        // 长度大于 1
        pivotloc = Partition(L, low, high);
        // 将 L.r[low..high]一分为二
        QSort(L, low, pivotloc - 1);
        // 对低子表递归排序, pivotloc 是枢轴位置
        QSort(L, pivotloc + 1, high);
        // 对高子表递归排序
    }
} // QSort
```

# 算法 10.7

void QuickSort(SqList &L) { //对顺序表L作快速排序。 QSort(L,1,L.length); } //QuickSort

# 算法 10.8

快速排序的平均时间为  $T_{avg}(n) = kn\ln n$ ，其中  $n$  为待排序序列中记录的个数， $k$  为某个常数，经验证明，在所有同数量级的此类（先进的）排序方法中，快速排序的常数因子  $k$  最小。因此，就平均时间而言，快速排序是目前被认为是最好的一种内部排序方法。

下面我们来分析快速排序的平均时间性能。

假设  $T(n)$  为对  $\pmb{n}$  个记录L.r[1..n]进行快速排序所需时间，则由算法QuickSort可见，

$$
T (n) = T _ {p a s s} (n) + T (k - 1) + T (n - k)
$$

其中  $T_{\text{pass}}(n)$  为对  $n$  个记录进行一趟快速排序 Partition  $(L,1,n)$  所需时间，从算法 10.7 可见，它和记录数  $n$  成正比，可以  $cn$  表示之（ $c$  为某个常数）； $T(k-1)$  和  $T(n-k)$  分别为对 L.r[1..k-1] 和 L.r[k+1..n] 中记录进行快速排序 QSort(L,1,k-1) 和 QSort(L, k+1,n) 所需时间。假设待排列中的记录是随机排列的，则在一趟排序之后， $k$  取 1 至  $n$  之间任何一值的概率相同，快速排序所需时间的平均值则为

$$
\begin{array}{l} T _ {\text {a v g}} (n) = c n + \frac {1}{n} \sum_ {k = 1} ^ {n} \left[ T _ {\text {a v g}} (k - 1) + T _ {\text {a v g}} (n - k) \right] \\ = c n + \frac {2}{n} \sum_ {i = 0} ^ {n - 1} T _ {\text {a v g}} (i) \tag {10-8} \\ \end{array}
$$

假定  $T_{avg}(1) \leqslant b(b$  为某个常量), 类同式(9-19)的推导, 由式(10-8)可推出

$$
\begin{array}{l} T _ {\text {a v g}} (n) = \frac {n + 1}{n} T _ {\text {a v g}} (n - 1) + \frac {2 n - 1}{n} c \\ <   \frac {n + 1}{2} T _ {\text {a v g}} (1) + 2 (n + 1) \left(\frac {1}{2} + \frac {1}{3} + \dots + \frac {1}{n + 1}\right) c \\ <   \left(\frac {b}{2} + 2 c\right) (n + 1) \ln (n + 1) \quad n \geqslant 2 \tag {10-9} \\ \end{array}
$$

通常, 快速排序被认为是, 在所有同数量级  $(O(n\log n))$  的排序方法中, 其平均性能最好。但是, 若初始记录序列按关键字有序或基本有序时, 快速排序将蜕化为起泡排序, 其时间复杂度为  $O(n^{2})$  。为改进之, 通常依“三者取中”的法则来选取枢轴记录, 即比较 L. r[s]. key、L. r[t]. key 和 L. r[  $\left[\frac{s + t}{2}\right]$ . key, 取三者中其关键字取中值的记录为枢轴, 只要将该记录和 L. r[s]互换, 算法 10.6(b) 不变。经验证明, 采用三者取中的规则可大大改善快速排序在最坏情况下的性能。然而, 即使如此, 也不能使快速排序在待排记录序列已按关键字有序的情况下达到  $O(n)$  的时间复杂度。为此, 可如下所述修改“一次划分”算法: 在指针 high 减 1 和 low 增 1 的同时进行“起泡”操作, 即在相邻两个记录处于“逆序”时进行互换, 同时在算法中附设两个布尔型变量分别指示指针 low 和 high 在从两端向中间的移动过程中是否进行过交换记录的操作, 若指针 low 在从低端向中间的移动过

程中没有进行交换记录的操作, 则不再需要对低端子表进行排序; 类似地, 若指针 high 在从高端向中间的移动过程中没有进行交换记录的操作, 则不再需要对高端子表进行排序。显然, 如此“划分”将进一步改善快速排序的平均性能。

由以上讨论可知，从时间上看，快速排序的平均性能优于前面讨论过的各种排序方法，从空间上看，前面讨论的各种方法，除2-路插入排序之外，都只需要一个记录的附加空间即可，但快速排序需一个栈空间来实现递归。若每一趟排序都将记录序列均匀地分割成长度相接近的两个子序列，则栈的最大深度为  $\lfloor \log_2n\rfloor +1$  （包括最外层参量进栈)，但是，若每趟排序之后，枢轴位置均偏向子序列的一端，则为最坏情况，栈的最大深度为  $n$  。如果改写算法10.7，在一趟排序之后比较分割所得两部分的长度，且先对长度短的子序列中的记录进行快速排序，则栈的最大深度可降为  $O(\log n)$  。

# 10.4 选择排序

选择排序(Selection Sort)的基本思想是：每一趟在  $n - i + 1 (i = 1,2,\dots ,n - 1)$  个记录中选取关键字最小的记录作为有序序列中第  $i$  个记录。其中最简单且为读者最熟悉的是简单选择排序(Simple Selection Sort)。

# 10.4.1 简单选择排序

一趟简单选择排序的操作为：通过  $n - i$  次关键字间的比较，从  $n - i + 1$  个记录中选出关键字最小的记录，并和第  $i(1 \leqslant i \leqslant n)$  个记录交换之。

显然，对L.r[1..n]中记录进行简单选择排序的算法为：令  $i$  从1至  $n - 1$  ，进行  $n - 1$  趟选择操作，如算法10.9所示。容易看出，简单选择排序过程中，所需进行记录移动的操作次数较少，其最小值为“0”，最大值为  $3(n - 1)$  。然而，无论记录的初始排列如何，所需进行的关键字间的比较次数相同，均为  $n(n - 1) / 2$  。因此，总的时间复杂度也是  $O(n^{2})$  。

```txt
void SelectSort (SqlList &L) { //对顺序表L作简单选择排序。 for  $(\mathrm{i} = 1;\mathrm{i} <   \mathrm{L}.$  length;  $+ + \mathrm{i})$  { //选择第i小的记录，并交换到位 j  $=$  SelectMinKey(L,i); //在L.r[i..L.length]中选择key最小的记录 if  $(\mathrm{i}! = \mathrm{j})$  L.r[i]  $\longleftrightarrow$  L.r[j]; //与第i个记录交换 } //SelectSort
```

# 算法 10.9

那么，能否加以改进呢？

从上述可见，选择排序的主要操作是进行关键字间的比较，因此改进简单选择排序应从如何减少“比较”出发考虑。显然，在  $n$  个关键字中选出最小值，至少进行  $n - 1$  次比较，然而，继续在剩余的  $n - 1$  个关键字中选择次小值就并非一定要进行  $n - 2$  次比较，若能利用前  $n - 1$  次比较所得信息，则可减少以后各趟选择排序中所用的比较次数。实际上，体育比赛中的锦标赛便是一种选择排序。例如，在8个运动员中决出前3名至多需要11场

比赛, 而不是  $7 + 6 + 5 = 18$  场比赛 (它的前提是, 若乙胜丙, 甲胜乙, 则认为甲必能胜丙)。例如, 图 10.8(a) 中最低层的叶子结点中 8 个选手之间经过第一轮的 4 场比赛之后选拔出 4 个优胜者“CHA”、“BAO”、“DIAO”和“WANG”, 然后经过两场半决赛和一场决赛之后, 选拔出冠军“BAO”。显然, 按照锦标赛的传递关系, 亚军只能产生于分别在决赛, 半决赛和第一轮比赛中输给冠军的选手中。由此, 在经过“CHA”和“LIU”、“CHA”和“DIAO”的两场比赛之后, 选拔出亚军“CHA”, 同理, 选拔殿军的比赛只要在“ZHAO”、“LIU”和“DIAO”3个选手之间进行即可。按照这种锦标赛的思想可导出树形选择排序。

![](images/0c61c91661dba6b64195077232d579d7a0581752d2e87ff0b12c11f1f6dd7a7b.jpg)

![](images/00a220a33963389a1bdf4b3e9a8b6d36820cefa5014476bde77cc3f4c9a33db7.jpg)

图10.8 锦标赛过程示意图  
![](images/60eaf99ccce5f1d2f49336adc128ba0516bb316c80261bbb8229a3d8df4baa1f.jpg)  
(a) 选拔冠军的比赛程序；(b) 选拔亚军的两场比赛；(c) 选拔季军的两场比赛

# 10.4.2 树形选择排序

树形选择排序（Tree Selection Sort），又称锦标赛排序（Tournament Sort），是一种按照锦标赛的思想进行选择排序的方法。首先对  $n$  个记录的关键字进行两两比较，然后在其中  $\left\lceil \frac{n}{2} \right\rceil$  个较小者之间再进行两两比较，如此重复，直至选出最小关键字的记录为止。

这个过程可用一棵有  $n$  个叶子结点的完全二叉树表示。例如，图10.9(a)中的二叉树表示从8个关键字中选出最小关键字的过程。8个叶子结点中依次存放排序之前的8个关键字，每个非终端结点中的关键字均等于其左、右孩子结点中较小的关键字，则根结点中的关键字即为叶子结点中的最小关键字。在输出最小关键字之后，根据关系的可传递性，欲选出次小关键字，仅需将叶子结点中的最小关键字(13)改为“最大值”，然后从该叶子结点开始，和其左(或右)兄弟的关键字进行比较，修改从叶子结点到根的路径上各结点的关键字，则根结点的关键字即为次小关键字。同理，可依次选出从小到大的所有关键字（参见图10.9(b)和(c))。由于含有  $n$  个叶子结点的完全二叉树的深度为  $\lceil \log_2n\rceil +1$  ，则在树形选择排序中，除了最小关键字之外，每选择一个次小关键字仅需进行  $\lceil \log_2n\rceil$  次比较，因此，它的时间复杂度为  $O(n\log n)$  。但是，这种排序方法尚有辅助存储空间较多、和“最大值”进行多余的比赛等缺点。为了弥补，威洛姆斯(J.willioms)在1964年提出了另一种形式的选择排序——堆排序。

![](images/7b6128cdd312079a95cc5d930d40cb832220a1f855c60eadce345449184f1158.jpg)

![](images/e8f6c9456c2a643b2aeaeacc6112f47ebb161ee56c473e3b3c66a0e002dd11c9.jpg)

图10.9 树形选择排序示例  
![](images/5373160965526c213dac2429754ca65e39aec746e13f23ef7d306ad933bb4f08.jpg)  
（a）选出最小关键字为13；（b）选出次小关键字为27；（c）选出居第三的关键字为38

# 10.4.3 堆排序

堆排序(Heap Sort)只需要一个记录大小的辅助空间，每个待排序的记录仅占有一个存储空间。

堆的定义如下： $n$  个元素的序列  $\{k_1, k_2, \dots, k_n\}$  当且仅当满足下关系时，称之为堆。

$$
\left\{ \begin{array}{l} k _ {i} \leqslant k _ {2 i} \\ k _ {i} \leqslant k _ {2 i + 1} \end{array} \right.
$$

$$
\text {或} \left\{ \begin{array}{l l} k _ {i} \geqslant k _ {2 i} \\ k _ {i} \geqslant k _ {2 i + 1} \end{array} \right.
$$

$$
\left(i = 1, 2, \dots , \lfloor \frac {n}{2} \rfloor\right)
$$

若将和此序列对应的一维数组(即以一维数组作此序列的存储结构)看成是一个完全二叉树, 则堆的含义表明, 完全二叉树中所有非终端结点的值均不大于 (或不小于) 其左、右孩子结点的值。由此, 若序列  $\{k_{1}, k_{2}, \cdots, k_{n}\}$  是堆, 则堆顶元素 (或完全二叉树的根) 必为序列中  $n$  个元素的最小值 (或最大值)。例如, 下列两个序列为堆, 对应的完全二叉树如图 10.10 所示。

(a)  
![](images/e26819fa6298f37f4bb21803c9e0d9bda3ad448aace22a12de5af43bb989e16b.jpg)  
(a) 堆顶元素取最大值；(b) 堆顶元素取最小值

![](images/d179ef7f807e3ab8dee17c270c23fc40391e64bf7eb0138e7af316b06fa7a428.jpg)  
(b)  
图10.10 堆的示例

$$
\begin{array}{l} \{9 6, 8 3, 2 7, 3 8, 1 1, 0 9 \} \\ \{1 2, 3 6, 2 4, 8 5, 4 7, 3 0, 5 3, 9 1 \} \\ \end{array}
$$

若在输出堆顶的最小值之后，使得剩余  $n - 1$  个元素的序列重又建成一个堆，则得到  $n$  个元素中的次小值。如此反复执行，便能得到一个有序序列，这个过程称之为堆排序。

由此，实现堆排序需要解决两个问题：（1)如何由一个无序序列建成一个堆？（2)如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？

下面先讨论第二个问题。例如，图10.11(a)是个堆，假设输出堆顶元素之后，以堆中最后一个元素替代之，如图10.11(b)所示。此时根结点的左、右子树均为堆，则仅需自上至下进行调整即可。首先以堆顶元素和其左、右子树根结点的值比较之，由于右子树根结点的值小于左子树根结点的值且小于根结点的值，则将27和97交换之；由于97替代了27之后破坏了右子树的“堆”，则需进行和上述相同的调整，直至叶子结点，调整后的状态如图10.11(c)所示，此时堆顶为  $n - 1$  个元素中的最小值。重复上述过程，将堆顶元素27和堆中最后一个元素97交换且调整，得到如图10.11(d)所示新的堆。

我们称这个自堆顶至叶子的调整过程为“筛选”。

从一个无序序列建堆的过程就是一个反复“筛选”的过程。若将此序列看成是一个完全二叉树，则最后一个非终端结点是第  $\lfloor n / 2\rfloor$  个元素，由此“筛选”只需从第  $\lfloor n / 2\rfloor$  个元素开始。例如，图10.12(a)中的二叉树表示一个有8个元素的无序序列

$$
\{4 9, 3 8, 6 5, 9 7, 7 6, 1 3, 2 7, \overline {{4 9}} \}
$$

则筛选从第4个元素开始，由于  $97 > \overline{49}$  ，则交换之，交换后的序列如图10.12(b)所示，同理，在第3个元素65被筛选之后序列的状态如图10.12(c)所示。由于第2个元素38不大于其左、右子树根的值，则筛选后的序列不变。图10.12(e)所示为筛选根元素49之后建成的堆。

堆排序的算法如算法10.11所示，其中筛选的算法如算法10.10所示。为使排序结果和10.1节中的定义一致，即：使记录序列按关键字非递减有序排列，则在堆排序的算法

![](images/6a82a762cb6e864927f5fac2c20721a17a3611b3c0d755940cfaf12624e5f1d8.jpg)  
(a)

![](images/b61ac5196fabf7b708e263ad7558d15efe27ede8493f69d0f1502000022eeb8e.jpg)  
13

13  
(c)  
图10.11 输出堆顶元素并调整建新堆的过程  
![](images/e9944c5755e05ac44f7cad440d18b404b30f24845a90f304d5b0e9262ea76227.jpg)  
(a) 堆；(b) 13 和 97 交换后的情形；(c) 调整后的新堆；

![](images/3e54a4453d8e7faf074f3e18a4b0dc468a1cbefe294bc6388c7e2a86ae6ad240.jpg)  
13  
(d)

![](images/cf6b3b4205f261849aaa7f347f59615fe97ef4f372caec12cfdbe3a7a0dc9b71.jpg)  
(d) 27 和 97 交换后再进行调整建成的新堆

![](images/6ab41e504e3aa430181345e6b8cf3dbf58aa185f622dfa8fd654b6531b01579b.jpg)

![](images/a74168bed8b3ae6866a2908b0902dffc296bdd238a880bfd02dc0a2c56366041.jpg)  
(a) 元序序列；(b) 97 被筛选之后的状态；(c) 68 被筛选之后的状态；

![](images/507c85e8a924c5a92020c13f5563c7db20ef8ec1c09b3e05890f24d0bd1a0a4a.jpg)  
(d) 38 故得证之后的状况；（e）49 故得证之后建成的梁

![](images/c16d6c464a278d42d5bbc892ad16f0bebc616f3d9b0a7c63ed0c2228ecae51e2.jpg)  
图10.12 重始堆过程示例

中先建一个“大顶堆”，即先选得一个关键字为最大的记录并与序列中最后一个记录交换，然后对序列中前  $n - 1$  记录进行筛选，重新将它调整为一个“大顶堆”，如此反复直至排序结束。由此，“筛选”应沿关键字较大的孩子结点向下进行。

```javascript
typedef SqList HeapType; //堆采用顺序表存储表示  
void HeapAdjust (HeapType &H, int s, int m) { //已知H.r[s..m]中记录的关键字除H.r[s].key之外均满足堆的定义，本函数调整H.r[s] //的关键字，使H.r[s..m]成为一个大顶堆(对其中记录的关键字而言) rc = H.r[s]; for（j=2*s；j<=m；j*=2）{//沿key较大的孩子结点向下筛选 if（j<m&&&LT(H.r[j].key,H.r[j+1].key)) ++j; //j为key较大的记录的下标 if(!LT(rc.key,H.r[j].key)) break; //rc应插人在位置s上 H.r[s] = H.r[j]；s = j; } H.r[s] = rc; //插入 } //HeapAdjust
```

# 算法 10.10

```javascript
void HeapSort (HeapType&H) { //对顺序表H进行堆排序。 for  $(\mathrm{i} = \mathrm{H}. \mathrm{length} / 2; \mathrm{i} > 0; - - \mathrm{i})$  //把H.r[1..H.length]建成大顶堆 HeapAdjust(H,i,H.length); for  $(\mathrm{i} = \mathrm{H}. \mathrm{length}; \mathrm{i} > 1; - - \mathrm{i})$  { H.r[1]  $\leftarrow \rightarrow$  H.r[i]; //将堆顶记录和当前未经排序子序列Hr[1..i]中 //最后一个记录相互交换 HeapAdjust(H,1,i-1); //将H.r[1..i-1]重新调整为大顶堆 }}//HeapSort
```

# 算法 10.11

堆排序方法对记录数较少的文件并不值得提倡，但对  $n$  较大的文件还是很有效的。因为其运行时间主要耗费在建初始堆和调整建新堆时进行的反复“筛选”上。对深度为  $k$  的堆，筛选算法中进行的关键字比较次数至多为  $2(k - 1)$  次，则在建含  $n$  个元素、深度为  $h$  的堆时，总共进行的关键字比较次数不超过  $4n$  。①又， $n$  个结点的完全二叉树的深度为  $\lfloor \log_2 n \rfloor + 1$ ，则调整建新堆时调用 HeapAdjust 过程  $n - 1$  次，总共进行的比较次数不超过

下式之值，

$$
2 (\lfloor \log_ {2} (n - 1) \rfloor + \lfloor \log_ {2} (n - 2) \rfloor + \dots + \log_ {2} 2) <   2 n (\lfloor \log_ {2} n \rfloor)
$$

由此，堆排序在最坏的情况下，其时间复杂度也为  $O(n\log n)$  。相对于快速排序来说，这是堆排序的最大优点。此外，堆排序仅需一个记录大小供交换用的辅助存储空间。

# 10.5 归并排序

归并排序(Merging Sort)是又一类不同的排序方法。“归并”的含义是将两个或两个以上的有序表组合成一个新的有序表。它的实现方法早已为读者所熟悉,无论是顺序存储结构还是链表存储结构,都可在  $O(m + n)^{\text{①}}$  的时间量级上实现。利用归并的思想容易实现排序。假设初始序列含有  $\pmb{n}$  个记录,则可看成是  $\pmb{n}$  个有序的子序列,每个子序列的长度为1,然后两两归并,得到  $\left\lceil \frac{n}{2} \right\rceil$  个长度为2或1的有序子序列;再两两归并,……,如此重复,直至得到一个长度为  $\pmb{n}$  的有序序列为止,这种排序方法称为2-路归并排序。例如图10.13为2-路归并排序的一个例子。

![](images/55912f901f554eada68015159479d1886fffdb002007262ee2d8f9b973fc816f.jpg)  
图10.13 2-路归并排序示例

2-路归并排序中的核心操作是将一维数组中前后相邻的两个有序序列归并为一个有序序列，其算法(类似于算法2.7)如算法10.12所示。

```c
void Merge(RcType SR[], RcType &TR[], int i, int m, int n) {
// 将有序的 SR[i..m]和 SR[m+1..n]归并为有序的 TR[i..n]
for (j=m+1, k=i; i<=m && j<=n; ++k) {
// 将 SR 中记录由小到大地并入 TR
if (LQ(SR[i].key, SR[j].key)) TR[k] = SR[i++];
else TR[k] = SR[j++];
}
if (i<=m) TR[k..n] = SR[i..m];
if (j<=n) TR[k..n] = SR[j..n];
} // Merge
```

# 算法 10.12

一趟归并排序的操作是，调用  $\left\lceil \frac{n}{2h}\right\rceil$  次算法 merge 将 SR[1..n] 中前后相邻且长度为  $h$  的有序段进行两两归并，得到前后相邻、长度为  $2h$  的有序段，并存放在 TR[1..n] 中，整个归并排序需进行  $\lceil \log_2 n \rceil$  趟。可见，实现归并排序需和待排记录等数量的辅助空间，其时间复杂度为  $O(n \log n)$ 。

递归形式的2-路归并排序的算法如算法10.13和算法10.14所示。值得提醒的是，递归形式的算法在形式上较简洁，但实用性很差。其非递归形式的算法可查阅参考书目[1]。

与快速排序和堆排序相比，归并排序的最大特点是，它是一种稳定的排序方法。但在一般情况下，很少利用2-路归并排序法进行内部排序，其他形式的归并排序如本书习题集中习题10.17所述。

```javascript
void MSort（RcType SR[]，RcType&TR1[]，int s,int t）{ //将SR[s..t]归并排序为TR1[s..t]。 if  $(s = = t)$  TR1[s]  $=$  SR[s]; else{ m=(s+t)/2; //将SR[s..t]平分为SR[s..m]和SR[m+1..t] MSort（SR，TR2，s，m）； //递归地将SR[s..m]归并为有序的TR2[s..m] MSort（SR，TR2，m+1，t）； //递归地将SR[m+1..t]归并为有序的TR2[m+1..t] Merge（TR2，TR1，s，m，t）; //将TR2[s..m]和TR2[m+1..t]归并到TR1[s..t] }}//MSort
```

# 算法 10.13

```javascript
voidMergeSort（SqList&L）{//对顺序表L作归并排序。MSort(L.r，L.r,1，L.length);}//MergeSort
```

# 算法 10.14

# 10.6 基数排序

基数排序（Radix Sorting）是和前面所述各类排序方法完全不相同的一种排序方法。从前几节的讨论可见，实现排序主要是通过关键字间的比较和移动记录这两种操作，而实现基数排序不需要进行记录关键字间的比较。基数排序是一种借助多关键字排序的思想对单逻辑关键字进行排序的方法。

# 10.6.1 多关键字的排序

什么是多关键字排序问题？先看一个具体例子。

已知扑克牌中52张牌面的次序关系为：

$\clubsuit 2 <   \clubsuit 3 <   \dots <  \clubsuit A <   \spadesuit 2 <   \spadesuit 3 <   \dots <  \spadesuit A$

$$
<   \text {心} 2 <   \text {心} 3 <   \dots <   \text {心} A <   \text {中} 2 <   \text {中} 3 <   \dots <   \text {中} A
$$

每一张牌有两个“关键字”: 花色  $(\spadesuit < \spadesuit < \spadesuit < \spadesuit)$  和面值  $(2 < 3 < \dots < A)$ , 且“花色”的地位高于“面值”, 在比较任意两张牌面的大小时, 必须先比较“花色”, 若“花色”相同, 则再比较面值。由此, 将扑克牌整理成如上所述次序关系时, 通常采用的办法是: 先按不同“花色”分成有次序的 4 堆, 每一堆的牌均具有相同的“花色”, 然后分别对每一堆按“面值”大小整理有序。

也可采用另一种办法：先按不同“面值”分成13堆，然后将这13堆牌自小至大叠在一起（“3”在“2”之上，“4”在“3”之上，……，最上面的是4张“A”），然后将这付牌整个颠倒过来再重新按不同“花色”分成4堆，最后将这4堆牌按自小至大的次序合在一起（在最下面，◆在最上面），此时同样得到一付满足如上次序关系的牌。这两种整理扑克牌的方法便是两种多关键字的排序方法。

一般情况下，假设有  $n$  个记录的序列

$$
\left\{R _ {1}, R _ {2}, \dots , R _ {n} \right\} \tag {10-10}
$$

且每个记录  $R_{i}$  中含有  $d$  个关键字  $(K_{i}^{0}, K_{i}^{1}, \dots, K_{i}^{d-1})$ , 则称序列 (10-10) 对关键字  $(K^{0}, K^{1}, \dots, K^{d-1})$  有序是指: 对于序列中任意两个记录  $R_{j}$  和  $R_{j}(1 \leqslant i < j \leqslant n)$  都满足下列有序关系:

$$
\left(K _ {i} ^ {0}, K _ {i} ^ {1}, \dots , K _ {i} ^ {d - 1}\right) <   \left(K _ {j} ^ {0}, K _ {j} ^ {1}, \dots , K _ {j} ^ {d - 1}\right)
$$

其中  $K^0$  称为最主位关键字， $K^{d-1}$  称为最次位关键字。为实现多关键字排序，通常有两种方法：第一种方法是：先对最主位关键字  $K^0$  进行排序，将序列分成若干子序列，每个子序列中的记录都具有相同的  $K^0$  值，然后分别就每个子序列对关键字  $K^1$  进行排序，按  $K^1$  值不同再分成若干更小的子序列，依次重复，直至对  $K^{d-2}$  进行排序之后得到的每一子序列中的记录都具有相同的关键字  $(K^0, K^1, \dots, K^{d-2})$  ，而后分别每个子序列对  $K^{d-1}$  进行排序，最后将所有子序列依次联接在一起成为一个有序序列，这种方法称之为最高位优先（Most Significant Digit first）法，简称 MSD 法；第二种方法是从最次位关键字  $K^{d-1}$  起进行排序。然后再对高一位的关键字  $K^{d-2}$  进行排序，依次重复，直至对  $K^0$  进行排序后便成为一个有序序列。这种方法称之为最低位优先（Least Significant Digit first）法，简称 LSD 法。

MSD和LSD只约定按什么样的“关键字次序”来进行排序，而未规定对每个关键字进行排序时所用的方法。但从上面所述可以看出这两种排序方法的不同特点：若按MSD进行排序，必须将序列逐层分割成若干子序列，然后对各子序列分别进行排序；而按LSD进行排序时，不必分成子序列，对每个关键字都是整个序列参加排序，但对  $K^i (0 \leqslant i \leqslant d - 2)$  进行排序时，只能用稳定的排序方法。另一方面，按LSD进行排序时，在一定的条件下（即对前一个关键字  $K^i (0 \leqslant i \leqslant d - 2)$  的不同值，后一个关键字  $K^{i + 1}$  均取相同值），也可以不利用前几节所述各种通过关键字间的比较来实现排序的方法，而是通过若干次“分配”和“收集”来实现排序，如上述第二种整理扑克牌的方法那样。

# 10.6.2 链式基数排序

基数排序是借助“分配”和“收集”两种操作对单逻辑关键字进行排序的一种内部排序方法。

有的逻辑关键字可以看成由若干个关键字复合而成的。例如, 若关键字是数值, 且其值都在  $0 \leqslant K \leqslant 999$  范围内, 则可把每一个十进制数字看成一个关键字, 即可认为  $K$  由 3 个关键字  $(K^0, K^1, K^2)$  组成, 其中  $K^0$  是百位数,  $K^1$  是十位数,  $K^2$  是个位数; 又若关键字  $K$  是由 5 个字母组成的单词, 则可看成是由 5 个关键字  $(K^0, K^1, K^2, K^3, K^4)$  组成, 其中  $K^{j-1}$  是 (自左至右的) 第  $j+1$  个字母。由于如此分解而得的每个关键字  $K^j$  都在相同的范围内 (对数字,  $0 \leqslant K^j \leqslant 9$ , 对字母  $A' \leqslant K^j \leqslant Z'$ ), 则按 LSD 进行排序更为方便, 只要从最低数位关键字起, 按关键字的不同值将序列中记录“分配”到 RADIX 个队列中后再“收集”之, 如此重复  $d$  次。按这种方法实现排序称之为基数排序, 其中“基”指的是 RADIX 的取值范围, 在上述两种关键字的情况下, 它们分别为“10”和“26”。

实际上，早在计算机出现之前，利用卡片分类机对穿孔卡上的记录进行排序就是用的这种方法。然而，在计算机出现之后却长期得不到应用，原因是所需的辅助存储量（RADIX×N个记录空间）太大。直到1954年有人提出用“计数”代替“分配”才使基数排序得以在计算机上实现，但此时仍需要  $n$  个记录和  $2 \times \mathrm{RADIX}$  个计数单元的辅助空间。此后，有人提出用链表作存储结构，则又省去了  $n$  个记录的辅助空间。下面我们就来介绍这种“链式基数排序”的方法。

先看一个具体例子。首先以静态链表存储  $n$  个待排记录，并令表头指针指向第一个记录，如图10.14(a)所示；第一趟分配对最低数位关键字(个位数)进行，改变记录的指针值将链表中的记录分配至10个链队列中去，每个队列中的记录关键字的个位数相等，如图10.14(b)所示，其中f[i]和e[i]分别为第  $i$  个队列的头指针和尾指针；第一趟收集是改变所有非空队列的队尾记录的指针域，令其指向下一个非空队列的队头记录，重新将10个队列中的记录链成一个链表，如图10.14(c)所示；第二趟分配，第二趟收集及第三趟分配和第三趟收集分别是对十位数和百位数进行的，其过程和个位数相同，如图10.14(d)～(g)所示。至此排序完毕。

在描述算法之前，尚需定义新的数据类型

```c
define MAX_NUM_OF_KEY 8 //关键字项数的最大值
#define RADIX 10 //关键字基数，此时是十进制整数的基数
#define MAX_SPACE 10000
typedef struct {
    KeysType keys[MAX_NUM_OF_KEY];
    InfoType otherItems;
    int next;
}SLCell;
typedef struct {
    SLCell r[MAX_SPACE];
    int keynum;
    int recnum;
}SLList;
typedef int ArrType[RADIX];
//指针数组类型
```

图10.14 链式基数排序示例  
![](images/8a0f498e0ef5209be2286d67c49032693dab133f25be3a91f7bdf7616aa65024.jpg)  
(a) 初始状态；(b) 第一趟分配之后；(c) 第一趟收集之后；(d) 第二趟分配之后；  
(e)第二趟收集之后；(f)第三趟分配之后；(g)第三趟收集之后的有序文件

算法10.15为链式基数排序中一趟分配的算法，算法10.16为一趟收集的算法，算法10.17为链式基数排序的算法。从算法中容易看出，对于  $n$  个记录(假设每个记录含  $d$  个关键字，每个关键字的取值范围为  $rd$  个值)进行链式基数排序的时间复杂度为  $O(d(n + rd))$  ，其中每一趟分配的时间复杂度为  $O(n)$  ，每一趟收集的时间复杂度为 $O(rd)$  ，整个排序需进行  $d$  趟分配和收集。所需辅助空间为  $2rd$  个队列指针。当然，由于

需用链表作存储结构, 则相对于其他以顺序结构存储记录的排序方法而言, 还增加了  $n$  个指针域的空间。

```txt
void Distribute(SCLell &r, int i, ArrType &f, ArrType &e) {
// 静态链表 L 的 r 域中记录已按 (keys[0], ..., keys[i-1]) 有序。
// 本算法按第 i 个关键字 keys[i] 建立 RADIUS 个子表，使同一子表中记录的 keys[i] 相同。
// f[0..RADIX-1] 和 e[0..RADIX-1] 分别指向各子表中第一个和最后一个记录。
for (j = 0; j < Radix; ++j) f[j] = 0; // 各子表初始化为空表
for (p = r[0].next; p; p = r[p].next) {
    j = ord(r[p].keys[i]); // ord 将记录中第 i 个关键字映射到 [0..RADIX-1],
    if (!f[j]) f[j] = p;
    else r[e[j]].next = p;
    e[j] = p; // 将 p 所指的结点插入第 j 个子表中
}
```

# 算法 10.15

```javascript
void Collect (SLCell &r, int i, ArrType f, ArrType e) {
// 本算法按 keys[i] 自小至大地将 f[0..RADIX-1] 所指各子表依次链接成一个链表,
// e[0..RADIX-1] 为各子表的尾指针。
for (j = 0; !f[j]; j = succ(j)); // 找第一个非空子表, succ 为求后继函数
r[0].next = f[j]; t = e[j]; // r[0].next 指向第一个非空子表中第一个结点
while (j<RADIX) {
for (j = succ(j); j<RADIX-1 && !f[j]; j=succ(j)); // 找下一个非空子表
if (f[j]) {r[t].next = f[j]; t = e[j]; }
}
r[t].next = 0; // t 指向最后一个非空子表中的最后一个结点
} // Collect
```

# 算法 10.16

```javascript
void RadixSort(SLList &L) {
// L是采用静态链表表示的顺序表。
// 对L作基数排序，使得L成为按关键字自小到大的有序静态链表，L.r[0]为头结点。
for (i = 0; i < L recnum; ++i) L.r[i].next = i + 1;
L.r[L-recnum].next = 0; //将L改造为静态链表
for (i = 0; i < L.keynum; ++i) { //按最低位优先依次对各关键字进行分配和收集
    Distribute(L.r, i, f, e); //第i趟分配
    Collect(L.r, i, f, e); //第i趟收集
}
```

# 算法 10.17

# 10.7 各种内部排序方法的比较讨论

综合比较本章内讨论的各种内部排序方法，大致有如下结果（见下页表）。

从下表可以得出如下几个结论：

<table><tr><td>排序方法</td><td>平均时间</td><td>最坏情况</td><td>辅助存储</td></tr><tr><td>简单排序</td><td>O(n2)</td><td>O(n2)</td><td>O(1)</td></tr><tr><td>快速排序</td><td>O(nlogn)</td><td>O(n2)</td><td>O(logn)</td></tr><tr><td>堆排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(1)</td></tr><tr><td>归并排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(n)</td></tr><tr><td>基数排序</td><td>O(d(n+rd))</td><td>O(d(n+rd))</td><td>O(rd)</td></tr></table>

（1）从平均时间性能而言，快速排序最佳，其所需时间最省，但快速排序在最坏情况下的时间性能不如堆排序和归并排序。而后两者相比较的结果是，在  $n$  较大时，归并排序所需时间较堆排序省，但它所需的辅助存储量最多。

（2）上表中的“简单排序”包括除希尔排序之外的所有插入排序，起泡排序和简单选择排序，其中以直接插入排序为最简单，当序列中的记录“基本有序”或  $n$  值较小时，它是最佳的排序方法，因此常将它和其他的排序方法，诸如快速排序、归并排序等结合在一起使用。

（3）基数排序的时间复杂度也可写成  $O(d \cdot n)$  。因此，它最适用于  $n$  值很大而关键字较小的序列。若关键字也很大，而序列中大多数记录的“最高位关键字”均不同，则亦可先按“最高位关键字”不同将序列分成若干“小”的子序列，而后进行直接插入排序。

（4）从方法的稳定性来比较，基数排序是稳定的内排方法，所有时间复杂度为  $O(n^{2})$  的简单排序法也是稳定的，然而，快速排序、堆排序和希尔排序等时间性能较好的排序方法都是不稳定的。一般来说，排序过程中的“比较”是在“相邻的两个记录关键字”间进行的排序方法是稳定的。值得提出的是，稳定性是由方法本身决定的，对不稳定的排序方法而言，不管其描述形式如何，总能举出一个说明不稳定的实例来。反之，对稳定的排序方法，总能找到一种不引起不稳定的描述形式。由于大多数情况下排序是按记录的主关键字进行的，则所用的排序方法是否稳定无关紧要。若排序按记录的次关键字进行，则应根据问题所需慎重选择排序方法及其描述算法。

综上所述，在本章讨论的所有排序方法中，没有哪一种是绝对最优的。有的适用于  $n$  较大的情况，有的适用于  $n$  较小的情况，有的……因此，在实用时需根据不同情况适当选用，甚至可将多种方法结合起来使用。

本章讨论的多数排序算法是在顺序存储结构上实现的，因此在排序过程中需进行大量记录的移动。当记录很大(即每个记录所占空间较多)时，时间耗费很大，此时可采用静态链表作存储结构。如表插入排序、链式基数排序，以修改指针代替移动记录。但是，有的排序方法，如快速排序和堆排序，无法实现表排序。在这种情况下可以进行“地址排序”，即另设一个地址向量指示相应记录；同时在排序过程中不移动记录而移动地址向量中相应分量的内容。例如对图10.15(a)所示记录序列进行地址排序时，可附设向量adr(1:8)。在开始排序之前令adr[i]：=i,凡在排序过程中需进行r[i]：=r[j]的操作时，均以adr[i]：=adr[j]代替，则在排序结束之后，地址向量中的值指示排序后的记录的次序，r[adr[1]]为关键字最小的记录，r[adr[8]]为关键字最大的记录，如图10.15(b)所

示。最后在需要时可根据adr的值重排记录的物理位置。重排算法如下：

图10.15 地址排序示例  
![](images/f937dba6ae1b9f57201d24d3deb225e42b5cad8f4a79e704cf3e852c00beadd5.jpg)  
(a) 待排记录和地址向量的初始状态；(b) 排序结束后的地址向量；(c) 重排记录过程中的状态

从  $i = 1$  起依次检查每个分量位置上的记录是否正确到位。若  $\mathrm{adr}[\mathrm{i}] = \mathrm{i}$ ，则  $\mathbf{r}[\mathbf{i}]$  中恰为第  $i$  个最小关键字的记录，该位置上的记录不需要调整；若  $\mathrm{adr}[\mathrm{i}] = \mathrm{k} \neq \mathrm{i}$ ，则说明  $\mathbf{r}[\mathbf{k}]$  中记录是第  $i$  个最小关键字的记录，应在暂存记录  $\mathbf{r}[\mathbf{i}]$  之后将  $\mathbf{r}[\mathbf{k}]$  中记录移至  $\mathbf{r}[\mathbf{i}]$  的位置①上。类似地，若  $\mathrm{adr}[\mathbf{k}] \neq \mathbf{k}$ ，则应将  $\mathbf{r}[\mathbf{adr}[\mathbf{k}]]$  中记录移至  $\mathbf{r}[\mathbf{k}]$  的位置上。依次类推，直至找到某个值  $\mathrm{j} = \mathrm{adr}[\mathrm{adr}[\dots \mathrm{adr}[\mathbf{k}]\dots ]]$ ，等式  $\mathrm{adr}[\mathrm{j}] = \mathrm{i}$  成立时，将暂存记录移至  $\mathbf{r}[\mathbf{j}]$  的位置上。至此完成一个调整记录位置的小循环。例如图10.15的例子，由于图10.15(b)中  $\mathrm{adr}[1] = 6$ ，则在暂存R(49)以后，需将R(13)从  $\mathbf{r}[6]$  的位置移至  $\mathbf{r}[1]$  的位置。又，因为  $\mathrm{adr}[6] = 2$ ，则应将R(65)从  $\mathbf{r}[2]$  的位置移至  $\mathbf{r}[6]$  的位置。同理，将R(27)移至  $\mathbf{r}[2]$  的位置，此时，因  $\mathrm{adr}[4] = 1$ ，则R(49)应置入  $\mathbf{r}[4]$  的位置上。完成上述调整后的记录及地址向量的状态如图10.15(c)所示。算法10.18即为上述重排记录的算法。

```javascript
void Rearrange（SqList&L,intadr[]){ //adr给出顺序表L的有序次序，即L.r[adr[i]]是第i小的记录。 //本算法按adr重排L.x,使其有序。 for（  $\mathbf{i} = 1$  ：  $\mathrm{i} <   \mathrm{L}$  .length;  $+ + \mathrm{i}$  ） if（adr[i]！=i）{ j=i; L.r[0]=L.r[i]; //暂存记录L.r[i] while（adr[j]！=i）{//调整L.r[adr[j]]的记录到位直到adr[j]=i为止 k=adr[j]; L.r[j]=L.r[k]; adr[j]=j; j=k; } L.r[j]=L.r[0]; adr[j]=j; //记录按序到位 }}//Rearrange
```

# 算法 10.18

从上述算法容易看出，除了在每个小循环中要暂存一次记录外，所有记录均一次移动

到位。而每个小循环至少移动两个记录，则这样的小循环至多有  $\lfloor n / 2\rfloor$  个，所以重排记录的算法中至多移动记录  $\lfloor 3n / 2\rfloor$  次。

本节最后要讨论的一个问题是，“内部排序可能达到的最快速度是什么”。我们已经看到，本章讨论的各种排序方法，其最坏情况下的时间复杂度或为  $O(n^{2})$  ，或为 $O(n\log n)$  ，其中  $O(n^{2})$  是它的上界，那么  $O(n\log n)$  是否是它的下界，也就是说，能否找到一种排序方法，它在最坏情况下的时间复杂度低于  $O(n\log n)$  呢？

由于本章讨论的各种排序方法，除基数排序之外，都是基于“关键字间的比较”这个操作进行的，则均可用一棵类似于图10.16所示的判定树来描述这类排序方法的过程。

![](images/5139a5d70fe5ed41862bdd44236f2a3f50424f288dcd0cd770688136099a4ae5.jpg)  
图10.16 描述排序过程的判定树

图10.16的判定树表示3个关键字分别为  $K_{1}, K_{2}$  和  $K_{3}$  的记录进行直接插入排序的过程，树中每个非终端结点表示两个关键字间的一次比较，其左、右子树分别表示这次比较所得的两种结果。假设  $K_{1} \neq K_{2} \neq K_{3} \neq K_{1}$ ，则排序之前依次排列的这3个记录  $\{R_{1}, R_{2}, R_{3}\}$  之间只可能有下列6种关系：(1)  $K_{1} < K_{2} < K_{3}$ ；(2)  $K_{1} < K_{3} < K_{2}$ ；(3)  $K_{3} < K_{1} < K_{2}$ ；(4)  $K_{2} < K_{1} < K_{3}$ ；(5)  $K_{2} < K_{3} < K_{1}$ ；(6)  $K_{3} < K_{2} < K_{1}$ ，换句话说，这3个记录经过排序只可能得到下列6种结果：(1)  $\{R_{1}, R_{2}, R_{3}\}$ ；(2)  $\{R_{1}, R_{3}, R_{2}\}$ ；(3)  $\{R_{3}, R_{1}, R_{2}\}$ ；(4)  $\{R_{2}, R_{1}, R_{3}\}$ ；(5)  $\{R_{2}, R_{3}, R_{1}\}$ ；(6)  $\{R_{3}, R_{2}, R_{1}\}$ ，而图10.16中的判定树上6个终端结点恰好表示这6种排序结果。判定树上进行的每一次比较都是必要的，因此，这个判定树足以描述通过“比较”进行的排序过程。并且，对每一个初始序列经排序达到有序所需进行的“比较”次数，恰为从树根到和该序列相应的叶子结点的路径长度。由于图10.16的判定树的深度为4，则对3个记录进行排序至少要进行3次比较。

推广至一般情况，对  $n$  个记录进行排序至少需进行多少次关键字间的比较，这个问题等价于，给定  $n$  个不同的砝码和一台天平，按重量的大小顺序排列这些砝码所需要的最少称重量次数问题。由于含  $n$  个记录的序列可能出现的初始状态有  $n!$  个，则描述  $n$  个记录排序过程的判定树必须有  $n!$  个叶子结点。因为，若少一个叶子，则说明尚有两种状态没有分辨出来。我们已经知道，若二叉树的高度为  $h$  ，则叶子结点的个数不超过  $2^{h-1}$  ；反之，若有  $u$  个叶子结点，则二叉树的高度至少为  $\lceil \log_2 u \rceil + 1$  。这就是说，描述  $n$  个记录排序的判定树上必定存在一条长度为  $\lceil \log_2 (n!) \rceil$  的路径。由此得到下述结论：任何一个借助“比较”进行排序的算法，在最坏情况下所需进行的比较次数至少为  $\lceil \log_2 (n!) \rceil$  。然而，这只是一个理论上的下界，一般的排序算法在  $n > 4$  时所需进行的比较次数均大于此值，直到

1956年，H.B.Demuth首先找到了对5个数进行排序只需要7次比较的方法[2]之后，Lester Ford和Selmer Johnson将其推广，提出了归并插入①(Merge Insertion)排序，在 $n < 11$ 时所用的比较次数和  $\lceil \log_2(n!) \rceil$  相同。②。根据斯特林公式，有  $\lceil \log_2(n!) \rceil = O(n \log n)$ ，上述结论从数量级上告诉我们，借助于“比较”进行排序的算法在最坏情况下能达到的最好的时间复杂度为  $O(n \log n)$ 。

① 归并插入排序的过程请参见《题集》第10章中最后一题。

② 下表中  $B(n), M(n)$  和  $F(n)$  分别表示对  $n$  个数进行折半插入排序、归并排序和归并插入排序时在最坏情况下所需进行的比较次数[2]：

<table><tr><td>n</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td><td>16</td><td>17</td><td>18</td></tr><tr><td>log2n!</td><td>0</td><td>1</td><td>3</td><td>5</td><td>7</td><td>10</td><td>13</td><td>16</td><td>19</td><td>22</td><td>26</td><td>29</td><td>33</td><td>37</td><td>41</td><td>45</td><td>49</td><td>53</td></tr><tr><td>F(n)</td><td>0</td><td>1</td><td>3</td><td>5</td><td>7</td><td>10</td><td>13</td><td>16</td><td>19</td><td>22</td><td>26</td><td>30</td><td>34</td><td>38</td><td>42</td><td>46</td><td>50</td><td>54</td></tr><tr><td>B(n)</td><td>0</td><td>1</td><td>3</td><td>5</td><td>8</td><td>11</td><td>14</td><td>17</td><td>21</td><td>25</td><td>29</td><td>33</td><td>37</td><td>41</td><td>45</td><td>49</td><td>54</td><td>59</td></tr><tr><td>M(n)</td><td>0</td><td>1</td><td>3</td><td>5</td><td>9</td><td>11</td><td>14</td><td>17</td><td>25</td><td>27</td><td>30</td><td>33</td><td>38</td><td>41</td><td>45</td><td>49</td><td>65</td><td>67</td></tr></table>

# 第11章 外部排序

上一章中已提到，外部排序指的是大文件的排序，即待排序的记录存储在外存储器上，在排序过程中需进行多次的内、外存之间的交换。因此，在本章讨论外部排序之前，首先需要了解对外存信息进行存取的特点。

# 11.1 外存信息的存取

计算机一般有两种存储器：内存储器(主存)和外存储器(辅存)。内存的信息可随机存取，且存取速度快，但价格贵、容量小。外存储器包括磁带和磁盘（或磁鼓），前者为顺序存取的设备，后者为随机存取的设备。

# 1.磁带信息的存取

磁带是薄薄涂上一层磁性材料的一条窄带。现在使用的磁带大多数有1/2英寸宽，最长可达3600英尺，绕在一个卷盘上。使用时，将磁带盘放在磁带机上，驱动器控制磁带盘转动，带动磁带向前移动。通过读/写头就可以读出磁带上的信息或者把信息写入磁带中(图11.1)。

在1/2英寸宽的带面上可以记录9位或7位二进制信息（通常称为9道带或7道带）。以9道带为例，每一

![](images/b33e03d36fe4a1dcad559fe26fac110427547599f77fd74ad6a40a880c374012.jpg)  
图11.1 磁带运动示意图

横排就可表示一个字符(8位表示一个字符,另一位作奇偶校验位)。因此,磁带上可记下各种文字信息或二进制信息。在磁带上信息按字符组①存放,而不是按字符存放。

磁带上信息的密度通常为每英寸800位或1600位或6250位（即每英寸的二进制字符数），移动速度是每秒200英寸。

磁带不是连续运转的设备，而是一种启停设备（启停时间约为5毫秒），它可以根据读/写的需要随时启动和停止。由于读/写信息应在旋转稳定时进行，而磁带从静止状态启动后，要经过一个加速的过程才能达到稳定状态；反之，在读/写结束后，从运动状态到完全停止，要经过一个减速的过程。因此，在磁带上相邻两组字符组(记录)之间要留一空白区，叫做间隙IRG(Inter Record Gap)。根据启停时间的需要，这个间隙通常为  $1 / 4\sim 3 / 4$  英寸。如果每个字符组的长度是80个字符，IRG为3/4英寸，则对密度为每英寸1600个字符的磁带，其利用率仅为1/16，有15/16的带用于IRG(参见图11.2(a))。

为了有效地利用磁带, 常常用组成块的办法来减少 IRG 的个数。在每次写信息时, 不是按用户给出的字符组记入磁带, 而是将若干个字符组合并成一块后一次写入磁带。于是, 每个字符组间就没有 IRG, 而变成块间的间隙 IBG(Inter Block Gap)。图 11.2(b)

(a)  
图11.2 磁带上信息存放示意图  
![](images/92f06089b5e4dff6680eeee2cf05c9e24eb240c56ada3c79f6291cd4a9043b11.jpg)  
(a) 字符组长 80 字符的磁带；(b) 成块存放的磁带

![](images/ca84ac40da64a544d91f8f6d1bd08b53b9d42989d210927f329887100a4609f9.jpg)  
(b)

表示将20个长度为80字符的字符组存放在磁带上的一个物理块中的情况。

成块的办法可以减少 IRG 的数目, 从而可以提高磁带的利用率, 块的长度大于 IBG 的长度。

成块还可减少I/O操作。因为一次I/O操作可把整个物理块都读到内存缓冲区中，然后再从缓冲区中取出所需要的信息(一个字符组)。每当要读一个字符组时，首先要查缓冲区中是否已有，若有，则不必执行I/O操作，直接从缓冲区读取即可。

软件要有处理成块、解块和保存字符组的功能。在使用者看来，每次读/写的却只是一个字符组[11]。

是否物理块越大，数据越紧凑，效率就越高呢？实际上不是这样的。物理块不能太大，通常只有1K字节～8K字节。这是因为如果一次读写太长，则出错的概率就增大，可靠性就降低；此外，若块太大，则在内存开辟的缓冲区就大，从而耗费内存空间也多。

在磁带上读写一块信息所需的时间由两部分组成：

$$
T _ {I / O} = t _ {a} + n \cdot t _ {w}
$$

其中： $t_a$  为延迟时间，读/写头到达传输信息所在物理块起始位置所需时间； $t_w$  为传输一个字符的时间。

显然，延迟时间和信息在磁带上的位置、当前读/写头所在位置有关。例如，若读/写头在第  $i$  和第  $i + 1$  个物理块之间的间隙上，则读第  $i + 1$  个物理块上的信息仅需几毫秒；若读/写头位于磁带的始端，而要读的信息在磁带的尾端，则必须使磁带向前运动，跳过中间的许多块，直到所需信息通过读/写头时才能得到，这可能需要几分钟的时间。因此，由于磁带是顺序存取的设备，则读/写信息之前先要进行顺序查找，并且当读/写头位于磁带尾端，而要读的信息在磁带始端时，尚需使磁带倒转运动。这是顺序存取设备的主要缺点，它使检索和修改信息很不方便。因此，顺序存取设备主要用于处理变化少、只进行顺序存取的大量数据。

# 2. 磁盘信息的存取

磁盘是一种直接存取的存储设备(DASD)。它是以存取时间变化不大为特征的。它不像磁带那样只能进行顺序存取，而可以直接存取任何字符组。它的容量大、速度快，存取速度比磁带快得多。磁盘是一个扁平的圆盘(与电唱机的唱片类似)，盘面上有许多称为磁道的圆圈，信息就记载在磁道上。由于磁道的圆圈为许多同心圆，所以可以直接存取。磁盘可以是单片的，也可以由若干盘片组成盘组。每一片上有两个面。以6片盘组为例，由于最顶上和最低下盘片的外侧面不存信息，所以总共只有10个面可用来保存信息，如图11.3所示。

磁盘驱动器执行读/写信息的功能。盘片装在一个主轴上，并绕主轴高速旋转，当磁

道在读/写头下通过时，便可以进行信息的读/写。

可以把磁盘分为固定头盘和活动头盘。固定头盘的每一道上都有独立的磁头，它是固定不动的，专负责读/写某一道上的信息。

活动头盘的磁头是可移动的。盘组也是可变的。一个面上只有一个磁头，它可以从该面上的一道移动到另一道。磁头装在一个动臂上，不同面上的磁头是同时移动的，并处于同一圆柱面上。各个面上半径相同的磁道组成一个圆柱面，圆柱面的个数就是盘片面上的磁道数。通常，每个面上有  $200 \sim 400$  道。在磁盘上标明一个具体信息必须用一个三维地址：柱面号、盘面号、块号。

其中，柱面号确定读/写头的径向运动，而块号确定信息在盘片圆圈上的位置。

为了访问一块信息，首先必须找柱面，移动臂使磁头移动到所需柱面上（称为定位或寻查）；然后等待要访问的信息转到磁头之下；最后，读/写所需信息。

![](images/b73317da52a6dafbd18b418e5fe246cd9912440ed4fdd7b5798bcbe2352f558a.jpg)  
图11.3 活动头盘示意图

所以，在磁盘上读写一块信息所需的时间由3部分组成：

$$
T _ {I / O} = t _ {\text {s e e k}} + t _ {l a} + n \cdot t _ {w m}
$$

其中：  $t_{\text{seek}}$  为寻查时间（seek time），即读/写头定位的时间；

$t_{la}$  为等待时间(latency time)，即等待信息块的初始位置旋转到读写头下的时间；

$t_{wm}$  为传输时间(transmission time)。

由于磁盘的旋转速度很快，约  $2400 \sim 3600$  转/分，则等待时间最长不超过25毫秒（旋转一圈的时间），磁盘的传输速率一般在  $10^{5}$  字符/秒和  $5 \times 10^{5}$  字符/秒之间，则在磁盘上读/写信息的时间主要花在寻查时间上(其最大寻查时间约为0.1秒)。因此，在磁盘上存放信息时应将相关的信息放在同一柱面或邻近柱面上，以求在读/写信息时尽量减少磁头来回移动的次数，以避免不必要的寻查时间。

# 11.2 外部排序的方法

外部排序基本上由两个相对独立的阶段组成。首先，按可用内存大小，将外存上含  $n$  个记录的文件分成若干长度为  $l$  的子文件或段（segment），依次读入内存并利用有效的内部排序方法对它们进行排序，并将排序后得到的有序子文件重新写入外存，通常称这些有序子文件为归并段或顺串(run)；然后，对这些归并段进行逐趟归并，使归并段（有序的子文件）逐渐由小至大，直至得到整个有序文件为止。显然，第一阶段的工作是上一章已经讨论过的内容。本章主要讨论第二阶段即归并的过程。先从一个具体例子来看外排中的归并是如何进行的？

假设有一个含10000个记录的文件，首先通过10次内部排序得到10个初始归并段 $\mathrm{R}1\sim \mathrm{R}10$  ，其中每一段都含1000个记录。然后对它们作如下图所示的两两归并，直至得

到一个有序文件为止。

![](images/72704d96ce9e481c61b273af44cbcebab6577d1cd1f399ae75d26c806e25da36.jpg)

从上图可见，由10个初始归并段到一个有序文件，共进行了4趟归并，每一趟从  $m$  个归并段得到  $\lceil m / 2\rceil$  个归并段。这种归并方法称为2-路平衡归并。

将两个有序段归并成一个有序段的过程, 若在内存进行, 则很简单, 上一章中的 merge 过程便可实现此归并。但是, 在外部排序中实现两两归并时, 不仅要调用 merge 过程, 而且要进行外存的读/写, 这是由于我们不可能将两个有序段及归并结果段同时存放在内存中的缘故。在 11.1 节中已经提到, 对外存上信息的读/写是以“物理块”为单位的。假设在上例中每个物理块可以容纳 200 个记录, 则每一趟归并需进行 50 次“读”和 50 次“写”, 4 趟归并加上内部排序时所需进行的读/写使得在外排中总共需进行 500 次的读/写。

一般情况下，

外部排序所需总的时间  $=$  内部排序(产生初始归并段)所需的时间  $(m\times t_{IS})+$

$$
\text {外 存 信 息 读 写 的 时 间} (d \times t _ {R O}) +
$$

$$
\text {内 部 归 并 所 需 的 时 间} \left(s \times u t _ {m g}\right) \tag {11-1}
$$

其中： $t_{IS}$  是为得到一个初始归并段进行内部排序所需时间的均值； $t_{IO}$  是进行一次外存读/写时间的均值； $ut_{mg}$  是对  $u$  个记录进行内部归并所需时间； $m$  为经过内部排序之后得到的初始归并段的个数； $s$  为归并的趟数； $d$  为总的读/写次数。由此，上例10000个记录利用2-路归并进行外排所需总的时间为：

$$
1 0 \times t _ {I S} + 5 0 0 \times t _ {I O} + 4 \times 1 0 0 0 0 t _ {m g}
$$

其中  $t_{IO}$  取决于所用的外存设备，显然， $t_{IO}$  较  $t_{mg}$  要大得多。因此，提高外排的效率应主要着眼于减少外存信息读写的次数  $d$ 。

下面来分析  $d$  和“归并过程”的关系。若对上例中所得的10个初始归并段进行5-路平衡归并(即每一趟将5个或5个以下的有序子文件归并成一个有序子文件), 则从下图可见, 仅需进行二趟归并, 外排时总的读/写次数便减至  $2 \times 100 + 100 = 300$ , 比2-路归并减少了200次的读/写。

![](images/5499e6016cb1ed15989f7ae40cef86355f7425449f436d3013a19b76fe4f8ef4.jpg)

可见，对同一文件而言，进行外排时所需读/写外存的次数和归并的趟数  $s$  成正比。

而在一般情况下，对  $m$  个初始归并段进行  $k$ -路平衡归并时，归并的趟数

$$
s = \left\lfloor \log_ {k} m \right\rfloor \tag {11-2}
$$

可见，若增加  $k$  或减少  $m$  便能减少  $s$  。下面分别就这两个方面讨论之。

# 11.3 多路平衡归并的实现

从式(11-2)得知，增加  $k$  可以减少  $s$  ，从而减少外存读/写的次数。但是，从下面的讨论中又可发现，单纯增加  $k$  将导致增加内部归并的时间  $ut_{mg}$  。那么，如何解决这个矛盾呢？

先看2-路归并。令  $u$  个记录分布在两个归并段上，按merge过程进行归并。每得到归并后的一个记录，仅需一次比较即可，则得到含  $u$  个记录的归并段需进行  $u - 1$  次比较。

再看  $k$ -路归并。令  $\pmb{u}$  个记录分布在  $\pmb{k}$  个归并段上，显然，归并后的第一个记录应是  $\pmb{k}$  个归并段中关键字最小的记录，即应从每个归并段的第一个记录的相互比较中选出最小者，这需要进行  $k-1$  次比较。同理，每得到归并后的有序段中的一个记录，都要进行  $k-1$  次比较。显然，为得到含  $\pmb{u}$  个记录的归并段需进行  $(u-1)(k-1)$  次比较。由此，对  $\pmb{n}$  个记录的文件进行外排时，在内部归并过程中进行的总的比较次数为  $s(k-1)(n-1)$  。假设所得初始归并段为  $\pmb{m}$  个，则由式(11-2)可得内部归并过程中进行比较的总的次数为

$$
\left\lfloor \log_ {k} m \right\rfloor (k - 1) (n - 1) t _ {m g} = \left\lfloor \frac {\log_ {2} m}{\log_ {2} k} \right\rfloor (k - 1) (n - 1) t _ {m g} \tag {11-3}
$$

由于  $\frac{k - 1}{\log_2 k}$  随  $k$  的增长而增长，则内部归并时间亦随  $k$  的增长而增长。这将抵消由于增大  $k$  而减少外存信息读写时间所得效益，这是我们所不希望的。然而，若在进行  $k$  -路归并时利用“败者树”(Tree of Loser)，则可使在  $k$  个记录中选出关键字最小的记录时仅需进行  $\lfloor \log_2 k \rfloor$  次比较，从而使总的归并时间由式(11-3)变为  $\lfloor \log_2 m \rfloor (n - 1) t_{mg}$ ，显然，这个式子和  $k$  无关，它不再随  $k$  的增长而增长。

那末, 什么是“败者树”? 它是树形选择排序的一种变型。相对地, 我们可称图 10.8 和图 10.9 中的二叉树为“胜者树”, 因为每个非终端结点均表示其左、右孩子结点中的“胜者”。反之, 若在双亲结点中记下刚进行完的这场比赛中的败者, 而让胜者去参加更高一层的比赛, 便可得到一棵“败者树”。例如, 图 11.4(a) 所示为一棵实现 5-路归并的败者树  $\mathrm{ls}[0..4]$ , 图中方形结点表示叶子结点 (也可看成是外结点), 分别为 5 个归并段中当前参加归并选择的记录的关键字; 败者树中根结点  $\mathrm{ls}[1]$  的双亲结点  $\mathrm{ls}[0]$  为“冠军”, 在此指示各归并段中的最小关键字记录为第三段中的当前记录; 结点  $\mathrm{ls}[3]$  指示 b1 和 b2 两个叶子结点中的败者即 b2, 而胜者 b1 和 b3(b3 是叶子结点 b3、b4 和 b0 经过两场比赛后选出的获胜者) 进行比较, 结点  $\mathrm{ls}[1]$  则指示它们中的败者为 b1。在选得最小关键字的记录之后, 只要修改叶子结点 b3 中的值, 使其为同一归并段中的下一个记录的关键字, 然后从该结点向上和双亲结点所指的关键字进行比较, 败者留在该双亲结点, 胜者继续向上直至树根的双亲。如图 11.4(b) 所示, 当第 3 个归并段中第 2 个记录参加归并时, 选得的最小关键字记录为第一个归并段中的记录。为了防止在归并过程中某个归并段变空, 可以在每个归并段中附加一个关键字为最大值的记录。当选出的“冠军”记录的关键字为最大值

![](images/70bdc02813737ec72acc00bd68e8b045e25e63133eb2a83e5d17a0ca759af911.jpg)  
(a)  
图11.4 实现5-路归并的败者树

![](images/4c90e2cf23a9c2b999b09170e3ea806206eb0e35ef420172e6391e75a8efd131.jpg)  
(b)

时, 表明此次归并已完成。由于实现  $k$ -路归并的败者树的深度为  $\lceil \log_2 k \rceil + 1$ , 则在  $k$  个记录中选择最小关键字仅需进行  $\lceil \log_2 k \rceil$  次比较。败者树的初始化也容易实现, 只要先令所有的非终端结点指向一个含最小关键字的叶子结点, 然后从各个叶子结点出发调整非终端结点为新的败者即可。

下面的算法11.1简单描述利用败者树进行  $k$  -路归并的过程。为了突出如何利用败者树进行归并，在算法中避开了外存信息存取的细节，可以认为归并段已在内存。算法11.2描述在从败者树选得最小关键字的记录之后，如何从叶到根调整败者树选得下一个最小关键字。算法11.3为初建败者树的过程的算法描述。

```txt
typedef int LoserTree[k]; //败者树是完全二叉树且不含叶子，可采用顺序存储结构  
typedef struct{keyTypekey;  
}ExNode,External  $[k + 1]$  ：//外结点，只存放待归并记录的关键字  
voidK_Merge(LoserTree&ls,External&b){//利用败者树ls将编号从0到  $k - 1$  的  $\mathbf{k}$  个输入归并段中的记录归并到输出归并段。//b[0]至b[k-1]为败者树上的k个叶子结点，分别存放k个输入归并段中当前记录的关键字。for  $(i = 0;i <   k; + + i)$  input(b[i].key); //分别从k个输入归并段读入该段当前//第一个记录的关键字到外结点CreateLoserTree(1s); //建败者树ls，选得最小关键字为b[ls[0]].keywhile  $(\mathtt{b}[1\mathtt{s}[0]].\mathtt{key}! = \mathtt{MAXKEY})$  {q=ls[O]; //q指示当前最小关键字所在归并段output(q); //将编号为q的归并段中当前(关键字为b[q].key)的记录//写至输出归并段input(b[q].key,q); //从编号为q的输入归并段中读入下一个记录的关键字Adjust(1s,q); //调整败者树，选择新的最小关键字} //whileoutput（1s[0]); //将含最大关键字MAXKEY的记录写至输出归并段} //K_Merge
```

# 算法 11.1

```txt
void Adjust (LoserTree &ls, int s) {
// 沿从叶子结点 b[s] 到根结点 ls[0] 的路径调整败者树
t = (s + k) / 2; // ls[t] 是 b[s] 的双亲结点
while (!>0) {
if (b[s].key > b[ls[t]].key) s←→ls[t]; // s 指示新的胜者
t = t / 2;
}
ls[0] = s;
} // Adjust
```

# 算法 11.2

```javascript
void CreateLoserTree(LoserTree &ls) { //已知b[0]到b[k-1]为完全二叉树ls的叶子结点存有k个关键字，沿从叶子//到根的k条路径将ls调整成为败者树。  
 $\mathtt{b[k].key} = \mathtt{MINKEY};$  //设MINKEY为关键字可能的最小值for  $(i = 0;i <   k; + + i)\quad \mathtt{ls[i]} = \mathtt{k};$  //设置ls中“败者”的初值for  $(i = k - 1;i > = 0; - - i)$  Adjust(1s,i); //依次从b[k-1],b[k-2],...，b[0]出发调//整败者  
} //CreateLoserTree
```

# 算法 11.3

最后要提及一点,  $k$  值的选择并非越大越好, 如何选择合适的  $k$  是一个需要综合考虑的问题。

# 11.4 置换-选择排序

由11-2式得知，归并的趟数不仅和  $k$  成反比，也和  $m$  成正比，因此，减少  $m$  是减少  $s$  的另一条途径。然而，我们从11.2节的讨论中也得知， $m$  是外部文件经过内部排序之后得到的初始归并段的个数，显然， $m = \lceil n / l \rceil$ ，其中  $n$  为外部文件中的记录数， $l$  为初始归并段中的记录数。回顾上一章讨论的各种内排方法，在内排过程中移动记录和对关键字进行比较都是在内存中进行的。因此，用这些方法进行内部排序得到的各个初始归并段的长度  $l$ （除最后一段外）都相同，且完全依赖于进行内部排序时可用内存工作区的大小，则  $m$  也随其而限定。由此，若要减少  $m$ ，即增加  $l$ ，就必须探索新的排序方法。

置换-选择排序(Replacement-Selection Sorting)是在树形选择排序的基础上得来的，它的特点是：在整个排序(得到所有初始归并段)的过程中，选择最小(或最大)关键字和输入、输出交叉或平行进行。

先从具体例子谈起。已知初始文件含有24个记录，它们的关键字分别为51,49,39,46,38,29,14,61,15,30,1,48,52,3,63,27,4,13,89,24,46,58,33,76。假设内存工作区可容纳6个记录，则按上章讨论的选择排序可求得如下4个初始归并段：

```csv
RUN1:29,38,39,46,49,51  
RUN2:1,14,15,30,48,61
```

RUN3:3,4,13,27,52,63

RUN4:24,33,46,58,76,89

若按置换-选择进行排序，则可求得如下3个初始归并段：

RUN1:29,38,39,46,49,51,61

RUN2:1,3,14,15,27,30,48,52,63,89

RUN3:4,13,24,33,46,58,76

假设初始待排文件为输入文件 FI, 初始归并段文件为输出文件 FO, 内存工作区为 WA, FO 和 WA 的初始状态为空, 并设内存工作区 WA 的容量可容纳  $w$  个记录, 则置换-选择排序的操作过程为:

（1）从FI输入w个记录到工作区WA。  
（2）从WA中选出其中关键字取最小值的记录，记为MINIMAX记录。  
（3）将MINIMAX记录输出到FO中去。  
（4）若FI不空，则从FI输入下一个记录到WA中。  
（5）从WA中所有关键字比MINIMAX记录的关键字大的记录中选出最小关键字记录，作为新的MINIMAX记录。  
(6) 重复  $(3) \sim (5)$ , 直至在 WA 中选不出新的 MINIMAX 记录为止, 由此得到一个初始归并段, 输出一个归并段的结束标志到 FO 中去。  
（7）重复  $(2)\sim (6)$  ，直至WA为空。由此得到全部初始归并段。

例如，以上所举之例的置换-选择过程如图11.5所示。

<table><tr><td>FO</td><td>WA</td><td>FI</td></tr><tr><td>空</td><td>空</td><td>51,49,39,46,38,29,14,61,15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>空</td><td>51,49,39,46,38,29</td><td>14,61,15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29</td><td>51,49,39,46,38</td><td>14,61,15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29</td><td>51,49,39,46,38,14</td><td>61,15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38</td><td>51,49,39,46, ,14</td><td>61,15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38</td><td>51,49,39,46,61,14</td><td>15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39</td><td>51,49, ,46,61,14</td><td>15,30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39</td><td>51,49,15,46,61,14</td><td>30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46</td><td>51,49,15, ,61,14</td><td>30,1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46</td><td>51,49,15,30,61,14</td><td>1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46,49</td><td>51, ,15,30,61,14</td><td>1,48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46,49</td><td>51,1,15,30,61,14</td><td>48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46,49,51</td><td>,1,15,30,61,14</td><td>48,52,3,63,27,4,…</td></tr><tr><td>29,38,39,46,49,51</td><td>48,1,15,30,61,14</td><td>52,3,63,27,4,…</td></tr><tr><td>29,38,39,46,49,51,61</td><td>48,1,15,30, ,14</td><td>52,3,63,27,4,…</td></tr></table>

续表  

<table><tr><td>FO</td><td>WA</td><td>FI</td></tr><tr><td>29,38,39,46,49,51,61</td><td>48,1,15,30,52,14</td><td>3.63,27,4,…</td></tr><tr><td>29,38,39,46,49,51,61,*</td><td>48,1,15,30,52,14</td><td>3.63,27,4,…</td></tr><tr><td>29,38,39,46,49,51,61,*,1</td><td>48, ,15,30,52,14</td><td>3.63,27,4,…</td></tr><tr><td>29,38,39,46,49,51,61,*,1</td><td>48,3,15,30,52,14</td><td>63,27,4,…</td></tr><tr><td>⋮</td><td>⋮</td><td>⋮</td></tr></table>

图11.5 置换-选择排序过程示例

在 WA 中选择 MINIMAX 记录的过程需利用“败者树”来实现。关于“败者树”本身，上节已有详细讨论，在此仅就置换-选择排序中的实现细节加以说明。（1）内存工作区中的记录作为败者树的外部结点，而败者树中根结点的双亲结点指示工作区中关键字最小的记录；（2）为了便于选出 MINIMAX 记录，为每个记录附设一个所在归并段的序号，在进行关键字的比较时，先比较段号，段号小的为胜者；段号相同的则关键字小的为胜者；（3）败者树的建立可从设工作区中所有记录的段号均为“零”开始，然后从 FI 逐个输入  $w$  个记录到工作区时，自下而上调整败者树，由于这些记录的段号为“1”，则它们对于“零”段的记录而言均为败者，从而逐个填充到败者树的各结点中去。算法 11.4 是置换-选择排序的简单描述，其中，求得一个初始归并段的过程如算法 11.5 所述。算法 11.6 和算法 11.7 分别描述了置换-选择排序中的败者树的调整和初建的过程。

```txt
typedef struct{RcdType rec; //记录KeyType key; //从记录中抽取的关键字int rnum; //所属归并段的段号}RcdNode,WorkArea[w]; //内存工作区，容量为w  
void Replace_Selection(LoserTree&ls,WorkArea&wa,FILE\*fi,FILE\*fo){//在败者树ls和内存工作区wa上用置换-选择排序求初始归并段，fi为输入文件//（只读文件)指针，fo为输出文件(只写文件)指针，两个文件均已打开Construct.Loser(ls,wa); //初建败者树rc  $=$  rmax  $= 1$  ： //rc指示当前生成的初始归并段的段号，//rmax指示wa中关键字所属初始归并段的最大段号while  $(\mathrm{rc} <   = \mathrm{rmax})$  { //"rc=rmax+1"标志输入文件的置换-选择排序已完成get.run(ls,wa); //求得一个初始归并段fwrite(&RUNEND.SYMBOL,sizeof(struct RcdType),1,fo); //将段结束标志写入输出文件rc  $=$  wa[ls[0]].rnum; //设置下一段的段号}}//Replace.Selection
```

# 算法 11.4

```javascript
void get_run (LoserTree &ls, WorkArea &wa) { // 求得一个初始归并段，fi为输入文件指针，f0为输出文件指针 while(wa[ls[0]].rnum == rc) { // 选得的MINIMAX记录属当前段时 q = ls[0]; // q指示MINIMAX记录在wa中的位置 minimax = wa[q].key;
```

```javascript
fwrite(&wa[q].rec,sizeof(RcdType),1,fo); //将刚选好的MINIMAX记录写入输出文件  
if(feof(fi)){wa[q].rnum  $=$  rmax+1;wa[q].key  $\equiv$  MAXKEY} //输入文件结束，虚设记录（属"rmax+1"段）  
else{ //输入文件非空时 fread(&wa[q].rec,sizeof(RcdType)，1,fi）； //从输入文件读入下一记录 wa[q].key  $\equiv$  wa[q].rec.key; //提取关键字 if(wa[q].key  $<$  minimax){ //新读人的记录属下一段 rmax  $\equiv$  rc+1;wa[q].rnum  $\equiv$  rmax; } elsewa[q].rnum  $\equiv$  rc; //新读人的记录属当前段 }Select.Minimax(1s,wa,q); //选择新的MINIMAX记录 }//while }//get.run
```

# 算法 11.5

```c
void Select_MinMax(LoserTree &ls, WorkArea wa, int q) {
// 从wa[q]起到败者树的根比较选择MINIMAX记录，并由q指示它所在的归并段
for (t = (w + q)/2, p = ls[t]; t > 0; t = t/2, p = ls[t])
if (wa[p].rnum < wa[q].rnum || wa[p].rnum == wa[q].rnum && wa[p].key < wa[q].key)
q←→ls[t]; //q指示新的胜利者
ls[0] = q;
} //Select.Minimax
```

# 算法 11.6

```javascript
void Construct_Loser(LoserTree&ls,WorkArea&wa){//输入w个记录到内存工作区wa，建得败者树ls，选出关键字最小的记录并由s指示//其在wa中的位置for  $(\mathrm{i} = 0;\mathrm{i} <   \mathrm{w}; + + \mathrm{i})$  wa[i].rnum  $=$  wa[i].key  $= 1s[i] = 0$  //工作区初始化for  $(\mathrm{i} = \mathrm{w} - 1;\mathrm{i} > = 0; - - \mathrm{i})$  {fread（&wa[i].rec,sizeof(RcdType)，1,fi）; //输入一个记录wa[i].key  $=$  wa[i].rec.key; //提取关键字wa[i].rnum  $= 1$  //其段号为"1"Select_MinMax(1s,wa,i); //调整败者}}//Construct.Loser
```

# 算法 11.7

利用败者树对前面例子进行置换-选择排序时的局部状况如图11.6所示，其中图  $11.6(a)\sim (g)$  显示了败者树建立过程中的状态变化状况。最后得到最小关键字的记录为wa[0]，之后，输出wa[0].rec，并从FI中输入下一个记录至wa[0]，由于它的关键字小于刚刚输出的记录的关键字，则设此新输入的记录的段号为2(如图11.6(h)所示)，而由于在输出wa[1]之后新输入的关键字较wa[1].key大，则该新输入的记录的段号仍为1(如图11.6(i)所示)。图11.6(j)所示为在输出6个记录之后选得的MINIMAX记录为

![](images/4403816686d57285af03eb1f3a7b7f4977940579e80150c96f47be78e32fd404.jpg)  
(a)

![](images/298259ddc6df44e57bfc39aceb0b06f449029b541f8aaf85100496419f311516.jpg)  
(b)

![](images/c76a5d7803665ea0831c290f874162f7caf7f0511813843cad74374642c8b10d.jpg)  
(c)

![](images/509ad600a9915fc3b4b68305471fca45e03f4c7ff3ea6417636ce29a4a9072f0.jpg)  
(d)

![](images/505397d5c6f0cd86839b7deee277ef027102d420f5ebda724b2f17f3a0e33d38.jpg)  
(e)

![](images/d95afb6a9b374d580187f4b5ba7435a57331debcb3023ca5dd8eeee416ab5487.jpg)  
(f)

![](images/bea33c4cdff862331ce3be9672da3108ef4e90360f68f0eb801060912c491a12.jpg)  
（g）

![](images/95a2b464fb024eee22c3703e827da1d6fb2ccce922a951efb80b4f1eaa1c4bac.jpg)  
(h)

![](images/1aae1471070ef037fbdf8f3c0848786f2522e5e4c833cb660805373da90f449f.jpg)  
(i)

(j)  
图11.6 置换～选择过程中的败者树  
![](images/42091a1932f777c0677e29909ebc108a84e8d08b73f9bb7233001e7ed053656f.jpg)  
(a)  $\sim$  (g) 建立败者树, 选出最小关键字记录  $w a[0]$ ; (h)  $\sim$  (l) 选好新的 MINIMAX 记录

![](images/791ab4670aa37f61f1cc0a57e3aa258f3e6e55056ae5c37d8406489af89a7536.jpg)  
(k)

![](images/12985479ee4ceb3b2df548ad7d7411e17c294b55e80259fcf9b3e1e2c89bf6a9.jpg)  
(1)

wa[1]时的败者树。图11.6(k)表明在输出该记录wa[1]之后，由于输入的下一个记录的关键字较小，其段号亦为2，致使工作区中所有记录的段号均为2。由此败者树选出的新

的 MINIMAX 记录的段号大于当前生成的归并段的序号, 这说明该段已结束, 而此新的 MINIMAX 记录应是下一归并段中的第一个记录。

从上述可见，由置换-选择排序所得初始归并段的长度不等。且可证明，当输入文件中记录的关键字为随机数时，所得初始归并段的平均长度为内存工作区大小  $\pmb{w}$  的两倍。这个证明是E.F.Moore在1961年从置换-选择排序和扫雪机的类比中得出的。

假设一台扫雪机在环形路上等速行进扫雪，又下雪的速度也是均匀的（即每小时落到地面上的雪量相等），雪均匀地落在扫雪机的前、后路面上，边下雪边扫雪。显然，在某个时刻之后，整个系统达到平衡状态，路面上的积雪总量不变。且在任何时刻，整个路面上的积雪都形成一个均匀的斜面，紧靠扫雪机前端的积雪最厚，其深度为  $h$ ，而在扫雪机刚扫过的路面上的积雪深度为零。若将环形路伸展开来，路面积雪状态如图11.7所示。假设此刻路面积雪的总体积为  $w$ ，环形路一圈的长度为  $l$ ，由于扫雪机在任何时刻扫走的雪的深度均为  $h$ ，则扫雪机在环形路上走一圈扫掉的积雪体积为  $lh$  即  $2w$ 。

![](images/98895b27c0935994925bb15f8f72d1b4c6b09c2178fbc6fb2f6e6cbea1f248b3.jpg)  
图11.7 环形路上扫雪机系统平衡时的状态

将置换-选择排序与此类比，工作区中的记录好比路面的积雪，输出的 MINIMAX 记录好比扫走的雪，新输入的记录好比新下的雪，当关键字为随机数时，新记录的关键字比 MINIMAX 大或小的概率相等。若大，则属当前的归并段（好比落在扫雪机前面的积雪，在这一圈中将被扫走）；若小，则属下一归并段（好比落在扫雪机后面的积雪，在下一圈中才能扫走）。由此，得到一个初始归并段好比扫雪机走一圈。假设工作区的容量为  $w$ ，则置换-选择所得初始归并段长度的期望值便为  $2w$ 。

容易看出，若不计输入、输出的时间，则对  $n$  个记录的文件而言，生成所有初始归并段所需时间为  $O(n \log w)$ 。

# 11.5 最佳归并树

这一节要讨论的问题是，由置换-选择生成所得的初始归并段，其各段长度不等对平衡归并有何影响？

假设由置换-选择得到9个初始归并段，其长度(即记录数)依次为：9,30,12,18,3,17,2,6,24。现作3-路平衡归并，其归并树(表示归并过程的图)如图11.8所示，图中每个圆圈表示一个初始归并段，圆圈中数字表示归并段的长度。假设每个记录占一个物理块，则两趟归并所需对外存进行的读/写次数为

$$
(9 + 3 0 + 1 2 + 1 8 + 3 + 1 7 + 2 + 6 + 2 4) \times 2 \times 2 = 4 8 4
$$

若将初始归并段的长度看成是归并树中叶子结点的权，则此三叉树的带权路径长度的两

![](images/44baace94c7525a2a67f67a4c51830ab57e797fbf226823e7eda0d2a560eedc0.jpg)  
图11.8 3-路平衡归并的归并树

倍恰为484。显然，归并方案不同，所得归并树亦不同，树的带权路径长度(或外存读/写次数)亦不同。回顾在第6章中曾讨论了有  $n$  个叶子结点的带权路径长度最短的二叉树称赫夫曼树，同理，存在有  $n$  个叶子结点的带权路径长度最短的3叉、4叉、…、 $k$  叉树，亦称为赫夫曼树。因此，若对长度不等的  $m$  个初始归并段，构造一棵赫夫曼树作为归并树，便可使在进行外部归并时所需对外存进行的读/写次数达最少。例如，对上述9个初始归并段可构造一棵如图11.9所示的归并树，按此树进行归并，仅需对外存进行446次读/写，这棵归并树便称做最佳归并树。

![](images/ccf80ac1fd47c7469b6b08126ee87490092cb0646a8476301294a8b66d04bc5f.jpg)  
图11.9 3-路平衡归并的最佳归并树

![](images/bd2bd24cb81d15e2545cc5ec16506146abd4831d85b0aab786e763d32726b44b.jpg)  
图11.10 8个归并段的最佳归并树

图11.9的赫夫曼树是一棵真正的3叉树，即树中只有度为3或0的结点。假若只有8个初始归并段，例如，在前面例子中少了一个长度为30的归并段。如果在设计归并方案时，缺额的归并段留在最后，即除了最后一次作2-路归并外，其他各次归并仍都是3-路归并，容易看出此归并方案的外存读/写次数为386。显然，这不是最佳方案。正确的做法是，当初始归并段的数目不足时，需附加长度为零的“虚段”，按照赫夫曼树构成的原则，权为零的叶子应离树根最远，因此，这个只有8个初始归并段的归并树应如图11.10所示。

那么，如何判定附加虚段的数目？当3叉树中只有度为3和0的结点时，必有  $n_3 = (n_0 - 1) / 2$  ，其中，  $n_3$  是度为3的结点数，  $n_0$  是度为零的结点数。由于  $n_3$  必为整数，则  $(n_0 - 1)\mathrm{MOD}2 = 0$  。这就是说，对3-路归并而言，只有当初始归并段的个数为偶数时，才需加1个虚段。

在一般情况下，对  $k$  路归并而言，容易推算得到，若  $(m - 1) \mod (k - 1) = 0$  ，则不需要加虚段，否则需附加  $k - (m - 1) \mod (k - 1) - 1$  个虚段。换句话说，第一次归并为  $(m - 1) \mod (k - 1) + 1$  路归并。

若按最佳归并树的归并方案进行磁盘归并排序，需在内存建立一张载有归并段的长度和它在磁盘上的物理位置的索引表。

# 第12章文件

和表类似，文件是大量记录的集合。习惯上称存储在主存储器(内存储器)中的记录集合为表，称存储在二级存储器(外存储器)中的记录集合为文件。本章讨论文件在外存储器中的表示方法及其各种运算的实现方法。

# 12.1 有关文件的基本概念

·文件及其类别

文件(file)是由大量性质相同的记录组成的集合。可按其记录的类型不同而分成两类：操作系统的文件和数据库文件。

操作系统中的文件仅是一维的连续的字符序列, 无结构、无解释。它也是记录的集合, 这个记录仅是一个字符组, 用户为了存取、加工方便, 把文件中的信息划分成若干组, 每一组信息称为一个逻辑记录, 且可按顺序编号。

数据库中的文件是带有结构的记录的集合；这类记录是由一个或多个数据项组成的集合，它也是文件中可存取的数据的基本单位。数据项是最基本的不可分的数据单位，也是文件中可使用的数据的最小单位。例如，图12.1所示为一个数据库文件，每个学生的情况是一个记录，它由10个数据项组成。

<table><tr><td>姓名</td><td>准考证号</td><td>政治</td><td>语文</td><td>数学</td><td>外语</td><td>物理</td><td>化学</td><td>生物</td><td>总分</td></tr><tr><td>王鸣</td><td>1501</td><td>78</td><td>90</td><td>104</td><td>95</td><td>87</td><td>83</td><td>40</td><td>577</td></tr><tr><td>刘青</td><td>1502</td><td>64</td><td>88</td><td>90</td><td>74</td><td>90</td><td>98</td><td>41</td><td>545</td></tr><tr><td>张朋</td><td>1503</td><td>90</td><td>101</td><td>85</td><td>89</td><td>76</td><td>87</td><td>42</td><td>570</td></tr><tr><td>崔永</td><td>1504</td><td>85</td><td>73</td><td>90</td><td>91</td><td>85</td><td>77</td><td>35</td><td>536</td></tr><tr><td>郑琳</td><td>1505</td><td>75</td><td>75</td><td>81</td><td>78</td><td>67</td><td>80</td><td>37</td><td>493</td></tr><tr><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td><td>:</td></tr></table>

图12.1 高考成绩文件

文件还可按记录的另一特性分成定长记录文件和不定长记录文件。若文件中每个记录含有的信息长度相同，则称这类记录为定长记录，由这类记录组成的文件称做定长记录文件；若文件中含有信息长度不等的不定长记录，则称不定长记录文件。

数据库文件还可按记录中关键字的多少分成单关键字文件和多关键字文件。若文件中的记录只有一个惟一标识记录的主关键字，则称单关键字文件；若文件中的记录除了含

有一个主关键字外，还含有若干个次关键字，则称为多关键字文件，记录中所有非关键字的数据项称为记录的属性。

- 记录的逻辑结构和物理结构

记录的逻辑结构是指记录在用户或应用程序员面前呈现的方式，是用户对数据的表示和存取方式。

记录的物理结构是数据在物理存储器上存储的方式，是数据的物理表示和组织。

通常，记录的逻辑结构着眼在用户使用方便，而记录的物理结构则应考虑提高存储空间的利用率和减少存取记录的时间，它根据不同的需要及设备本身的特性可以有多种方式。从11.1节的讨论中已得知：一个物理记录指的是计算机用一条I/O命令进行读写的基本数据单位，对于固定的设备和操作系统，它的大小基本上是固定不变的，而逻辑记录的大小是由使用要求定的。在物理记录和逻辑记录之间可能存在下列3种关系：

（1）一个物理记录存放一个逻辑记录。  
（2）一个物理记录包含多个逻辑记录。  
（3）多个物理记录表示一个逻辑记录。

总之，用户读/写一个记录是指逻辑记录，查找对应的物理记录则是操作系统的职责，图12.2简单表示了这种关系。图中的逻辑记录和物理记录满足上述第一种关系，物理记录之间用指针相链接。

![](images/3dcaac69288c681fea6e4da6e05279170902073f7bc5ef2aa4a5c554b60d60da.jpg)  
图12.2 记录的逻辑结构与物理结构差别示例

·文件的操作（运算）

文件的操作有两类：检索和修改。

文件的检索有下列3种方式：

（1）顺序存取：存取下一个逻辑记录。  
（2）直接存取：存取第  $i$  个逻辑记录。

以上两种存取方式都是根据记录序号（即记录存入文件时的顺序编号）或记录的相对位置进行存取的。  
（3）按关键字存取：给定一个值，查询一个或一批关键字与给定值相关的记录。对数据库文件可以有如下4种查询方式：  
① 简单询问：查询关键字等于给定值的记录。例如，在图12.1的文件中，给定一个准考证号码或学生姓名，查询相关记录。

② 区域询问：查询关键字属某个区域内的记录。例如，在图12.1的文件中查询某某中学的学生成绩，则给定准考证号的某个数值范围。  
③ 函数询问：给定关键字的某个函数。例如查询总分在全体学生的平均分以上的记录或处于中值的记录。  
④ 布尔询问：以上3种询问用布尔运算组合起来的询问。例如，查询总分在600分以上且数学在100分以上，或者总分在平均分以下的外语在98分以上的全部记录。

文件的修改包括插入一个记录、删除一个记录和更新一个记录3种操作。

文件的操作可以有实时和批量两种不同方式。通常实时处理对应答时间要求严格，应在接收询问之后几秒钟内完成检索和修改，而批量处理则不然。不同的文件系统其使用有不同的要求。例如，一个民航自动服务系统，其检索和修改都应实时处理；而银行的账户系统需实时检索，但可进行批量修改，即可以将一天的存款和提款记录在一个事务文件上，在一天的营业之后再进行批量处理。

- 文件的物理结构

文件在存储介质(磁盘或磁带)上的组织方式称为文件的物理结构。文件可以有各种各样的组织方式, 其基本方式有 3 种: 顺序组织、随机组织和链组织。一个特定的文件应采用何种物理结构应综合考虑各种因素, 如: 存储介质的类型、记录的类型、大小和关键字的数目以及对文件作何种操作等。本章将介绍几种常用的文件的物理结构。

# 12.2 顺序文件

顺序文件(Sequential File)是记录按其在文件中的逻辑顺序依次进入存储介质而建立的，即顺序文件中物理记录的顺序和逻辑记录的顺序是一致的。若次序相继的两个物理记录在存储介质上的存储位置是相邻的，则又称连续文件；若物理记录之间的次序由指针相链表示，则称串联文件。

顺序文件是根据记录的序号或记录的相对位置来进行存取的文件组织方式。它的特点是：

（1）存取第  $i$  个记录，必须先搜索在它之前的  $i - 1$  个记录。  
（2）插入新的记录时只能加在文件的末尾。  
（3）若要更新文件中的某个记录，则必须将整个文件进行复制。

由于顺序文件的优点是连续存取的速度快，因此主要用于只进行顺序存取、批量修改的情况。若对应答时间要求不严时亦可进行直接存取。

磁带是一种典型的顺序存取设备，因此存储在磁带上的文件只能是顺序文件。磁带文件适合于文件的数据量甚大、平时记录变化少、只作批量修改的情况。在对磁带文件作修改时，一般需用另一条复制带将原带上不变的记录复制一遍，同时在复制的过程中插入新的记录和用更改后的新记录代替原记录写入。为了修改方便起见，要求待复制的顺序文件按关键字有序（若非数据库文件，则可将逻辑记录号作为关键字）。

磁带文件的批处理过程可如下进行：

待修改的原始文件称做主文件，存放在一条磁带上，所有的修改请求集中构成一个文

件, 称做事务文件, 存放在另一台磁带上, 尚需第三台磁带作为新的主文件的存储介质。主文件按关键字自小至大(或自大至小)顺序有序, 事务文件必须和主文件有相同的有序

关系。因此，首先对事务文件进行排序，然后将主文件和事务文件归并成一个新的主文件。图12.3为这个过程的示意图。在归并的过程中，顺序读出主文件与事务文件中的记录，比较它们的关键字并分别进行处理。对于关键字不匹配的主文件中的记录，则直接将其写入新主文件中。“更改”和“删去”记录时，要求其关键字相匹配。“删去”不用写入，而“更改”则要将更改后的新记录写入新主文件。“插入”时不要求关键字相匹配，可直接将事务文件上要插入的记录写到新主文件的适当位置。

例如有一个银行的账目文件：其主文件保存着各储户的存款余额；每个储户作为一个记录，储户账号为关键字；记录按关键字从小到大顺序排列。一天的存入和支出集中在一个事务文件中，事务文件也按账号排序，成批地更改主文件并得到一个新的主文件，其过程如图12.4所示。

![](images/d7c3a8ff0a0fa2d9ad2af6121206b266f5f7fd438f89b5b40a478f314d887ab8.jpg)  
图12.3 磁带文件批处理示意图

![](images/aba3dd23645d685ff747018bd30875200b1847a06646c11c7ddeafcfa109c891.jpg)  
图12.4 银行账目文件成批修改示意图

批处理的示意算法如算法12.1所示。算法中用到的各符号的含义说明如下：

f——主文件；g——事务文件；h——新主文件。上述三者都按关键字递增排列。事务文件的每个记录中，还增设一个代码以示修改要求，其中：“I”表示插入；“D”表示删去；

“U”表示更改。

```txt
void MergeFile (FILE *f, FILE *g, FILE *h) {
// 由按关键字递增有序的非空顺序文件 f 和 g 归并得到新文件 h, 三个文件均已打开, 其中, f 和 g 为只读文件, 文件中各附加一个最大关键字记录, 且 g 文件中对 // 该记录的操作为插入。h 为只写文件。
```

```txt
fread (&fr, sizeof(RcdType), 1, f);  
fread (&gr, sizeof(RcdType), 1, g);  
while (!feof(f) || !feof(g)) {  
switch {  
    case fr.key < gr.key; // 复制“旧”主文件中记录  
    fwrite (&fr, sizeof(RcdType), 1, h);  
    if (!feof(f)) fread (&fr, sizeof(RcdType), 1, f); break;  
    case gr.code == 'D' && fr.key == gr.key; // 删除“旧”主文件中记录，即不复制  
    if (!feof(f)) fread (&fr, sizeof(RcdType), 1, f);  
    if (!feof(g)) fread (&gr, sizeof(RcdType), 1, g); break;  
    case gr.code == 'I' && fr.key > gr.key; // 插入，函数 P 把 gr 加工为 h 的结构  
    fwrite(P(gr), sizeof(RcdType), 1, h);  
    if (!feof(g)) fread (&gr, sizeof(RcdType), 1, g); break;  
    case gr.code == 'U' && fr.key == gr.key; // 更改“旧”主文件中记录  
    fwrite(Q(gr, gr), sizeof(RcdType), 1, h);  
    // 函数 Q 将 fr 和 gr 归并成一个 h 结构的记录  
    if (!feof(f)) fread (&fr, sizeof(RcdType), 1, f);  
    if (!feof(g)) fread (&gr, sizeof(RcdType), 1, g); break;  
    default ERROR(); // 其他均为出错情况  
} // switch  
} while  
} // MergeFile
```

# 算法 12.1

分析批处理算法的时间。假设主文件包含  $n$  个记录，事务文件包含  $m$  个记录。一般情况下，事务文件较小，可以进行内部排序，则时间复杂度为  $O(m\log m)$  。内部归并的时间复杂度为  $O(n + m)$ ，则总的内部处理的时间为  $O(m\log m + n)$  。假设所有的输入/输出都是通过缓冲区进行的，并假设缓冲区大小为  $s$  （个记录），则整个批处理过程中读/写外存的次数为  $2 \cdot \left\lceil \frac{m}{s} \right\rceil + 2 \cdot \left\lceil \frac{m + n}{s} \right\rceil$  。

磁盘上的顺序文件的批处理和磁带文件类似，只是当修改项中没有插入，且更新时不增加记录的长度时，可以不建立新的主文件，而直接修改原来的主文件即可。显然，磁盘

文件的批处理可以在一台磁盘组上进行。

对顺序文件进行顺序查找类似于第9章讨论的顺序查找，其平均查找长度为  $(n' + 1) / 2$  ，其中  $n'$  为文件所含物理记录的数目（相对外存读/写而言，内存查找的时间可以忽略不计）。对磁盘文件可以进行分块查找或折半查找（对不定长文件不能进行折半查找）。但是，若文件很大，在磁盘上占多个柱面时，折半查找将引起磁头来回移动，增加寻查时间。

假若某个顺序文件, 其记录修改的频率较低, 则用批处理并不适宜, 此时可另建立一个附加文件, 以存储新插入和更新后的记录, 待附加文件增大到一定程度时再进行批处理。在检索时可以先查主文件, 若不成功再查附加文件, 或反之。显然这将增加检索的时间, 但可以采取其他措施弥补之, 详细情况可参阅参考书目[13]。

# 12.3 索引文件

除了文件本身(称做数据区)之外，另建立一张指示逻辑记录和物理记录之间一一对应关系的表——索引表。这类包括文件数据区和索引表两大部分的文件称做索引文件。

图12.5所示为两个索引表的例子。索引表中的每一项称做索引项。不论主文件是否按关键字有序，索引表中的索引项总是按关键字(或逻辑记录号)顺序排列。若数据区中的记录也按关键字顺序排列，则称索引顺序文件。反之，若数据区中记录不按关键字顺序排列，则称索引非顺序文件。

<table><tr><td>逻辑记录号</td><td>标识</td><td>物理记录号</td></tr><tr><td>0</td><td>1</td><td>4</td></tr><tr><td>1</td><td>1</td><td>7</td></tr><tr><td>2</td><td>0</td><td>.</td></tr><tr><td>3</td><td>1</td><td>10</td></tr></table>

<table><tr><td>关键字ki</td><td>物理记录号</td></tr><tr><td>101</td><td>15</td></tr><tr><td>119</td><td>04</td></tr><tr><td>123</td><td>31</td></tr><tr><td>125</td><td>11</td></tr></table>

图12.5 索引表示例

索引表是由系统程序自动生成的。在记录输入建立数据区的同时建立一个索引表，表中的索引项按记录输入的先后次序排列，待全部记录输入完毕后再对索引表进行排序。例如，对应于图12.6(a)的数据文件，其索引表如图12.6(b)所示，而图12.6(c)为文件记录输入过程中建立的索引表。

索引文件的检索方式为直接存取或按关键字(进行简单询问)存取，检索过程和第9章讨论的分块查找相类似，应分两步进行：首先，查找索引表，若索引表上存在该记录，则根据索引项的指示读取外存上该记录；否则说明外存上不存在该记录，也就不需要访问外存。由于索引项的长度比记录小得多，则通常可将索引表一次读入内存，由此在索引文件中进行检索只访问外存两次，即一次读索引，一次读记录。并且由于索引表是有序的，则查找索引表时可用折半查找法。

物理记录号

101   
103   
104   
105   
108   
109   
110   
112

(a)  
![](images/aae5819ac3281dc3e9d6626d826abc1672ad85f51f778c19e79e86baefe27686.jpg)  
(a)文件数据区；(b)索引表；(c)输入过程中建立的索引表

1   
2   
3

![](images/d99dba7fe9450c74c6e014d3a407d3fca3a78d03358b40159c8bd93e7dae51cc.jpg)  
(b)

![](images/870d29af0ee2623d5e0bd088736b7fa22de2fed3853e6d896cbf68f381bb31ca.jpg)  
(c)  
图12.6 索引非顺序文件示例

索引文件的修改也容易进行。删除一个记录时，仅需删去相应的索引项；插入一个记录时，应将记录置于数据区的末尾，同时在索引表中插入索引项；更新记录时，应将更新后的记录置于数据区的末尾，同时修改索引表中相应的索引项。

当记录数目很大时，索引表也很大，以致一个物理块容纳不下。在这种情况下查阅索引仍要多次访问外存。为此，可以对索引表建立一个索引，称为查找表。假设图12.6(b)的索引表需占用3个物理块的外存，每一个物理块容纳3个索引，则建立的查找表如图12.7所示。检索记录时，先查找查找表，再查索引表，然后读取记录。3次访问外存即可。若查找表中项目还多，则可建立更高一级的索引。通常最高可有四级索引：数据文件  $\rightarrow$  索引表  $\rightarrow$  查找表  $\rightarrow$  第二查找表  $\rightarrow$  第三查找表。而检索过程从最高一级索引即第三查找表开始，仅需5次访问外存。

上述的多级索引是一种静态索引，各级索引均为顺序表结构。其结构简单，但修改很不方便，每次修改都要重组索引。因此，当数据文件在使用过程中记录变动较多时，应采用动态索引。如二叉排序树(或二叉平衡树)、B-树以及键树，这些都是树表结构，插入、删除都很方便。又由于它本身是层次结构，则无需建立多级索引，而且建立索引表的过程即排序的过程。通常，当数据文件的记录数不很多，内存容量足以容纳整个索引表时可采用二叉排序树(或平衡树)作索引，其查找性能已在第9章中进行了详细讨论。反之，当文件很大时，索引表(树表)本身也在外存，则查找索引时尚需多次访问外存，并且，访问外存的次数恰为查找路径上的结点数。显然，为减少访问外存的次数，就应尽量缩减索引表的深

<table><tr><td>最大关键字</td><td>物理块号</td></tr><tr><td>17</td><td>1</td></tr><tr><td>38</td><td>2</td></tr><tr><td>46</td><td>3</td></tr></table>

图12.7 图12.6(b)中索引表的索引

度。因此，此时宜采用  $m$  叉的B-树作索引表。 $m$  的选择取决于索引项的多少和缓冲区的大小。又，从“9.2.3/键树”的讨论可见，键树适用于作某些特殊类型的关键字的索引表。和上述对排序树的讨论类似，当索引表不大时，可采用双链表作存储结构（此时索引表在内存）；反之，则采用Trie树。总之，由于访问外存的时间比内存查找的时间大得多，所以

对外存中索引表的查找效能主要取决于访问外存的次数，即索引表的深度。

显然，索引文件只能是磁盘文件。

综上所述，由于数据文件中记录不按关键字顺序排列，则必须对每个记录建立一个索引项，如此建立的索引表称之为稠密索引，它的特点是可以在索引表中进行“预查找”，即从索引表便可确定待查记录是否存在或作某些逻辑运算。如果数据文件中的记录按关键字顺序有序，则可对一组记录建立一个索引项，这种索引表称之为非稠密索引，它不能进行“预查找”，但索引表占用的存储空间少，管理要求低。下一节将介绍两种有用的索引顺序文件。

# 12.4 ISAM文件和VSAM文件

# 12.4.1 ISAM文件

索引顺序存取方法 ISAM 为 Indexed Sequential Access Method 的缩写, 它是一种专为磁盘存取设计的文件组织方式。由于磁盘是以盘组、柱面和磁道三级地址存取的设备, 则可对磁盘上的数据文件建立盘组、柱面和磁道①三级索引。文件的记录在同一盘组上存放时, 应先集中放在一个柱面上, 然后再顺序存放在相邻的柱面上, 对同一柱面, 则应按盘面的次序顺序存放。例如图 12.8 为存放在一个磁盘组上的 ISAM 文件, 每个柱面建立一个磁道索引, 每个磁道索引项由两部分组成: 基本索引项和溢出索引项, 如图 12.9 所示, 每一部分都包括关键字和指针两项, 前者表示该磁道中最末一个记录的关键字 (在此为最大关键字), 后者指示该磁道中第一个记录的位置, 柱面索引的每一个索引项也由关键字和指针两部分组成, 前者表示该柱面中最末一个记录的关键字 (最大关键字), 后者指示该柱面上的磁道索引位置。柱面索引存放在某个柱面上, 若柱面索引较大, 占多个磁道时, 则可建立柱面索引的索引一主索引。

在 ISAM 文件上检索记录时, 先从主索引出发找到相应的柱面索引, 再从柱面索引找到记录所在柱面的磁道索引, 最后从磁道索引找到记录所在磁道的第一个记录的位置, 由此出发在该磁道上进行顺序查找直至找到为止; 反之, 若找遍该磁道而不存在此记录, 则表明该文件中无此记录。例如, 查找关键字为 21 的记录时的查找路径如图 12.8 中的粗实线所示。

从图12.8中读者可看到，每个柱面上还开辟有一个溢出区；并且，磁道索引项中有溢出索引项，这是为插入记录所设置的。由于ISAM文件中记录是按关键字顺序存放的，则在插入记录时需移动记录，并将同一磁道上最末一个记录移至溢出区，同时修改磁道索引项。通常溢出区可有3种设置方法：(1)集中存放——整个文件设一个大的单一的溢出区；(2)分散存放——每个柱面设一个溢出区；(3)集中与分散相结合——溢出时记录先移至每个柱面各自的溢出区，待满之后再使用公共溢出区。图12.8是第二种设置法。

每个柱面的基本区是顺序存储结构，而溢出区是链表结构。同一磁道溢出的记录由

![](images/0c6f87fc176c8a03305f5dbba50585daaeb554aedfed6a7b424155eebc709e0a.jpg)  
图12.8 ISAM文件结构示例

![](images/6c005120d879d707722ead4ba7961c67fd651e5924086131de8b6e728f4ea9f4.jpg)  
图12.9 磁道索引项结构

指针相链, 该磁道索引的溢出索引项中的关键字指示该磁道溢出的记录的最大关键字; 而指针则指示在溢出区中的第一个记录。图12.10所示为插入记录和溢出处理的具体例子。其中(a)为插入前的某一柱面上的状态; (b)为插入  $\mathbf{R}_{65}$  时, 将第二道中关键字大于65的记录顺次后移, 且使  $\mathbf{R}_{90}$  溢出至溢出区的情况; (c)为插入  $\mathbf{R}_{65}$  之后的状态, 此时2道的基本索引项的关键字改为80, 且溢出索引项的关键字改为90, 其指针指向第4道第一个记录即  $\mathbf{R}_{90}$ ; (d)是相继插入  $\mathbf{R}_{95}$  和  $\mathbf{R}_{83}$  后的状态,  $\mathbf{R}_{95}$  插人在第3道的第一个记录的位置而使  $\mathbf{R}_{145}$  溢出。而由于  $80 < 83 < 90$ , 则  $\mathbf{R}_{83}$  被直接插入到溢出区, 作为第2道在溢出区的第一个记录, 并将它的指针指向  $\mathbf{R}_{90}$  的位置, 同时修改第2道索引的溢出索引项的指针指向  $\mathbf{R}_{83}$  。

![](images/703ba284edaafb76e2e94b0d9417b0575d4ee40a721b2f436ec1b42ae114278f.jpg)

基本索引项 溢出索引项 基本索引项 溢出索引项

<table><tr><td>R50</td><td>R60</td><td>R70</td><td>R80</td><td>R90</td></tr><tr><td>R100</td><td>R120</td><td>R130</td><td>R136</td><td>R145</td></tr></table>

(a)  
(b)  
(c)  
(d)  
图12.10 ISAM文件的插入和溢出处理  
![](images/18ff4d3cb86a888b0d2871e656b23238664bc7c73c475f0ba985c3dc56ea1ff6.jpg)  
(a) 插入前；(b) 插入  $R_{65}$  时记录移动的情形；(c) 插入  $R_{65}$  后；(d) 先插入  $R_{95}$  再插入  $R_{83}$  后

<table><tr><td>R50</td><td>R60</td><td>R65</td><td>R70</td><td>R80</td></tr><tr><td>R100</td><td>R120</td><td>R130</td><td>R136</td><td>R145</td></tr><tr><td colspan="5">R90 /</td></tr></table>

<table><tr><td>80</td><td>T2&#x27;1</td><td>90</td><td>T4&#x27;3</td><td>136</td><td>T3&#x27;1</td><td>145</td><td>T4&#x27;2</td></tr></table>

<table><tr><td colspan="2">R50</td><td colspan="2">R60</td><td colspan="2">R65</td><td>R70</td><td>R80</td></tr><tr><td colspan="2">R95</td><td colspan="2">R100</td><td colspan="2">R120</td><td>R130</td><td>R136</td></tr><tr><td>R90</td><td>/</td><td>R145</td><td>/</td><td>R83</td><td>T4&#x27;1</td><td colspan="2"></td></tr></table>

ISAM 文件中删除记录的操作要比插入简单得多, 只需找到待删除的记录, 在其存储位置上作删除标记即可, 而不需要移动记录或改变指针, 但在经过多次的增删后, 文件的结构可能变得很不合理。此时, 大量的记录进入溢出区, 而基本区中又浪费很多空间。因此, 通常需要周期地整理 ISAM 文件。把记录读入内存, 重新排列, 复制成一个新的 ISAM 文件, 填满基本区而空出溢出区。

最后，我们简单讨论一下 ISAM 文件中柱面索引的位置。

通常，磁道索引放在每个柱面的第一道上，那么，柱面索引是否也放在文件的第一个

柱面上呢？由于每一次检索都需先查找柱面索引，则磁头需在各柱面间来回移动，我们希望磁头移动距离的平均值最小。假设文件占有  $n$  个柱面，柱面索引在第  $x$  柱面上。则磁头移动距离的平均值为：

$$
\begin{array}{l} \bar {s} = \frac {1}{n} \left[ \sum_ {i = 1} ^ {x} (x - i) + \sum_ {i = x + 1} ^ {n} (i - x) \right] \\ = \frac {1}{n} \left[ x ^ {2} - (n + 1) x + \frac {n (n + 1)}{2} \right] \\ \end{array}
$$

令  $\frac{\mathrm{d}s}{\mathrm{d}x} = 0$  ，得到  $x = \frac{n + 1}{2}$  。这就是说，柱面索引应放在数据文件的中间位置的柱面上。

# 12.4.2 VSAM文件

虚拟存储存取方法VSAM是Virtual Storage Access Method的缩写。这种存取方法利用了操作系统的虚拟存储器的功能，给用户提供方便。对用户来说，文件只有控制区间和控制区域等逻辑存储单位，与外存储器中柱面、磁道等具体存储单位没有必然的联系。用户在存取文件中的记录时，不需要考虑这个记录的当前位置是否在内存，也不需要考虑何时执行对外存进行“读/写”的指令。

VSAM 文件的结构如图 12.11 所示。它由 3 部分组成: 索引集、顺序集和数据集。

![](images/8ece639b152209a988523626a5dfb1a87f63011fab1d0e71488d552645499002.jpg)  
图12.11 VSAM文件的结构示意图

文件的记录均存放在数据集中, 数据集中的一个结点称为控制区间 (Control Interval), 它是一个 I/O 操作的基本单位, 它由一组连续的存储单元组成。控制区间的大小可随文件不同而不同, 但同一文件上控制区间的大小相同。每个控制区间含有一个或多个按关键字递增有序排列的记录。顺序集和索引集一起构成一棵  $\mathbf{B}^{+}$  树, 为文件的索引部分。顺序集中存放每个控制区间的索引项。每个控制区间的索引项由两部分信息组成, 即该控制区间中的最大关键字和指向控制区间的指针。若干相邻控制区间的索引项形成顺序集中的一个结点, 结点之间用指针相链结, 而每个结点又在其上一层的结点中建有索引, 且逐层向上建立索引。所有的索引项都由最大关键字和指针两部分信息组成, 这些高层的索引项形成  $\mathbf{B}^{+}$  树的非终端结点。因此, VSAM 文件既可在顺序集中进行顺序存取, 又可从最高层的索引  $(\mathbf{B}^{+}$  树的根结点) 出发进行按关键字存取。顺序集中一个结点连同其对应的所有控制区间形成一个整体, 称做控制区域 (Control Range)。每个控制区间可视为一个逻辑磁道, 而每个控制区域可视为一个逻辑柱面。

在VSAM文件中，记录可以是不定长的，则在控制区间中除了存放记录本身以外，还

有每个记录的控制信息(如记录的长度等)和整个区间的控制信息(如区间中存有的记录数等), 控制区间的结构如图 12.12 所示。在控制区间上存取一个记录时需从控制区间的两端出发同时向中间扫描。

<table><tr><td>记录1</td><td>...</td><td>记录n</td><td>未利用的空闲空间</td><td>记录n的控制信息</td><td>...</td><td>记录1的控制信息</td><td>控制区间的控制信息</td></tr></table>

图12.12 控制区间的结构示意图

VSAM 文件中没有溢出区, 解决插入的办法是在初建文件时留有空间。一是每个控制区间内不填满记录, 在最末一个记录和控制信息之间留有空隙; 二是在每个控制区域中有一些完全空的控制区间, 并在顺序集的索引中指明这些空区间。当插入新记录时, 大多数的新记录能插入到相应的控制区间内, 但要注意为了保持区间内记录的关键字自小至大有序, 则需将区间内关键字大于插入记录关键字的记录向控制信息的方向移动。若在若干记录插入之后控制区间已满, 则在下一个记录插入时要进行控制区间的分裂, 即将近乎一半的记录移到同一控制区域中全空的控制区间中, 并修改顺序集中相应索引。倘若控制区域中已经没有全空的控制区间, 则要进行控制区域的分裂, 此时顺序集中的结点亦要分裂, 由此尚需修改索引集中的结点信息。但由于控制区域较大, 很少发生分裂的情况。

在VSAM文件中删除记录时，需将同一控制区间中较删除记录关键字大的记录向前移动，把空间留给以后插入的新记录。若整个控制区间变空，则需修改顺序集中相应的索引项。

由此可见，VSAM文件占有较多的存储空间，一般只能保持约  $75\%$  的存储空间利用率。但它的优点是：动态地分配和释放存储空间，不需要对文件进行重组，并能较快地对插入的记录进行查找，查找一个后插入记录的时间与查找一个原有记录的时间是相同的。

为了作性能上的优化, VSAM 用了一些其他的技术, 如指针和关键字的压缩、索引的存放处理等。其详情读者可参阅参考书目[13]。

# 12.5 直接存取文件(散列文件)

直接存取文件指的是利用杂凑(Hash)法进行组织的文件。它类似于哈希表，即根据文件中关键字的特点设计一种哈希函数和处理冲突的方法将记录散列到存储设备上，故又称散列文件。

与哈希表不同的是，对于文件来说，磁盘上的文件记录通常是成组存放的。若干个记录组成一个存储单位，在散列文件中，这个存储单位叫做桶（Bucket）。假若一个桶能存放  $m$  个记录，这就是说， $m$  个同义词的记录可以存放在同一地址的桶中，而当第  $m + 1$  个同义词出现时才发生“溢出”。处理溢出也可采用哈希表中处理冲突的各种方法，但对散列文件，主要采用链地址法。

当发生“溢出”时，需要将第  $m + 1$  个同义词存放到另一个桶中，通常称此桶为“溢出桶”；相对地，称前  $m$  个同义词存放的桶为“基桶”。溢出桶和基桶大小相同，相互之间用指针相链接。当在基桶中没有找到待查记录时，就顺指针所指到溢出桶中进行查找。因此，希望同一散列地址的溢出桶和基桶在磁盘上的物理位置不要相距太远，最好在同一柱面上。例如，某一文件有18个记录，其关键字分别为278,109,063,930,589,184,505,269,008,083,164,215,330,810,620,110,384,355。桶的容量  $m = 3$  桶数  $b = 7$  。用除留余数法作哈希函数  $\mathrm{H}(\mathrm{key}) = \mathrm{key}$  MOD7。由此得到的直接存取文件如图12.13所示。

在直接文件中进行查找时，首先根据给定值求得哈希地址（即基桶号），将基桶的记录读入内存进行顺序查找，若找到关键字等于给定值的记录，则检索成功；否则，若基桶内没有填满记录或其指针域为空，则文件内不含有待查记录；否则根据指针域的值的指示将溢出桶的记录读入内存继续进行顺序查找，直至检索成功或不成功。因此，总的查找时间为：

$$
T = a (t e + t i)
$$

其中：  $a$  为存取桶数的期望值（相当于哈希表中的平均查找长度），对链地址处理溢出来说，  $a = 1 + \frac{\alpha}{2};te$  为存取一个桶所需的时间；  $ti$  为在内存中顺序查找一个记录所需时间。

$\alpha$  为装载因子，在散列文件中

$$
a = \frac {n}{b m}
$$

其中：  $n$  为文件的记录数，  $b$  为桶数，  $m$  为桶的容量。显然，增加  $m$  可减少  $\alpha$  ，也就使  $a$  减小，此时虽则使  $ti$  增大，但由于  $te > > ti$  ，则总的时间  $T$  仍可减少。图12.14展示了  $\alpha$  和  $\alpha$  的关系。

在直接存取文件中删除记录时，和哈希表一样，仅需对被删记录作一标记即可。

![](images/5412d8dd4329a58f7ad2f294acf4c0195e62be1a29ccfc28cf546f5f18c9e32d.jpg)  
图12.13 直接存取文件示例

![](images/57a12fad57efbc0c55f48592c0a12d164491687fc6d06b1b476cb336e290525e.jpg)  
图12.14 桶的容量和查找次数的关系

总之，直接存取文件的优点是：文件随机存放，记录不需进行排序；插入、删除方便，存取速度快，不需要索引区，节省存储空间。其缺点是：不能进行顺序存取，只能按关键字随机存取，且询问方式限于简单询问，并且在经过多次的插入、删除之后，也可能造成文件结构不合理，即溢出桶满而基桶内多数为被删除的记录。此时亦需重组文件。

# 12.6 多关键字文件

多关键字文件的特点是，在对文件进行检索操作时，不仅对主关键字进行简单询问，还经常需要对次关键字进行其他类型的询问检索。

例如，图12.1的高考成绩文件中，准考证号码为主关键字，“总分”和各单科成绩为次关键字。允许对此文件作如下询问：总分在600分以上的记录；数学的平均分数，等等。如果文件组织中只有主关键字索引，则为回答这些对次关键字的询问，只能顺序存取文件中的每一个记录进行比较，从而效率很低。为此，对多关键字文件，除了按以上几节讨论的方法组织文件之外，尚需建立一系列的次关键字索引。次关键字索引可以是稠密的，也可以是非稠密的；索引表可以是顺序表，也可以是树表。和主关键字索引表不同，每个索引项应包含次关键字、具有同一次关键字的多个记录的主关键字或物理记录号。下面讨论两种多关键字文件的组织方法。

# 12.6.1 多重表文件

多重表文件(Multilist File)的特点是: 记录按主关键字的顺序构成一个串联文件, 并建立主关键字的索引(称为主索引); 对每一个次关键字项建立次关键字索引(称为次索引), 所有具有同一次关键字的记录构成一个链表。主索引为非稠密索引, 次索引为稠密索引。每个索引项包括次关键字、头指针和链表长度。

例如, 图 12.15 所示为一个多重链表文件。其中, 学号为主关键字, 记录按学号顺序链接, 为了查找方便, 分成 3 个子链表, 其索引如图 12.15(b) 所示, 索引项中的主关键字为各子表中的最大值。专业、已修学分和选修课目为 3 个次关键字项, 它们的索引如图 12.15(c)~(e) 所示, 具有相同次关键字的记录链接在同一链表中。有了这些次关键字索引, 便容易处理各种次关键字的询问。例如, 若要查询已修学分在 400 分以上的学生, 只要在索引表上查找  $400 \sim 449$  这一项, 然后从它的链表头指针出发, 列出该链表中所有记录即可。又如, 若要查询是否有同时选修甲和乙课程的学生, 则或从索引表上“甲”的头指针出发, 或从“乙”的头指针出发, 读出每个记录, 察看是否同时选修这两门课程。此时可先比较两个链表的长度, 显然应读出长度较短的链表中的记录。

多重链表文件易于构造，也易于修改。如果不要求保持链表的某种次序，则插入一个新记录是容易的，此时可将记录插在链表的头指针之后。但是，要删去一个记录却很繁琐，需在每个次关键字的链表中删去该记录。

# 12.6.2 倒排文件

倒排文件和多重表文件的区别在于次关键字索引的结构不同。通常，称倒排文件中的次关键字索引为倒排表，具有相同次关键字的记录之间不设指针相链，而在倒排表中该次关键字的一项中存放这些记录的物理记录号。例如，上例文件的倒排表如图12.16所示。

倒排表作索引的好处在于检索记录较快。特别是对某些询问，不用读取记录，就可得

物理  

<table><tr><td>记录号</td><td>姓名</td><td colspan="2">学号</td><td colspan="2">专业</td><td colspan="2">已修学分</td><td colspan="6">选修课</td></tr><tr><td>01</td><td>王雯</td><td>1350</td><td>02</td><td>软件</td><td>02</td><td>412</td><td>03</td><td>丙</td><td>02</td><td>丁</td><td>03</td><td></td><td></td></tr><tr><td>02</td><td>马小燕</td><td>1351</td><td>03</td><td>软件</td><td>07</td><td>398</td><td>07</td><td>甲</td><td>04</td><td>丙</td><td>03</td><td></td><td></td></tr><tr><td>03</td><td>阮森</td><td>1352</td><td>04</td><td>计算机</td><td>05</td><td>436</td><td>A</td><td>乙</td><td>05</td><td>丙</td><td>04</td><td>丁</td><td>05</td></tr><tr><td>04</td><td>苏明明</td><td>1353</td><td>A</td><td>应用</td><td>06</td><td>402</td><td>08</td><td>甲</td><td>06</td><td>丙</td><td>08</td><td></td><td></td></tr><tr><td>05</td><td>田永</td><td>1354</td><td>06</td><td>计算机</td><td>A</td><td>384</td><td>02</td><td>乙</td><td>07</td><td>丁</td><td>09</td><td></td><td></td></tr><tr><td>06</td><td>杨青</td><td>1355</td><td>07</td><td>应用</td><td>09</td><td>356</td><td>10</td><td>甲</td><td>07</td><td></td><td></td><td></td><td></td></tr><tr><td>07</td><td>薛平平</td><td>1356</td><td>08</td><td>软件</td><td>08</td><td>398</td><td>A</td><td>甲</td><td>08</td><td>乙</td><td>A</td><td></td><td></td></tr><tr><td>08</td><td>崔子健</td><td>1357</td><td>A</td><td>软件</td><td>A</td><td>408</td><td>01</td><td>甲</td><td>09</td><td>丙</td><td>A</td><td></td><td></td></tr><tr><td>09</td><td>王洪</td><td>1358</td><td>10</td><td>应用</td><td>10</td><td>370</td><td>05</td><td>甲</td><td>10</td><td>丁</td><td>A</td><td></td><td></td></tr><tr><td>10</td><td>刘倩</td><td>1359</td><td>A</td><td>应用</td><td>A</td><td>364</td><td>09</td><td>甲</td><td>A</td><td></td><td></td><td></td><td></td></tr></table>

(a)  

<table><tr><td>主关键字</td><td>头指针</td></tr><tr><td>1353</td><td>01</td></tr><tr><td>1357</td><td>05</td></tr><tr><td>1359</td><td>09</td></tr></table>

(b)  

<table><tr><td>次关键字</td><td>头指针</td><td>长度</td></tr><tr><td>软件</td><td>01</td><td>4</td></tr><tr><td>计算机</td><td>03</td><td>2</td></tr><tr><td>应用</td><td>04</td><td>4</td></tr></table>

(c)  

<table><tr><td>次关键字</td><td>头指针</td><td>长度</td></tr><tr><td>350~399</td><td>06</td><td>6</td></tr><tr><td>400~449</td><td>04</td><td>4</td></tr></table>

(d)  

<table><tr><td>次关键字</td><td>头指针</td><td>长度</td></tr><tr><td>甲</td><td>02</td><td>7</td></tr><tr><td>乙</td><td>03</td><td>3</td></tr><tr><td>丙</td><td>01</td><td>5</td></tr><tr><td>丁</td><td>01</td><td>4</td></tr></table>

(e)

图12.15 多重表文件示例

(a)数据文件；(b)主关键字索引；(c)“专业”索引；(d)“已修学分”索引；(e)“选修课目”索引

到解答，如询问“软件”专业的学生中有否选课程“乙”的，则只要将“软件”索引中的记录号和“乙”索引中的记录号作求“交”的集合运算即可。

在插入和删除记录时，倒排表也要作相应的修改，值得注意的是倒排表中具有同一次关键字的记录号是有序排列的，则修改时要作相应移动。

若数据文件非串链文件，而是索引顺序文件（如 ISAM 文件），则倒排表中应存放记录的主关键字而不是物理记录号。

倒排文件的缺点是维护困难。在同一索引表中，不同的关键字其记录数不同，各倒排表的长度不等，同一倒排表中各项长度也不等。

<table><tr><td>软件</td><td>01, 02, 07, 08</td></tr><tr><td>计算机</td><td>03, 05</td></tr><tr><td>应用</td><td>04, 06, 09, 10</td></tr></table>

(a)专业倒排表  

<table><tr><td>350～399</td><td>02, 05, 06, 07, 09, 10</td></tr><tr><td>400～449</td><td>01, 03, 04, 08</td></tr></table>

(b)已修学分倒排表  

<table><tr><td>甲</td><td>02,04,06,07,08,09,10</td></tr><tr><td>乙</td><td>03,05,07,</td></tr><tr><td>丙</td><td>01,02,03,04,08</td></tr><tr><td>丁</td><td>01,03,05,09</td></tr></table>

(c) 选修课目倒排表

图12.16 倒排文件索引示例

# 附录A 名词索引

# 二 画

二叉树（binary tree）

二叉排序树 (binary sort tree)

二叉查找树（binary search tree）

二次探测（quadratic probing）

十字链表 (orthogonal list)

B-树

$\mathbf{B}^{+}$  树

Trie 树

# 页

121

227

227

257

103,164

238

246

249

# 三画

三元组表(list of 3-tuples)

广义表(Lists）(generalizedlists)

广度优先搜索（breadth-first search）

子孙（descendant）

子树（subtree）

子图（subgraph）

子串（substring）

AOV-网（ActivityOnVertexnetwork）

AOE-网（ActivityOnEdge network）

# 页

97

107

169

120

118

158

70

181

183

# 四画

元素 (element)

队列（queue）

队头(front)

队尾（rear）

双向链表 (doubly linked list)

双端队列（deque）（double—ended queue）

双亲（parents）

双链树（doubly linked tree）

中序遍历 (inorder traversal)

（表达式的）中缀表示（infix notation）

无序树（unordered tree）

无向图（undirected graph）（undigraph）

无用单元收集（garbage collection）

分配策略（allocation strategy）

# 页

6

58

59

59

35

60

120

248

139

129

120

157

206

196

分块查找（blocking search) 225

内部排序 (internal sorting) 263

文本编辑 (text editing) 84

文件 (files) 306

定长（文件）(have fixed size records) 306

不定长（文件）(have variable size records) 306

单关键字（文件）(haveonlyonekey) 306

多关键字（文件）（with more then one key) 306

开放定址(open addressing) 257

# 五 画 页

头指针（head pointer) 27

头结点(head node) 28

边 (edge) 157

边界标识法（boundary tag method) 198

生成树（spanning tree) 159,170

最小（生成树）（minimum) 173

生成森林（spanning forest) 160

可利用空间表 (available space list) 194

平均查找长度ASL(Average Search Length) 217

平衡二叉树（balanced binary tree) 233

平衡因子（balance factor) 233

平衡旋转（balance rotation) 234

平方取中 (mid-square method) 254

平衡归并（balanced merge) 296

归并排序 (merge sort) 283

归并插入排序 (merge insertion sort) 292

归并段 (merging segments) 295

外部排序 (external sorting) 263, 293

# 六 画 页

存储密度（storage density) 78

存储紧缩（storage compaction） 212

存储结构（storge structure) 6

顺序（存储结构）（sequential) 6

链式（存储结构）（linked) 6

先进先出FIFO(FirstInFirstOut) 58

先序遍历(preorder traversal) 128,139

（树的）先根（遍历）（preorder) 138

后进先出LIFO(Last In First Out) 44

后序遍历（postorder traversal) 128

（树的）后根（遍历）（postorder) 138

(表达式的)后缀表示(postfix notation) 129

回溯(backtracking) 149

有向图（digraph）（directed graph) 157

有向无环图 (directed acycline graph) 179

有序树 (ordered tree) 120

有序段 (sorted segment) 296

伙伴系统（buddy system) 203

网 (network) 158

关节点 (articulation point) 176

关键路径 (critical paths) 183

关键字 (Key) 214

主关键字（primarykey) 214

次关键字 (second key) 214

动态查找表 (Dynamic Search Table) 214,226

同义词 (synonym) 252

冲突 (collision) 252,256

再哈希 (rehash) 258

伪随机探测 (random probing) 257

地址排序 (sorting by address) 264,289

延迟时间（delay time) 294

寻查时间 (seek time) 295

传输时间（transmission time) 295

多路归并 (multi-way merge) 297

多重表文件 (multilist file) 319

# 七画

时间复杂度（time complexity） 15

渐近时间复杂度(asymptotic time complexity) 15

位（bit) 6

串（string） 70

空串 (null string) 70

空格串（blank string） 71

层、层次（level） 120

完全二叉树 (complete binary tree) 124

完全图 (complete graph) 158

邻接(点）（adjacent) 158

邻接矩阵（adjacency matrix） 161

邻接表（adjacency lists) 163

逆（邻接表）(inverse) 164

邻接多重表 (adjacency multilists) 166

连通图 (connected graph) 159

强（连通图）（strongly) 159

重连通（图）（biconnected) 176

连通分量 (connected component) 159

折半查找 (binary search) 218

折叠法 (folding method) 254

移位叠加 (shift folding) 255

间界叠加 (folding at the boundaries) 255

判定树 (decision tree) 145,220

希尔排序 (Shell's method) 271

快速排序（qksort）（quicksort) 273

间隙(gap) 293

字符组间的间隙 IRG (Inter Record Gap) 293

块间的间隙 IBG (Inter Block Gap) 293

# 八 页

空间复杂度 (space complexity) 17

抽象数据类型（Abstract Data Type)

原子类型(atomic data type) 8

固定聚合类型(fixed-aggregate data type) 8

可变聚合类型(variable-aggregate data type) 8

多形数据类型（polymorphic data type) 9

线性表 (linear lists) 18

线性链表 (linear linked lists) 27

线性探测 (linear probing) 257

线索二叉树 (threaded binary trees) 132

线索链表 (threaded linked lists) 132

单链表 (singly linked lists) 27

图（graph） 156

度 (degree) 120,158

in- degree) 158

出度 (out-degree) 158

頂点 (vertex) 156

弧（arc） 152

直接前驱(immediatepredecessor) 19

直接后继(immediate successor) 19

直接定址 (immediately allocate) 253

拓扑排序 (topological sort) 180

拓扑有序 (topological order) 186

表排序(list sort) 264,265

败者树 tree of loser) 297

307,308

查找表 (table) 214

# 九画

页

结点 (node) 6,120

孩子（children） 120

祖先 (ancester) 120

指针（pointer) 27

指示器 (cursor) 32

栈 (stack) 44

栈顶(top) 44

栈底(bottom) 44

树（tree) 118

树的计数（enumeration of tree) 152

树的遍历（traversal of tree) 138

哈希表（Hash table) 251

哈希函数（Hash function) 251

带权路径长度 (weighted path length) 144

(表达式的)前缀表示 (prefix notation) 129

前缀编码（prefix code) 146

首次拟合 (first-fit) 196

查找（searching) 214

顺序查找（sequential search) 216

顺串（runs） 295

顺序文件 (sequential file) 308

除留余数法（division method） 255

选择排序 (selection sort) 277

简单（选择排序）（simple) 277

树形（选择排序）（tree) 278

段（segments) 295

# 十画

离散事件模拟（discrete event simulation) 65

特殊矩阵（special matrices） 95

递归函数 (recursive function) 54

根(root) 118

起泡排序 (bubble sort) 272

索引顺序查找 (indexed sequential search) 225

索引顺序文件 (indexed sequential file) 311

ISAM (文件) (Indexed Sequential Access Method) 313

VSAM (文件) (Virtual Storage Access Method) 316

索引文件 (indexed file) 311

倒排文件 (inverted file) 319

# 十一画

页

深度（depth) 113,120

深度优先搜索DFS（Depth-First Search） 167

随机数法 (random number method) 256

排序 (sorting) 263

堆（heap) 75,279

堆排序 (heapsort) 279

基数排序 (radix sort) 284,286

控制区间 (control interval) 316

控制区域 (control range) 316

桶 (bucket) 317

虚段（dummy run) 305

# 十二画

页

链表 (linked list) 27

链地址法 (chaining) 258

链式基数排序 (linked radix sort) 286

循环链表 (circular linked list) 35

循环队列（circular queue） 63

等价关系 (equivalence relations) 139

等价类 (equivalence classes) 139

等待时间 (latency time) 295

森林 (forest) 121

最优树 (optimal tree) 144

最小生成树 (minimal spanning tree) 173

最短路径（shortest path) 186

最佳拟合 (best-fit) 197

最差拟合 (worst-fit) 197

最高位优先 MSD (Most Significant Digit first) 285

最低位优先LSD（LeastSignificantDigitfirst) 285

最佳归并树 (optimal merge tree) 304

斐波那契序列（Fibonacci numbers) 221

斐波那契查找 (Fibonacci search) 221

稀疏矩阵 (sparse matrix) 96

稀疏图（sparse graph） 158

装填因子 (load factor) 260

插入排序 (insertion sort) 265

直接（插入）(straight) 265

折半（插入）(binary) 266

2-路（插入）(2-way) 267

表（插入）（table) 267

散列文件（hashed file) 317

# 十三

数据（data）

数据元素（data element）

数据项（data item）

数据对象（data object）

数据关系（data relation）

数据结构（data structure）

逻辑结构（logical structure）

物理结构（physical structure）

数据类型（data type）

数组（arrays）

数字分析法（digital analysis method）

数字查找树（digital search tree）

频度（frequency count）

路径（path）

稠密图 (dense graph)

锦标赛排序（tournament sort）

置换-选择排序（replacement selection sort）

满二叉树（full binary tree）

# 十四画

算法（algorithm）

静态链表 (implementing linked lists using array)

模式匹配（patternmatching）

静态查找表 (Static Search Table)

稳定的排序法（stable sorting method）

缩小增量排序（diminishing increment sort）

磁盘（disk）

赫夫曼树（Huffman tree）

赫夫曼编码（Huffman codes）

页

4

4

4,18

4

8

5

6

6

7

90

254

247

15

144,159

158

278

299

124

页

13

32

79

214,216

263

271

294

144

146

# 附录B 函数索引

# 第1章 页

Bubble sort (a[], n) // 将 a 中整数序列重新排列成自小至大有序的整数序列 16

# 第2章

AddPolyn ( &Pa, &Pb) // 多项式加法: Pa = Pa + Pb 43

CreateList_L (&L, n) // 逆位序输入  $\mathbf{n}$  个元素的值，建立带表头结点的单链线性表 L 30

CreatPoln ( &P, m) // 输入  $\mathfrak{m}$  项的系数和指数，建立表示一元多项式的有序链表 P 42

difference (&-space, &S) // 在一维数组 space 中建立表示集合  $(A - B) \cup (B - A)$

//的静态链表 33

Free_ SL ( &space, k) // 将下标为  $\mathbf{k}$  的空闲结点回收到备用链表 33

GetElem_L(L,i, &e) // 由 e 返回带头结点的单链表 L 中第 i 个数据元素 29

InitList_Sq (&L) //构造一个空的顺序存储结构的线性表L 23

InitSpace_ SL ( &space) // 将一维数组 space 的各个分量链成一个备用链表 33

ListDelete_Sq (&L, i, &e) // 在顺序线性表 L 中删除第 i 个元素，并由 e 返回其值

ListDelete_L (&L, i, &e) // 在带头结点的单链线性表 L 中，删除第 i 个元素，

//并由e返回其值 30

ListDelete_DuL (&L, i, &e) // 删除带头结点双链循环线性表 L 的第 i 个元素 37

ListInsert_Sq（&L,i,e） //在顺序线性表L的第i个元素之前插入新的元素e 24

ListInsert_L(L,i,e) //在带头结点的单链线性表L的第i个元素之前插入元素e 29,38

ListInsert_DuL (&L, i, e) // 在带头结点的双链循环线性表 L 的第 i 个元素之前插入元素 e 36

LocateElem  $\pm$  Sq（L，e，（\*compare)）//在顺序线性表L中查找第1个值与e满足关系函数

// compare()的元素的位序 25

LocateElel.SL(S,e) //在静态单链线性表L中查找第1个值为e的元素 32

Malloc_SL (&space) // 若备用空间链表非空, 则返回分配的结点下标, 否则返回 0 33

MergeList(La,Lb,&Lc) //归并有序线性表La和Lb得到新的有序线性表Lc 21

MergeList_Sq(La,Lb,&Lc) //归并有序顺序表La和Lb得到新的有序顺序表Lc 26

MergeList_L (&La, &Lb, &Lc) // 归并有序单链表 La 和 Lb 得到新的有序单链表 Lc 31,39

union ( &La, Lb) // 将所有在线性表 Lb 中但不在 La 中的数据元素插入到 La 20

# 第3章

Bank_Simulation(CloseTime) //银行业务模拟，统计一天内客户在银行逗留的平均时间 68

Conversion() //对于输入的任意一个非负十进制整数，打印输出与其等值的八进制数 48

DeQueue  $(\& Q,\& e)$  //删除非空链队列Q的队头元素，并用e返回其值 62

DeQueue  $(\& .Q,\& e)$  //删除非空循环队列  $Q$  的队头元素，并用e返回其值 65

DestroyQueue (&Q) //销毁链队列Q 62

EnQueue  $(\& \mathbf{Q},e)$  //插入元素e为链队列  $\pmb{Q}$  的新的队尾元素 62

EnQueue (&Q, e) // 插入元素 e 为循环队列 Q 的新的队尾元素 65

EvaluateExpression() // 按算符优先算法对从终端读入的算术表达式求值 53

GetTop(S, &e) // 用 e 返回非空顺序栈 S 的栈顶元素 47

Hanoi (n, x, y, z) // 将塔座  $\mathbf{x}$  上编号为 1 至  $\mathbf{n}$  的  $\mathbf{n}$  个圆盘按规则搬到塔座  $\mathbf{z}$  上

InitQueue (&Q) //构造一个空的链队列Q 62

InitQueue (&Q) //构造一个空的循环队列Q 64

InitStack ( &S) // 构造一个空的顺序栈 S 47

LineEdit() //一个简单的行编辑程序 50

MazePath (maze, start, end) // 求迷宫 maze 中从人口 start 到出口 end 的一条通道 51

Push ( &S, e) // 插入元素 e 为顺序栈 S 新的栈顶元素 47

Pop (&S, &e) // 删除非空顺序栈 S 的栈顶元素，用 e 返回其值 47

QueueLength (Q) // 返回循环队列 Q 中的元素个数, 即队列的长度 64

# 第4章

ClearString (&S) // 将堆存储结构的串 S 清为空串 77

Concat ( &T, S1, S2) // 用 T 返回由顺序存储结构串 S1 和 S2 联接而成的新串

Concat（&T，S1，S2） //用T返回由堆存储结构的串S1和S2联接而成的新串 77

get_next(T, &next[]) // 求模式串T的next函数值 83

get_nextval（T，&nextval[]） //求模式串T的next函数修正值 84

Index (S,T,pos) //返回非空子串T在主串S中的位置 72,79

Index_KMP(S,T,pos) //利用next函数值求非空子串T在主串S中的位置 82

StrAssign（&T，\*chars） //把串常量chars赋为堆存储结构的串T的值 76

StrCompare（S，T） //返回堆存储结构的串S和T的比较结果 77

InsIdxList(&idxlist,bno) //将书号为bno的关键词插入索引表idxlist 88

StrInsert (&S, pos, T) // 在堆存储结构的串 S 中第 pos 个字符之前插入串 T

StrLength (S) //返回堆存储结构的串S的长度 77

SubString（&Sub，S，pos，len）//用Sub返回顺序存储结构的串S中第pos个字符起长度为

//len的子串 75

SubString（&Sub，S，pos，len）//用Sub返回堆存储结构的串S中第pos个字符起长度

// 为len的子串 77

# 第5章

CopyGList ( &T, L) // 采用头尾链表存储结构，由广义表L复制得到广义表T

CreateGList ( &L, S) // 采用头尾链表存储结构，由广义表的书写形式串S创建广义表L 116

CreateSMatrix_OL（&M） //创建用十字链表存储表示的稀疏矩阵M 104

FastTransposeSMatrix(M,&T)//求用三元组顺序表表示的稀疏矩阵M的转置矩阵T 100

GListDepth (L) // 采用头尾链表存储结构, 求广义表 L 的深度 114

MultSMatrix(M,N, &Q) // 求采用行逻辑链接存储表示的矩阵乘积  $\mathbf{Q} = \mathbf{M} \times \mathbf{N}$  102

Sever (&.str, &hstr) // 以第一个', '为分界符, 将非空串 str 分割成两部分: hsub 和 str 117

TransposeSMatrix(M,&T) //求采用三元组顺序表表示的稀疏矩阵M的转置矩阵T 99

# 第6章

页

CreateBiTree ( &T) // 按先序次序输入结点值，构造二叉链表表示的二叉树 T 131

find_mfset (S, i) // 找集合 S 中 i 所在子集的根 141

fix_mfset (&S, i) // 确定  $i$  所在子集，并将从  $i$  至根路径上所有结点都变成根的孩子结点 143

GetPowerSet (i,A,&B) // 用线性表表示集合时求A的幂集  $\rho (\mathbf{A})$  150

HuffmanCoding (&HT, &HC, *w, n): // 构造赫夫曼树 HT, 并求得字符的赫夫曼编码 HC 147

InOrderTraverse (T, (*Visit)) // 中序遍历二叉树 T 的非递归算法 130,131

InOrderTraverse_Thr（T，\*Visit)) //中序遍历二叉线索链表示的二叉树T 134

InOrderThreading（&Thrt，T）//中序遍历二叉树T,生成中序线索链表 Thrt 134

InThreading(p) //对以P为根的二叉树进行中序线索化 135

merge_ mfset ( &S, i, j) // 求 S 中两个互不相交的子集 Si 和 Sj 的并集  $\mathbf{S}_i \cup \mathbf{S}_j$  141

mix_mfset ( &S, i, j) // 求两个互不相交的子集  $S_{1}$  和  $S_{2}$  的并集  $S_{1} \cup S_{2}$  142

PreOrderTraverse (T, (*Visit))// 先序遍历二叉树 T 的递归算法 129

PowerSet (i, n) // 求含  $\mathbf{n}$  个元素的集合 A 的幂集  $p(A)$

Trial (i, n) // 求  $\mathbf{n}$  皇后问题棋盘的合法布局，并输出之 151

# 第7章

BFSTraverse(G，（\*Visit)) //按广度优先遍历图G,访问(Visit)图中所有顶点 170

CreateGraph（&G） //构造图G的数组(邻接矩阵)表示存储结构 162

CreateUDN（&G） //构造无向网G的数组(邻接矩阵)表示存储结构 162

CreateDG（&G） //构造有向图  $\mathbf{G}$  的十字链表存储结构 165

CriticalPath (G) // 输出有向网 G 的各项关键活动 185

DFS(G,v) //从第  $\mathbf{v}$  个顶点出发递归地深度优先遍历图G！ 169

DFSArticul (G, v0) // 从第 v0 个顶点出发深度优先遍历图 G, 查找并输出关节点 178

DFSForest (G, &T) // 建立无向图 G 的深度优先生成森林的(最左)孩子(右)兄弟链表 T 171

DFSTraverse(G，(\*Visit)) //对图G作深度优先遍历 169

DFSTree (G, v, &T) // 从第 v 个顶点出发深度优先遍历图 G, 建立以 T 为根的生成树 172

FindArticul (G) // 查找并输出连通图 G 上全部关节点 178

MiniSpanTree_PRIM（G，u） //用普里姆算法从第  $\mathbf{u}$  个顶点出发构造网G的最小生成树T 175

ShortestPath_DIJ（G，v0，&P，&D） //用Dijkstra算法求有向网G中从顶点v0

// 到其余顶点  $\mathbf{v}$  的最短路径  $\mathrm{P}[\mathrm{v}]$  及其带权长度  $\mathrm{D}[\mathrm{v}]$  189

ShortestPath_FLOYD（G，&P[]，&D） //用Floyd算法求有向网G中各对顶点v

//和w之间的最短路径P[v][w]及其带权长度D[v][w] 191

TopologicalOrder (G, &T) // 求有向网 G 中各顶点事件的最早发生时间 ve 185

TopologicalSort (G) // 若  $\mathbf{G}$  无回路, 则输出  $\mathbf{G}$  的顶点的一个拓扑序列 182

# 第8章

页

AllocBoundTag (&pav, n) // 边界标识法的存储分配算法 200

AllocBuddy (&avail, n) // 伙伴系统的存储分配算法 205

MarkList (GL) //遍历非空广义表GL,对表中所有未加标志的结点加标志 209

<table><tr><td></td><td>第9章</td><td>页</td></tr><tr><td>CreateSOSTree (&amp;T, ST)</td><td>//由有序表ST构造一棵次优查找树T</td><td>225</td></tr><tr><td>DeleteBST (&amp;T, key)</td><td>//若二叉排序树T中存在关键字等于key的数据元素时,则删除</td><td></td></tr><tr><td></td><td>//该数据元素结点p并返回TRUE;否则返回FALSE</td><td>230</td></tr><tr><td>InsertAVL (&amp;T, e, &amp;taller)</td><td>//在平衡的二叉排序树T中插入原树中不存在有相同关键字的结点,若因插入而使二叉排序树失去平衡,则作平衡旋转处理</td><td>237</td></tr><tr><td>InsertBST (&amp;T, e)</td><td>//当二叉排序树T中不存在关键字等于e.key的数据元素时,插入e并返回TRUE</td><td>228</td></tr><tr><td>InsertBTree (&amp;T, K, q, i)</td><td>//在m阶B树T上结点*q的key[i]与key[i+1]之间插入关键字K</td><td>244</td></tr><tr><td>InsertHash (&amp;H, e)</td><td>//查找不成功时插入数据元素e到开放定址哈希表H中,并返回OK;若冲突次数过大,则重建哈希表</td><td>259</td></tr><tr><td>LeftBalance (&amp;T)</td><td>//对以指针T所指结点为根的二叉树作左平衡旋转处理</td><td>237</td></tr><tr><td>L_Rotate (&amp;p)</td><td>//对以p^为根的二叉排序树作左旋处理,处理之后p指向新的树根结点</td><td>236</td></tr><tr><td>R_Rotate (&amp;p)</td><td>//对以p^为根的二叉排序树作右旋处理,处理之后p指向新的树根结点</td><td>236</td></tr><tr><td>Search_Bin (ST, key)</td><td>//在有序表ST中折半查找其关键字等于key的 数据元素</td><td>220</td></tr><tr><td>SearchBST (T, key, f, &amp;p)</td><td>//在T所指二叉排序树中递归查找其关键字等于key的 数据元素</td><td>228</td></tr><tr><td>SearchBTree (T, K)</td><td>//在m阶B树T上查找关键字K,返回结果(pt,i,tag)</td><td>240</td></tr><tr><td>SearchDLTree (T, K)</td><td>//在非空双链树T中查找关键字等于K的记录</td><td>248</td></tr><tr><td>SearchHash (H, K, &amp;p, &amp;c)</td><td>//在开放定址哈希表H中查找关键码为K的元素</td><td>259</td></tr><tr><td>Search_Seq (ST, key)</td><td>//在顺序表ST中顺序查找其关键字等于key的数据元素</td><td>216</td></tr><tr><td>SearchTrie (T, K)</td><td>//在键树T中查找关键字等于K的记录</td><td>250</td></tr><tr><td colspan="3">SecondOptimal (&amp;T, R[], sw[], low, high) //由有序表R[low..high]及其累计权值表sw</td></tr><tr><td></td><td>//递归构造次优查找树T</td><td>223</td></tr></table>

<table><tr><td></td><td>第10章</td><td>页</td></tr><tr><td rowspan="2">Arrange( &amp;SL)</td><td>// 根据静态链表SL中各结点的指针值调整记录位置,使得SL</td><td></td></tr><tr><td>// 中记录按关键字非递减有序顺序排列</td><td>269</td></tr><tr><td>BInsertSort( &amp;L)</td><td>// 对顺序表L作折半插入排序</td><td>267</td></tr><tr><td rowspan="2">Collect( &amp;r, i, f, e)</td><td>// 本算法按 keys[i]自小至大地将f[0..RADIX-1]所指各子表</td><td></td></tr><tr><td>// 依次链接成一个链表,e[0..RADIX-1]为各子表的尾指针</td><td>288</td></tr><tr><td rowspan="3">Distribute( &amp;r, i, &amp;f, &amp;e)</td><td>// 静态链表L的r域中记录已按(keys[0], ..., keys[i-1])有序,</td><td></td></tr><tr><td>// 本算法按第i个关键字 keys[i]建立 RADIX个子表,使同一子</td><td></td></tr><tr><td>// 表中记录的 keys[i]相同</td><td>288</td></tr><tr><td rowspan="2">HeapAdjust( &amp;H, s, m)</td><td>// 已知H.r[s..m]中记录的关键字除H.r[s].key之外均满足</td><td></td></tr><tr><td>// 堆的定义,本函数调整H.r[s]的关键字,使H.r[s..m]成为</td><td></td></tr><tr><td></td><td>// 一个大顶堆(对其中记录的关键字而言)</td><td>282</td></tr><tr><td>HeapSort ( &amp;H )</td><td>// 对顺序表 H 进行堆排序</td><td>282</td></tr><tr><td>InsertSort ( &amp;L )</td><td>// 对顺序表 L 作直接插入排序</td><td>265</td></tr><tr><td>Merge (SR[ ], &amp;TR[ ], i, m, n)</td><td>// 将有序的 SR[i..m] 和 SR[m+1..n] 归并为有序的</td><td></td></tr><tr><td></td><td>// TR[i..n]</td><td>283</td></tr><tr><td>MergeSort ( &amp;L )</td><td>// 对顺序表 L 作归并排序</td><td>284</td></tr><tr><td>Msort (SR[ ], &amp;TR1[ ], s, t)</td><td>// 将 SR[s..t] 归并排序为 TR1[s..t]</td><td>284</td></tr><tr><td>Partition ( &amp;L, low, high)</td><td>// 交换顺序表 L 中子序列 L.r[low..high] 的记录，使枢轴记录到位，并返回其所在位置</td><td>274</td></tr><tr><td>Qsort ( &amp;L, low, high)</td><td>// 对顺序表 L 中的子序列 L.r[low..high] 进行快速排序</td><td>275</td></tr><tr><td>QuickSort ( &amp;L)</td><td>// 对顺序表 L 进行快速排序</td><td>276</td></tr><tr><td>RadixSort ( &amp;L)</td><td>// L 是采用静态链表示的顺序表，对 L 作基数排序，使得 L 成为按关键字自小到大的有序静态链表，L.r[0]为头结点</td><td>288</td></tr><tr><td>Rearrange ( &amp;L, adr[])</td><td>// adr 给出顺序表 L 的有序次序，即 L.r[adr[i]]是第 i 小的记录，</td><td></td></tr><tr><td></td><td>// 本算法按 adr 重排 L.r，使其有序</td><td>290</td></tr><tr><td>SelectSort ( &amp;L)</td><td>// 对顺序表 L 作简单选择排序</td><td>277</td></tr><tr><td>ShellInsert ( &amp;L, dk)</td><td>// 对顺序表 L 作一趟希尔插入排序，dk 为增量</td><td>272</td></tr><tr><td>ShellSort ( &amp;L, dhta[ ], t)</td><td>// 按增量序列 dhta[0..t-1] 对顺序表 L 作希尔排序</td><td>272</td></tr></table>

<table><tr><td></td><td>第11章</td><td>页</td></tr><tr><td>Adjust (&amp;ls, s)</td><td>// 沿从叶子结点b[s]到根结点ls[0]的路径调整败者树</td><td>299</td></tr><tr><td rowspan="2">Construct_Loser (&amp;ls, &amp;wa)</td><td>// 输入w个记录到内存工作区wa,建得败者树ls,选出关键字</td><td rowspan="2">302</td></tr><tr><td>// 最小的记录</td></tr><tr><td rowspan="2">CreateLoserTree (&amp;ls)</td><td>// 已知b[0]到b[k-1]为完全二叉树ls的叶子结点存有k</td><td rowspan="2">299</td></tr><tr><td>// 个关键字,沿从叶子到根的k条路径将ls调整成为败者树</td></tr><tr><td>get_run (&amp;ls, &amp;wa)</td><td>// 求得一个初始归并段</td><td>301</td></tr><tr><td>K_Merge (&amp;ls, &amp;b)</td><td>// 利用败者树ls将编号从0到k-1的k个输入归并段中</td><td>298</td></tr><tr><td>Replace_Selection (&amp;ls, &amp;wa, *fi, *fo) // 在败者树ls和内存工作区wa上用置换-选择</td><td>// 排序求初始归并段,fi为输入文件,fo为输出文件</td><td>301</td></tr><tr><td rowspan="2">Select_MinMax (&amp;ls, wa, q)</td><td>// 从wa[q]起到败者树的根比较选择MINIMAX记录,并由</td><td rowspan="2">302</td></tr><tr><td>// q指示它所在的归并段</td></tr></table>

<table><tr><td>第12章</td><td>页</td></tr><tr><td>MergeFile(*f, *g, *h) // 由按关键字递增有序的非空顺序文件f和g归并得到新文件h</td><td>310</td></tr></table>

# 参考书目

[1] Horowitz E, Sahni S. Fundamentals of Data Structures. Pitmen Publishing Limited, 1976  
[2] Knuth D E. The Art of Computer Programming, volume 1/Fundamental Algorithms; volume3/ Sorting and Searching. Addison-Wesley Publishing Company, Inc., 1973  
[3] Gotlieb C C, Gotlieb L R. Data Types and Structures. Prentice—Hall Inc., 1978  
[4] Tenenbaum A M, Augenshtein M J. Data Structures Using PASCAL. Prentice-Hall, Inc., 1981  
[5] Baron R J, Shapiro L G. Data Structures and their Implementation. Van Nostrand Reinhold Company, 1980  
[6] Aho A V, Hopcroft J E, Ullman J D. Data Structures and Algorithms. Addison-Wesley Publishing Company, Inc., 1983  
[7] Esakov J, Weiss T. Data Structures: An Advanced Approach Using C. Prentice-Hall, Inc., 1989  
[8] [美]S巴斯．计算机算法：设计和分析引论．朱洪等译．上海：复旦大学出版社，1985  
[9] Wirth N. Algorithms + Dada Structures = Programs. Prentice-Hall, Inc., 1976  
[10] Lewis T G, Smith M Z. Applying Data Structures. Houghton Mifflin Company, 1976  
[11] Donovan J J. Operating System. McGraw-Hill, Inc., 1974  
[12] Tremblay J P, Sorenson P G. An Introduction to Data Structure with Applications, Second Edition. McGraw-Hill, Inc., 1984  
[13] 姚诗斌．数据库系统基础．计算机工程与应用，1981年第8期  
[14] Stubbs D F, Wibre N W. Data Structures with Abstract Data Types and Pascal. Brooks/ Cole Publishing Company, 1985

# 读者意见反馈

亲爱的读者：

感谢您一直以来对清华版计算机教材的支持和爱护。为了今后为您提供更优秀的教材，请您抽出宝贵的时间来填写下面的意见反馈表，以便我们更好地对本教材做进一步改进。同时如果您在使用本教材的过程中遇到了什么问题，或者有什么好的建议，也请您来信告诉我们。

地址：北京市海淀区双清路学研大厦A座602 计算机与信息分社营销室收

邮编：100084 电子邮件：jsjjc@tup.tsinghua.edu.cn

电话：010-62770175-4608/4409 邮购电话：010-62786544

教材名称：数据结构（C语言版）

ISBN: 978-7-302-14751-0

个人资料

姓名： 年龄： 所在院校/专业：

文化程度： 通信地址：

联系电话： 电子信箱：

您使用本书是作为：□指定教材 □选用教材 □辅导教材 □自学教材

您对本书封面设计的满意度：

□很满意 □满意 □一般 □不满意 改进建议

您对本书印刷质量的满意度：

□很满意□满意□一般□不满意改进建议

您对本书的总体满意度：

从语言质量角度看□很满意□满意□一般□不满意

从科技含量角度看□很满意□满意□一般□不满意

本书最令您满意的是：

□指导明确 □内容充实 □讲解详尽 □实例丰富

您认为本书在哪些地方应进行修改？（可附页）

您希望本书在哪些方面进行改进？（可附页）

# 清华大学计算机系列教材

<table><tr><td>书名</td><td>作者</td><td>定价</td></tr><tr><td>数据结构(C语言版)(有盘)</td><td>严蔚敏</td><td>30</td></tr><tr><td>数据结构(C语言版)(无盘)</td><td>严蔚敏</td><td>22</td></tr><tr><td>数据结构题集(C语言版)</td><td>严蔚敏</td><td>16</td></tr><tr><td>微型计算机技术及应用(第4版)</td><td>戴梅萼、史嘉权</td><td>36</td></tr><tr><td>微型计算机技术及应用习题、实验题与综合训练题集(第4版)</td><td>戴梅萼、史嘉权</td><td>17</td></tr><tr><td>计算机组成与结构(第4版)</td><td>王爱英</td><td>39</td></tr><tr><td>计算机组成与结构(第4版)习题详解与实验指导</td><td>王爱英</td><td>18</td></tr><tr><td>MPI并行程序设计实例教程</td><td>张武生、薛巍等</td><td>39</td></tr><tr><td>数据结构(用面向对象方法与C++语言描述)第二版</td><td>殷人昆</td><td>39</td></tr><tr><td>编译原理(第二版)</td><td>张素琴</td><td>35</td></tr><tr><td>编译原理课程辅导</td><td>张素琴</td><td>18</td></tr><tr><td>计算机系统结构(第2版)</td><td>郑纬民、汤志忠</td><td>42</td></tr><tr><td>IBM PC汇编语言程序设计(第二版)</td><td>沈美明</td><td>34.8</td></tr><tr><td>80x86汇编语言程序设计</td><td>沈美明</td><td>46</td></tr><tr><td>计算机图形学(第3版)</td><td>孙家广</td><td>39</td></tr><tr><td>计算机图形学基础教程(第2版)</td><td>孙家广、胡事民</td><td>23</td></tr><tr><td>多媒体技术基础(第3版)</td><td>林福宗</td><td>53</td></tr><tr><td>多媒体技术教程</td><td>林福宗</td><td>33</td></tr><tr><td>多媒体技术课程设计与学习辅导</td><td>林福宗</td><td>25</td></tr><tr><td>计算机组成与设计(第3版)</td><td>王诚</td><td>35</td></tr><tr><td>计算机组成与设计(第3版)实验指导</td><td>王诚</td><td>27</td></tr><tr><td>程序设计基础(第2版)</td><td>吴文虎</td><td>28</td></tr><tr><td>程序设计基础(第2版)习题解答与上机指导</td><td>吴文虎</td><td>19</td></tr><tr><td>图论与代数结构</td><td>戴一奇</td><td>12.9</td></tr><tr><td>数理逻辑与集合论(第2版)</td><td>石纯一</td><td>18</td></tr><tr><td>数理逻辑与集合论(第2版)精要与题解</td><td>王宏</td><td>16</td></tr><tr><td>信号处理原理</td><td>郑方</td><td>26</td></tr><tr><td>人工智能导论</td><td>林尧瑞、马少平</td><td>16</td></tr><tr><td>数字逻辑与数字集成电路(第2版)</td><td>王尔乾</td><td>29</td></tr><tr><td>计算机网络与Internet教程(第2版)</td><td>张尧学</td><td>28</td></tr><tr><td>计算机网络(第2版)</td><td>胡道元</td><td>39</td></tr><tr><td>网络安全(第2版)</td><td>胡道元</td><td>43</td></tr><tr><td>计算机局域网(第三版)</td><td>胡道元</td><td>39</td></tr><tr><td>实用软件工程(第二版)</td><td>郑人杰</td><td>32</td></tr><tr><td>系统分析与控制</td><td>孙增圻</td><td>17.5</td></tr><tr><td>电子商务软件技术教程(第2版)</td><td>王克宏等</td><td>23</td></tr></table>

# 清华大学计算机系列教材

这套教材已伴随着计算机科学与技术的飞速发展茁壮成长了二十余年，获得了国家科学技术进步奖、国家级优秀教材特等奖等29项部级以上奖励，被几百所高校选作教材，教学效果非常好。现经修订和增加新品种、新内容，基本涵盖了本科生和硕士研究生的主要课程。这套系列教材体系完整、结构严谨、理论结合实际、注重素质培养。

# 本书特点：

$\spadesuit$  涵盖教学大纲内容，兼顾学科知识的广度和深度，适用面广；  
$\spadesuit$  引入抽象数据类型的基本概念，有助于培养学生的数据抽象和算法设计能力；  
$\spadesuit$  以C伪码语言描述存储结构和算法，有助于提高学生的程序设计能力；  
$\spadesuit$  对算法进行详尽的定性或定量的时间分析，有助于奠定学生的算法分析基础；  
提供了全书120余个算法C语言源码、80余个算法执行过程的动态演示，有助于学生对数据结构和算法的分析和理解。