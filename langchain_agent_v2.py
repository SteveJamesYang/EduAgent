import os
import json
import requests
import re
import unicodedata
from bs4 import BeautifulSoup
from readability import Document

from langchain_deepseek import ChatDeepSeek
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.agents import AgentAction, AgentFinish
from langchain_community.utilities import SearchApiAPIWrapper
from langchain_core.tools import tool
from openai import OpenAI
from typing import List, Tuple, Any, Dict

_SURROGATE_RE = re.compile(r'[\ud800-\udfff]')

# ========= ä» config/config.json è¯»å– API Key =========

def load_api_config() -> dict:
    """
    ä» ./config/config.json åŠ è½½é…ç½®ã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥ï¼Œè¿”å›ç©º dictã€‚
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    cfg_path = os.path.join(base_dir, "config", "config.json")
    if not os.path.exists(cfg_path):
        print(f"[warn] æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {cfg_path}ï¼Œå°†ä»…ä½¿ç”¨å·²æœ‰ç¯å¢ƒå˜é‡ä¸­çš„ API Key")
        return {}
    try:
        with open(cfg_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, dict):
            print(f"[warn] é…ç½®æ–‡ä»¶ {cfg_path} å†…å®¹ä¸æ˜¯ JSON å¯¹è±¡ï¼Œå°†å¿½ç•¥ã€‚")
            return {}
        return data
    except Exception as e:
        print(f"[warn] è§£æé…ç½®æ–‡ä»¶ {cfg_path} å¤±è´¥: {e}ï¼Œå°†ä»…ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ API Key")
        return {}

_API_CFG = load_api_config()


def ensure_env_key(name: str, required: bool = False) -> str | None:
    """
    ç¡®ä¿æŸä¸ª API Key å­˜åœ¨äºç¯å¢ƒå˜é‡ä¸­ï¼š
    - ä¼˜å…ˆä½¿ç”¨å·²ç»å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼›
    - å¦åˆ™ä» _API_CFG ä¸­è¯»å–å¹¶å†™å…¥ os.environï¼›
    - å¦‚æœ required=True ä¸”æœ€ç»ˆä»æ²¡æœ‰ï¼ŒæŠ›å‡º RuntimeErrorã€‚
    """
    val = os.getenv(name)
    if val:
        return val

    if name in _API_CFG and _API_CFG[name]:
        val = str(_API_CFG[name])
        os.environ[name] = val
        return val

    if required:
        raise RuntimeError(
            f"[fatal] å¿…éœ€çš„ API Key '{name}' æœªåœ¨ç¯å¢ƒå˜é‡æˆ– config/config.json ä¸­æ‰¾åˆ°ã€‚"
        )
    else:
        print(f"[warn] å¯é€‰ API Key '{name}' æœªè®¾ç½®ï¼Œç›¸å…³å·¥å…·å¯èƒ½æ— æ³•ä½¿ç”¨ã€‚")
        return None


# è¯´æ˜ï¼šLLM çš„ Key ä¼šåœ¨ build_llm() ä¸­æŒ‰æ‰€é€‰æä¾›æ–¹æŒ‰éœ€æ£€æŸ¥ï¼›è¿™é‡Œä»…æ£€æŸ¥å·¥å…·ç›¸å…³çš„å¯é€‰ Key
ensure_env_key("SEARCHAPI_API_KEY", required=False)
# Tavily çš„ Key åœ¨çœŸæ­£æ„å»º TavilySearch å·¥å…·æ—¶å†æŒ‰éœ€ ensure_env_key("TAVILY_API_KEY")


def env_flag(name: str, default: bool = True) -> bool:
    """
    ä»ç¯å¢ƒå˜é‡è¯»å–ä¸€ä¸ªå¸ƒå°”å¼€å…³ï¼š
    - æœªè®¾ç½® => default
    - å…è®¸çš„"çœŸ"å€¼ï¼š1 / true / yes / y / onï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    - å…è®¸çš„"å‡"å€¼ï¼š0 / false / no / n / off
    """
    v = os.getenv(name)
    if v is None:
        return default
    v = v.strip().lower()
    if v in ("1", "true", "yes", "y", "on"):
        return True
    if v in ("0", "false", "no", "n", "off"):
        return False
    return default


def fix_surrogates(s: str) -> str:
    """æŠŠæ½œåœ¨çš„ UTF-16 ä»£ç†å¯¹"å¤åŸ"ä¸ºçœŸå®å­—ç¬¦ã€‚"""
    if not isinstance(s, str):
        return s
    b = s.encode('utf-16', 'surrogatepass')
    s2 = b.decode('utf-16', 'ignore')  # ignore=ä¸¢å¼ƒå­¤ç«‹ä»£ç†
    s2 = _SURROGATE_RE.sub('', s2)
    return unicodedata.normalize('NFC', s2)


def clean_text(obj):
    """é€’å½’æ¸…æ´—ï¼šä¿®å¤ä»£ç† â†’ åˆ é™¤æ®‹ç•™ä»£ç† â†’ ä¿è¯å¯ UTF-8 ç¼–ç ã€‚"""
    if isinstance(obj, str):
        s = fix_surrogates(obj)
        # æç«¯å…œåº•ï¼šä»»ä½•ä»ä¸å¯ç¼–ç çš„å­—ç¬¦éƒ½å¿½ç•¥
        return s.encode('utf-8', 'ignore').decode('utf-8', 'ignore')
    elif isinstance(obj, dict):
        return {k: clean_text(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        t = [clean_text(x) for x in obj]
        return type(obj)(t) if not isinstance(obj, tuple) else tuple(t)
    return obj


# ========= LLM æœ¬ä½“ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œ/ç¯å¢ƒå˜é‡åˆ‡æ¢ï¼‰ =========
# çº¦å®šï¼š
#   - eval_computer_exam_alltypes.py é‡Œå¯ç”¨ --llm deepseek/qwen/doubao/kimi/mimoï¼ˆé»˜è®¤ deepseekï¼‰
#   - ä¹Ÿå¯ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼šEDUAGENT_LLM=deepseek|qwen|doubao|kimi|mimo
#   - å¯é€‰è¦†ç›–ï¼šEDUAGENT_LLM_MODEL / EDUAGENT_LLM_BASE_URL
#   - Qwen å…¼å®¹ OpenAI Modeï¼šbase_url é»˜è®¤ https://dashscope-intl.aliyuncs.com/compatible-mode/v1
#   - Doubao(æ–¹èˆŸ) æ•°æ®é¢ APIï¼šbase_url é»˜è®¤ https://ark.cn-beijing.volces.com/api/v3/
#   - Kimiï¼šbase_url é»˜è®¤ https://api.moonshot.cn/v1
#   - Mimoï¼ˆå°ç±³ï¼‰ï¼šbase_url é»˜è®¤ https://api.mi.ai/v1
#
# æ³¨æ„ï¼šDoubao çš„ model å¾€å¾€æ˜¯ä½ åœ¨æ§åˆ¶å°é‡Œçœ‹åˆ°çš„ "Model ID"ï¼Œå¿…é¡»è‡ªè¡Œå¡«å†™ã€‚

def ensure_any_env_key(names: list[str], required: bool = False, alias: str = "") -> str | None:
    """åœ¨å¤šä¸ªå€™é€‰ç¯å¢ƒå˜é‡åé‡Œå¯»æ‰¾ API Keyï¼›ä¹Ÿä¼šå°è¯•ä» config/config.json å†™å…¥åˆ°ç¯å¢ƒå˜é‡ã€‚"""
    for n in names:
        v = os.getenv(n)
        if v:
            return v
    for n in names:
        if n in _API_CFG and _API_CFG[n]:
            v = str(_API_CFG[n])
            os.environ[n] = v
            return v
    if required:
        hint = alias or ("/".join(names))
        raise RuntimeError(f"[fatal] å¿…éœ€çš„ API Key '{hint}' æœªåœ¨ç¯å¢ƒå˜é‡æˆ– config/config.json ä¸­æ‰¾åˆ°ã€‚")
    return None


def get_cfg_or_env(names: list[str], default: str = "") -> str:
    """æŒ‰ä¼˜å…ˆçº§è¯»å–é…ç½®å€¼ï¼šç¯å¢ƒå˜é‡ -> config/config.json -> defaultã€‚"""
    for n in names:
        v = os.getenv(n)
        if v is not None and str(v).strip() != "":
            return str(v).strip()
    for n in names:
        if n in _API_CFG and str(_API_CFG[n]).strip() != "":
            return str(_API_CFG[n]).strip()
    return default


def build_llm():
    provider = (os.getenv("EDUAGENT_LLM", "deepseek") or "deepseek").strip().lower()
    # provider = (os.getenv("EDUAGENT_LLM", "mimo") or "mimo").strip().lower()
    # provider = (os.getenv("EDUAGENT_LLM", "kimi") or "kimi").strip().lower()
    # provider = (os.getenv("EDUAGENT_LLM", "doubao") or "doubao").strip().lower()
    # provider = (os.getenv("EDUAGENT_LLM", "qwen") or "qwen").strip().lower()

    # ç»Ÿä¸€çš„å¯é€‰è¦†ç›–ï¼ˆå‘½ä»¤è¡Œä¼šå†™åˆ°è¿™é‡Œï¼‰
    override_model = (os.getenv("EDUAGENT_LLM_MODEL") or "").strip()
    override_base = (os.getenv("EDUAGENT_LLM_BASE_URL") or "").strip()

    if provider in ("deepseek", "ds"):
        ensure_any_env_key(["DEEPSEEK_API_KEY"], required=True, alias="DEEPSEEK_API_KEY")
        model = override_model or get_cfg_or_env(["DEEPSEEK_MODEL"], default="deepseek-reasoner")
        return provider, model, "", ChatDeepSeek(
            model=model,
            temperature=0,
            max_tokens=None,
            timeout=None,
            max_retries=2,

        )

    if provider in ("qwen", "tongyi", "qw"):
        api_key = ensure_any_env_key(
            ["QWEN_API_KEY", "DASHSCOPE_API_KEY", "TONGYI_API_KEY"],
            required=True,
            alias="QWEN_API_KEY/DASHSCOPE_API_KEY",
        )
        base_url = override_base or get_cfg_or_env(
            ["QWEN_BASE_URL", "DASHSCOPE_BASE_URL"],
            default="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        model = override_model or get_cfg_or_env(["QWEN_MODEL"], default="qwen-max")
        return provider, model, base_url, ChatOpenAI(
            model=model,
            temperature=0,
            max_retries=2,
            api_key=api_key,
            base_url=base_url,
        )

    if provider in ("doubao", "ark", "volcengine", "db"):
        api_key = ensure_any_env_key(
            ["ARK_API_KEY", "DOUBAO_API_KEY", "VOLCENGINE_API_KEY", "VOLC_API_KEY"],
            required=True,
            alias="ARK_API_KEY/DOUBAO_API_KEY",
        )
        base_url = override_base or get_cfg_or_env(
            ["DOUBAO_BASE_URL", "ARK_BASE_URL"],
            default="https://ark.cn-beijing.volces.com/api/v3",
        )
        model = (override_model or get_cfg_or_env(["DOUBAO_MODEL", "ARK_MODEL"], default="doubao-seed-1-8-251228")).strip()
        if not model:
            raise RuntimeError(
                "[fatal] é€‰æ‹© doubao æ—¶å¿…é¡»æŒ‡å®š Model IDï¼šé€šè¿‡ç¯å¢ƒå˜é‡ DOUBAO_MODEL æˆ–å‘½ä»¤è¡Œ --llm_modelï¼ˆä¼šå†™å…¥ EDUAGENT_LLM_MODELï¼‰ã€‚"
            )
        return provider, model, base_url, ChatOpenAI(
            model=model,
            temperature=0,
            max_retries=2,
            api_key=api_key,
            base_url=base_url,
        )
    
    if provider in ("kimi", "moonshot"):
        api_key = ensure_any_env_key(
            ["KIMI_API_KEY", "MOONSHOT_API_KEY"],
            required=True,
            alias="KIMI_API_KEY/MOONSHOT_API_KEY",
        )
        base_url = override_base or get_cfg_or_env(
            ["KIMI_BASE_URL", "MOONSHOT_BASE_URL"],
            default="https://api.moonshot.cn/v1",
        )
        model = override_model or get_cfg_or_env(["KIMI_MODEL"], default="kimi-k2-thinking-turbo")
        return provider, model, base_url, ChatOpenAI(
            model=model,
            temperature=0,
            max_retries=2,
            api_key=api_key,
            base_url=base_url,
        )
    
    if provider in ("mimo", "mi", "xiaomi"):
        api_key = ensure_any_env_key(
            ["MIMO_API_KEY", "MI_API_KEY", "XIAOMI_API_KEY"],
            required=True,
            alias="MIMO_API_KEY/MI_API_KEY",
        )
        base_url = override_base or get_cfg_or_env(
            ["MIMO_BASE_URL", "MI_BASE_URL"],
            default="https://api.xiaomimimo.com/v1",
        )
        model = override_model or get_cfg_or_env(["MIMO_MODEL"], default="mimo-v2-flash")
        return provider, model, base_url, ChatOpenAI(
            model=model,
            temperature=0,
            max_retries=2,
            api_key=api_key,
            base_url=base_url,
        )

    raise RuntimeError(f"[fatal] ä¸æ”¯æŒçš„ EDUAGENT_LLM={provider}ï¼Œå¯é€‰ deepseek/qwen/doubao/kimi/mimoã€‚")


_LLM_PROVIDER, _LLM_MODEL, _LLM_BASE_URL, llm = build_llm()
print(f"[llm] provider={_LLM_PROVIDER} model={_LLM_MODEL}" + (f" base_url={_LLM_BASE_URL}" if _LLM_BASE_URL else ""))


# ========= å·¥å…·å¼€å…³ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰ =========
# åœ¨ eval_computer_exam_alltypes.py ä¸­é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼š
#   EDUAGENT_USE_KB / EDUAGENT_USE_NEWS / EDUAGENT_USE_WEB /
#   EDUAGENT_USE_SEARCHAPI / EDUAGENT_USE_FETCHURL
USE_KB = env_flag("EDUAGENT_USE_KB", True)
USE_NEWS = env_flag("EDUAGENT_USE_NEWS", True)
USE_WEB = env_flag("EDUAGENT_USE_WEB", True)
USE_SEARCHAPI = env_flag("EDUAGENT_USE_SEARCHAPI", True)
USE_FETCHURL = env_flag("EDUAGENT_USE_FETCHURL", True)

# ========= å·¥å…·æ„å»º =========
tools = []

# ----- çŸ¥è¯†åº“æ£€ç´¢ï¼ˆå¯å…³é—­ï¼‰ -----
kb_tool = None
if USE_KB:
    embed = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        encode_kwargs={"normalize_embeddings": True}
    )
    vs = FAISS.load_local(
        "kb_store/faiss_bge_m3",
        embed,
        allow_dangerous_deserialization=True
    )
    retriever = vs.as_retriever(search_kwargs={"k": 4})
    kb_tool = create_retriever_tool(
        retriever,
        name="kb_search",
        description="åœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¸ç”¨æˆ·é—®é¢˜å¼ºç›¸å…³çš„ç‰‡æ®µï¼Œç”¨äºç§æœ‰èµ„æ–™é—®ç­”ä¸å¼•ç”¨ã€‚",
    )
    tools.append(kb_tool)

# ----- Tavilyï¼šæ–°é—»æœç´¢ï¼ˆå¯å…³é—­ï¼‰ -----
news_today_tool = None
if USE_NEWS:
    tavily_key = ensure_env_key("TAVILY_API_KEY", required=True)
    news_today_tool = TavilySearch(
        max_results=8,
        topic="news",           # å…³é”®ï¼šæ–°é—»é€šé“
        time_range="day",       # æ—¶æ•ˆï¼šé™åˆ¶ä¸º"æœ€è¿‘ä¸€å¤©"
        search_depth="advanced",
        include_answer=True,
        include_raw_content=False,
        tavily_api_key=tavily_key,
        name="news_search",  # å”¯ä¸€åç§°
        description="æœç´¢å½“å¤©æœ€æ–°çš„è®¡ç®—æœºä¸æ•™è‚²ç›¸å…³æ–°é—»èµ„è®¯ã€çªå‘é€šçŸ¥"
    )
    tools.append(news_today_tool)

# ----- Tavilyï¼šé€šç”¨ Web æœç´¢ï¼ˆå¯å…³é—­ï¼‰ -----
web_search_tool = None
if USE_WEB:
    tavily_key = ensure_env_key("TAVILY_API_KEY", required=True)
    web_search_tool = TavilySearch(
        max_results=6,
        topic="general",
        time_range="week",      # æ—¶æ•ˆä¸‹é™
        search_depth="basic",
        include_answer=False,
        include_raw_content=False,
        tavily_api_key=tavily_key,
        name="web_search",  # å”¯ä¸€åç§°
        description="é€šç”¨ç½‘é¡µæœç´¢ï¼Œç”¨äºæŸ¥æ‰¾æŠ€æœ¯èµ„æ–™ã€æ–‡æ¡£ç­‰éæ–°é—»ç±»ä¿¡æ¯"
    )
    tools.append(web_search_tool)

# ----- SearchAPI å·¥å…·ï¼ˆå¯å…³é—­ï¼‰ -----
search = SearchApiAPIWrapper()


@tool("searchapi_search", return_direct=False)
def searchapi_search(query: str) -> str:
    """ä½¿ç”¨ SearchAPI è¿›è¡Œé€šç”¨ç½‘é¡µæœç´¢ã€‚è¾“å…¥è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œè¿”å›æœç´¢ç»“æœæ‘˜è¦ã€‚"""
    return search.run(query)


if USE_SEARCHAPI:
    tools.append(searchapi_search)

# ----- æŠ“å–ç½‘é¡µæ­£æ–‡ï¼ˆå¯å…³é—­ï¼‰ -----
@tool("fetch_url", return_direct=False)
def fetch_url(url: str) -> str:
    """æŠ“å–æŒ‡å®š URL çš„æ­£æ–‡å¹¶æç‚¼ä¸»è¦å†…å®¹ï¼Œç”¨äºè¿›ä¸€æ­¥å›ç­”ä¸å¼•ç”¨ã€‚"""
    try:
        r = requests.get(url, timeout=25, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
        doc = Document(r.text)
        html = doc.summary()
        text = BeautifulSoup(html, "html.parser").get_text(" ")
        return text[:8000]
    except Exception as e:
        return f"[fetch_failed] {e}"

if USE_FETCHURL:
    tools.append(fetch_url)

# ä¸ºåé¢æ„é€ æç¤ºè¯å‡†å¤‡ä¸€äº›æ ‡å¿—
HAS_KB = USE_KB and (kb_tool is not None)
HAS_WEB = any([USE_NEWS, USE_WEB, USE_SEARCHAPI, USE_FETCHURL])  # æœ‰ä»»æ„ç½‘é¡µç›¸å…³å·¥å…·å³å¯è§†ä¸ºæœ‰ Web


# ========= ç³»ç»Ÿæç¤ºè¯ï¼ˆæ ¹æ®å·¥å…·å¼€å…³åŠ¨æ€é€‚é…ï¼‰ =========
def build_system_prompt() -> str:
    lines = []
    lines.append(
        "ä½ æ˜¯ä¸€åé¢å‘ã€èŒä¸šæŠ€æœ¯å­¦é™¢è®¡ç®—æœºå­¦ç§‘æ•™è‚²ã€‘çš„è¯¾ç¨‹æ•™å­¦é—®ç­”æ™ºèƒ½ä½“ã€‚"
        "ä½ çš„èŒè´£æ˜¯ï¼šå›´ç»•è®¡ç®—æœºåŸºç¡€ã€ç¨‹åºè®¾è®¡ã€æ•°æ®ç»“æ„ä¸ç®—æ³•ã€æ“ä½œç³»ç»Ÿã€è®¡ç®—æœºç½‘ç»œã€"
        "æ•°æ®åº“ã€Web/ç§»åŠ¨å¼€å‘ã€è½¯ä»¶å·¥ç¨‹ã€äº‘è®¡ç®—ä¸DevOpsã€AIä¸æ•°æ®åˆ†æã€æ•™å­¦ç»„ç»‡ä¸è¯„ä»·ç­‰ä¸»é¢˜ï¼Œ"
        "ä¸ºæ•™å¸ˆå’Œå­¦ç”Ÿæä¾›**å‡†ç¡®ã€å¯æº¯æºã€å¯æ“ä½œ**çš„ç­”å¤ä¸ç¤ºä¾‹ã€‚"
    )

    # -------- çŸ¥è¯†æ¥æºä¼˜å…ˆçº§ --------
    lines.append("")
    lines.append("ã€çŸ¥è¯†æ¥æºä¼˜å…ˆçº§ã€‘")

    if HAS_KB:
        lines.append("1) **æœ¬åœ°çŸ¥è¯†åº“ï¼ˆkb_searchï¼‰ä¼˜å…ˆ**")
        lines.append("   - è¯¥åº“åŒ…å«è¯¾ç¨‹ç« èŠ‚ã€æ•™å­¦ç›®æ ‡ã€çŸ¥è¯†ç‚¹ã€å®è®­è¯´æ˜ã€è¯„ä»·Rubricã€æ¡ˆä¾‹ä¸æ¨¡æ¿ã€‚")
        lines.append("   - å¯¹â€œè¯¾ç¨‹æ•™å­¦é—®ç­”/æ•™å­¦è®¾è®¡/çŸ¥è¯†ç‚¹è§£é‡Š/å®è·µæ­¥éª¤/ä½œä¸šä¸é¡¹ç›®è§„èŒƒâ€ç­‰ï¼Œä¼˜å…ˆæ£€ç´¢æœ¬åœ°çŸ¥è¯†åº“å¹¶å¼•ç”¨ã€‚")

    if HAS_WEB:
        idx = 2 if HAS_KB else 1
        lines.append(f"{idx}) **ç½‘é¡µæ£€ç´¢ä¸åœ¨çº¿èµ„æ–™**")
        web_desc = []
        if USE_NEWS:
            web_desc.append("`news_today_tool`ï¼šå½“å¤©è®¡ç®—æœºä¸æ•™è‚²ç›¸å…³èµ„è®¯ã€çªå‘é€šçŸ¥ï¼›")
        if USE_WEB:
            web_desc.append("`web_search_tool`ï¼šé€šç”¨æŠ€æœ¯èµ„æ–™ä¸æ–‡æ¡£ï¼›")
        if USE_SEARCHAPI:
            web_desc.append("`searchapi_search`ï¼šè¡¥å……é•¿å°¾ç½‘é¡µæ£€ç´¢ï¼›")
        if USE_FETCHURL:
            web_desc.append("`fetch_url`ï¼šæŠ“å– URL æ­£æ–‡å¹¶æç‚¼ä¸»è¦å†…å®¹ã€‚")
        if web_desc:
            # åˆå¹¶ä¸ºä¸€ä¸¤è¡Œè¯´æ˜
            lines.append("   - å½“æœ¬åœ°ä¿¡æ¯ä¸è¶³ï¼Œæˆ–é—®é¢˜æ¶‰åŠ**æœ€æ–°æ¡†æ¶ç‰ˆæœ¬å˜æ›´ã€è¿‘ä¸€å‘¨çš„æŠ€æœ¯æ–°é—»ã€ç¬¬ä¸‰æ–¹åº“ç”¨æ³•**æ—¶ï¼Œå†è°ƒç”¨ç½‘é¡µå·¥å…·ã€‚")
            lines.append("   - " + " ".join(web_desc))
    if (not HAS_KB) and (not HAS_WEB):
        lines.append("1) å½“å‰ç¯å¢ƒä¸‹**ä¸å…·å¤‡å¤–éƒ¨æ£€ç´¢å·¥å…·**ï¼Œä½ åªèƒ½åŸºäºè‡ªèº«å·²æœ‰çš„é€šç”¨çŸ¥è¯†ä¸é¢˜ç›®å†…å®¹è¿›è¡Œæ¨ç†ä¸ä½œç­”ã€‚")

    # -------- æ£€ç´¢ä¸å·¥å…·ä½¿ç”¨åŸåˆ™ --------
    lines.append("")
    lines.append("ã€æ£€ç´¢ä¸å·¥å…·ä½¿ç”¨åŸåˆ™ã€‘")
    if HAS_KB and HAS_WEB:
        lines.append("- é‡‡ç”¨â€œå…ˆçŸ¥è¯†åº“â†’åç½‘é¡µâ€çš„ä¸¤é˜¶æ®µç­–ç•¥ï¼›æœç´¢å…³é”®è¯å°½é‡å…·ä½“ï¼ŒåŠ å…¥è¯¾ç¨‹å/æŠ€æœ¯å/ç‰ˆæœ¬å·/å…³é”®æœ¯è¯­ã€‚")
    elif HAS_KB and (not HAS_WEB):
        lines.append("- ä¼˜å…ˆä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢ï¼›åœ¨çŸ¥è¯†åº“å¬å›ä¸è¶³æ—¶ï¼ŒåŸºäºå·²çŸ¥å†…å®¹è¿›è¡Œåˆç†æ¨ç†å¹¶æ¸…æ™°è¯´æ˜ä¸ç¡®å®šæ€§ã€‚")
    elif (not HAS_KB) and HAS_WEB:
        lines.append("- ç›´æ¥ä½¿ç”¨ç½‘é¡µå·¥å…·è¿›è¡Œæ£€ç´¢ï¼›æœç´¢å…³é”®è¯å°½é‡å…·ä½“ï¼ŒåŠ å…¥è¯¾ç¨‹å/æŠ€æœ¯å/ç‰ˆæœ¬å·/å…³é”®æœ¯è¯­ã€‚")
    else:
        lines.append("- ä¸å…·å¤‡æ£€ç´¢å·¥å…·æ—¶ï¼Œä¸¥ç¦å‡è£…è°ƒç”¨æ£€ç´¢ï¼›åªèƒ½åŸºäºå·²æœ‰çŸ¥è¯†æ¨ç†ï¼Œå¦‚ä¸ç¡®å®šåº”æ˜ç¡®è¯´æ˜ã€‚")

    if HAS_WEB or HAS_KB:
        lines.append("- ä¸ä¸ºæ— å…³æˆ–å¯ç›´æ¥æ¨å¯¼çš„é—®é¢˜æ»¥ç”¨å¤–éƒ¨æœç´¢ï¼›å¦‚ç¡®éœ€å¤šæ¬¡æ£€ç´¢æ—¶ï¼Œåº”åˆå¹¶ç»“æœã€å»é‡å½’çº³ã€‚")
        lines.append("- è¿”å›å†…å®¹åŠ¡å¿…**é™„æ¥æºæ ‡æ³¨**ï¼š")
        if HAS_KB:
            lines.append("  - çŸ¥è¯†åº“ï¼šã€”KBï½œæ¡ç›®æˆ–ç« èŠ‚åï½œchunk_id/æ ‡é¢˜ã€•")
        if HAS_WEB:
            lines.append("  - ç½‘é¡µï¼šã€”ç½‘é¡µæ ‡é¢˜ï½œURLã€•")
    else:
        lines.append("- æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ä½ æ— æ³•è®¿é—®å¤–éƒ¨èµ„æ–™ï¼Œåªèƒ½ç»™å‡ºåŸºäºç°æœ‰çŸ¥è¯†çš„å‚è€ƒæ€§å›ç­”ã€‚")

    # -------- å›ç­”ç»“æ„ --------
    lines.append("")
    lines.append("ã€å›ç­”ç»“æ„ï¼ˆå»ºè®®æ¨¡æ¿ï¼‰ã€‘")
    lines.append("1. **ç»“è®ºé€Ÿè§ˆ**ï¼ˆ2â€“4 å¥ï¼Œç›´æ¥å›ç­”é—®é¢˜ï¼‰")
    lines.append("2. **æ ¸å¿ƒçŸ¥è¯†ç‚¹/åŸç†**ï¼ˆç²¾ç‚¼å®šä¹‰ã€è¦ç‚¹åˆ—è¡¨ï¼‰")
    lines.append("3. **æ­¥éª¤ä¸ç¤ºä¾‹**ï¼ˆç»™å‡ºå¯æ‰§è¡Œæ­¥éª¤ï¼›æ¶‰åŠä»£ç æ—¶é™„**æœ€å°å¯è¿è¡Œç¤ºä¾‹**ä¸å…³é”®æ³¨é‡Šï¼‰")
    lines.append("4. **å¸¸è§é”™è¯¯ä¸æ’æŸ¥**ï¼ˆå‘ç‚¹ã€å¤æ‚åº¦/å®‰å…¨æ€§/è¾¹ç•Œæ¡ä»¶ï¼‰")
    lines.append("5. **å»¶ä¼¸ä¸å®è·µ**ï¼ˆè¯¾ç¨‹/å®è®­å¦‚ä½•è½åœ°ã€è¯„ä»·è¦ç‚¹ã€ä¸å…¶ä»–çŸ¥è¯†çš„è¡”æ¥ï¼‰")
    if HAS_KB or HAS_WEB:
        lines.append("6. **æ¥æºä¸è¿›ä¸€æ­¥é˜…è¯»**ï¼ˆå¼•ç”¨ KB ä¸ç½‘é¡µå‡ºå¤„ï¼‰")

    # -------- ä»£ç ä¸ç¤ºä¾‹é£æ ¼ --------
    lines.append("")
    lines.append("ã€ä»£ç ä¸ç¤ºä¾‹é£æ ¼ã€‘")
    lines.append("- ç¤ºä¾‹è¦**å¯è¿è¡Œã€å¯å¤ç°ã€æœ€å°åŒ–**ï¼›å¿…è¦æ—¶æä¾›è¾“å…¥è¾“å‡ºæ ·ä¾‹ä¸æµ‹è¯•ç”¨ä¾‹ã€‚")
    lines.append("- æŒ‡æ˜å¤æ‚åº¦ï¼ˆæ—¶é—´/ç©ºé—´ï¼‰ä¸é€‚ç”¨åœºæ™¯ï¼›æ¶‰åŠå‘½ä»¤è¡Œ/è„šæœ¬æ“ä½œï¼Œæ ‡æ³¨ç³»ç»Ÿä¸ç‰ˆæœ¬å‰æã€‚")
    lines.append("- æ¶‰åŠæ•°æ®åº“/ç½‘ç»œ/ç³»ç»Ÿæ“ä½œæ—¶ï¼Œç»™å‡º**å®‰å…¨æ³¨æ„**ä¸**å›æ»š/æ¢å¤**æ–¹æ¡ˆã€‚")
    lines.append("- æ•™å­¦éœ€è¦æ—¶å¯æä¾›å¤šè¯­è¨€å¯¹ç…§ï¼ˆå¦‚ C/Python/SQL/JavaScriptï¼‰ï¼Œä½†ä¿æŒç®€æ´ã€‚")

    # -------- æ•™å­¦ä¸å­¦æœ¯è§„èŒƒ --------
    lines.append("")
    lines.append("ã€æ•™å­¦ä¸å­¦æœ¯è§„èŒƒã€‘")
    lines.append("- é¿å…ç›´æ¥ç»™å‡ºæ•´ä»½å¯æŠ„è¢­çš„ä½œä¸š/è€ƒè¯•ç­”æ¡ˆï¼›å¦‚ç”¨æˆ·æ˜ç¡®è¦æ±‚å®Œæ•´è§£æ³•ï¼Œåº”**å…ˆç»™æ€è·¯ä¸å…³é”®æ­¥éª¤**ï¼Œå†ç»™å¯è¿è¡Œå‚è€ƒå®ç°ï¼Œå¹¶æé†’**ç‹¬ç«‹æ€è€ƒä¸å­¦æœ¯è¯šä¿¡**ã€‚")
    lines.append("- ä¸ç¼–é€ ä¸å¯éªŒè¯çš„èµ„æ–™ï¼›ä¸ç¡®å®šå°±æ˜ç¡®è¯´æ˜å¹¶ç»™å‡ºæŸ¥è¯è·¯å¾„ã€‚")
    lines.append("- æ¶‰åŠæ½œåœ¨é£é™©çš„å†…å®¹ï¼ˆå¦‚æ¸—é€æµ‹è¯•ã€ç ´åæ€§è„šæœ¬ï¼‰åº”ç»™å‡º**åˆæ³•åˆè§„ä¸è¾¹ç•Œ**æç¤ºï¼Œä»…åœ¨**æ•™å­¦ä¸æˆæƒç¯å¢ƒ**ä¸­æ¼”ç¤ºã€‚")

    # -------- è¯­æ°”ä¸æ ¼å¼ --------
    lines.append("")
    lines.append("ã€è¯­æ°”ä¸æ ¼å¼ã€‘")
    lines.append("- ä¸“ä¸šã€å‹å¥½ã€å±‚æ¬¡æ¸…æ™°ï¼›ç”¨æ ‡é¢˜/åˆ—è¡¨/ä»£ç å—ç»„ç»‡å†…å®¹ã€‚")
    lines.append("- æœ¯è¯­é¦–æ¬¡å‡ºç°æ—¶å¯åŠ **ç²—ä½“**æˆ–æ‹¬å·è§£é‡Šã€‚")
    lines.append("- é‡è¦ç»“è®ºä¸æ³¨æ„äº‹é¡¹å¯ä½¿ç”¨â€œğŸ‘‰ æç¤ºâ€æˆ–â€œâš  æ³¨æ„â€é«˜äº®ã€‚")

    # -------- ç¤ºä¾‹å¼•ç”¨æ ¼å¼ï¼ˆæŒ‰å®é™…å¯ç”¨æƒ…å†µï¼‰ --------
    lines.append("")
    lines.append("ã€ç¤ºä¾‹å¼•ç”¨æ ¼å¼ã€‘")
    if HAS_KB:
        lines.append("- KB å¼•ç”¨ç¤ºä¾‹ï¼šã€”KBï½œæ•°æ®åº“æŠ€æœ¯ä¸åº”ç”¨ï½œCSK-DB-CH4ã€•")
    if HAS_WEB:
        lines.append("- ç½‘é¡µå¼•ç”¨ç¤ºä¾‹ï¼šã€”PostgreSQL 16 Docsï½œhttps://www.postgresql.org/docs/16/index.htmlã€•")
    if (not HAS_KB) and (not HAS_WEB):
        lines.append("- å½“å‰ç¯å¢ƒä¸‹æ—  KB ä¸ç½‘é¡µæ£€ç´¢ç¤ºä¾‹ï¼Œä½ å¯ä»¥çœç•¥å…·ä½“æ¥æºæ ‡æ³¨ï¼Œä½†éœ€æ˜ç¡®åŒºåˆ†â€œå·²æœ‰çŸ¥è¯†â€ä¸â€œçŒœæµ‹/æ¨æ–­â€ã€‚")

    lines.append("è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸Šè§„åˆ™å¼€å±•å¯¹è¯ã€æ£€ç´¢ä¸ç”Ÿæˆï¼ˆå¦‚æŸç±»å·¥å…·æœªå¯ç”¨ï¼Œåˆ™ä¸è¦å‡è£…ä½¿ç”¨è¯¥å·¥å…·ï¼‰ã€‚")

    # ========= æ–°å¢ï¼šå›¾ä¹¦é¦†åº§ä½é¢„çº¦ç³»ç»Ÿæ•°æ®åº“è®¾è®¡è¯•é¢˜æ ·ä¾‹ =========
    lines.append("")
    lines.append("# è¯•é¢˜å›ç­”æ ·ä¾‹")
    lines.append("## è¯•é¢˜ï¼šå¤§å­¦å›¾ä¹¦é¦†åº§ä½é¢„çº¦ç³»ç»Ÿæ•°æ®åº“è®¾è®¡")
    lines.append("")
    lines.append("**é—®é¢˜æè¿°**")
    lines.append("æŸå¤§å­¦å›¾ä¹¦é¦†éœ€è¦å¼€å‘ä¸€ä¸ªåº§ä½é¢„çº¦ç®¡ç†ç³»ç»Ÿï¼Œè¦æ±‚æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š")
    lines.append("")
    lines.append("1. å›¾ä¹¦é¦†æœ‰å¤šä¸ªæ¥¼å±‚ï¼Œæ¯ä¸ªæ¥¼å±‚æœ‰å¤šä¸ªåŒºåŸŸï¼ˆå¦‚è‡ªä¹ åŒºã€è®¨è®ºåŒºã€é™éŸ³åŒºï¼‰")
    lines.append("2. æ¯ä¸ªåŒºåŸŸæœ‰å¤šä¸ªåº§ä½ï¼Œåº§ä½æœ‰ä¸åŒç±»å‹ï¼ˆæ™®é€šåº§ä½ã€å¸¦ç”µè„‘åº§ä½ã€å°ç»„è®¨è®ºæ¡Œï¼‰")
    lines.append("3. å­¦ç”Ÿå¯ä»¥é¢„çº¦æœªæ¥7å¤©å†…çš„åº§ä½ï¼Œæ¯æ¬¡é¢„çº¦æ—¶é•¿ä¸º1-4å°æ—¶")
    lines.append("4. æ¯ä¸ªå­¦ç”Ÿæ¯å¤©æœ€å¤šå¯é¢„çº¦2ä¸ªæ—¶é—´æ®µ")
    lines.append("5. éœ€è¦è®°å½•å­¦ç”Ÿçš„é¢„çº¦ã€ç­¾åˆ°ã€ç­¾é€€æ—¶é—´ï¼ˆè¶…æ—¶15åˆ†é’Ÿæœªç­¾åˆ°è‡ªåŠ¨å–æ¶ˆé¢„çº¦ï¼‰")
    lines.append("6. ç³»ç»Ÿéœ€è¦æ”¯æŒåº§ä½çŠ¶æ€ç®¡ç†ï¼ˆå¯ç”¨ã€ç»´ä¿®ä¸­ã€å·²é¢„çº¦ã€ä½¿ç”¨ä¸­ï¼‰")
    lines.append("7. ä¸€ä¸ªå­¦ç”Ÿåœ¨åŒä¸€æ—¶é—´æ®µåªèƒ½é¢„çº¦ä¸€ä¸ªåº§ä½")
    lines.append("8. æ¯ä¸ªåº§ä½åœ¨åŒä¸€æ—¶é—´æ®µåªèƒ½è¢«ä¸€ä¸ªå­¦ç”Ÿé¢„çº¦")
    lines.append("")
    lines.append("è¯·è®¾è®¡è¯¥ç³»ç»Ÿçš„å…³ç³»å‹æ•°æ®åº“è¡¨ç»“æ„ï¼Œè‡³å°‘åŒ…å«ï¼š")
    lines.append("")
    lines.append("- åˆ—å‡ºæ‰€æœ‰å¿…è¦çš„è¡¨ï¼ˆè‡³å°‘6ä¸ªè¡¨ï¼‰")
    lines.append("- æ¯ä¸ªè¡¨çš„ä¸»é”®ã€å¤–é”®å’Œå…³é”®å­—æ®µ")
    lines.append("- ç®€è¦è¯´æ˜è¡¨ä¹‹é—´çš„å…³ç³»")
    lines.append("- ç”¨SQLè¯­å¥åˆ›å»ºåŒ…å«å…³é”®çº¦æŸçš„é¢„çº¦è¡¨")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## æ€ç»´é“¾æç¤ºæ ·ä¾‹")
    lines.append("")
    lines.append("### ç¬¬ä¸€æ­¥ï¼šç†è§£éœ€æ±‚ï¼Œæå–å®ä½“")
    lines.append("")
    lines.append("ä»é—®é¢˜æè¿°ä¸­è¯†åˆ«å‡ºæ ¸å¿ƒå®ä½“ï¼š")
    lines.append("")
    lines.append("1. **å­¦ç”Ÿ**ï¼ˆStudentï¼‰- ç³»ç»Ÿç”¨æˆ·")
    lines.append("2. **å›¾ä¹¦é¦†æ¥¼å±‚**ï¼ˆFloorï¼‰- ç‰©ç†ä½ç½®å±‚çº§")
    lines.append("3. **åŒºåŸŸ**ï¼ˆAreaï¼‰- åŠŸèƒ½åˆ†åŒºï¼ˆè‡ªä¹ åŒºã€è®¨è®ºåŒºç­‰ï¼‰")
    lines.append("4. **åº§ä½**ï¼ˆSeatï¼‰- å¯é¢„çº¦çš„æœ€å°å•ä½")
    lines.append("5. **é¢„çº¦è®°å½•**ï¼ˆReservationï¼‰- å­¦ç”Ÿä¸åº§ä½çš„é¢„çº¦å…³ç³»")
    lines.append("6. **é¢„çº¦æ—¶é—´æ®µ**ï¼ˆTimeSlotï¼‰- ç³»ç»Ÿæ”¯æŒçš„æ—¶é—´åˆ†æ®µ")
    lines.append("")
    lines.append("### ç¬¬äºŒæ­¥ï¼šåˆ†æå±æ€§ä¸å…³ç³»")
    lines.append("")
    lines.append("- æ¥¼å±‚ä¸åŒºåŸŸï¼šä¸€å¯¹å¤šï¼ˆä¸€ä¸ªæ¥¼å±‚æœ‰å¤šä¸ªåŒºåŸŸï¼‰")
    lines.append("- åŒºåŸŸä¸åº§ä½ï¼šä¸€å¯¹å¤šï¼ˆä¸€ä¸ªåŒºåŸŸæœ‰å¤šä¸ªåº§ä½ï¼‰")
    lines.append("- å­¦ç”Ÿä¸é¢„çº¦ï¼šä¸€å¯¹å¤šï¼ˆä¸€ä¸ªå­¦ç”Ÿå¯ä»¥æœ‰å¤šä¸ªé¢„çº¦è®°å½•ï¼‰")
    lines.append("- åº§ä½ä¸é¢„çº¦ï¼šä¸€å¯¹å¤šï¼ˆä¸€ä¸ªåº§ä½å¯ä»¥æœ‰å¤šä¸ªé¢„çº¦è®°å½•ï¼‰")
    lines.append("- æ—¶é—´æ®µä¸é¢„çº¦ï¼šä¸€å¯¹å¤šï¼ˆä¸€ä¸ªæ—¶é—´æ®µå¯ä»¥æœ‰å¤šä¸ªé¢„çº¦ï¼‰")
    lines.append("- é¢„çº¦è¡¨éœ€è¦åŒæ—¶å…³è”å­¦ç”Ÿã€åº§ä½å’Œæ—¶é—´æ®µ")
    lines.append("")
    lines.append("### ç¬¬ä¸‰æ­¥ï¼šè®¾è®¡è¡¨ç»“æ„")
    lines.append("")
    lines.append("**1. å­¦ç”Ÿè¡¨ï¼ˆstudentï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("student_id    (ä¸»é”®ï¼Œå­¦å·)")
    lines.append("name          (å§“å)")
    lines.append("phone         (è”ç³»æ–¹å¼ï¼Œå”¯ä¸€)")
    lines.append("email         (é‚®ç®±ï¼Œå”¯ä¸€)")
    lines.append("major         (ä¸“ä¸š)")
    lines.append("credit_score  (ä¿¡ç”¨åˆ†ï¼Œç”¨äºé™åˆ¶è¿çº¦ç”¨æˆ·)")
    lines.append("created_at    (æ³¨å†Œæ—¶é—´)")
    lines.append("```")
    lines.append("")
    lines.append("**2. æ¥¼å±‚è¡¨ï¼ˆfloorï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("floor_id      (ä¸»é”®)")
    lines.append("floor_number  (æ¥¼å±‚å·ï¼Œå¦‚1ã€2ã€3)")
    lines.append("description   (æ¥¼å±‚æè¿°)")
    lines.append("open_time     (å¼€æ”¾æ—¶é—´ï¼Œå¦‚'08:00:00')")
    lines.append("close_time    (å…³é—­æ—¶é—´ï¼Œå¦‚'22:00:00')")
    lines.append("```")
    lines.append("")
    lines.append("**3. åŒºåŸŸè¡¨ï¼ˆareaï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("area_id       (ä¸»é”®)")
    lines.append("floor_id      (å¤–é”®ï¼Œå¼•ç”¨floorè¡¨)")
    lines.append("area_name     (åŒºåŸŸåç§°ï¼Œå¦‚'é™éŸ³è‡ªä¹ åŒº')")
    lines.append("area_type     ('quiet', 'discussion', 'computer')")
    lines.append("max_capacity  (æœ€å¤§å®¹çº³äººæ•°)")
    lines.append("```")
    lines.append("")
    lines.append("**4. åº§ä½è¡¨ï¼ˆseatï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("seat_id       (ä¸»é”®)")
    lines.append("area_id       (å¤–é”®ï¼Œå¼•ç”¨areaè¡¨)")
    lines.append("seat_number   (åº§ä½ç¼–å·ï¼Œå¦‚'A01')")
    lines.append("seat_type     ('normal', 'computer', 'group')")
    lines.append("status        ('available', 'reserved', 'in_use', 'maintenance')")
    lines.append("has_power     (æ˜¯å¦æœ‰ç”µæºï¼Œå¸ƒå°”)")
    lines.append("has_light     (æ˜¯å¦æœ‰å°ç¯ï¼Œå¸ƒå°”)")
    lines.append("```")
    lines.append("")
    lines.append("**5. æ—¶é—´æ®µè¡¨ï¼ˆtime_slotï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("slot_id       (ä¸»é”®)")
    lines.append("date          (æ—¥æœŸï¼ŒYYYY-MM-DD)")
    lines.append("start_time    (å¼€å§‹æ—¶é—´ï¼Œå¦‚'09:00:00')")
    lines.append("end_time      (ç»“æŸæ—¶é—´ï¼Œå¦‚'12:00:00')")
    lines.append("duration      (æ—¶é•¿ï¼Œå•ä½ï¼šåˆ†é’Ÿ)")
    lines.append("```")
    lines.append("")
    lines.append("**6. é¢„çº¦è®°å½•è¡¨ï¼ˆreservationï¼‰**")
    lines.append("")
    lines.append("```")
    lines.append("reservation_id (ä¸»é”®)")
    lines.append("student_id     (å¤–é”®)")
    lines.append("seat_id        (å¤–é”®)")
    lines.append("slot_id        (å¤–é”®)")
    lines.append("reserved_at    (é¢„çº¦æ—¶é—´)")
    lines.append("checkin_time   (ç­¾åˆ°æ—¶é—´ï¼Œå¯ç©º)")
    lines.append("checkout_time  (ç­¾é€€æ—¶é—´ï¼Œå¯ç©º)")
    lines.append("status         ('reserved', 'checked_in', 'completed', 'cancelled', 'expired')")
    lines.append("cancelled_at   (å–æ¶ˆæ—¶é—´ï¼Œå¯ç©º)")
    lines.append("```")
    lines.append("")
    lines.append("### ç¬¬å››æ­¥ï¼šè€ƒè™‘çº¦æŸä¸ä¼˜åŒ–")
    lines.append("")
    lines.append("- å­¦ç”Ÿè¡¨ï¼š`phone`å’Œ`email`å­—æ®µéœ€å”¯ä¸€çº¦æŸ")
    lines.append("- åº§ä½è¡¨ï¼š`(area_id, seat_number)`ç»„åˆåº”å”¯ä¸€ï¼Œé¿å…é‡å¤ç¼–å·")
    lines.append("- æ—¶é—´æ®µè¡¨ï¼š`(date, start_time, end_time)`ç»„åˆåº”å”¯ä¸€")
    lines.append("- é¢„çº¦è¡¨ï¼š`(student_id, slot_id)`ç»„åˆåº”å”¯ä¸€ï¼Œé˜²æ­¢åŒä¸€å­¦ç”Ÿé‡å¤é¢„çº¦")
    lines.append("- é¢„çº¦è¡¨ï¼š`(seat_id, slot_id)`ç»„åˆåº”å”¯ä¸€ï¼Œé˜²æ­¢åº§ä½è¢«é‡å¤é¢„çº¦")
    lines.append("- æ·»åŠ ç´¢å¼•ï¼š`reservation(student_id, status)`ï¼Œ`reservation(seat_id, slot_id)`")
    lines.append("- è€ƒè™‘è§¦å‘å™¨ï¼šè‡ªåŠ¨æ›´æ–°åº§ä½çŠ¶æ€ï¼Œè¶…æ—¶è‡ªåŠ¨å–æ¶ˆé¢„çº¦")
    lines.append("")
    lines.append("### ç¬¬äº”æ­¥ï¼šç¼–å†™å…³é”®SQL")
    lines.append("")
    lines.append("```sql")
    lines.append("-- åˆ›å»ºé¢„çº¦è®°å½•è¡¨ï¼ŒåŒ…å«å¤šä¸ªçº¦æŸ")
    lines.append("CREATE TABLE reservation (")
    lines.append("    reservation_id INT PRIMARY KEY AUTO_INCREMENT,")
    lines.append("    student_id VARCHAR(20) NOT NULL,")
    lines.append("    seat_id INT NOT NULL,")
    lines.append("    slot_id INT NOT NULL,")
    lines.append("    reserved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,")
    lines.append("    checkin_time TIMESTAMP NULL,")
    lines.append("    checkout_time TIMESTAMP NULL,")
    lines.append("    status ENUM('reserved', 'checked_in', 'completed', 'cancelled', 'expired') DEFAULT 'reserved',")
    lines.append("    cancelled_at TIMESTAMP NULL,")
    lines.append("    -- å¤–é”®çº¦æŸ")
    lines.append("    FOREIGN KEY (student_id) REFERENCES student(student_id) ON DELETE CASCADE,")
    lines.append("    FOREIGN KEY (seat_id) REFERENCES seat(seat_id) ON DELETE CASCADE,")
    lines.append("    FOREIGN KEY (slot_id) REFERENCES time_slot(slot_id) ON DELETE CASCADE,")
    lines.append("    -- é˜²æ­¢åŒä¸€å­¦ç”Ÿåœ¨åŒä¸€æ—¶é—´æ®µé‡å¤é¢„çº¦")
    lines.append("    UNIQUE KEY unique_student_slot (student_id, slot_id),")
    lines.append("    -- é˜²æ­¢åŒä¸€åº§ä½åœ¨åŒä¸€æ—¶é—´æ®µè¢«é‡å¤é¢„çº¦")
    lines.append("    UNIQUE KEY unique_seat_slot (seat_id, slot_id),")
    lines.append("    -- ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºç´¢å¼•")
    lines.append("    INDEX idx_student_status (student_id, status),")
    lines.append("    INDEX idx_seat_status (seat_id, status),")
    lines.append("    INDEX idx_reservation_time (reserved_at),")
    lines.append("    INDEX idx_checkin_status (checkin_time, status)")
    lines.append(");")
    lines.append("")
    lines.append("-- ç¤ºä¾‹ï¼šåˆ›å»ºè§¦å‘å™¨ï¼Œé¢„çº¦æ—¶è‡ªåŠ¨æ›´æ–°åº§ä½çŠ¶æ€")
    lines.append("DELIMITER $$")
    lines.append("CREATE TRIGGER update_seat_status_on_reserve")
    lines.append("AFTER INSERT ON reservation")
    lines.append("FOR EACH ROW")
    lines.append("BEGIN")
    lines.append("    UPDATE seat SET status = 'reserved' WHERE seat_id = NEW.seat_id;")
    lines.append("END$$")
    lines.append("DELIMITER ;")
    lines.append("```")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## æ€ç»´é“¾æ€»ç»“")
    lines.append("")
    lines.append("1. **éœ€æ±‚åˆ†æ â†’ 2. å®ä½“æå– â†’ 3. å…³ç³»å»ºæ¨¡ â†’ 4. å±æ€§è®¾è®¡ â†’ 5. çº¦æŸä¼˜åŒ– â†’ 6. SQLå®ç°**")
    lines.append("è¿™ç§ç»“æ„åŒ–æ€ç»´é“¾é€‚ç”¨äºæ•°æ®åº“è®¾è®¡ç±»é—®é¢˜ï¼š")
    lines.append("- **éœ€æ±‚åˆ†æ**ï¼šæ˜ç¡®ä¸šåŠ¡è§„åˆ™å’Œçº¦æŸæ¡ä»¶")
    lines.append("- **å®ä½“æå–**ï¼šè¯†åˆ«ç³»ç»Ÿä¸­çš„æ ¸å¿ƒå¯¹è±¡")
    lines.append("- **å…³ç³»å»ºæ¨¡**ï¼šç¡®å®šå®ä½“é—´çš„å…³ç³»ï¼ˆ1:1, 1:n, n:mï¼‰")
    lines.append("- **å±æ€§è®¾è®¡**ï¼šä¸ºæ¯ä¸ªå®ä½“è®¾è®¡åˆé€‚çš„å­—æ®µ")
    lines.append("- **çº¦æŸä¼˜åŒ–**ï¼šè€ƒè™‘æ•°æ®å®Œæ•´æ€§ã€æ€§èƒ½ä¼˜åŒ–")
    lines.append("- **SQLå®ç°**ï¼šå°†è®¾è®¡è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„DDLè¯­å¥")
    lines.append("")


    return "\n".join(lines)


SYSTEM = build_system_prompt()

prompt = ChatPromptTemplate.from_messages([
    ("system", SYSTEM),
    MessagesPlaceholder("chat_history"),
    ("user", "{input}"),
    MessagesPlaceholder("agent_scratchpad"),
])


class DeepSeekThinkingAgentExecutor(AgentExecutor):
    """é€‚é… DeepSeek æ€è€ƒæ¨¡å¼çš„ Agent Executor"""

    def _construct_scratchpad(
            self, intermediate_steps: List[Tuple[AgentAction, str]]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºé€‚åˆ DeepSeek æ€è€ƒæ¨¡å¼çš„ agent_scratchpad"""
        thoughts = []
        for action, observation in intermediate_steps:
            # æ·»åŠ æ€è€ƒå†…å®¹
            thoughts.append({
                "role": "assistant",
                "content": action.log,
                "reasoning_content": action.log  # DeepSeek éœ€è¦çš„å­—æ®µ
            })
            # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ
            thoughts.append({
                "role": "tool",
                "content": observation,
                "tool_call_id": getattr(action, 'tool_call_id', 'call_1')
            })
        return thoughts

# ========= Agent / Executor =========
if tools:
    print(f"[debug] å·²åŠ è½½çš„å·¥å…·åˆ—è¡¨:")
    for i, tool in enumerate(tools):
        print(f"  [{i}] {tool.name}: {getattr(tool, 'description', 'æ— æè¿°')}")

    # æœ‰å·¥å…·ï¼šæ„å»º Tool Agent
    agent = create_openai_tools_agent(llm, tools, prompt)
    if _LLM_PROVIDER == "deepseek" and "deepseek-reasoner" in _LLM_MODEL.lower():
        executor = DeepSeekThinkingAgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=5,  # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°
        )
    else:
        executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=5,  # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°
        )
else:
    # æ²¡æœ‰ä»»ä½•å·¥å…·ï¼šé€€åŒ–ä¸ºç®€å• LLM é“¾ï¼Œä½†å¯¹å¤–ä»æš´éœ² executor.invoke æ¥å£
    class SimpleExecutor:
        def __init__(self, llm_, prompt_):
            self.llm = llm_
            self.prompt = prompt_

        def invoke(self, inputs: dict):
            # inputs æœŸæœ›åŒ…å« "input" å’Œ "chat_history"
            _in = dict(inputs or {})
            _in.setdefault("chat_history", [])
            _in.setdefault("agent_scratchpad", [])
            messages = self.prompt.format_messages(**_in)
            resp = self.llm.invoke(messages)
            text = getattr(resp, "content", str(resp))
            return {"output": text}

    executor = SimpleExecutor(llm, prompt)


# ========= äº¤äº’å…¥å£ =========
if __name__ == "__main__":
    print(f"LangChain Agent Readyï¼provider={_LLM_PROVIDER} model={_LLM_MODEL}" + (f" base_url={_LLM_BASE_URL}" if _LLM_BASE_URL else "") + " (Ctrl+C é€€å‡º)")
    chat_history = []
    try:
        while True:
            q = input("\nYou> ").strip()
            q = clean_text(q)
            if not q:
                continue
            out = executor.invoke({"input": q, "chat_history": chat_history})
            print("\nRAEA>", out["output"])

            # åˆ†æä¸­é—´æ­¥éª¤
            if "intermediate_steps" in out:
                print(f"\n{'=' * 60}")
                print("ğŸ“Š å·¥å…·ä½¿ç”¨åˆ†æ:")
                print('=' * 60)

                steps = out["intermediate_steps"]
                print(f"æ€»å…±æ‰§è¡Œäº† {len(steps)} ä¸ªå·¥å…·æ­¥éª¤:")

                for i, step in enumerate(steps, 1):
                    tool_name = step[0].tool if hasattr(step[0], 'tool') else str(step[0])
                    tool_input = step[0].tool_input if hasattr(step[0], 'tool_input') else str(step[0])
                    tool_output = step[1][:200] + "..." if len(str(step[1])) > 200 else step[1]

                    print(f"\næ­¥éª¤ {i}:")
                    print(f"  ğŸ› ï¸  å·¥å…·: {tool_name}")
                    print(f"  ğŸ“ è¾“å…¥: {tool_input}")
                    print(f"  ğŸ“„ è¾“å‡º: {tool_output}")

                # ç»Ÿè®¡å·¥å…·ä½¿ç”¨é¢‘ç‡
                tool_counts = {}
                for step in steps:
                    tool_name = step[0].tool if hasattr(step[0], 'tool') else str(step[0])
                    tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1

                print(f"\nğŸ“ˆ å·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
                for tool, count in tool_counts.items():
                    print(f"  {tool}: {count}æ¬¡")

            chat_history.extend([("human", q), ("ai", out["output"])])
    except KeyboardInterrupt:
        print("\nBye")